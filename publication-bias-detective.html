<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Publication Bias Detective: The Evidence That Never Saw Light</title>
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Cormorant+Garamond:ital,wght@0,400;0,600;0,700;1,400;1,600&family=Source+Sans+Pro:wght@300;400;600;700&display=swap" rel="stylesheet">
  <script src="https://cdn.plot.ly/plotly-2.27.0.min.js"></script>
  <script>
if (typeof Plotly === 'undefined') {
  document.addEventListener('DOMContentLoaded', function() {
    document.querySelectorAll('[id*="plot"], [id*="chart"], .plotly-graph-div, .js-plotly-plot').forEach(function(el) {
      el.innerHTML = '<div style="padding:2rem;text-align:center;background:#2a2a4a;border:1px dashed #D4AF37;border-radius:8px;color:#FAF8F5;margin:1rem 0;"><p style="font-size:1.1rem;margin-bottom:0.5rem;">Interactive chart unavailable offline</p><p style="font-size:0.85rem;opacity:0.7;">Connect to the internet to load interactive Plotly.js visualizations</p></div>';
    });
  });
}
</script>
  <style>
    :root {
      --navy: #1E2761;
      --deep-navy: #141B3D;
      --gold: #D4AF37;
      --cream: #FAF8F5;
      --red: #dc2626;
      --green: #16a34a;
      --purple: #7c3aed;
      --amber: #f59e0b;
      --teal: #0d9488;
      --detective-blue: #1e3a5f;
      --evidence-red: #991b1b;
    }
    * { margin: 0; padding: 0; box-sizing: border-box; }
    html, body {
      height: 100%;
      font-family: 'Source Sans Pro', sans-serif;
      background: var(--deep-navy);
      color: var(--cream);
    }
    .course-container { display: flex; height: 100vh; overflow: hidden; }

    /* Sidebar */
    .sidebar {
      width: 320px;
      background: linear-gradient(180deg, var(--detective-blue) 0%, var(--deep-navy) 100%);
      border-right: 1px solid rgba(212,175,55,0.2);
      display: flex; flex-direction: column; flex-shrink: 0;
    }
    .sidebar-header {
      padding: 1.5rem;
      border-bottom: 1px solid rgba(212,175,55,0.2);
      background: rgba(0,0,0,0.2);
    }
    .sidebar-header h1 {
      font-family: 'Cormorant Garamond', Georgia, serif;
      font-size: 1.3rem; font-weight: 700; color: var(--gold); margin-bottom: 0.25rem;
    }
    .sidebar-header p { font-size: 0.75rem; color: rgba(255,255,255,0.6); }
    .sidebar-badge {
      display: inline-block; padding: 0.25rem 0.5rem;
      background: linear-gradient(135deg, var(--evidence-red), #b91c1c);
      border-radius: 4px; font-size: 0.65rem; font-weight: 700;
      text-transform: uppercase; letter-spacing: 0.05em; margin-top: 0.5rem;
    }
    .module-list { flex: 1; overflow-y: auto; padding: 1rem 0; }
    .module-item {
      display: flex; align-items: center; gap: 0.75rem;
      padding: 0.65rem 1.25rem; cursor: pointer; transition: all 0.2s;
      border-left: 3px solid transparent;
    }
    .module-item:hover { background: rgba(212,175,55,0.1); }
    .module-item.active { background: rgba(212,175,55,0.15); border-left-color: var(--gold); }
    .module-item.completed .module-number { background: var(--green); color: white; }
    .module-number {
      width: 26px; height: 26px; border-radius: 50%;
      background: rgba(255,255,255,0.1); display: flex;
      align-items: center; justify-content: center;
      font-size: 0.75rem; font-weight: 600; flex-shrink: 0;
    }
    .module-info { flex: 1; min-width: 0; }
    .module-title { font-size: 0.85rem; font-weight: 600; white-space: nowrap; overflow: hidden; text-overflow: ellipsis; }
    .module-subtitle { font-size: 0.7rem; color: rgba(255,255,255,0.5); }
    .sidebar-footer { padding: 1rem; border-top: 1px solid rgba(212,175,55,0.2); }
    .progress-bar-container { margin-top: 0.75rem; }
    .progress-label { font-size: 0.75rem; color: rgba(255,255,255,0.6); margin-bottom: 0.25rem; }
    .progress-bar { height: 6px; background: rgba(255,255,255,0.1); border-radius: 3px; overflow: hidden; }
    .progress-fill { height: 100%; background: linear-gradient(90deg, var(--evidence-red), var(--gold)); border-radius: 3px; transition: width 0.3s; }

    /* Main Content */
    .main-content { flex: 1; display: flex; flex-direction: column; overflow: hidden; }
    .top-bar {
      display: flex; justify-content: space-between; align-items: center;
      padding: 1rem 2rem; background: rgba(0,0,0,0.3);
      border-bottom: 1px solid rgba(212,175,55,0.15);
    }
    .module-indicator { font-size: 0.9rem; color: rgba(255,255,255,0.7); }
    .slide-counter { font-size: 0.8rem; color: var(--gold); margin-left: 1rem; }
    .top-bar-actions { display: flex; gap: 0.75rem; }
    .top-bar-btn {
      padding: 0.5rem 1rem; background: rgba(255,255,255,0.1);
      border: 1px solid rgba(255,255,255,0.2); border-radius: 6px;
      color: var(--cream); font-size: 0.85rem; cursor: pointer; transition: all 0.2s;
    }
    .top-bar-btn:hover { background: rgba(255,255,255,0.15); }
    .top-bar-btn:disabled { opacity: 0.5; cursor: not-allowed; }
    .slide-container { flex: 1; overflow-y: auto; padding: 2rem; }
    .slide { display: none; max-width: 1000px; margin: 0 auto; }
    .slide.active { display: block; }

    /* Storytelling Styles */
    .rhetoric-question {
      font-family: 'Cormorant Garamond', Georgia, serif;
      font-size: 1.8rem; font-style: italic; color: var(--gold);
      text-align: center; padding: 3rem 2rem; line-height: 1.5;
      border-left: 4px solid var(--evidence-red);
      background: linear-gradient(135deg, rgba(153,27,27,0.1), transparent);
      margin: 1rem 0;
    }
    .case-file {
      background: linear-gradient(135deg, rgba(30,58,95,0.4), rgba(15,15,26,0.6));
      border: 1px solid rgba(212,175,55,0.3);
      border-radius: 12px; padding: 2rem; margin: 1.5rem 0;
    }
    .case-file-header {
      display: flex; align-items: center; gap: 1rem; margin-bottom: 1.5rem;
      padding-bottom: 1rem; border-bottom: 1px solid rgba(212,175,55,0.2);
    }
    .case-number {
      background: var(--evidence-red); color: white;
      padding: 0.5rem 1rem; border-radius: 4px;
      font-weight: 700; font-size: 0.8rem; text-transform: uppercase;
    }
    .case-title { font-size: 1.3rem; font-weight: 700; color: var(--gold); }
    .case-source { font-size: 0.8rem; color: rgba(255,255,255,0.5); margin-top: 0.25rem; }
    .evidence-timeline { margin: 1.5rem 0; }
    .timeline-event {
      display: flex; gap: 1rem; padding: 1rem 0;
      border-left: 2px solid rgba(212,175,55,0.3); margin-left: 1rem; padding-left: 1.5rem;
      position: relative;
    }
    .timeline-event::before {
      content: ''; position: absolute; left: -6px; top: 1.2rem;
      width: 10px; height: 10px; border-radius: 50%;
      background: var(--gold); border: 2px solid var(--deep-navy);
    }
    .timeline-event.buried::before { background: var(--evidence-red); }
    .timeline-event.revealed::before { background: var(--green); }
    .timeline-year {
      font-weight: 700; color: var(--gold); min-width: 80px;
      font-family: 'Cormorant Garamond', serif; font-size: 1.1rem;
    }
    .timeline-text { color: rgba(255,255,255,0.85); line-height: 1.6; }

    .evidence-box {
      background: rgba(153,27,27,0.15); border: 1px solid rgba(153,27,27,0.4);
      border-radius: 8px; padding: 1.5rem; margin: 1rem 0;
    }
    .evidence-box.found {
      background: rgba(22,163,74,0.15); border-color: rgba(22,163,74,0.4);
    }
    .evidence-header {
      display: flex; align-items: center; gap: 0.75rem;
      font-weight: 700; margin-bottom: 1rem; font-size: 1.1rem;
    }
    .evidence-icon { font-size: 1.5rem; }

    .statistic-card {
      background: linear-gradient(135deg, rgba(124,58,237,0.2), rgba(124,58,237,0.05));
      border: 1px solid rgba(124,58,237,0.3);
      border-radius: 12px; padding: 1.5rem; text-align: center; margin: 1rem 0;
    }
    .statistic-value {
      font-size: 3rem; font-weight: 700; color: var(--gold);
      font-family: 'Cormorant Garamond', serif;
    }
    .statistic-label { font-size: 0.9rem; color: rgba(255,255,255,0.7); margin-top: 0.5rem; }
    .statistic-context { font-size: 0.8rem; color: var(--evidence-red); margin-top: 0.5rem; font-weight: 600; }

    /* Tool Panel */
    .tool-panel {
      background: linear-gradient(135deg, rgba(13,148,136,0.1), rgba(13,148,136,0.02));
      border: 1px solid rgba(13,148,136,0.3);
      border-radius: 12px; padding: 1.5rem; margin: 1.5rem 0;
    }
    .tool-header {
      display: flex; align-items: center; gap: 0.75rem;
      margin-bottom: 1rem; padding-bottom: 0.75rem;
      border-bottom: 1px solid rgba(13,148,136,0.2);
    }
    .tool-icon { font-size: 1.5rem; }
    .tool-title { font-size: 1.1rem; font-weight: 700; color: var(--teal); }
    .tool-description { font-size: 0.85rem; color: rgba(255,255,255,0.6); margin-bottom: 1rem; }
    .tool-controls {
      display: flex; flex-wrap: wrap; gap: 1rem; margin-bottom: 1rem;
      padding: 1rem; background: rgba(0,0,0,0.2); border-radius: 8px;
    }
    .tool-control { display: flex; flex-direction: column; gap: 0.25rem; }
    .tool-control label { font-size: 0.8rem; color: rgba(255,255,255,0.6); }
    .tool-control input, .tool-control select {
      padding: 0.5rem; border-radius: 4px; border: 1px solid rgba(255,255,255,0.2);
      background: rgba(255,255,255,0.1); color: var(--cream); font-size: 0.9rem;
    }
    .plot-area {
      background: rgba(0,0,0,0.3); border-radius: 8px;
      min-height: 400px; margin: 1rem 0;
    }

    /* Decision Tree */
    .decision-tree {
      background: linear-gradient(135deg, rgba(245,158,11,0.1), rgba(245,158,11,0.02));
      border: 1px solid rgba(245,158,11,0.3);
      border-radius: 12px; padding: 1.5rem; margin: 1.5rem 0;
    }
    .decision-title {
      font-size: 1.2rem; font-weight: 700; color: var(--amber); margin-bottom: 0.5rem;
    }
    .decision-situation {
      font-size: 0.95rem; color: rgba(255,255,255,0.8);
      padding: 1rem; background: rgba(0,0,0,0.2); border-radius: 8px;
      margin-bottom: 1.5rem; line-height: 1.6;
    }
    .decision-node { margin: 1rem 0; }
    .decision-question {
      font-weight: 600; color: var(--cream); margin-bottom: 1rem;
      padding: 1rem; background: rgba(245,158,11,0.1); border-radius: 8px;
    }
    .decision-branches { display: flex; flex-direction: column; gap: 0.5rem; }
    .decision-branch {
      width: 100%; text-align: left; font-family: inherit; font-size: inherit;
      color: var(--cream); padding: 1rem; background: rgba(255,255,255,0.05);
      border: 1px solid rgba(255,255,255,0.1); border-radius: 8px;
      cursor: pointer; transition: all 0.2s;
    }
    .decision-branch:hover {
      background: rgba(255,255,255,0.1); border-color: var(--gold);
    }
    .decision-branch:focus {
      outline: 3px solid var(--gold); outline-offset: 2px;
    }
    .decision-outcome {
      padding: 1.5rem; border-radius: 8px; margin-top: 1rem;
    }
    .decision-outcome.good {
      background: rgba(22,163,74,0.15); border: 1px solid rgba(22,163,74,0.4);
    }
    .decision-outcome.bad {
      background: rgba(220,38,38,0.15); border: 1px solid rgba(220,38,38,0.4);
    }
    .decision-outcome.neutral {
      background: rgba(245,158,11,0.15); border: 1px solid rgba(245,158,11,0.4);
    }
    .outcome-title { font-weight: 700; font-size: 1.1rem; margin-bottom: 0.75rem; }
    .outcome-text { line-height: 1.6; margin-bottom: 0.75rem; }
    .outcome-case { font-size: 0.85rem; color: rgba(255,255,255,0.6); font-style: italic; }

    /* Method Box */
    .method-box {
      background: rgba(255,255,255,0.03); border: 1px solid rgba(255,255,255,0.1);
      border-radius: 8px; padding: 1.5rem; margin: 1rem 0;
    }
    .method-box h3 { color: var(--gold); margin-bottom: 0.75rem; }
    .method-box ul { padding-left: 1.5rem; }
    .method-box li { margin: 0.5rem 0; line-height: 1.5; }

    /* Quiz */
    .quiz-container { margin: 1.5rem 0; }
    .quiz-question {
      font-size: 1.1rem; font-weight: 600; margin-bottom: 1.5rem;
      padding: 1rem; background: rgba(124,58,237,0.1); border-radius: 8px;
    }
    .quiz-options { display: flex; flex-direction: column; gap: 0.75rem; }
    .quiz-option {
      padding: 1rem; background: rgba(255,255,255,0.05);
      border: 1px solid rgba(255,255,255,0.1); border-radius: 8px;
      cursor: pointer; transition: all 0.2s;
    }
    .quiz-option:hover { background: rgba(255,255,255,0.1); }
    .quiz-option.correct { background: rgba(22,163,74,0.2); border-color: var(--green); }
    .quiz-option.incorrect { background: rgba(220,38,38,0.2); border-color: var(--red); }
    .quiz-explanation {
      margin-top: 1rem; padding: 1rem; background: rgba(124,58,237,0.1);
      border-radius: 8px; display: none;
    }
    .quiz-explanation.visible { display: block; }

    /* Slide Title */
    .slide-title {
      font-family: 'Cormorant Garamond', Georgia, serif;
      font-size: 2rem; color: var(--gold); margin-bottom: 1.5rem;
      border-bottom: 2px solid rgba(212,175,55,0.3); padding-bottom: 0.75rem;
    }

    /* Principle Display */
    .principle-display {
      text-align: center; padding: 3rem;
      background: linear-gradient(135deg, rgba(212,175,55,0.1), transparent);
      border-radius: 12px; margin: 1rem 0;
    }
    .principle-number {
      font-size: 4rem; font-weight: 700; color: var(--gold); opacity: 0.3;
      font-family: 'Cormorant Garamond', serif;
    }
    .principle-text {
      font-family: 'Cormorant Garamond', Georgia, serif;
      font-size: 1.8rem; font-style: italic; color: var(--cream);
      max-width: 700px; margin: 0 auto; line-height: 1.5;
    }

    /* Cycle Return */
    .cycle-return {
      background: linear-gradient(135deg, rgba(212,175,55,0.1), transparent);
      border-left: 4px solid var(--gold);
      padding: 1.5rem; margin: 1.5rem 0; border-radius: 0 8px 8px 0;
    }
    .cycle-return .principle-recall {
      font-family: 'Cormorant Garamond', serif;
      font-size: 1.2rem; font-style: italic; color: var(--gold);
    }

    /* Clinical Guide */
    .clinical-guide {
      background: rgba(13,148,136,0.1); border: 1px solid rgba(13,148,136,0.3);
      border-radius: 12px; padding: 1.5rem; margin: 1.5rem 0;
    }
    .clinical-guide h3 { color: var(--teal); margin-bottom: 1rem; }
    .clinical-guide ul { padding-left: 1.5rem; }
    .clinical-guide li { margin: 0.75rem 0; line-height: 1.5; }

    /* Glossary Overlay */
    .glossary-overlay {
      position: fixed; top: 0; left: 0; right: 0; bottom: 0;
      background: rgba(0,0,0,0.9); z-index: 1000;
      display: none; justify-content: center; align-items: center;
    }
    .glossary-overlay.open { display: flex; }
    .glossary-panel {
      background: var(--navy); border: 1px solid rgba(212,175,55,0.3);
      border-radius: 12px; width: 90%; max-width: 600px; max-height: 80vh;
      overflow: hidden; display: flex; flex-direction: column;
    }
    .glossary-header {
      padding: 1rem 1.5rem; border-bottom: 1px solid rgba(212,175,55,0.2);
      display: flex; justify-content: space-between; align-items: center;
    }
    .glossary-close {
      background: none; border: none; color: var(--cream);
      font-size: 1.5rem; cursor: pointer;
    }
    .glossary-search {
      padding: 0.75rem 1rem; margin: 1rem;
      background: rgba(255,255,255,0.1); border: 1px solid rgba(255,255,255,0.2);
      border-radius: 8px; color: var(--cream); font-size: 1rem; width: calc(100% - 2rem);
    }
    .glossary-content { flex: 1; overflow-y: auto; padding: 1rem; }
    .glossary-term { padding: 1rem; border-bottom: 1px solid rgba(255,255,255,0.1); }

    /* Contrast Box - Two-path comparison style */
    .contrast-box {
      display: grid;
      grid-template-columns: 1fr 1fr;
      gap: 0;
      margin: 1.5rem 0;
      border-radius: 12px;
      overflow: hidden;
    }
    .contrast-side {
      padding: 1.5rem;
    }
    .contrast-side.dark {
      background: linear-gradient(135deg, rgba(153,27,27,0.3), rgba(153,27,27,0.1));
      border: 1px solid rgba(153,27,27,0.4);
    }
    .contrast-side.light {
      background: linear-gradient(135deg, rgba(22,163,74,0.3), rgba(22,163,74,0.1));
      border: 1px solid rgba(22,163,74,0.4);
    }
    .contrast-header {
      font-family: 'Cormorant Garamond', serif;
      font-size: 1.3rem;
      font-weight: 700;
      margin-bottom: 1rem;
      padding-bottom: 0.75rem;
      border-bottom: 1px solid rgba(255,255,255,0.2);
    }
    .contrast-side.dark .contrast-header { color: #fca5a5; }
    .contrast-side.light .contrast-header { color: #86efac; }
    .contrast-items { list-style: none; padding: 0; }
    .contrast-items li {
      padding: 0.5rem 0;
      padding-left: 1.5rem;
      position: relative;
      line-height: 1.5;
    }
    .contrast-side.dark .contrast-items li::before {
      content: '✗';
      position: absolute;
      left: 0;
      color: #ef4444;
    }
    .contrast-side.light .contrast-items li::before {
      content: '✓';
      position: absolute;
      left: 0;
      color: #22c55e;
    }
    .contrast-consequence {
      margin-top: 1rem;
      padding: 1rem;
      background: rgba(0,0,0,0.3);
      border-radius: 8px;
      font-style: italic;
    }

    /* Oath/Emphatic Statement */
    .oath-box {
      background: linear-gradient(135deg, rgba(212,175,55,0.15), rgba(212,175,55,0.05));
      border: 2px solid var(--gold);
      border-radius: 12px;
      padding: 2rem;
      margin: 1.5rem 0;
      text-align: center;
    }
    .oath-header {
      font-family: 'Cormorant Garamond', serif;
      font-size: 1.1rem;
      color: var(--gold);
      text-transform: uppercase;
      letter-spacing: 0.15em;
      margin-bottom: 1rem;
    }
    .oath-text {
      font-family: 'Cormorant Garamond', serif;
      font-size: 1.4rem;
      line-height: 1.8;
      color: var(--cream);
    }
    .oath-text strong {
      color: var(--gold);
    }

    /* Death Toll Counter */
    .death-toll {
      background: linear-gradient(135deg, rgba(153,27,27,0.4), rgba(0,0,0,0.3));
      border: 1px solid rgba(153,27,27,0.6);
      border-radius: 12px;
      padding: 1.5rem;
      text-align: center;
      margin: 1rem 0;
    }
    .death-toll-number {
      font-size: 3.5rem;
      font-weight: 700;
      color: #ef4444;
      font-family: 'Cormorant Garamond', serif;
    }
    .death-toll-label {
      font-size: 1rem;
      color: rgba(255,255,255,0.8);
      margin-top: 0.5rem;
    }
    .death-toll-source {
      font-size: 0.75rem;
      color: rgba(255,255,255,0.5);
      margin-top: 0.5rem;
      font-style: italic;
    }

    /* Learning Objectives Box */
    .learning-objectives {
      background: linear-gradient(135deg, rgba(59,130,246,0.15), rgba(59,130,246,0.05));
      border: 1px solid rgba(59,130,246,0.4);
      border-left: 4px solid #3b82f6;
      border-radius: 0 12px 12px 0;
      padding: 1.5rem;
      margin: 1.5rem 0;
    }
    .learning-objectives-header {
      display: flex;
      align-items: center;
      gap: 0.75rem;
      font-weight: 700;
      color: #60a5fa;
      margin-bottom: 1rem;
      font-size: 1.1rem;
    }
    .learning-objectives ul {
      padding-left: 1.5rem;
      margin: 0;
    }
    .learning-objectives li {
      margin: 0.5rem 0;
      line-height: 1.5;
      color: rgba(255,255,255,0.9);
    }

    /* Key Takeaways Box */
    .key-takeaways {
      background: linear-gradient(135deg, rgba(34,197,94,0.15), rgba(34,197,94,0.05));
      border: 1px solid rgba(34,197,94,0.4);
      border-radius: 12px;
      padding: 1.5rem;
      margin: 1.5rem 0;
    }
    .key-takeaways-header {
      display: flex;
      align-items: center;
      gap: 0.75rem;
      font-weight: 700;
      color: #4ade80;
      margin-bottom: 1rem;
      font-size: 1.1rem;
    }
    .key-takeaways ul {
      padding-left: 1.5rem;
      margin: 0;
    }
    .key-takeaways li {
      margin: 0.5rem 0;
      line-height: 1.5;
    }

    /* Common Mistakes Warning */
    .common-mistakes {
      background: linear-gradient(135deg, rgba(239,68,68,0.15), rgba(239,68,68,0.05));
      border: 1px solid rgba(239,68,68,0.4);
      border-radius: 12px;
      padding: 1.5rem;
      margin: 1.5rem 0;
    }
    .common-mistakes-header {
      display: flex;
      align-items: center;
      gap: 0.75rem;
      font-weight: 700;
      color: #f87171;
      margin-bottom: 1rem;
      font-size: 1.1rem;
    }
    .common-mistakes ul {
      padding-left: 1.5rem;
      margin: 0;
    }
    .common-mistakes li {
      margin: 0.5rem 0;
      line-height: 1.5;
    }

    /* Patient Communication Box */
    .patient-communication {
      background: linear-gradient(135deg, rgba(168,85,247,0.15), rgba(168,85,247,0.05));
      border: 1px solid rgba(168,85,247,0.4);
      border-radius: 12px;
      padding: 1.5rem;
      margin: 1.5rem 0;
    }
    .patient-communication-header {
      font-weight: 700;
      color: #c084fc;
      margin-bottom: 1rem;
      font-size: 1.1rem;
    }
    .dialogue-box {
      background: rgba(0,0,0,0.3);
      border-radius: 8px;
      padding: 1rem;
      margin: 0.75rem 0;
    }
    .dialogue-speaker {
      font-weight: 600;
      color: var(--gold);
      margin-bottom: 0.25rem;
    }
    .dialogue-text {
      font-style: italic;
      line-height: 1.6;
      color: rgba(255,255,255,0.85);
    }

    /* Protagonist Story Box */
    .protagonist-story {
      background: linear-gradient(135deg, rgba(212,175,55,0.1), transparent);
      border: 1px solid rgba(212,175,55,0.3);
      border-radius: 12px;
      padding: 1.5rem;
      margin: 1.5rem 0;
    }
    .protagonist-name {
      font-family: 'Cormorant Garamond', serif;
      font-size: 1.5rem;
      font-weight: 700;
      color: var(--gold);
      margin-bottom: 0.5rem;
    }
    .protagonist-title {
      font-size: 0.9rem;
      color: rgba(255,255,255,0.6);
      margin-bottom: 1rem;
    }
    .protagonist-quote {
      font-style: italic;
      border-left: 3px solid var(--gold);
      padding-left: 1rem;
      margin: 1rem 0;
      color: rgba(255,255,255,0.9);
    }

    /* Legal Disclaimer */
    .legal-disclaimer {
      background: rgba(245,158,11,0.1);
      border: 1px solid rgba(245,158,11,0.3);
      border-radius: 8px;
      padding: 1rem;
      margin: 1rem 0;
      font-size: 0.85rem;
      color: rgba(255,255,255,0.7);
    }
    .legal-disclaimer strong {
      color: var(--amber);
    }

    /* Printable Checklist */
    .printable-checklist {
      background: rgba(255,255,255,0.05);
      border: 2px dashed rgba(255,255,255,0.2);
      border-radius: 12px;
      padding: 1.5rem;
      margin: 1.5rem 0;
    }
    .printable-checklist-header {
      text-align: center;
      font-weight: 700;
      color: var(--gold);
      margin-bottom: 1rem;
      font-size: 1.1rem;
    }
    .checklist-item {
      display: flex;
      align-items: flex-start;
      gap: 0.75rem;
      padding: 0.5rem 0;
      border-bottom: 1px solid rgba(255,255,255,0.1);
    }
    .checklist-box {
      width: 18px;
      height: 18px;
      border: 2px solid rgba(255,255,255,0.4);
      border-radius: 3px;
      flex-shrink: 0;
      margin-top: 2px;
    }

    /* Additional Patient Communication Styles */
    .communication-header {
      display: flex;
      align-items: center;
      gap: 0.75rem;
      font-weight: 700;
      color: #c084fc;
      margin-bottom: 1rem;
      font-size: 1.1rem;
    }
    .scenario {
      background: rgba(0,0,0,0.2);
      border-radius: 8px;
      padding: 1rem;
      margin-bottom: 1rem;
      font-style: italic;
    }
    .script-box {
      background: rgba(168,85,247,0.2);
      border-radius: 8px;
      padding: 1rem;
      margin: 1rem 0;
    }
    .script-label {
      font-weight: 600;
      color: #c084fc;
      margin-bottom: 0.5rem;
    }
    .script-text {
      font-size: 1.05rem;
      line-height: 1.7;
      color: rgba(255,255,255,0.95);
    }
    .key-points {
      margin-top: 1rem;
      padding-top: 1rem;
      border-top: 1px solid rgba(168,85,247,0.3);
    }
    .key-points ul {
      padding-left: 1.5rem;
      margin: 0.5rem 0 0 0;
    }

    /* Additional Protagonist Story Styles */
    .protagonist-header {
      margin-bottom: 1rem;
    }
    .protagonist-role {
      font-size: 0.9rem;
      color: rgba(255,255,255,0.6);
    }
    .protagonist-narrative {
      line-height: 1.7;
      margin-bottom: 1rem;
    }
    .protagonist-impact {
      margin-top: 1rem;
      padding-top: 1rem;
      border-top: 1px solid rgba(212,175,55,0.3);
      color: rgba(255,255,255,0.9);
    }

    /* Additional Legal Disclaimer Styles */
    .disclaimer-header {
      display: flex;
      align-items: center;
      gap: 0.75rem;
      font-weight: 700;
      color: #fbbf24;
      margin-bottom: 0.75rem;
    }
    .disclaimer-text {
      line-height: 1.6;
    }
    .disclaimer-resources {
      margin-top: 1rem;
      padding-top: 0.75rem;
      border-top: 1px solid rgba(245,158,11,0.3);
    }
    .disclaimer-resources ul {
      padding-left: 1.5rem;
      margin: 0.5rem 0 0 0;
    }
    .disclaimer-resources a {
      color: #fbbf24;
    }

    /* Additional Printable Checklist Styles */
    .checklist-header {
      display: flex;
      align-items: center;
      gap: 0.75rem;
      font-weight: 700;
      color: var(--gold);
      margin-bottom: 0.5rem;
      font-size: 1.2rem;
    }
    .print-instruction {
      color: rgba(255,255,255,0.6);
      font-size: 0.9rem;
      margin-bottom: 1rem;
    }
    .checklist-section {
      margin: 1rem 0;
    }
    .checklist-section h4 {
      color: #60a5fa;
      margin-bottom: 0.5rem;
      font-size: 0.95rem;
    }
    .checklist-section ul {
      list-style: none;
      padding: 0;
      margin: 0;
    }
    .checklist-section li {
      display: flex;
      align-items: flex-start;
      gap: 0.75rem;
      padding: 0.4rem 0;
    }
    .print-btn {
      display: block;
      width: 100%;
      margin-top: 1.5rem;
      padding: 0.75rem;
      background: var(--gold);
      color: #1a1a2e;
      border: none;
      border-radius: 8px;
      font-weight: 600;
      cursor: pointer;
      font-size: 1rem;
    }
    .print-btn:hover {
      background: #e6c847;
    }

    /* Key Takeaways Action Item */
    .action-item {
      margin-top: 1rem;
      padding: 1rem;
      background: rgba(34,197,94,0.2);
      border-radius: 8px;
      border-left: 4px solid #4ade80;
    }

    /* Common Mistakes Header */
    .mistakes-header {
      display: flex;
      align-items: center;
      gap: 0.75rem;
      font-weight: 700;
      color: #f87171;
      margin-bottom: 1rem;
      font-size: 1.1rem;
    }

    /* Practice Case Styles */
    .practice-case {
      background: linear-gradient(135deg, rgba(6,182,212,0.15), rgba(6,182,212,0.05));
      border: 1px solid rgba(6,182,212,0.4);
      border-radius: 12px;
      padding: 1.5rem;
      margin: 1.5rem 0;
    }
    .practice-header {
      display: flex;
      align-items: center;
      gap: 0.75rem;
      font-weight: 700;
      color: #22d3ee;
      margin-bottom: 1rem;
      font-size: 1.1rem;
    }
    .case-scenario {
      background: rgba(0,0,0,0.2);
      border-radius: 8px;
      padding: 1rem;
      margin-bottom: 1rem;
      line-height: 1.6;
    }
    .sample-data {
      margin: 1rem 0;
    }
    .sample-data h4 {
      color: #22d3ee;
      margin-bottom: 0.5rem;
    }
    .data-table {
      width: 100%;
      border-collapse: collapse;
      font-size: 0.9rem;
    }
    .data-table th, .data-table td {
      padding: 0.5rem;
      border: 1px solid rgba(6,182,212,0.3);
      text-align: center;
    }
    .data-table th {
      background: rgba(6,182,212,0.2);
      color: #22d3ee;
      font-weight: 600;
    }
    .practice-questions {
      margin-top: 1rem;
    }
    .practice-questions h4 {
      color: #22d3ee;
      margin-bottom: 0.5rem;
    }
    .practice-questions ol {
      padding-left: 1.5rem;
    }
    .practice-questions li {
      margin: 0.5rem 0;
      line-height: 1.5;
    }
    .answers-reveal {
      margin-top: 1rem;
      background: rgba(0,0,0,0.2);
      border-radius: 8px;
      padding: 1rem;
    }
    .answers-reveal summary {
      cursor: pointer;
      color: #22d3ee;
      font-weight: 600;
    }
    .answers-reveal ol {
      padding-left: 1.5rem;
      margin-top: 0.75rem;
    }

    /* Pre-Assessment Styles */
    .pre-assessment {
      background: linear-gradient(135deg, rgba(249,115,22,0.15), rgba(249,115,22,0.05));
      border: 1px solid rgba(249,115,22,0.4);
      border-radius: 12px;
      padding: 1.5rem;
      margin: 1.5rem 0;
    }
    .assessment-header {
      display: flex;
      align-items: center;
      gap: 0.75rem;
      font-weight: 700;
      color: #fb923c;
      margin-bottom: 1rem;
      font-size: 1.1rem;
    }

    /* Redemption Story Styles */
    .redemption-story {
      background: linear-gradient(135deg, rgba(52,211,153,0.15), rgba(52,211,153,0.05));
      border: 1px solid rgba(52,211,153,0.4);
      border-radius: 12px;
      padding: 1.5rem;
      margin: 1.5rem 0;
    }
    .redemption-header {
      display: flex;
      align-items: center;
      gap: 0.75rem;
      font-weight: 700;
      color: #34d399;
      margin-bottom: 1rem;
      font-size: 1.1rem;
    }
    .redemption-narrative {
      line-height: 1.7;
      margin-bottom: 1rem;
    }
    .redemption-lesson {
      background: rgba(52,211,153,0.2);
      border-radius: 8px;
      padding: 1rem;
      border-left: 4px solid #34d399;
    }

    /* Real-World Story Styles */
    .story-container {
      background: linear-gradient(135deg, rgba(30,58,95,0.5), rgba(15,15,26,0.7));
      border: 1px solid rgba(212,175,55,0.4);
      border-radius: 16px;
      padding: 2rem;
      margin: 1.5rem 0;
      position: relative;
    }
    .story-container::before {
      content: '';
      position: absolute;
      top: 0;
      left: 0;
      right: 0;
      height: 4px;
      background: linear-gradient(90deg, var(--evidence-red), var(--gold));
      border-radius: 16px 16px 0 0;
    }
    .story-opening {
      font-family: 'Cormorant Garamond', Georgia, serif;
      font-size: 1.6rem;
      font-style: italic;
      color: var(--gold);
      text-align: center;
      padding: 2rem 1.5rem;
      line-height: 1.6;
      border-left: 4px solid var(--evidence-red);
      background: linear-gradient(135deg, rgba(153,27,27,0.15), transparent);
      margin: -2rem -2rem 1.5rem -2rem;
      border-radius: 16px 16px 0 0;
    }
    .stats-box {
      display: grid;
      grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
      gap: 1rem;
      background: rgba(124,58,237,0.15);
      border: 1px solid rgba(124,58,237,0.4);
      border-radius: 12px;
      padding: 1.5rem;
      margin: 1.5rem 0;
    }
    .stats-box-header {
      grid-column: 1 / -1;
      font-weight: 700;
      color: #a78bfa;
      font-size: 1.1rem;
      padding-bottom: 0.75rem;
      border-bottom: 1px solid rgba(124,58,237,0.3);
      margin-bottom: 0.5rem;
      display: flex;
      align-items: center;
      gap: 0.5rem;
    }
    .stat-item {
      text-align: center;
      padding: 1rem;
      background: rgba(0,0,0,0.2);
      border-radius: 8px;
    }
    .stat-value {
      font-size: 1.8rem;
      font-weight: 700;
      color: var(--gold);
      font-family: 'Cormorant Garamond', serif;
    }
    .stat-label {
      font-size: 0.85rem;
      color: rgba(255,255,255,0.7);
      margin-top: 0.25rem;
    }
    .interactive-decision-tree {
      background: linear-gradient(135deg, rgba(245,158,11,0.12), rgba(245,158,11,0.03));
      border: 1px solid rgba(245,158,11,0.4);
      border-radius: 12px;
      padding: 1.5rem;
      margin: 1.5rem 0;
    }
    .decision-scenario {
      background: rgba(0,0,0,0.3);
      border-radius: 8px;
      padding: 1.25rem;
      margin-bottom: 1.5rem;
      border-left: 4px solid var(--amber);
    }
    .decision-scenario-title {
      font-weight: 700;
      color: var(--amber);
      margin-bottom: 0.5rem;
      font-size: 1.1rem;
    }
    .decision-path {
      margin: 1rem 0;
      padding: 1.25rem;
      border-radius: 8px;
      cursor: pointer;
      transition: all 0.3s ease;
      border: 2px solid transparent;
    }
    .decision-path.path-a {
      background: linear-gradient(135deg, rgba(220,38,38,0.15), rgba(220,38,38,0.05));
      border-color: rgba(220,38,38,0.4);
    }
    .decision-path.path-a:hover {
      background: linear-gradient(135deg, rgba(220,38,38,0.25), rgba(220,38,38,0.1));
      border-color: rgba(220,38,38,0.6);
      transform: translateX(5px);
    }
    .decision-path.path-b {
      background: linear-gradient(135deg, rgba(34,197,94,0.15), rgba(34,197,94,0.05));
      border-color: rgba(34,197,94,0.4);
    }
    .decision-path.path-b:hover {
      background: linear-gradient(135deg, rgba(34,197,94,0.25), rgba(34,197,94,0.1));
      border-color: rgba(34,197,94,0.6);
      transform: translateX(5px);
    }
    .decision-path:focus {
      outline: 3px solid var(--gold);
      outline-offset: 2px;
    }
    .path-header {
      font-weight: 700;
      font-size: 1.05rem;
      margin-bottom: 0.75rem;
      display: flex;
      align-items: center;
      gap: 0.75rem;
    }
    .path-a .path-header { color: #fca5a5; }
    .path-b .path-header { color: #86efac; }
    .path-arrow {
      display: inline-block;
      margin-left: 0.5rem;
      transition: transform 0.2s;
    }
    .decision-path:hover .path-arrow {
      transform: translateX(5px);
    }
    .path-consequence {
      padding-top: 0.75rem;
      border-top: 1px dashed rgba(255,255,255,0.2);
      margin-top: 0.75rem;
      font-size: 0.95rem;
      line-height: 1.6;
    }
    .revelation-box {
      background: linear-gradient(135deg, rgba(212,175,55,0.2), rgba(212,175,55,0.08));
      border: 2px solid var(--gold);
      border-radius: 12px;
      padding: 1.5rem;
      margin: 1.5rem 0;
      text-align: center;
    }
    .revelation-header {
      font-family: 'Cormorant Garamond', serif;
      font-size: 1rem;
      text-transform: uppercase;
      letter-spacing: 0.2em;
      color: var(--gold);
      margin-bottom: 1rem;
    }
    .revelation-text {
      font-family: 'Cormorant Garamond', Georgia, serif;
      font-size: 1.3rem;
      line-height: 1.7;
      color: var(--gold);
      font-style: italic;
    }
    .revelation-detail {
      margin-top: 1rem;
      font-size: 0.95rem;
      color: rgba(255,255,255,0.8);
      font-family: 'Source Sans Pro', sans-serif;
      font-style: normal;
    }
    .story-refrain {
      text-align: center;
      padding: 1.5rem;
      margin: 1.5rem 0;
      background: linear-gradient(90deg, transparent, rgba(212,175,55,0.1), transparent);
      border-top: 1px solid rgba(212,175,55,0.3);
      border-bottom: 1px solid rgba(212,175,55,0.3);
    }
    .story-refrain p {
      font-family: 'Cormorant Garamond', Georgia, serif;
      font-size: 1.4rem;
      font-style: italic;
      color: var(--gold);
      margin: 0;
    }
    .story-timeline {
      position: relative;
      padding-left: 2rem;
      margin: 1.5rem 0;
    }
    .story-timeline::before {
      content: '';
      position: absolute;
      left: 8px;
      top: 0;
      bottom: 0;
      width: 2px;
      background: linear-gradient(180deg, var(--gold), var(--evidence-red), var(--green));
    }
    .timeline-step {
      position: relative;
      padding: 1rem 0 1rem 1.5rem;
    }
    .timeline-step::before {
      content: '';
      position: absolute;
      left: -1.5rem;
      top: 1.25rem;
      width: 12px;
      height: 12px;
      border-radius: 50%;
      background: var(--gold);
      border: 2px solid var(--deep-navy);
    }
    .timeline-step.danger::before { background: var(--evidence-red); }
    .timeline-step.success::before { background: var(--green); }
    .step-label {
      font-weight: 700;
      color: var(--gold);
      font-size: 0.9rem;
      text-transform: uppercase;
      letter-spacing: 0.05em;
      margin-bottom: 0.25rem;
    }
    .step-content {
      line-height: 1.6;
      color: rgba(255,255,255,0.9);
    }

    /* Print styles */
    @media print {
      .course-nav, .progress-bar, .nav-buttons {
        display: none !important;
      }
      .printable-checklist {
        border: 2px solid #333;
        page-break-inside: avoid;
      }
      .checklist-box {
        border: 2px solid #333;
      }
    }

    /* Mobile Responsiveness */
    @media (max-width: 900px) {
      .course-container {
        flex-direction: column;
      }
      .sidebar {
        width: 100%;
        height: auto;
        max-height: 200px;
        border-right: none;
        border-bottom: 1px solid rgba(212,175,55,0.2);
      }
      .module-list {
        display: flex;
        flex-wrap: nowrap;
        overflow-x: auto;
        padding: 0.5rem;
        gap: 0.5rem;
      }
      .module-item {
        flex-shrink: 0;
        padding: 0.5rem 0.75rem;
        border-left: none;
        border-bottom: 3px solid transparent;
      }
      .module-item.active {
        border-left: none;
        border-bottom-color: var(--gold);
      }
      .sidebar-footer {
        padding: 0.5rem 1rem;
      }
      .main-content {
        height: calc(100vh - 200px);
      }
      .slide-container {
        padding: 1rem;
      }
      .rhetoric-question {
        font-size: 1.4rem;
        padding: 1.5rem 1rem;
      }
      .principle-text {
        font-size: 1.4rem;
      }
      .tool-controls {
        flex-direction: column;
      }
      .contrast-box {
        flex-direction: column;
      }
    }

    @media (max-width: 600px) {
      .sidebar {
        max-height: 150px;
      }
      .module-info {
        display: none;
      }
      .module-number {
        width: 32px;
        height: 32px;
        font-size: 0.9rem;
      }
      .slide-title {
        font-size: 1.5rem;
      }
      .case-file-header {
        flex-direction: column;
        align-items: flex-start;
      }
      .decision-branches {
        gap: 0.5rem;
      }
      .decision-branch {
        padding: 0.75rem;
      }
      .data-table {
        font-size: 0.75rem;
      }
      .data-table th, .data-table td {
        padding: 0.25rem;
      }
    }

    /* Floating Glossary Button */
    .floating-glossary {
      position: fixed;
      bottom: 20px;
      right: 20px;
      width: 56px;
      height: 56px;
      border-radius: 50%;
      background: var(--gold);
      color: var(--deep-navy);
      border: none;
      cursor: pointer;
      font-size: 1.5rem;
      box-shadow: 0 4px 12px rgba(0,0,0,0.3);
      z-index: 1000;
      display: flex;
      align-items: center;
      justify-content: center;
      transition: transform 0.2s, box-shadow 0.2s;
    }
    .floating-glossary:hover {
      transform: scale(1.1);
      box-shadow: 0 6px 16px rgba(0,0,0,0.4);
    }
    @media (min-width: 901px) {
      .floating-glossary {
        display: none;
      }
    }

    /* Reading Level Indicator */
    .reading-level {
      display: inline-block;
      padding: 0.25rem 0.75rem;
      background: rgba(124,58,237,0.2);
      border: 1px solid rgba(124,58,237,0.4);
      border-radius: 20px;
      font-size: 0.75rem;
      color: #a78bfa;
      margin-top: 0.5rem;
    }

    /* Module Time Estimate */
    .module-time {
      font-size: 0.65rem;
      color: rgba(255,255,255,0.4);
      margin-top: 0.15rem;
    }

    /* Chart Accessibility Description */
    .chart-description {
      position: absolute;
      left: -9999px;
      width: 1px;
      height: 1px;
      overflow: hidden;
    }
    .chart-description-visible {
      position: static;
      width: auto;
      height: auto;
      background: rgba(0,0,0,0.3);
      padding: 0.75rem;
      margin-top: 0.5rem;
      border-radius: 8px;
      font-size: 0.85rem;
      color: rgba(255,255,255,0.7);
    }

    /* Animation */
    .animate-in {
      animation: fadeSlideIn 0.4s ease-out;
    }
    @keyframes fadeSlideIn {
      from { opacity: 0; transform: translateY(20px); }
      to { opacity: 1; transform: translateY(0); }
    }

    /* ============================================
       ACCESSIBILITY FEATURES
       ============================================ */

    /* Skip to Content Link */
    .skip-link {
      position: absolute;
      top: -100px;
      left: 50%;
      transform: translateX(-50%);
      background: var(--gold);
      color: var(--deep-navy);
      padding: 0.75rem 1.5rem;
      border-radius: 0 0 8px 8px;
      font-weight: 600;
      text-decoration: none;
      z-index: 10000;
      transition: top 0.3s ease;
    }
    .skip-link:focus {
      top: 0;
      outline: 3px solid var(--evidence-red);
      outline-offset: 2px;
    }

    /* Visible Focus States */
    *:focus {
      outline: 2px solid var(--gold);
      outline-offset: 2px;
    }
    *:focus:not(:focus-visible) {
      outline: none;
    }
    *:focus-visible {
      outline: 3px solid var(--gold);
      outline-offset: 2px;
    }
    button:focus-visible,
    .top-bar-btn:focus-visible,
    .module-item:focus-visible {
      outline: 3px solid var(--gold);
      outline-offset: 2px;
      box-shadow: 0 0 0 4px rgba(212, 175, 55, 0.3);
    }
    input:focus-visible,
    textarea:focus-visible,
    select:focus-visible {
      outline: 3px solid var(--gold);
      outline-offset: 0;
      border-color: var(--gold);
    }
    a:focus-visible {
      outline: 3px solid var(--gold);
      outline-offset: 2px;
      text-decoration: underline;
    }

    /* ============================================
       DARK/LIGHT MODE TOGGLE
       ============================================ */

    /* Light Mode Variables */
    .light-mode {
      --navy: #e8e8f0;
      --deep-navy: #f5f5fa;
      --gold: #b8860b;
      --cream: #1a1a2e;
      --detective-blue: #d0dbe8;
      --evidence-red: #dc2626;
    }
    .light-mode .course-container {
      background: #f5f5fa;
    }
    .light-mode .sidebar {
      background: linear-gradient(180deg, #e8eef5 0%, #f5f5fa 100%);
      border-right-color: rgba(184, 134, 11, 0.3);
    }
    .light-mode .sidebar-header {
      background: rgba(0, 0, 0, 0.05);
    }
    .light-mode .main-content {
      background: #ffffff;
    }
    .light-mode .top-bar {
      background: rgba(0, 0, 0, 0.05);
      border-bottom-color: rgba(184, 134, 11, 0.2);
    }
    .light-mode .slide-container {
      background: #ffffff;
    }
    .light-mode .case-file {
      background: linear-gradient(135deg, rgba(208, 219, 232, 0.6), rgba(245, 245, 250, 0.8));
      border-color: rgba(184, 134, 11, 0.4);
    }
    .light-mode .evidence-box {
      background: rgba(220, 38, 38, 0.1);
      border-color: rgba(220, 38, 38, 0.3);
    }
    .light-mode .evidence-box.found {
      background: rgba(22, 163, 74, 0.1);
      border-color: rgba(22, 163, 74, 0.3);
    }
    .light-mode .top-bar-btn {
      background: rgba(0, 0, 0, 0.08);
      border-color: rgba(0, 0, 0, 0.15);
      color: #1a1a2e;
    }
    .light-mode .top-bar-btn:hover {
      background: rgba(0, 0, 0, 0.12);
    }
    .light-mode .glossary-overlay .glossary-panel {
      background: #ffffff;
      border-color: rgba(184, 134, 11, 0.3);
    }
    .light-mode .glossary-search {
      background: #f5f5fa;
      border-color: rgba(0, 0, 0, 0.2);
      color: #1a1a2e;
    }

    /* Theme Toggle Button */
    .theme-toggle {
      position: fixed;
      top: 20px;
      right: 20px;
      width: 44px;
      height: 44px;
      border-radius: 50%;
      background: var(--detective-blue);
      border: 2px solid var(--gold);
      color: var(--gold);
      font-size: 1.2rem;
      cursor: pointer;
      z-index: 1000;
      display: flex;
      align-items: center;
      justify-content: center;
      transition: all 0.3s ease;
      box-shadow: 0 2px 10px rgba(0, 0, 0, 0.3);
    }
    .theme-toggle:hover {
      transform: scale(1.1);
      box-shadow: 0 4px 15px rgba(0, 0, 0, 0.4);
    }
    .light-mode .theme-toggle {
      background: #ffffff;
    }

    /* ============================================
       CERTIFICATE OF COMPLETION
       ============================================ */

    .certificate-overlay {
      position: fixed;
      inset: 0;
      background: rgba(0, 0, 0, 0.9);
      z-index: 10000;
      display: none;
      align-items: center;
      justify-content: center;
      padding: 2rem;
    }
    .certificate-overlay.open {
      display: flex;
    }
    .certificate-container {
      background: linear-gradient(135deg, #fdf6e3 0%, #fff8dc 50%, #fdf6e3 100%);
      border: 8px double var(--gold);
      border-radius: 12px;
      padding: 3rem;
      max-width: 700px;
      width: 100%;
      text-align: center;
      position: relative;
      box-shadow: 0 20px 60px rgba(0, 0, 0, 0.5);
    }
    .certificate-seal {
      position: absolute;
      top: -30px;
      left: 50%;
      transform: translateX(-50%);
      width: 60px;
      height: 60px;
      background: linear-gradient(135deg, var(--gold), #c5a028);
      border-radius: 50%;
      display: flex;
      align-items: center;
      justify-content: center;
      font-size: 1.8rem;
      box-shadow: 0 4px 15px rgba(212, 175, 55, 0.5);
    }
    .certificate-title {
      font-family: 'Cormorant Garamond', Georgia, serif;
      font-size: 2.5rem;
      font-weight: 700;
      color: var(--detective-blue);
      margin-top: 1rem;
      text-transform: uppercase;
      letter-spacing: 0.15em;
    }
    .certificate-subtitle {
      font-size: 1rem;
      color: #666;
      margin-bottom: 1.5rem;
    }
    .certificate-body {
      font-size: 1.1rem;
      color: #333;
      line-height: 1.8;
      margin: 1.5rem 0;
    }
    .certificate-name {
      font-family: 'Cormorant Garamond', Georgia, serif;
      font-size: 2rem;
      font-weight: 700;
      color: var(--evidence-red);
      border-bottom: 2px solid var(--gold);
      display: inline-block;
      padding: 0 2rem 0.5rem;
      margin: 1rem 0;
    }
    .certificate-date {
      font-size: 0.9rem;
      color: #666;
      margin-top: 1.5rem;
    }
    .certificate-id {
      font-size: 0.75rem;
      color: #999;
      margin-top: 0.5rem;
      font-family: monospace;
    }
    .certificate-actions {
      display: flex;
      gap: 1rem;
      justify-content: center;
      margin-top: 2rem;
    }
    .certificate-btn {
      padding: 0.75rem 1.5rem;
      border-radius: 8px;
      font-weight: 600;
      cursor: pointer;
      transition: all 0.2s;
    }
    .certificate-btn.primary {
      background: var(--gold);
      color: var(--deep-navy);
      border: none;
    }
    .certificate-btn.secondary {
      background: transparent;
      color: #666;
      border: 2px solid #ccc;
    }
    .certificate-btn:hover {
      transform: translateY(-2px);
      box-shadow: 0 4px 12px rgba(0, 0, 0, 0.2);
    }
    .certificate-close {
      position: absolute;
      top: 1rem;
      right: 1rem;
      width: 32px;
      height: 32px;
      border-radius: 50%;
      border: none;
      background: #eee;
      color: #666;
      font-size: 1.2rem;
      cursor: pointer;
    }

    /* Certificate Name Input Modal */
    .name-input-modal {
      position: fixed;
      inset: 0;
      background: rgba(0, 0, 0, 0.8);
      z-index: 10001;
      display: none;
      align-items: center;
      justify-content: center;
    }
    .name-input-modal.open {
      display: flex;
    }
    .name-input-box {
      background: var(--deep-navy);
      border: 2px solid var(--gold);
      border-radius: 12px;
      padding: 2rem;
      max-width: 400px;
      width: 90%;
      text-align: center;
    }
    .name-input-box h3 {
      color: var(--gold);
      margin-bottom: 1rem;
    }
    .name-input-box input {
      width: 100%;
      padding: 0.75rem;
      font-size: 1.1rem;
      border: 2px solid rgba(212, 175, 55, 0.3);
      border-radius: 8px;
      background: rgba(255, 255, 255, 0.1);
      color: var(--cream);
      margin-bottom: 1rem;
    }
    .name-input-box button {
      padding: 0.75rem 2rem;
      background: var(--gold);
      color: var(--deep-navy);
      border: none;
      border-radius: 8px;
      font-weight: 600;
      cursor: pointer;
    }

    /* Reduced Motion */
    @media (prefers-reduced-motion: reduce) {
      *, *::before, *::after {
        animation-duration: 0.01ms !important;
        animation-iteration-count: 1 !important;
        transition-duration: 0.01ms !important;
      }
    }
    .mobile-menu-toggle{display:none;position:fixed;top:12px;left:12px;z-index:1001;background:#1E2761;border:1px solid #D4AF37;color:#D4AF37;width:40px;height:40px;border-radius:8px;font-size:1.2rem;cursor:pointer;align-items:center;justify-content:center;}
    @media(max-width:768px){.mobile-menu-toggle{display:flex;}.sidebar{transform:translateX(-100%);transition:transform 0.3s ease;position:fixed;z-index:1000;height:100vh;}.sidebar.open{transform:translateX(0);}.sidebar-overlay{display:none;position:fixed;inset:0;background:rgba(0,0,0,0.5);z-index:999;}.sidebar-overlay.show{display:block;}}
  </style>
</head>
<body>
  <!-- Skip to Content Link (Accessibility) -->
  <a href="#main-content" class="skip-link" id="skipLink">Skip to main content</a>
  <button class="mobile-menu-toggle" aria-expanded="false" onclick="toggleSidebar()" aria-label="Toggle navigation menu">&#9776;</button>
  <div class="sidebar-overlay" onclick="document.querySelector('.sidebar').classList.remove('open');this.classList.remove('show');"></div>

  <div class="course-container">
    <!-- Sidebar -->
    <nav class="sidebar" aria-label="Course navigation">
      <div class="sidebar-header">
        <a href="index.html" style="display:block;font-size:0.7rem;color:rgba(212,175,55,0.7);text-decoration:none;margin-bottom:0.5rem;" onmouseover="this.style.color='#D4AF37'" onmouseout="this.style.color='rgba(212,175,55,0.7)'">&larr; Course Library</a>
        <h1>Publication Bias Detective</h1>
        <p>The Evidence That Never Saw Light</p>
        <span class="sidebar-badge">Investigation Unit</span>
      </div>
      <div class="module-list" id="moduleList"></div>
      <div class="sidebar-footer">
        <button class="top-bar-btn" style="width:100%;margin-bottom:0.5rem;" onclick="openGlossary()">
          Investigator's Glossary
        </button>
        <div class="progress-bar-container">
          <div class="progress-label">Case Progress: <span id="progressPercent">0%</span></div>
          <div class="progress-bar"><div class="progress-fill" id="progressFill" style="width:0%"></div></div>
        </div>
      </div>
    </nav>

    <!-- Main Content -->
    <div class="main-content">
      <div class="top-bar">
        <div>
          <span class="module-indicator" id="moduleIndicator">Case File 0</span>
          <span class="slide-counter" id="slideCounter">1 / 1</span>
        </div>
        <div class="top-bar-actions">
          <button class="top-bar-btn" id="prevBtn" onclick="prevSlide()">Previous</button>
          <button class="top-bar-btn" id="nextBtn" onclick="nextSlide()">Next</button>
        </div>
      </div>
      <div class="slide-container" id="main-content"></div>
    </div>
  </div>

  <!-- Glossary Overlay -->
  <div class="glossary-overlay" id="glossaryOverlay">
    <div class="glossary-panel">
      <div class="glossary-header">
        <h3 style="color:var(--gold)">Investigator's Glossary</h3>
        <button class="glossary-close" onclick="closeGlossary()">&times;</button>
      </div>
      <input type="text" class="glossary-search" placeholder="Search terms..." oninput="filterGlossary()" id="glossarySearch">
      <div class="glossary-content" id="glossaryContent"></div>
    </div>
  </div>

  <!-- Theme Toggle Button -->
  <button class="theme-toggle" id="themeToggle" onclick="toggleTheme()" aria-label="Toggle dark/light mode" title="Toggle dark/light mode">
    🌙
  </button>

  <!-- Certificate Overlay -->
  <div class="certificate-overlay" id="certificateOverlay" role="dialog" aria-labelledby="certTitle">
    <div class="certificate-container" id="certificateContainer">
      <button class="certificate-close" onclick="closeCertificate()" aria-label="Close certificate">&times;</button>
      <div class="certificate-seal">🏆</div>
      <h1 class="certificate-title" id="certTitle">Certificate of Completion</h1>
      <p class="certificate-subtitle">Publication Bias Detective Training Program</p>
      <div class="certificate-body">
        <p>This is to certify that</p>
        <div class="certificate-name" id="certName">Investigator Name</div>
        <p>has successfully completed the</p>
        <p><strong style="color: var(--detective-blue); font-size: 1.2rem;">Publication Bias Detective Course</strong></p>
        <p>demonstrating proficiency in identifying, assessing, and mitigating publication bias in systematic reviews and meta-analyses.</p>
      </div>
      <div class="certificate-date" id="certDate">Completed on: January 1, 2025</div>
      <div class="certificate-id" id="certId">Certificate ID: PBD-000000</div>
      <div class="certificate-actions">
        <button class="certificate-btn primary" onclick="printCertificate()">Print Certificate</button>
        <button class="certificate-btn secondary" onclick="closeCertificate()">Close</button>
      </div>
    </div>
  </div>

  <!-- Name Input Modal for Certificate -->
  <div class="name-input-modal" id="nameInputModal" role="dialog" aria-labelledby="nameInputTitle">
    <div class="name-input-box">
      <h3 id="nameInputTitle">Congratulations, Investigator!</h3>
      <p style="color: rgba(255,255,255,0.7); margin-bottom: 1rem;">You've completed all modules. Enter your name for your certificate:</p>
      <input type="text" id="investigatorName" placeholder="Your full name" aria-label="Your full name" />
      <button onclick="generateCertificate()">Generate Certificate</button>
    </div>
  </div>

<script>
// ============================================================
// SIDEBAR TOGGLE
// ============================================================
function toggleSidebar() {
  var sidebar = document.querySelector('.sidebar');
  var overlay = document.querySelector('.sidebar-overlay');
  var btn = document.querySelector('.mobile-menu-toggle');
  if (sidebar) sidebar.classList.toggle('open');
  if (overlay) overlay.classList.toggle('show');
  if (btn) btn.setAttribute('aria-expanded', btn.getAttribute('aria-expanded') === 'true' ? 'false' : 'true');
}

// ============================================================
// GLOSSARY TERMS
// ============================================================
const glossaryTerms = [
  { term: "Publication Bias", def: "The tendency for studies with positive/significant results to be published more often than studies with negative/null results, distorting the evidence base." },
  { term: "Funnel Plot", def: "A scatter plot of effect size vs. precision (or sample size). Asymmetry suggests possible publication bias or other small-study effects." },
  { term: "Egger's Test", def: "A statistical test for funnel plot asymmetry. Regresses standardized effect on precision. Significant result (p<0.10) suggests bias." },
  { term: "Begg's Test", def: "Rank correlation test between effect size and variance. Less powerful than Egger's but makes fewer assumptions." },
  { term: "Trim and Fill", def: "Method that estimates missing studies by 'trimming' the asymmetric part of the funnel, estimating the true center, then 'filling' in imputed studies." },
  { term: "Contour-Enhanced Funnel Plot", def: "Funnel plot with significance contours (p=0.05, 0.01) overlaid. Helps distinguish publication bias from other causes of asymmetry." },
  { term: "File Drawer Problem", def: "Rosenthal's term for unpublished null studies 'filed away' in researchers' drawers, never seeing the light of publication." },
  { term: "Fail-Safe N", def: "Number of null studies that would need to exist to reduce a significant meta-analytic result to non-significance. Higher = more robust." },
  { term: "Selection Model", def: "Statistical model that explicitly models the probability of publication as a function of p-value or effect size." },
  { term: "P-Curve", def: "Distribution of significant p-values. A right-skewed p-curve (many p<0.025) suggests true effect; left-skewed or flat suggests p-hacking or no effect." },
  { term: "Small-Study Effects", def: "Phenomenon where smaller studies show larger effects. Publication bias is one cause; others include genuine heterogeneity or methodological differences." },
  { term: "Trial Registry", def: "Database where trials are registered before starting (e.g., ClinicalTrials.gov). Allows detection of unpublished completed trials." },
  { term: "FOIA Request", def: "Freedom of Information Act request to obtain unpublished data from regulatory agencies like FDA." },
  { term: "Outcome Reporting Bias", def: "Selective reporting of some outcomes but not others within a study, based on results." },
  { term: "Spin", def: "Misleading reporting that presents results more favorably than data warrant, even without data fabrication." },
  { term: "Grey Literature", def: "Research not published in peer-reviewed journals: dissertations, conference abstracts, government reports, etc." },
  { term: "PET-PEESE", def: "Precision-Effect Test and Precision-Effect Estimate with Standard Error. Regression-based methods to correct for publication bias." },
  { term: "3PSM", def: "Three-Parameter Selection Model. Models selection probability as a step function at p=0.05." }
];

// ============================================================
// COURSE MODULES
// ============================================================
const modules = [
  // MODULE 0: THE GATEWAY
  {
    id: 0,
    title: "The Gateway",
    subtitle: "Opening the Case",
    estimatedMinutes: 15,
    slides: [
      {
        type: 'title',
        content: {
          title: "Publication Bias Detective",
          subtitle: "The Evidence That Never Saw Light",
          text: "Welcome, investigator. You are about to enter the hidden world of buried evidence, suppressed trials, and the systematic distortion of medical truth."
        }
      },
      {
        type: 'quiz',
        content: {
          question: "PRE-ASSESSMENT: Before we begin, what do you think publication bias typically does to meta-analytic effect estimates?",
          options: [
            { id: 'a', text: "Makes them more accurate by filtering out low-quality studies", correct: false },
            { id: 'b', text: "Inflates them by selectively publishing positive results", correct: true },
            { id: 'c', text: "Has no systematic effect — biases cancel out", correct: false },
            { id: 'd', text: "Deflates them by suppressing the most dramatic findings", correct: false }
          ],
          explanation: "Correct! Publication bias typically INFLATES effect estimates. Positive and statistically significant results are more likely to be published, while negative, null, or inconvenient findings often remain hidden. This creates a systematic overestimate of treatment effects in the published literature. By the end of this course, you'll understand exactly how this happens and what you can do about it."
        }
      },
      {
        type: 'learning-objectives',
        content: {
          intro: "By the end of this module, you will be able to:",
          objectives: [
            "Define publication bias and explain why it occurs",
            "Describe the magnitude of publication bias in medicine using real data",
            "Identify 3 high-profile cases where publication bias caused patient harm",
            "Recognize why systematic reviews without bias assessment are incomplete",
            "Explain the difference between positive, negative, and null findings"
          ]
        }
      },
      {
        type: 'rhetoric',
        content: {
          question: "Have you not considered that of the 74 antidepressant trials submitted to the FDA, the published literature made it appear that 94% were positive — when the FDA's own records showed only 51% were positive?"
        }
      },
      {
        type: 'case-file',
        content: {
          caseNumber: "CASE ZERO",
          title: "The Magnitude of the Problem",
          source: "Turner et al., NEJM 2008 — The Study That Exposed an Industry",
          timeline: [
            { year: "The Question", text: "Erick Turner, an FDA reviewer turned researcher, asked: What if we could see ALL the antidepressant trials — not just the published ones?", type: "normal" },
            { year: "The Method", text: "He obtained FDA records for 74 trials of 12 antidepressants. Then compared what FDA saw vs. what journals published.", type: "normal" },
            { year: "The Discovery", text: "Of 38 FDA-positive trials: 37 published (97%). Of 36 FDA-negative/questionable trials: only 14 published (39%). And of those 14, 11 were SPUN to appear positive.", type: "buried" },
            { year: "The Impact", text: "Published literature effect size: 0.41. Including unpublished: 0.31. A 32% INFLATION of apparent efficacy. Millions prescribed based on distorted evidence.", type: "revealed" }
          ],
          realData: {
            totalTrials: "74 trials submitted to FDA",
            publishedPositive: "94% appeared positive in literature",
            actualPositive: "51% were positive per FDA",
            effectInflation: "32% overestimate in published literature"
          }
        }
      },
      {
        type: 'content',
        content: {
          title: "Your Investigation Toolkit",
          sections: [
            {
              heading: "Case File 1: The Buried Bodies",
              items: [
                "Reboxetine — The drug where 74% of patient data was hidden",
                "Neurontin — The $430 million fraud",
                "Vioxx — The deaths that were known but not told"
              ]
            },
            {
              heading: "Case File 2: The Funnel of Truth",
              items: [
                "Reading funnel plots — the detective's X-ray",
                "Asymmetry and what it reveals",
                "Contour-enhanced plots — seeing significance boundaries"
              ]
            },
            {
              heading: "Case File 3: The Statistical Tests",
              items: [
                "Egger's regression — the mathematical detector",
                "Begg's rank correlation — the non-parametric approach",
                "When tests fail and why"
              ]
            },
            {
              heading: "Case File 4: The Correction Methods",
              items: [
                "Trim and Fill — estimating the missing",
                "Selection models — modeling the censorship",
                "P-curve — the shape of truth"
              ]
            },
            {
              heading: "Case File 5: The Hunt",
              items: [
                "Trial registries — finding what was started",
                "FDA and EMA requests — the regulatory paper trail",
                "Grey literature — the unpublished frontier"
              ]
            }
          ]
        }
      },
      {
        type: 'principle',
        content: {
          number: "I",
          text: "The absence of evidence is not evidence of absence — it may be evidence of suppression."
        }
      },
      {
        type: 'key-takeaways',
        content: {
          takeaways: [
            "Publication bias inflates apparent treatment effects by ~30% on average",
            "The Turner antidepressant study revealed 94% vs 51% discrepancy between published and actual positive trials",
            "Missing data cannot be assumed to be neutral — it is systematically biased toward null/negative results",
            "Every meta-analysis without bias assessment may be overestimating treatment effects",
            "Publication bias is not random error — it is systematic distortion"
          ],
          actionItem: "Before accepting any meta-analysis conclusion, ask: 'What efforts were made to find unpublished data?'"
        }
      }
    ]
  },

  // MODULE 1: THE BURIED BODIES
  {
    id: 1,
    title: "The Buried Bodies",
    subtitle: "Case Studies in Suppression",
    estimatedMinutes: 25,
    slides: [
      {
        type: 'learning-objectives',
        content: {
          intro: "By the end of this module, you will be able to:",
          objectives: [
            "Analyze 3 landmark cases of publication bias and their patient impact",
            "Calculate the proportion of hidden data in the Reboxetine case",
            "Explain the financial and regulatory mechanisms that enable suppression",
            "Identify warning signs that published evidence may be incomplete",
            "Describe the human cost of evidence suppression in deaths and disability"
          ]
        }
      },
      {
        type: 'principle',
        content: {
          number: "I",
          text: "What is hidden shapes belief as powerfully as what is shown."
        }
      },
      {
        type: 'rhetoric',
        content: {
          question: "Have you not seen how Pfizer buried the evidence that gabapentin did not work for the conditions they promoted — then paid $430 million when the bodies were exhumed?"
        }
      },
      {
        type: 'case-file',
        content: {
          caseNumber: "CASE 1A",
          title: "Reboxetine: The 74% Solution",
          source: "Eyding et al., BMJ 2010 — IQWiG's Systematic Investigation",
          timeline: [
            { year: "2000s", text: "Reboxetine marketed as an effective antidepressant. Published trials showed it worked. Doctors prescribed it. Patients took it.", type: "normal" },
            { year: "The Hunt", text: "German Institute for Quality and Efficiency (IQWiG) demanded ALL trial data from Pfizer — published AND unpublished.", type: "normal" },
            { year: "The Exhumation", text: "They found: 74% of patient data had NEVER been published. 8 trials, 2,256 patients — buried.", type: "buried" },
            { year: "The Truth", text: "Published data: Reboxetine significantly better than placebo. ALL data: NO significant difference. The published literature was a curated lie.", type: "revealed" },
            { year: "The Verdict", text: "IQWiG rated reboxetine's benefit as 'not proven.' It was withdrawn or restricted in several countries.", type: "revealed" }
          ],
          realData: {
            publishedPatients: "26% of patient data published",
            hiddenPatients: "74% of patient data suppressed",
            publishedEffect: "Significant benefit vs placebo",
            trueEffect: "No significant benefit vs placebo",
            hiddenTrials: "8 trials with 2,256 patients never published"
          }
        }
      },
      {
        type: 'statistic-card',
        content: {
          value: "74%",
          label: "of reboxetine patient data was hidden from publication",
          context: "The published literature was built on 26% of the evidence"
        }
      },
      {
        type: 'case-file',
        content: {
          caseNumber: "CASE 1B",
          title: "Neurontin: The Off-Label Machine",
          source: "Steinman et al., JAMA 2006 + DOJ Settlement 2004",
          timeline: [
            { year: "1994", text: "Gabapentin (Neurontin) approved by FDA for epilepsy. Limited market.", type: "normal" },
            { year: "The Strategy", text: "Parke-Davis/Pfizer promoted it for off-label uses: pain, bipolar, migraine. But trials for these uses were negative.", type: "normal" },
            { year: "The Burial", text: "Internal documents revealed: Negative trials were suppressed. Positive-looking analyses were cherry-picked. Medical writers ghostwrote favorable papers.", type: "buried" },
            { year: "The Evidence", text: "One internal email: 'We have to be careful about what we publish... the data do not look good.' Another: Draft publications for uses where data 'ichould be positive.'", type: "buried" },
            { year: "The Settlement", text: "2004: Pfizer paid $430 million in criminal and civil penalties. But by then, Neurontin had generated $2.7 billion in off-label sales.", type: "revealed" }
          ],
          realData: {
            approvedUse: "Epilepsy only",
            offLabelSales: "90% of sales were off-label",
            settlement: "$430 million (criminal + civil)",
            revenue: "$2.7 billion from off-label promotion",
            ratio: "6:1 profit to penalty ratio"
          }
        }
      },
      {
        type: 'case-file',
        content: {
          caseNumber: "CASE 1C",
          title: "Vioxx: The Deaths They Knew",
          source: "Krumholz et al., JAMA 2007 + Congressional Testimony",
          timeline: [
            { year: "1999", text: "Vioxx (rofecoxib) launched. Merck's blockbuster painkiller. Marketed as safer for stomach than older NSAIDs.", type: "normal" },
            { year: "2000", text: "VIGOR trial finds 5-fold increase in heart attacks vs. naproxen. Merck's interpretation: Naproxen is cardioprotective. Not: Vioxx is cardiotoxic.", type: "normal" },
            { year: "2000-2004", text: "Internal documents show Merck knew of cardiovascular signal. Training materials taught sales reps to 'DODGE' questions about CV safety.", type: "buried" },
            { year: "The Revelation", text: "APPROVe trial stopped: 2x heart attacks. Vioxx withdrawn. FDA scientist David Graham estimates: 88,000-140,000 excess heart attacks, ~30% fatal.", type: "revealed" },
            { year: "The Reckoning", text: "Merck settles for $4.85 billion. Internal documents revealed systematic suppression of safety signals.", type: "revealed" }
          ],
          realData: {
            yearsOnMarket: "5 years (1999-2004)",
            estimatedHeartAttacks: "88,000-140,000 excess cases",
            estimatedDeaths: "26,000-55,000",
            settlement: "$4.85 billion",
            internalKnowledge: "Cardiovascular signal known internally by 2000"
          }
        }
      },
      {
        type: 'case-file',
        content: {
          caseNumber: "CASE 1D",
          title: "Study 329: The Children They Endangered",
          source: "Jureidini et al., BMJ 2015 — RIAT Reanalysis of GlaxoSmithKline Data",
          timeline: [
            { year: "2001", text: "Study 329 published in JAACAP. Claimed: 'Paroxetine is generally well-tolerated and effective for major depression in adolescents.' Authors included prominent academics.", type: "normal" },
            { year: "The Hidden", text: "Internal GSK documents showed: 8 suicide-related events in paroxetine group vs 1 in placebo. The drug INCREASED suicidal behavior. This was HIDDEN from the publication.", type: "buried" },
            { year: "The Spin", text: "The published paper reclassified suicidal events as 'emotional lability.' Efficacy was claimed by switching to non-pre-specified outcomes. The paper was ghostwritten.", type: "buried" },
            { year: "2004", text: "FDA issues black box warning for pediatric antidepressants. GSK fined $3 billion (2012) for fraud including Study 329. The drug had been prescribed to millions of children.", type: "revealed" },
            { year: "2015", text: "RIAT reanalysis using actual trial data: 'Paroxetine is neither safe nor effective.' The opposite of the original conclusion. Same data, honest analysis.", type: "revealed" }
          ],
          realData: {
            originalClaim: "Effective and well-tolerated",
            realityAfterReanalysis: "Neither safe nor effective",
            suicidalEvents: "8 in paroxetine vs 1 in placebo",
            settlement: "$3 billion (GSK total fraud settlement)",
            childrenExposed: "Millions prescribed worldwide before warning"
          }
        }
      },
      {
        type: 'death-toll',
        content: {
          number: "26,000–55,000",
          label: "Estimated excess deaths from Vioxx alone",
          source: "FDA scientist David Graham's congressional testimony, 2004"
        }
      },
      {
        type: 'oath',
        content: {
          header: "By the Evidence They Buried",
          text: "By the trials that were hidden, and the patients who were harmed —<br><strong>the cost of suppression is measured in lives.</strong><br><br>Every buried study is a betrayal. Every spin is a deception.<br>The detective does not look away. The detective counts the cost."
        }
      },
      {
        type: 'contrast',
        content: {
          title: "Two Paths in the Face of Negative Data",
          darkSide: {
            header: "The Path of Concealment",
            items: [
              "Hide the negative trials",
              "Spin the language ('emotional lability' not 'suicidal')",
              "Ghostwrite favorable papers",
              "Promote off-label use despite evidence",
              "Pay the fine as cost of doing business"
            ],
            consequence: "Result: Reboxetine prescribed as effective (it wasn't). Vioxx killed tens of thousands. Study 329 endangered children."
          },
          lightSide: {
            header: "The Path of Transparency",
            items: [
              "Publish all trials regardless of outcome",
              "Report adverse events accurately",
              "Allow independent data access",
              "Follow the evidence, not the market",
              "Accept reduced profits for patient safety"
            ],
            consequence: "Result: Doctors can make informed decisions. Patients receive treatments that actually work. Trust in medicine is preserved."
          }
        }
      },
      {
        type: 'decision-tree',
        content: {
          title: "The Reviewer's Dilemma",
          situation: "You're conducting a meta-analysis of a pain medication. You find 12 published trials — all positive, effect size d=0.45. A colleague mentions rumors of unpublished negative trials. The manufacturer won't share data. What do you do?",
          nodes: [
            {
              id: 'start',
              question: "You have 12 positive published trials. Do you proceed with the meta-analysis?",
              branches: [
                { id: 'a', text: "Yes — publish with the available data and note limitations", nextNode: 'publish' },
                { id: 'b', text: "Hunt for unpublished data before proceeding", nextNode: 'hunt' },
                { id: 'c', text: "Apply statistical tests for publication bias", nextNode: 'test' }
              ]
            },
            {
              id: 'publish',
              type: 'outcome',
              consequence: 'bad',
              title: "The Reboxetine Replay",
              text: "Your meta-analysis shows strong efficacy (d=0.45). Guidelines cite it. Prescriptions increase. Two years later, regulatory investigation reveals 8 unpublished negative trials. True effect: d=0.15, non-significant. Your published meta-analysis contributed to patients receiving ineffective treatment.",
              realCase: "This is exactly what happened with reboxetine. Multiple published meta-analyses showed benefit — until IQWiG obtained the unpublished data and the effect disappeared."
            },
            {
              id: 'hunt',
              question: "You search ClinicalTrials.gov and find 6 completed trials with no published results. You contact trialists and file FOIA requests. What happens?",
              branches: [
                { id: 'd', text: "You obtain 4 of 6 trial datasets — 3 are negative", nextNode: 'found' },
                { id: 'e', text: "Requests denied or ignored — you have no new data", nextNode: 'blocked' }
              ]
            },
            {
              id: 'found',
              type: 'outcome',
              consequence: 'good',
              title: "The Truth Emerges",
              text: "Including the unpublished data: effect drops to d=0.22, barely significant. Your meta-analysis reports BOTH estimates, notes the discrepancy, and warns about likely publication bias. Clinicians can make informed decisions. Your work prevents another reboxetine.",
              realCase: "This is what Turner did with antidepressants and Eyding did with reboxetine — obtaining regulatory data to reveal the true picture."
            },
            {
              id: 'blocked',
              question: "You can't get unpublished data. Your funnel plot looks suspicious. What do you report?",
              branches: [
                { id: 'f', text: "Report the effect but with strong caveats and bias assessment", nextNode: 'cautious' },
                { id: 'g', text: "Use trim-and-fill to estimate adjusted effect", nextNode: 'adjust' }
              ]
            },
            {
              id: 'cautious',
              type: 'outcome',
              consequence: 'neutral',
              title: "The Honest Unknown",
              text: "You report: 'Published trials suggest d=0.45, but funnel plot asymmetry and registry search indicate likely missing negative trials. We located 6 unpublished trials that could not be obtained. True effect is likely smaller.' GRADE assessment: downgrade for publication bias. You've flagged the problem even without solving it.",
              realCase: "GRADE explicitly allows downgrading for suspected publication bias. Transparency about uncertainty is more valuable than false precision."
            },
            {
              id: 'adjust',
              type: 'outcome',
              consequence: 'neutral',
              title: "The Statistical Correction",
              text: "Trim-and-fill imputes 5 missing studies. Adjusted effect: d=0.28. You report both estimates with explanation. Caveat: Trim-and-fill assumes publication bias is the ONLY cause of asymmetry, and doesn't recover the actual missing data. It's an approximation, not a solution.",
              realCase: "Trim-and-fill is widely used but has limitations. It can over- or under-correct. Selection models may be more accurate but require assumptions about the selection mechanism."
            },
            {
              id: 'test',
              question: "Egger's test: p=0.03 (significant asymmetry). Begg's test: p=0.08 (borderline). Funnel plot shows gap in bottom-left. What do you conclude?",
              branches: [
                { id: 'h', text: "Publication bias is confirmed — adjust the estimate", nextNode: 'confirmed' },
                { id: 'i', text: "Tests are suggestive but not definitive — investigate further", nextNode: 'investigate' }
              ]
            },
            {
              id: 'confirmed',
              type: 'outcome',
              consequence: 'bad',
              title: "The Overconfident Conclusion",
              text: "You state 'publication bias confirmed' and apply trim-and-fill. But Egger's test has high false positive rate with few studies and high heterogeneity. The asymmetry might be due to genuine effect modification (smaller trials in sicker patients). You've made a statistical inference that requires clinical verification.",
              realCase: "Funnel plot asymmetry has many causes beyond publication bias: heterogeneity, methodological differences in small studies, true biology. Tests can't distinguish these."
            },
            {
              id: 'investigate',
              type: 'outcome',
              consequence: 'good',
              title: "The Comprehensive Assessment",
              text: "You use contour-enhanced funnel plots: missing studies are in non-significant regions (suggests publication bias, not heterogeneity). You check if smaller studies differ methodologically (they don't). You search registries (find unpublished trials). You report: 'Multiple lines of evidence suggest publication bias' with GRADE downgrade. Full transparency, appropriate uncertainty.",
              realCase: "Modern guidance recommends multiple approaches: visual assessment, statistical tests, registry searches, and clinical judgment. No single method is sufficient."
            }
          ]
        }
      },
      {
        type: 'case-file',
        content: {
          caseNumber: "CASE 1E",
          title: "Avandia: The 83,000 Heart Attacks",
          source: "Nissen & Wolski, NEJM 2007 + Senate Finance Committee Investigation",
          timeline: [
            { year: "1999", text: "Rosiglitazone (Avandia) approved for diabetes. GlaxoSmithKline's blockbuster drug.", type: "normal" },
            { year: "The Hidden Signal", text: "By 2000, GSK's internal meta-analysis showed 30% increased risk of cardiac events. They commissioned more analyses — all showed the same signal. NONE were published.", type: "buried" },
            { year: "2007", text: "Cardiologist Steven Nissen obtains 42 trial datasets through legal discovery. His meta-analysis: 43% increased MI risk (OR 1.43, p=0.03). Published in NEJM.", type: "revealed" },
            { year: "The Toll", text: "FDA estimates: 83,000 excess heart attacks from 1999-2007. GSK had known since 2000. Seven years of silence. Seven years of prescriptions.", type: "revealed" },
            { year: "The Reckoning", text: "GSK pays $3 billion settlement (2012). Avandia restricted. But the damage was done — and the published literature had hidden it.", type: "revealed" }
          ],
          realData: {
            approvalYear: "1999",
            internalSignalYear: "2000",
            publicRevelationYear: "2007",
            yearsOfSuppression: "7 years",
            estimatedExcessMIs: "83,000",
            settlement: "$3 billion"
          }
        }
      },
      {
        type: 'rhetoric',
        content: {
          question: "Have you not considered that for SEVEN YEARS, a company knew their drug caused heart attacks — and said nothing? That 83,000 hearts were damaged while the evidence sat in corporate files?"
        }
      },
      {
        type: 'case-file',
        content: {
          caseNumber: "CASE 1F",
          title: "The DECREASE Fraud: When the Data Was Invented",
          source: "Erasmus MC Investigation 2012 + Bouri et al. BMJ 2014 Reanalysis",
          timeline: [
            { year: "Background", text: "Don Poldermans was the world's leading expert on beta-blockers before surgery. His DECREASE trials showed dramatic mortality reduction. Guidelines worldwide changed based on his work.", type: "normal" },
            { year: "The Suspicion", text: "Other researchers couldn't replicate his results. His effect sizes were impossibly large. Data patterns seemed too clean.", type: "normal" },
            { year: "2012", text: "Erasmus Medical Center investigation: Poldermans fabricated data in multiple studies. He invented patients. He falsified outcomes.", type: "buried" },
            { year: "The Reanalysis", text: "Bouri et al. reanalyzed all beta-blocker trials EXCLUDING Poldermans' data. Without his studies: NO mortality benefit, possible HARM. Guidelines had been based on fraud.", type: "revealed" },
            { year: "The Cost", text: "European guidelines caused an estimated 10,000 excess deaths per year by recommending routine beta-blockers. Based on fabricated evidence.", type: "revealed" }
          ],
          realData: {
            fraudulentTrials: "DECREASE I, II, IV",
            originalClaim: "34% mortality reduction",
            truthWithoutFraud: "No benefit, possible harm",
            estimatedAnnualDeaths: "~10,000 excess deaths/year in Europe",
            guidelineImpact: "ESC guidelines changed worldwide practice"
          }
        }
      },
      {
        type: 'death-toll',
        content: {
          number: "10,000/year",
          label: "Estimated excess deaths in Europe from guidelines based on DECREASE fraud",
          source: "Bouri et al., Heart 2014"
        }
      },
      {
        type: 'decision-tree',
        content: {
          title: "The Whistleblower's Crossroads",
          situation: "You're a junior researcher at a pharmaceutical company. You've discovered that your company has 5 unpublished trials showing the drug increases cardiovascular events. The drug is already approved and generating $2 billion/year. Your supervisor tells you to focus on other projects and 'let the medical affairs team handle regulatory issues.' What do you do?",
          nodes: [
            {
              id: 'start',
              question: "You've found evidence of hidden harm. Your career is at stake. What do you do?",
              branches: [
                { id: 'a', text: "Stay silent — it's above your pay grade", nextNode: 'silent' },
                { id: 'b', text: "Report internally through compliance channels", nextNode: 'internal' },
                { id: 'c', text: "Become a whistleblower — contact FDA or journalists", nextNode: 'whistleblow' }
              ]
            },
            {
              id: 'silent',
              type: 'outcome',
              consequence: 'bad',
              title: "The Weight of Silence",
              text: "You stay silent. The drug continues selling. Heart attacks continue occurring. Years later, the truth emerges through litigation. You read that thousands were harmed. You knew. You said nothing. The money you earned was blood money. The career you protected was built on complicity.",
              realCase: "Many pharmaceutical employees knew about Vioxx, Avandia, and other scandals. Most stayed silent. Some testified later that the guilt never left them."
            },
            {
              id: 'internal',
              question: "You file an internal compliance report. Weeks pass. The compliance officer thanks you and says 'the matter is being handled.' What do you do next?",
              branches: [
                { id: 'd', text: "Trust the process — compliance will handle it", nextNode: 'trust' },
                { id: 'e', text: "Follow up and demand evidence of action", nextNode: 'followup' },
                { id: 'f', text: "Document everything and prepare external escalation", nextNode: 'document' }
              ]
            },
            {
              id: 'trust',
              type: 'outcome',
              consequence: 'bad',
              title: "The False Assurance",
              text: "Nothing changes. Months later, you're quietly transferred to a different division. The drug continues. You learn that 'compliance handling' meant legal review of how to defend future litigation, not how to protect patients. Your report was filed — and buried alongside the trials.",
              realCase: "Internal compliance often protects the company, not patients. Cheryl Eckard at GSK reported manufacturing problems internally for years before becoming a federal whistleblower."
            },
            {
              id: 'followup',
              type: 'outcome',
              consequence: 'neutral',
              title: "The Paper Trail",
              text: "You demand meeting notes, action items, regulatory filings. You're told this is 'privileged information.' Your persistence is noted — not positively. You're labelled 'not a team player.' But you've created a record. When the scandal eventually breaks, your documented concerns become evidence.",
              realCase: "Documentation protects whistleblowers legally. Peter Rost at Pfizer kept meticulous records that later proved invaluable in legal proceedings."
            },
            {
              id: 'document',
              type: 'outcome',
              consequence: 'good',
              title: "The Prepared Path",
              text: "You keep copies of everything. You consult a whistleblower attorney. You understand the False Claims Act and qui tam provisions. When internal channels fail, you're ready. Your documentation becomes the foundation for a federal case. You face retaliation — but you're protected by law, and you sleep at night.",
              realCase: "Successful whistleblowers like Cheryl Eckard and John Kopchinski prepared extensively before going external. Eckard received $96 million; Kopchinski received $51 million."
            },
            {
              id: 'whistleblow',
              question: "You decide to go external. But how?",
              branches: [
                { id: 'g', text: "Contact a journalist at a major newspaper", nextNode: 'journalist' },
                { id: 'h', text: "File a qui tam lawsuit under seal with documentation", nextNode: 'quitam' },
                { id: 'i', text: "Report directly to FDA's MedWatch", nextNode: 'fda' }
              ]
            },
            {
              id: 'journalist',
              type: 'outcome',
              consequence: 'neutral',
              title: "The Public Revelation",
              text: "A journalist investigates. The story breaks. But without legal protection, you're fired immediately. The company claims you violated confidentiality. You face expensive litigation. The truth is out — but your career and finances are destroyed. Journalism exposes, but doesn't protect the exposer.",
              realCase: "Many whistleblowers who went to media first faced devastating retaliation. Legal protection requires following specific procedures."
            },
            {
              id: 'quitam',
              type: 'outcome',
              consequence: 'good',
              title: "The Protected Path",
              text: "A qui tam lawyer files under seal. The government investigates with your evidence. Years later, the case resolves: the company pays billions, patients are warned, and you receive 15-25% of the recovery. The process was long and stressful, but you're protected by law and rewarded for integrity.",
              realCase: "The False Claims Act has recovered over $70 billion since 1986. Pharmaceutical cases account for a large share. Whistleblowers share in recoveries."
            },
            {
              id: 'fda',
              type: 'outcome',
              consequence: 'neutral',
              title: "The Regulatory Route",
              text: "FDA takes your report seriously. They request documents from the company. The company lawyers up. The process takes years. Eventually, a warning is added to the label. But you have no financial protection, no legal shield. You did the right thing — but the system didn't protect you for doing it.",
              realCase: "FDA relies on voluntary reporting and has limited enforcement power. David Graham, an FDA scientist, faced internal retaliation for his Vioxx analysis."
            }
          ]
        }
      },
      {
        type: 'legal-disclaimer',
        content: {
          text: "This educational content about whistleblowing is provided for informational purposes only and does NOT constitute legal advice. Whistleblower protections vary SIGNIFICANTLY by country, jurisdiction, employer type (government vs. private), and type of misconduct. The consequences of disclosure can be severe, including termination, blacklisting, and personal liability. INTERNATIONAL NOTE: The resources below are primarily US-focused. Many countries have different (often weaker) protections. EU Directive 2019/1937 provides baseline protections in Europe, but implementation varies. BEFORE taking any action on suspected misconduct, consult with a qualified attorney who specializes in whistleblower protection law in YOUR jurisdiction.",
          resources: [
            { name: "Government Accountability Project (US)", url: "https://whistleblower.org/" },
            { name: "National Whistleblower Center (US)", url: "https://www.whistleblowers.org/" },
            { name: "OSHA Whistleblower Protection Program (US)", url: "https://www.osha.gov/whistleblower" },
            { name: "Whistleblower Network News (International)", url: "https://whistleblowersblog.org/" },
            { name: "EU Whistleblower Directive Info", url: "https://ec.europa.eu/info/aid-development-cooperation-fundamental-rights/your-rights-eu/whistleblower-protection_en" }
          ]
        }
      },
      {
        type: 'contrast',
        content: {
          title: "Two Scientists Discover Hidden Harm",
          darkSide: {
            header: "The Silent Witness",
            items: [
              "Sees the unpublished trials",
              "Raises concern once, is dismissed",
              "Accepts 'it's being handled'",
              "Focuses on other projects",
              "Years later, reads about the deaths",
              "Lives with the knowledge of what they didn't do"
            ],
            consequence: "Result: Career preserved. Conscience damaged. When the scandal breaks, they weren't part of the cover-up — but they weren't part of the solution either."
          },
          lightSide: {
            header: "The Persistent Voice",
            items: [
              "Sees the same unpublished trials",
              "Documents everything meticulously",
              "Escalates through proper channels",
              "When channels fail, consults attorney",
              "Files protected disclosure",
              "Faces retaliation but persists"
            ],
            consequence: "Result: Career disrupted but rebuilt. Patients protected. Years later, receives recognition and compensation. Sleeps soundly knowing they acted when it mattered."
          }
        }
      },
      {
        type: 'clinical-guide',
        content: {
          title: "Red Flags for Publication Bias",
          items: [
            "ALL published trials are positive (especially for subjective outcomes)",
            "Effect sizes are implausibly large compared to mechanism",
            "Industry-sponsored trials have larger effects than independent trials",
            "Conference abstracts never became full publications",
            "Registered trials on ClinicalTrials.gov have no published results",
            "Results were presented at conferences then 'disappeared'",
            "Internal documents (litigation, FOIA) reveal suppressed trials",
            "Funnel plot shows asymmetric gap in bottom-left quadrant"
          ]
        }
      },
      {
        type: 'cycle-return',
        content: {
          principle: "What is hidden shapes belief as powerfully as what is shown. The detective's first task is knowing that something IS hidden."
        }
      },
      {
        type: 'quiz',
        content: {
          question: "In the reboxetine case, what percentage of patient data was never published?",
          options: [
            { id: 'a', text: "26%", correct: false },
            { id: 'b', text: "51%", correct: false },
            { id: 'c', text: "74%", correct: true },
            { id: 'd', text: "94%", correct: false }
          ],
          explanation: "74% of patient data from reboxetine trials was never published. Only 26% made it into the published literature. When IQWiG obtained all the data, the drug's apparent efficacy disappeared. This case demonstrates why unpublished data matters more than published data volume."
        }
      },
      {
        type: 'protagonist-story',
        content: {
          name: "Dr. Erick Turner",
          role: "FDA Reviewer turned Whistleblower Researcher",
          narrative: "As an FDA medical reviewer, Erick Turner saw something troubling: antidepressant trials submitted to the FDA often had different results than what appeared in published journals. After leaving the FDA, he conducted the landmark 2008 study comparing FDA records to published literature for 74 antidepressant trials. What he found shocked medicine: while published literature suggested 94% of trials were positive, FDA records showed only 51% were truly positive.",
          quote: "The literature looked like it came from Lake Wobegon, where all the children are above average.",
          impact: "His study, published in NEJM, fundamentally changed how we understand publication bias. It provided the clearest evidence that published medical literature systematically exaggerates treatment efficacy."
        }
      },
      {
        type: 'key-takeaways',
        content: {
          takeaways: [
            "Reboxetine case: 74% of patient data hidden, drug approval revoked when full data emerged",
            "Vioxx case: 88,000-140,000 excess heart attacks, company knew early",
            "Paroxetine Study 329: Suicide risk hidden, ghostwritten, led to $3 billion settlement",
            "Financial incentives powerfully drive selective publication",
            "Regulatory submissions often tell a different story than published papers"
          ],
          actionItem: "For any drug you prescribe regularly, search for FDA reviews or regulatory documents — compare what regulators saw to what was published."
        }
      }
    ]
  },

  // MODULE 2: THE FUNNEL OF TRUTH
  {
    id: 2,
    title: "The Funnel of Truth",
    subtitle: "Visual Detection",
    estimatedMinutes: 20,
    slides: [
      {
        type: 'learning-objectives',
        content: {
          intro: "By the end of this module, you will be able to:",
          objectives: [
            "Explain the statistical principles behind funnel plot asymmetry",
            "Interpret funnel plots and identify patterns suggesting publication bias",
            "Distinguish between small-study effects and true publication bias",
            "Use interactive funnel plot tools to assess your own meta-analyses",
            "Recognize limitations and confounders of funnel plot interpretation"
          ]
        }
      },
      {
        type: 'principle',
        content: {
          number: "II",
          text: "The funnel reveals what the forest conceals — the shape of what was published, and the shadow of what was not."
        }
      },
      {
        type: 'rhetoric',
        content: {
          question: "Have you not seen how a symmetric funnel plot declares: 'Publication was fair to all results' — while an asymmetric funnel whispers: 'Someone chose what you would see'?"
        }
      },
      {
        type: 'content',
        content: {
          title: "The Logic of the Funnel",
          sections: [
            {
              heading: "Why a Funnel Shape?",
              items: [
                "Large studies (top): precise estimates, cluster tightly around true effect",
                "Small studies (bottom): imprecise, scatter widely around true effect",
                "If ALL studies are published regardless of results: symmetric scatter",
                "If ONLY significant results are published: asymmetric scatter"
              ]
            },
            {
              heading: "Reading the X-Axis (Effect Size)",
              items: [
                "Horizontal position shows each study's effect estimate",
                "Pooled estimate typically shown as vertical line",
                "Distance from center shows deviation from average"
              ]
            },
            {
              heading: "Reading the Y-Axis (Precision)",
              items: [
                "Standard error (inverted: 0 at top, larger SE at bottom)",
                "OR sample size (larger at top)",
                "OR precision (1/SE, larger at top)",
                "Top = more precise = more confident estimates"
              ]
            }
          ]
        }
      },
      {
        type: 'tool-funnel',
        content: {
          id: 'funnel-basic',
          title: "Interactive Funnel Plot",
          description: "Explore how publication bias distorts the funnel shape. Toggle bias on/off to see the effect."
        }
      },
      {
        type: 'content',
        content: {
          title: "Asymmetry: The Fingerprint of Bias",
          sections: [
            {
              heading: "The Missing Corner",
              items: [
                "Bottom-left gap: Small, non-significant, negative studies missing",
                "This is the classic publication bias pattern",
                "Small studies with null results → filed away, never published",
                "Large studies published regardless (too big to bury)"
              ]
            },
            {
              heading: "But Asymmetry Has Other Causes",
              items: [
                "TRUE HETEROGENEITY: Small studies in sicker patients → larger effects (real)",
                "METHODOLOGICAL DIFFERENCES: Small studies less rigorous → inflated effects",
                "CHANCE: With few studies, asymmetry can occur randomly",
                "ARTEFACT: Some effect measures (OR) create asymmetry naturally"
              ]
            }
          ]
        }
      },
      {
        type: 'tool-contour',
        content: {
          id: 'contour-funnel',
          title: "Contour-Enhanced Funnel Plot",
          description: "Contours show significance boundaries. If missing studies fall in non-significant regions, publication bias is likely. If they fall in significant regions, other explanations apply."
        }
      },
      {
        type: 'case-file',
        content: {
          caseNumber: "CASE 2A",
          title: "The HRT Reversal: When Observation Deceived",
          source: "WHI Trial, JAMA 2002 + Decades of Observational Studies",
          timeline: [
            { year: "1980s-90s", text: "Observational studies consistently showed: women on HRT had 40-50% LOWER heart disease risk. Meta-analyses confirmed it. Guidelines recommended HRT for cardioprotection.", type: "normal" },
            { year: "The Logic", text: "Why wouldn't it work? Estrogen improves lipid profiles. The biology made sense. The consistent observational data 'proved' it.", type: "normal" },
            { year: "2002", text: "Women's Health Initiative (WHI) — the first large randomized trial — STOPPED EARLY. HRT INCREASED cardiovascular events by 29%. The opposite of what everyone believed.", type: "revealed" },
            { year: "The Explanation", text: "Healthy user bias: Women who took HRT were healthier, more educated, more health-conscious. The 'protection' was confounding, not causation. And unpublished negative observational studies? Nobody looked for them.", type: "revealed" }
          ],
          realData: {
            observationalEstimate: "40-50% risk reduction",
            rctResult: "29% risk INCREASE",
            discrepancy: "Complete reversal",
            yearsOfWrongPractice: "20+ years",
            cause: "Healthy user bias + possible publication bias in observational studies"
          }
        }
      },
      {
        type: 'rhetoric',
        content: {
          question: "Have you not seen how for twenty years, the medical community believed — with 'strong evidence' — that hormone therapy protected the heart? And how a single randomized trial revealed that observation had deceived them all?"
        }
      },
      {
        type: 'oath',
        content: {
          header: "By the Funnel's Testimony",
          text: "The funnel plot does not lie — <strong>but it can be misread.</strong><br><br>Asymmetry is a witness, not a verdict.<br>It testifies that something is unusual.<br>It does not testify WHY.<br><br>The detective who sees asymmetry and cries 'bias!'<br>is no better than the one who sees symmetry and cries 'truth!'<br><br><strong>Both must investigate. Both must verify. Both must doubt.</strong>"
        }
      },
      {
        type: 'decision-tree',
        content: {
          title: "The Journal Editor's Dilemma",
          situation: "You're the editor of a major medical journal. A researcher submits a well-conducted trial showing NO effect of a popular supplement on cognitive function (null result, p=0.67). Three positive trials have been published elsewhere. The methods are rigorous. The sample size is adequate. Your reviewers are split — some say 'not novel enough,' others say 'important null finding.' What do you do?",
          nodes: [
            {
              id: 'start',
              question: "A rigorous null trial arrives at your desk. What's your decision?",
              branches: [
                { id: 'a', text: "Reject — null findings aren't exciting enough for our journal", nextNode: 'reject' },
                { id: 'b', text: "Accept — null findings are scientifically important", nextNode: 'accept' },
                { id: 'c', text: "Request additional analyses to find 'something interesting'", nextNode: 'fish' }
              ]
            },
            {
              id: 'reject',
              type: 'outcome',
              consequence: 'bad',
              title: "The Bias-Creating Decision",
              text: "You reject the null study. The researcher, demoralized, files it away. The published literature now contains 3 positive trials and 0 negative trials. Future meta-analysts will see only the positives. Your decision — multiplied across thousands of editors — IS publication bias. You didn't suppress evidence maliciously. You just found it boring.",
              realCase: "Studies show null results are 50% less likely to be published. Most journal editors cite 'lack of novelty' as the reason. The cumulative effect distorts the evidence base."
            },
            {
              id: 'accept',
              type: 'outcome',
              consequence: 'good',
              title: "The Counter-Cultural Choice",
              text: "You accept the null study with an editorial on the importance of publishing negative results. Meta-analysts now have a more complete picture: 3 positive trials and 1 negative. The effect estimate shrinks. Clinicians make better-informed decisions. You've contributed to truth — even though it won't boost your impact factor.",
              realCase: "PLOS ONE and other journals now explicitly welcome null results. Some specialty journals focus on negative findings. The culture is slowly changing."
            },
            {
              id: 'fish',
              type: 'outcome',
              consequence: 'bad',
              title: "The p-Hacking Invitation",
              text: "You ask: 'Did you check subgroups? Any secondary outcomes significant?' The researcher re-analyzes. In men over 65 with baseline cognitive impairment, there's a hint of effect (p=0.04). The paper is revised to emphasize this 'finding.' You've published — but you've also taught the researcher that fishing for significance is how to get published.",
              realCase: "This dynamic — editors requesting 'interesting' reanalyses — is a major driver of p-hacking and selective reporting. It creates false positives that look like real findings."
            }
          ]
        }
      },
      {
        type: 'contrast',
        content: {
          title: "Two Funnels, Two Truths",
          darkSide: {
            header: "The Funnel That Appeared Symmetric",
            items: [
              "15 studies form a beautiful symmetric cone",
              "Egger's test: p=0.45 (not significant)",
              "Conclusion: 'No evidence of publication bias'",
              "BUT: Registry search not performed",
              "BUT: All studies industry-funded",
              "BUT: 8 registered trials have no published results"
            ],
            consequence: "The funnel looked clean because the unpublished studies were never plotted. Absence from the graph ≠ absence from reality."
          },
          lightSide: {
            header: "The Funnel That Appeared Asymmetric",
            items: [
              "12 studies show clear asymmetry",
              "Egger's test: p=0.02 (significant)",
              "Initial conclusion: 'Publication bias!'",
              "BUT: Small studies were in sicker patients",
              "BUT: Larger effects in severe disease is expected",
              "BUT: Stratified analysis shows no bias within severity groups"
            ],
            consequence: "The funnel looked biased because of genuine heterogeneity. The asymmetry was biology, not suppression. Investigation revealed the truth."
          }
        }
      },
      {
        type: 'decision-tree',
        content: {
          title: "Interpreting Funnel Asymmetry",
          situation: "Your funnel plot shows clear asymmetry — studies are missing from the bottom-left. You have 15 studies in your meta-analysis. How do you interpret this?",
          nodes: [
            {
              id: 'start',
              question: "You see funnel plot asymmetry with missing small negative studies. What's your interpretation?",
              branches: [
                { id: 'a', text: "Publication bias is confirmed — small negative studies weren't published", nextNode: 'bias_confirmed' },
                { id: 'b', text: "Check where missing studies fall relative to significance contours", nextNode: 'contours' },
                { id: 'c', text: "Examine whether small studies differ systematically from large ones", nextNode: 'heterogeneity' }
              ]
            },
            {
              id: 'bias_confirmed',
              type: 'outcome',
              consequence: 'bad',
              title: "The Premature Conclusion",
              text: "You conclude publication bias without considering alternatives. But asymmetry can have multiple causes. If small studies enrolled sicker patients (common in proof-of-concept trials), larger effects are EXPECTED. Your 'bias' may be biology. Always consider: Is there a clinical reason small studies might differ?",
              realCase: "Sterne et al. (BMJ 2011) documented that 'small-study effects' is a better term than 'publication bias' because the causes are multiple."
            },
            {
              id: 'contours',
              question: "You add contour enhancement. Missing studies fall clearly in the p>0.05 region (non-significant). What does this suggest?",
              branches: [
                { id: 'd', text: "Publication bias is the most likely explanation", nextNode: 'bias_likely' },
                { id: 'e', text: "Could still be heterogeneity — need more investigation", nextNode: 'more_check' }
              ]
            },
            {
              id: 'bias_likely',
              type: 'outcome',
              consequence: 'good',
              title: "The Informed Assessment",
              text: "Contour-enhanced plots show the 'missing' studies would have been non-significant. This pattern specifically suggests publication bias — studies weren't published BECAUSE they weren't significant. This doesn't prove bias exists, but it's the most parsimonious explanation. Report this finding with appropriate caveats.",
              realCase: "Peters et al. (JAMA 2008) introduced contour-enhanced funnel plots specifically to distinguish publication bias from heterogeneity."
            },
            {
              id: 'more_check',
              type: 'outcome',
              consequence: 'good',
              title: "The Thorough Investigation",
              text: "You're right to be cautious. You also: (1) Check if small studies used different interventions/populations, (2) Run Egger's test (p=0.02), (3) Search registries for unpublished trials (find 3), (4) Compare industry vs. independent funding. Multiple lines of evidence strengthen your conclusion.",
              realCase: "Cochrane guidance recommends against relying on any single method. Visual, statistical, and empirical (registry search) approaches should be combined."
            },
            {
              id: 'heterogeneity',
              question: "You examine study characteristics. Small studies enrolled patients from specialty clinics; large studies enrolled from primary care. Severity differs. What now?",
              branches: [
                { id: 'f', text: "This explains the asymmetry — it's heterogeneity, not bias", nextNode: 'heterogeneity_explains' },
                { id: 'g', text: "Both could be true — subgroup analysis AND bias assessment needed", nextNode: 'both_true' }
              ]
            },
            {
              id: 'heterogeneity_explains',
              type: 'outcome',
              consequence: 'neutral',
              title: "The Clinical Explanation",
              text: "Specialty clinics enroll sicker patients who may respond more to treatment (higher baseline = more room to improve). The 'asymmetry' reflects genuine effect modification, not suppression. You should do subgroup analysis by setting and report effects separately. The funnel wasn't lying — you were asking it the wrong question.",
              realCase: "In trials of intensive care interventions, smaller single-center studies often show larger effects than multicenter trials — not bias, but case-mix differences."
            },
            {
              id: 'both_true',
              type: 'outcome',
              consequence: 'good',
              title: "The Nuanced Truth",
              text: "Heterogeneity AND publication bias can coexist. You stratify by setting and STILL see asymmetry within strata. You report: 'Effect modification by setting accounts for SOME asymmetry; residual asymmetry suggests possible publication bias.' You've separated the explainable from the suspicious.",
              realCase: "This layered analysis is the gold standard. First explain what you can clinically, then assess residual asymmetry for bias."
            }
          ]
        }
      },
      {
        type: 'clinical-guide',
        content: {
          title: "Funnel Plot Interpretation Checklist",
          items: [
            "LOOK: Is there asymmetry? Which direction? Which corner is 'missing'?",
            "CONTOUR: Do missing studies fall in significant or non-significant regions?",
            "COUNT: Do you have at least 10 studies? (Fewer = unreliable assessment)",
            "CHECK: Do small and large studies differ systematically (population, setting, quality)?",
            "TEST: Run Egger's test — but remember it's suggestive, not definitive",
            "SEARCH: Are there unpublished registered trials?",
            "COMPARE: Do industry-sponsored studies differ from independent ones?",
            "REPORT: Describe the assessment process, not just the conclusion"
          ]
        }
      },
      {
        type: 'cycle-return',
        content: {
          principle: "The funnel reveals what the forest conceals. Learn to read its shape — but remember, asymmetry is a fingerprint that can belong to multiple suspects."
        }
      },
      {
        type: 'quiz',
        content: {
          question: "In a contour-enhanced funnel plot, if 'missing' studies would fall in the p>0.05 (non-significant) region, this most strongly suggests:",
          options: [
            { id: 'a', text: "Heterogeneity between studies", correct: false },
            { id: 'b', text: "Publication bias — non-significant studies weren't published", correct: true },
            { id: 'c', text: "The meta-analysis has too few studies", correct: false },
            { id: 'd', text: "The effect measure is inappropriate", correct: false }
          ],
          explanation: "When missing studies fall in non-significant regions, it suggests they weren't published BECAUSE they weren't significant — the hallmark of publication bias. If missing studies fell in significant regions, other explanations (heterogeneity, different populations) would be more likely. Contour enhancement helps make this distinction."
        }
      },
      {
        type: 'key-takeaways',
        content: {
          takeaways: [
            "Funnel plots should be symmetric IF no publication bias (larger studies clustered, smaller studies spread)",
            "Contour-enhanced funnel plots add significance regions to help distinguish bias from heterogeneity",
            "Missing studies in non-significant regions strongly suggest publication bias",
            "Missing studies in significant regions suggest other explanations (heterogeneity, true effect variation)",
            "Visual inspection is subjective — always combine with statistical tests"
          ],
          actionItem: "Practice reading funnel plots with the interactive tool. Start identifying the gap pattern — where would missing studies fall?"
        }
      }
    ]
  },

  // MODULE 3: THE STATISTICAL TESTS
  {
    id: 3,
    title: "The Tests",
    subtitle: "Statistical Detection",
    estimatedMinutes: 30,
    slides: [
      {
        type: 'learning-objectives',
        content: {
          intro: "By the end of this module, you will be able to:",
          objectives: [
            "Calculate and interpret Egger's regression test for funnel plot asymmetry",
            "Explain when to use Begg's test vs Egger's test",
            "Recognize the limitations of statistical tests with <10 studies",
            "Interpret discordant test results (Egger's positive, Begg's negative)",
            "Apply appropriate thresholds (p<0.10) and understand why they differ from conventional p<0.05"
          ]
        }
      },
      {
        type: 'principle',
        content: {
          number: "III",
          text: "The eye suspects, but the test quantifies. Yet no test can see what truly happened — only what the data suggest."
        }
      },
      {
        type: 'rhetoric',
        content: {
          question: "Have you not considered that Egger's regression reduces the complex question of hidden evidence to a single p-value — powerful yet perilous, suggestive yet not conclusive?"
        }
      },
      {
        type: 'content',
        content: {
          title: "Egger's Regression Test",
          sections: [
            {
              heading: "The Logic",
              items: [
                "Regress effect size (standardized by SE) against precision (1/SE)",
                "If NO bias: intercept should be near zero",
                "If bias toward positive results: positive intercept",
                "The slope reflects the true underlying effect"
              ]
            },
            {
              heading: "The Equation",
              items: [
                "Effect/SE = intercept + slope × (1/SE)",
                "Test whether intercept differs from 0",
                "Significant p-value (typically p<0.10) suggests asymmetry",
                "More liberal threshold (0.10 vs 0.05) because test has low power"
              ]
            },
            {
              heading: "Limitations",
              items: [
                "Low power with <10 studies — may miss real bias",
                "High false positive rate with heterogeneity",
                "Assumes linear relationship between effect and precision",
                "Different variants exist (Egger, Peters, Harbord) for different outcomes"
              ]
            }
          ]
        }
      },
      {
        type: 'tool-egger',
        content: {
          id: 'egger-test',
          title: "Egger's Test Calculator",
          description: "Enter study data to calculate Egger's regression test for funnel plot asymmetry."
        }
      },
      {
        type: 'content',
        content: {
          title: "Begg's Rank Correlation",
          sections: [
            {
              heading: "The Method",
              items: [
                "Correlate effect size ranks with variance ranks",
                "Uses Kendall's tau correlation",
                "If NO bias: no correlation (tau near 0)",
                "If bias: positive correlation (large effects with large variance)"
              ]
            },
            {
              heading: "Comparison with Egger's",
              items: [
                "Less powerful than Egger's (rank-based loses information)",
                "But makes fewer parametric assumptions",
                "Better for non-normally distributed effects",
                "Often reported alongside Egger's for completeness"
              ]
            }
          ]
        }
      },
      {
        type: 'content',
        content: {
          title: "Harbord's Test for Binary Outcomes",
          sections: [
            {
              heading: "Why a Different Test for Binary Data?",
              items: [
                "Egger's test has inflated Type I error with binary outcomes (OR, RR)",
                "The relationship between effect and precision is mathematically constrained for ratios",
                "Harbord's test uses score-based statistics that account for this",
                "Peters' test is an alternative using sample size rather than SE"
              ]
            },
            {
              heading: "When to Use Harbord's vs Egger's",
              items: [
                "BINARY outcomes (OR, RR, RD): Use Harbord's or Peters' test",
                "CONTINUOUS outcomes (MD, SMD): Use Egger's test",
                "SURVIVAL outcomes (HR): Harbord's or modified tests",
                "Rule: Match the test to your effect measure"
              ]
            },
            {
              heading: "Peters' Test (Alternative)",
              items: [
                "Regress effect on 1/n (inverse sample size) instead of SE",
                "Less prone to false positives than Egger's for OR",
                "Recommended by Cochrane for meta-analyses of odds ratios",
                "Similar interpretation: significant intercept suggests asymmetry"
              ]
            }
          ]
        }
      },
      {
        type: 'content',
        content: {
          title: "Newer Alternatives: Doi Plot and LFK Index",
          sections: [
            {
              heading: "Doi Plot",
              items: [
                "Plots Z-scores against a normal quantile (|Z|) axis",
                "Creates an asymmetric pattern that's easier to read than funnel plots",
                "Major asymmetry: obvious deviation from the line",
                "More sensitive to asymmetry patterns than traditional funnel"
              ]
            },
            {
              heading: "LFK Index",
              items: [
                "Quantifies Doi plot asymmetry as a single number",
                "LFK > 1 or < -1: Minor asymmetry",
                "LFK > 2 or < -2: Major asymmetry",
                "Provides objective measure rather than relying on visual assessment"
              ]
            },
            {
              heading: "When to Use",
              items: [
                "Consider as supplement to funnel plot + Egger's",
                "Particularly useful when visual assessment is ambiguous",
                "Available in some meta-analysis software (R metafor, Stata)",
                "Not yet universally adopted — mention if used"
              ]
            }
          ]
        }
      },
      {
        type: 'case-file',
        content: {
          caseNumber: "CASE 3A",
          title: "When Tests Disagree: The Statin Example",
          source: "Naci et al., BMJ 2013 — Meta-analysis of statins for mortality",
          timeline: [
            { year: "The Data", text: "29 trials of statins vs placebo/usual care for all-cause mortality. Forest plot shows significant benefit (RR 0.86). Funnel plot shows... some asymmetry.", type: "normal" },
            { year: "Egger's Test", text: "p = 0.12. Not significant at 0.10 threshold. Suggests no publication bias.", type: "normal" },
            { year: "Begg's Test", text: "p = 0.08. Borderline significant. Suggests possible publication bias.", type: "normal" },
            { year: "The Dilemma", text: "Tests disagree. Visual inspection shows some gap in bottom-left. What to conclude?", type: "buried" },
            { year: "The Resolution", text: "Authors report BOTH tests, note discordance, state 'some evidence of small-study effects.' Transparency > certainty.", type: "revealed" }
          ],
          realData: {
            eggerP: "p = 0.12 (not significant)",
            beggP: "p = 0.08 (borderline)",
            studies: "29 trials",
            visualAssessment: "Mild asymmetry visible",
            conclusion: "Uncertain — reported with caveats"
          }
        }
      },
      {
        type: 'decision-tree',
        content: {
          title: "Interpreting Discordant Tests",
          situation: "Your meta-analysis has 18 studies. Egger's test: p=0.04 (significant). Begg's test: p=0.21 (not significant). Visual inspection shows mild asymmetry. Your funnel has moderate heterogeneity (I²=55%). What do you conclude?",
          nodes: [
            {
              id: 'start',
              question: "Egger's is significant, Begg's is not, visual shows mild asymmetry. What's your interpretation?",
              branches: [
                { id: 'a', text: "Egger's is more powerful — publication bias is present", nextNode: 'egger_rules' },
                { id: 'b', text: "Tests disagree — evidence is inconclusive", nextNode: 'inconclusive' },
                { id: 'c', text: "Check if heterogeneity could explain the discordance", nextNode: 'heterogeneity' }
              ]
            },
            {
              id: 'egger_rules',
              type: 'outcome',
              consequence: 'bad',
              title: "The Oversimplification",
              text: "While Egger's IS more powerful, it's also more prone to false positives when heterogeneity exists. Your I²=55% is substantial. The 'asymmetry' Egger's detected may be effect modification, not bias. Concluding 'bias present' without addressing heterogeneity is premature.",
              realCase: "Sterne et al. showed that Egger's test has inflated Type I error rates when heterogeneity is present. The test detects asymmetry, not bias specifically."
            },
            {
              id: 'inconclusive',
              type: 'outcome',
              consequence: 'neutral',
              title: "The Honest Assessment",
              text: "You report: 'Evidence for publication bias is mixed. Egger's test was significant (p=0.04) but Begg's was not (p=0.21). Visual asymmetry is mild. In the presence of moderate heterogeneity (I²=55%), these tests have limited reliability. We cannot confidently assess publication bias.' This is honest but unhelpful for decision-making.",
              realCase: "Many meta-analyses reach this uncomfortable middle ground. Transparency about uncertainty is valuable, but readers need guidance."
            },
            {
              id: 'heterogeneity',
              question: "You investigate further. Small studies were from Asia (different populations), large studies from Europe/US. Disease severity differed by region. What now?",
              branches: [
                { id: 'd', text: "Heterogeneity explains the asymmetry — it's not publication bias", nextNode: 'explained' },
                { id: 'e', text: "Do stratified analysis by region and test within strata", nextNode: 'stratify' }
              ]
            },
            {
              id: 'explained',
              type: 'outcome',
              consequence: 'good',
              title: "The Clinical Insight",
              text: "The apparent 'asymmetry' reflects genuine regional differences in populations and disease. Asian populations had more severe disease (baseline risk 25% vs 15%), explaining larger effects in smaller trials. This is heterogeneity, not suppression. You report this finding — it's clinically important and explains the discordant tests.",
              realCase: "In cardiovascular trials, regional differences in baseline risk routinely cause heterogeneity that can mimic publication bias on funnel plots."
            },
            {
              id: 'stratify',
              type: 'outcome',
              consequence: 'good',
              title: "The Stratified Assessment",
              text: "Within Asian studies (8 trials): no asymmetry, Egger p=0.45. Within European studies (10 trials): no asymmetry, Egger p=0.38. The POOLED asymmetry was confounded by region. Publication bias is now considered unlikely — the heterogeneity between regions created the apparent funnel asymmetry.",
              realCase: "Stratified funnel plots (by subgroup) can reveal that apparent bias is actually confounding by a third variable."
            }
          ]
        }
      },
      {
        type: 'clinical-guide',
        content: {
          title: "Statistical Test Interpretation Guide",
          items: [
            "SAMPLE SIZE: With <10 studies, tests have very low power — don't trust a negative result",
            "CONCORDANCE: If Egger's, Begg's, AND visual all agree, confidence is higher",
            "HETEROGENEITY: High I² inflates false positives for Egger's — interpret cautiously",
            "EFFECT MEASURE: Use Peters' test for OR (better properties than Egger's for binary outcomes)",
            "REPORT BOTH: Always report Egger's AND visual assessment, note any discordance",
            "THRESHOLD: p<0.10 is conventional (not 0.05) because of low power",
            "NEVER CONCLUDE 'NO BIAS': A non-significant test doesn't prove absence of bias"
          ]
        }
      },
      {
        type: 'content',
        content: {
          title: "When Publication Bias Is Less of a Concern",
          sections: [
            {
              heading: "Signs That Reduce Concern",
              items: [
                "HARD OUTCOMES: Mortality, hospitalization — harder to manipulate or spin than 'quality of life'",
                "LARGE TRIALS: Fewer small studies means less selective publishing opportunity",
                "PROSPECTIVE REGISTRATION: All trials registered before starting, with pre-specified outcomes",
                "INDEPENDENT REPLICATION: Non-industry trials confirm industry findings",
                "SYMMETRIC FUNNEL: Visual inspection shows no gap, tests negative, registry search finds no missing trials"
              ]
            },
            {
              heading: "The Balanced Perspective",
              items: [
                "Not every asymmetric funnel means suppression",
                "Not every meta-analysis of drug trials is biased",
                "Publication bias is ONE threat to validity — consider others too",
                "The goal is accurate assessment, not maximum skepticism"
              ]
            }
          ]
        }
      },
      {
        type: 'contrast',
        content: {
          title: "Two Meta-Analyses: Different Risk Profiles",
          darkSide: {
            header: "HIGH RISK for Publication Bias",
            items: [
              "Subjective outcome (pain scores, depression scales)",
              "All trials industry-funded",
              "Multiple small trials, few large confirmatory",
              "No prospective registration",
              "Asymmetric funnel, all published trials positive",
              "Registry shows unpublished completed trials"
            ],
            consequence: "Interpretation: Treat effect estimates with high suspicion. Apply corrections, search for unpublished data, downgrade GRADE for bias."
          },
          lightSide: {
            header: "LOW RISK for Publication Bias",
            items: [
              "Objective outcome (all-cause mortality)",
              "Mix of industry and government-funded trials",
              "Includes large multicenter confirmatory trials",
              "Most trials prospectively registered",
              "Symmetric funnel, mix of positive and null results",
              "Registry search finds no missing completed trials"
            ],
            consequence: "Interpretation: Publication bias is a lesser concern (not zero, but modest). Focus assessment on other biases: allocation concealment, attrition, etc."
          }
        }
      },
      {
        type: 'cycle-return',
        content: {
          principle: "The eye suspects, but the test quantifies. Yet remember: the test detects asymmetry, not bias. Asymmetry is a clue; bias is a conclusion that requires judgment."
        }
      },
      {
        type: 'quiz',
        content: {
          question: "Your meta-analysis has 8 studies. Egger's test gives p=0.23. You should conclude:",
          options: [
            { id: 'a', text: "No publication bias is present", correct: false },
            { id: 'b', text: "Publication bias may or may not be present — the test has low power with 8 studies", correct: true },
            { id: 'c', text: "The meta-analysis is valid and unbiased", correct: false },
            { id: 'd', text: "You need to use Begg's test instead", correct: false }
          ],
          explanation: "With only 8 studies, Egger's test has very low power to detect publication bias even when it exists. A non-significant result does NOT mean no bias — it means the test couldn't detect it. Cochrane recommends at least 10 studies for meaningful interpretation of these tests. You should report the test result but not over-interpret a negative finding."
        }
      },
      {
        type: 'common-mistakes',
        content: {
          mistakes: [
            { mistake: "Concluding 'no bias' from non-significant test", correction: "Non-significant tests may lack power — especially with <10 studies. Say 'insufficient evidence to detect bias.'" },
            { mistake: "Ignoring heterogeneity when interpreting Egger's", correction: "High I² increases false positive rate for Egger's. Check for confounders before concluding bias." },
            { mistake: "Only using one test", correction: "Report Egger's AND visual assessment. Note concordance or discordance. Neither alone is sufficient." },
            { mistake: "Using standard p<0.05 threshold", correction: "Convention uses p<0.10 for publication bias tests because of low power. Adjust your interpretation." }
          ]
        }
      },
      {
        type: 'key-takeaways',
        content: {
          takeaways: [
            "Egger's test: regression-based, more powerful but sensitive to heterogeneity",
            "Begg's test: rank-based, less powerful but more robust to distributional assumptions",
            "Use p<0.10 threshold (not 0.05) due to low power of these tests",
            "With <10 studies, tests have very limited value — rely more on visual assessment and external evidence",
            "Discordant tests often indicate heterogeneity is confounding the assessment"
          ],
          actionItem: "For your next meta-analysis, plan to report: visual funnel plot, Egger's test with p-value, sample size, and heterogeneity (I²) to contextualize findings."
        }
      }
    ]
  },

  // MODULE 4: THE CORRECTION
  {
    id: 4,
    title: "The Correction",
    subtitle: "Adjusting for Bias",
    estimatedMinutes: 35,
    slides: [
      {
        type: 'learning-objectives',
        content: {
          intro: "By the end of this module, you will be able to:",
          objectives: [
            "Apply and interpret the Trim-and-Fill method and understand its assumptions",
            "Explain PET-PEESE regression and when it outperforms Trim-and-Fill",
            "Use the Fail-Safe N to assess robustness (with appropriate caveats)",
            "Describe selection models (Copas, 3PSM) and their role in sensitivity analysis",
            "Choose appropriate correction methods based on data characteristics"
          ]
        }
      },
      {
        type: 'principle',
        content: {
          number: "IV",
          text: "To estimate what was hidden is to guess at shadows — necessary, but never mistake the estimate for the truth."
        }
      },
      {
        type: 'rhetoric',
        content: {
          question: "Have you not considered that trim-and-fill 'imputes' studies that may never have existed — a statistical conjecture, not a recovery of buried evidence?"
        }
      },
      {
        type: 'content',
        content: {
          title: "Trim and Fill Method",
          sections: [
            {
              heading: "The Logic",
              items: [
                "1. TRIM: Remove the most extreme small studies from the asymmetric side",
                "2. ESTIMATE: Calculate pooled effect from remaining (symmetric) studies",
                "3. FILL: Add imputed mirror-image studies to create symmetry",
                "4. RE-ESTIMATE: Calculate adjusted pooled effect including imputed studies"
              ]
            },
            {
              heading: "The Assumption",
              items: [
                "Asymmetry is ENTIRELY due to suppression of small negative studies",
                "The 'true' funnel would be symmetric around the true effect",
                "Missing studies are mirror images of observed asymmetric studies"
              ]
            },
            {
              heading: "The Limitations",
              items: [
                "If asymmetry is due to heterogeneity (not bias), trim-and-fill OVERCORRECTS",
                "Imputed studies are fictional — they may not represent real unpublished trials",
                "Does not recover actual missing data — just estimates what they might show",
                "Performance varies; can under- or over-correct depending on true mechanism"
              ]
            }
          ]
        }
      },
      {
        type: 'tool-trimfill',
        content: {
          id: 'trim-fill-tool',
          title: "Trim and Fill Visualizer",
          description: "See how trim-and-fill imputes missing studies and adjusts the pooled effect."
        }
      },
      {
        type: 'content',
        content: {
          title: "PET-PEESE: Precision-Effect Testing",
          sections: [
            {
              heading: "What is PET-PEESE?",
              items: [
                "An alternative to trim-and-fill that estimates bias-corrected effects via regression",
                "PET = Precision-Effect Test: regress effect on SE, intercept estimates bias-corrected effect",
                "PEESE = Precision-Effect Estimate with Standard Error: regress effect on SE², better when true effect exists",
                "Two-step conditional estimator: Use PET to test if effect exists, then PEESE to estimate it"
              ]
            },
            {
              heading: "The Two-Step Process",
              items: [
                "STEP 1 (PET): Regress effect sizes on standard errors (effect = β₀ + β₁×SE)",
                "If PET intercept β₀ is significant (p<0.10): True effect likely exists → use PEESE",
                "STEP 2 (PEESE): Regress effect sizes on variance (effect = β₀ + β₁×SE²)",
                "PEESE intercept provides bias-corrected effect estimate",
                "If PET not significant: Conclude no evidence for true effect beyond bias"
              ]
            },
            {
              heading: "Advantages over Trim-and-Fill",
              items: [
                "Better performance in simulations when publication bias is moderate to severe",
                "Provides explicit test of whether true effect exists after accounting for bias",
                "Less assumption-dependent than selection models",
                "Works with meta-regression framework — can include moderators"
              ]
            },
            {
              heading: "Limitations",
              items: [
                "Requires 10+ studies for reliable estimates",
                "Assumes linear relationship between effect and SE/variance",
                "Can over-correct when heterogeneity explains small-study effects",
                "PET can have low power to detect true effects"
              ]
            }
          ]
        }
      },
      {
        type: 'tool-petpeese',
        content: {
          id: 'pet-peese-tool',
          title: "PET-PEESE Calculator",
          description: "Enter your meta-analysis data to calculate PET and PEESE bias-corrected estimates."
        }
      },
      {
        type: 'case-file',
        content: {
          caseNumber: "CASE 4A",
          title: "Trim-and-Fill vs Reality: The Antidepressant Test",
          source: "Turner et al. NEJM 2008 — Comparing estimate to FDA truth",
          timeline: [
            { year: "The Opportunity", text: "Turner had BOTH: published literature AND FDA's complete trial registry. This allowed a rare test: Does trim-and-fill correctly estimate the unpublished data?", type: "normal" },
            { year: "Published Only", text: "Meta-analysis of published trials: effect size = 0.41 (strongly effective)", type: "normal" },
            { year: "Trim-and-Fill", text: "Applied to published data: imputes 6 studies, adjusted effect = 0.34. A 17% reduction.", type: "normal" },
            { year: "FDA Truth", text: "Including ALL FDA trials (published + unpublished): effect size = 0.31. True reduction was 24%.", type: "revealed" },
            { year: "The Verdict", text: "Trim-and-fill UNDERESTIMATED the bias. It corrected somewhat, but not enough. Better than nothing, but not a substitute for actual data.", type: "revealed" }
          ],
          realData: {
            publishedEffect: "d = 0.41",
            trimFillEffect: "d = 0.34 (17% reduction)",
            trueEffect: "d = 0.31 (24% reduction)",
            trimFillAccuracy: "Corrected ~70% of the bias"
          }
        }
      },
      {
        type: 'content',
        content: {
          title: "Selection Models",
          sections: [
            {
              heading: "The Concept",
              items: [
                "Explicitly model the PROBABILITY of publication",
                "P(published) depends on p-value, effect direction, or statistical significance",
                "Estimate selection function parameters from the observed data",
                "Adjust effect estimate accounting for estimated selection"
              ]
            },
            {
              heading: "Common Selection Models",
              items: [
                "3PSM: Three-parameter selection model — step function at p=0.05",
                "Copas model: Continuous selection probability based on effect and variance",
                "Weight-function models: Flexible specification of selection weights"
              ]
            },
            {
              heading: "Advantages over Trim-and-Fill",
              items: [
                "Explicitly models the selection mechanism",
                "Can accommodate more complex selection patterns",
                "Provides uncertainty intervals that account for selection uncertainty"
              ]
            },
            {
              heading: "Disadvantages",
              items: [
                "Requires assumptions about the selection function",
                "May be unstable with few studies",
                "Multiple models can give different answers"
              ]
            }
          ]
        }
      },
      {
        type: 'content',
        content: {
          title: "P-Curve Analysis",
          sections: [
            {
              heading: "The Logic",
              items: [
                "Examine the DISTRIBUTION of significant p-values (p<0.05)",
                "If true effect exists: p-curve should be RIGHT-SKEWED (many p<0.01)",
                "If no effect + selective reporting: p-curve is FLAT or LEFT-SKEWED",
                "If p-hacking: spikes just below 0.05"
              ]
            },
            {
              heading: "Interpretation",
              items: [
                "Right-skewed p-curve: Evidence for true effect",
                "Flat p-curve: Suggests no true effect (or underpowered studies)",
                "Left-skewed: Suggests selective reporting or p-hacking",
                "Spike at 0.04-0.05: Classic p-hacking signature"
              ]
            }
          ]
        }
      },
      {
        type: 'tool-pcurve',
        content: {
          id: 'pcurve-tool',
          title: "P-Curve Analyzer",
          description: "Enter p-values from significant studies to assess evidential value."
        }
      },
      {
        type: 'content',
        content: {
          title: "Fail-Safe N (Rosenthal's Method)",
          sections: [
            {
              heading: "The Concept",
              items: [
                "How many unpublished null studies would need to exist to make your result non-significant?",
                "If the number is large, the finding is 'robust' to publication bias",
                "If the number is small, a few file-drawer studies could nullify your conclusion"
              ]
            },
            {
              heading: "The Formula",
              items: [
                "N = (ΣZ / 1.645)² - k, where k = number of studies",
                "Alternatively: N = k × (mean Z / 1.645)² - k",
                "Rule of thumb: N > 5k + 10 suggests robustness"
              ]
            },
            {
              heading: "Limitations (Important!)",
              items: [
                "Assumes missing studies have EXACTLY zero effect (unrealistic)",
                "Doesn't account for systematic bias in effect direction",
                "Can give misleadingly large N when effects are inflated",
                "Modern methods (selection models, trim-and-fill) are preferred"
              ]
            }
          ]
        }
      },
      {
        type: 'tool-failsafe',
        content: {
          id: 'failsafe-tool',
          title: "Fail-Safe N Calculator",
          description: "Calculate how many null studies would need to exist to nullify your meta-analytic result."
        }
      },
      {
        type: 'contrast',
        content: {
          title: "Two Approaches to Bias Correction",
          darkSide: {
            header: "The Overconfident Analyst",
            items: [
              "Runs trim-and-fill once",
              "Reports adjusted estimate as 'true effect'",
              "Ignores model assumptions",
              "Dismisses discordant methods",
              "Claims bias has been 'corrected'"
            ],
            consequence: "Result: False precision. Readers believe the adjusted number. If assumptions wrong, they're misled. The overconfidence perpetuates poor practice."
          },
          lightSide: {
            header: "The Humble Analyst",
            items: [
              "Runs multiple methods (trim-fill, selection models, PET-PEESE)",
              "Reports a RANGE of plausible effects",
              "States assumptions explicitly",
              "Notes when methods disagree (that's informative!)",
              "Acknowledges uncertainty in all corrections"
            ],
            consequence: "Result: Honest uncertainty. Readers see the bounds. Decision-makers understand the risk. Science advances through acknowledged limitation."
          }
        }
      },
      {
        type: 'decision-tree',
        content: {
          title: "Choosing a Correction Method",
          situation: "Your meta-analysis shows significant funnel asymmetry (Egger p=0.02). You want to estimate a bias-adjusted effect. Which method should you use?",
          nodes: [
            {
              id: 'start',
              question: "You've detected likely publication bias. How do you adjust your estimate?",
              branches: [
                { id: 'a', text: "Use trim-and-fill — it's the most widely recognized", nextNode: 'trimfill' },
                { id: 'b', text: "Use a selection model — it models the mechanism", nextNode: 'selection' },
                { id: 'c', text: "Report the unadjusted estimate with caveats — corrections are unreliable", nextNode: 'noadjust' }
              ]
            },
            {
              id: 'trimfill',
              question: "Trim-and-fill imputes 4 studies. Adjusted effect drops from OR 0.65 to OR 0.78. Do you report this as the 'true' effect?",
              branches: [
                { id: 'd', text: "Yes — the adjusted estimate corrects for bias", nextNode: 'overclaim' },
                { id: 'e', text: "Report both estimates as sensitivity analysis", nextNode: 'sensitivity' }
              ]
            },
            {
              id: 'overclaim',
              type: 'outcome',
              consequence: 'bad',
              title: "The False Certainty",
              text: "Trim-and-fill corrects for an ASSUMED mechanism. If the asymmetry was partly heterogeneity (not bias), you've overcorrected. If it was severe bias, you've undercorrected. Presenting the adjusted estimate as 'truth' gives false precision. You don't know which scenario applies.",
              realCase: "Turner's antidepressant analysis showed trim-and-fill only captured ~70% of the actual bias — still substantial residual inflation."
            },
            {
              id: 'sensitivity',
              type: 'outcome',
              consequence: 'good',
              title: "The Honest Range",
              text: "You report: 'Unadjusted OR 0.65 (0.55-0.77). Trim-and-fill adjusted OR 0.78 (0.65-0.94). The true effect likely lies within this range.' You've conveyed uncertainty appropriately. Readers can see that conclusions are sensitive to bias assumptions.",
              realCase: "This approach — reporting unadjusted and adjusted as bounds — is recommended by several methodologists."
            },
            {
              id: 'selection',
              question: "You run a 3-parameter selection model. It gives OR 0.82 (0.68-0.99), suggesting more bias than trim-and-fill. A Copas model gives OR 0.75 (0.60-0.93), suggesting less. What do you do?",
              branches: [
                { id: 'f', text: "Average the models", nextNode: 'average' },
                { id: 'g', text: "Report all models as sensitivity analyses showing range of plausible adjustments", nextNode: 'range' }
              ]
            },
            {
              id: 'average',
              type: 'outcome',
              consequence: 'bad',
              title: "The False Synthesis",
              text: "Averaging models with different assumptions doesn't give you 'the truth' — it gives you a number that may not correspond to any meaningful quantity. The models disagree because they make different assumptions. The disagreement IS the information, not something to be averaged away.",
              realCase: "Model averaging in bias-correction can be appropriate with proper weighting, but simple averaging of point estimates obscures the model uncertainty that's the key finding."
            },
            {
              id: 'range',
              type: 'outcome',
              consequence: 'good',
              title: "The Full Picture",
              text: "You report: 'Adjustments range from OR 0.75 (Copas) to OR 0.82 (3PSM). All adjusted estimates remain significant but are attenuated from the unadjusted OR 0.65. We cannot determine which selection model best represents the true mechanism, but results suggest the unadjusted estimate is inflated by approximately 15-25%.'",
              realCase: "This transparent reporting of model uncertainty follows best practices for sensitivity analysis."
            },
            {
              id: 'noadjust',
              type: 'outcome',
              consequence: 'neutral',
              title: "The Conservative Choice",
              text: "You report the unadjusted effect with a clear warning: 'Funnel plot asymmetry suggests publication bias (Egger p=0.02). The reported effect (OR 0.65) is likely inflated. Bias-adjusted estimates vary depending on assumptions. Interpret with caution.' This is honest but may frustrate readers wanting a 'corrected' number.",
              realCase: "Some methodologists argue this is the only defensible approach — corrections are too model-dependent to be reliable."
            }
          ]
        }
      },
      {
        type: 'clinical-guide',
        content: {
          title: "Bias Correction Best Practices",
          items: [
            "NEVER claim an adjusted estimate is the 'true' effect — it's a sensitivity analysis",
            "REPORT BOTH: Original estimate AND adjusted estimate(s) as bounding scenarios",
            "TRY MULTIPLE METHODS: If they all agree, more confidence; if they disagree, that's important",
            "SEEK ACTUAL DATA: Registry searches and FOIA are better than statistical correction",
            "CONSIDER THE MECHANISM: Is asymmetry likely bias, heterogeneity, or both?",
            "STATE ASSUMPTIONS: Make clear what assumptions each correction method requires",
            "DOWNGRADE GRADE: If substantial bias likely, reduce certainty regardless of adjustment"
          ]
        }
      },
      {
        type: 'cycle-return',
        content: {
          principle: "To estimate what was hidden is to guess at shadows. Statistical corrections are tools for sensitivity analysis, not truth recovery. The only sure path to truth is finding the actual hidden data."
        }
      },
      {
        type: 'quiz',
        content: {
          question: "Trim-and-fill adjusts your pooled effect from OR 0.60 to OR 0.75. What can you conclude?",
          options: [
            { id: 'a', text: "The true effect is OR 0.75", correct: false },
            { id: 'b', text: "The true effect lies somewhere between OR 0.60 and OR 0.75", correct: false },
            { id: 'c', text: "If publication bias is the cause of asymmetry, the effect may be closer to OR 0.75, but this correction is uncertain", correct: true },
            { id: 'd', text: "The meta-analysis is unreliable and should not be published", correct: false }
          ],
          explanation: "Trim-and-fill provides a plausible adjustment IF publication bias is the true cause of asymmetry AND IF the missing studies would be mirror-images of observed studies. These are strong assumptions. The adjusted estimate is a sensitivity analysis, not a definitive correction. Turner's comparison showed trim-and-fill only partially corrected for actual bias."
        }
      },
      {
        type: 'patient-communication',
        content: {
          scenario: "A patient asks about a new medication. You know a recent meta-analysis supports it, but you're aware of publication bias concerns.",
          script: "The research generally supports this medication, but I want to be honest with you — studies with positive results are more likely to get published than negative ones. The overall evidence suggests benefit, but the true effect might be somewhat smaller than the published studies show. Based on your specific situation, I think the potential benefits still outweigh the risks, but let's monitor closely and adjust if needed.",
          keyPoints: [
            "Acknowledge uncertainty without causing undue alarm",
            "Explain publication bias in accessible terms",
            "Frame in context of patient's individual risk-benefit",
            "Emphasize shared decision-making and monitoring"
          ]
        }
      },
      {
        type: 'key-takeaways',
        content: {
          takeaways: [
            "Trim-and-Fill imputes mirror-image studies — corrects ~70% of bias in validation studies",
            "PET-PEESE uses regression to estimate bias-corrected effects — two-step conditional estimator",
            "Selection models (3PSM, Copas) explicitly model publication probability — more flexible but complex",
            "P-curve analyzes distribution of p-values to detect p-hacking or evidential value",
            "All corrections are sensitivity analyses, not truth recovery — finding actual data is always better"
          ],
          actionItem: "For your next meta-analysis, run both trim-and-fill AND PET-PEESE as sensitivity analyses. Report both alongside your main estimate."
        }
      }
    ]
  },

  // MODULE 5: THE HUNT
  {
    id: 5,
    title: "The Hunt",
    subtitle: "Finding Hidden Evidence",
    estimatedMinutes: 25,
    slides: [
      {
        type: 'learning-objectives',
        content: {
          intro: "By the end of this module, you will be able to:",
          objectives: [
            "Search ClinicalTrials.gov and other registries for unpublished studies",
            "File FOIA requests and navigate regulatory document access",
            "Evaluate the quality and usability of grey literature sources",
            "Contact trialists systematically to request unpublished data",
            "Build a comprehensive search strategy that goes beyond published literature"
          ]
        }
      },
      {
        type: 'principle',
        content: {
          number: "V",
          text: "Better to find one buried study than to impute ten imaginary ones."
        }
      },
      {
        type: 'rhetoric',
        content: {
          question: "Have you not seen how ClinicalTrials.gov records what was STARTED — and comparing to what was PUBLISHED reveals the graveyard of abandoned results?"
        }
      },
      {
        type: 'case-file',
        content: {
          caseNumber: "CASE 5A",
          title: "The Registry Detective: Ross's Investigation",
          source: "Ross et al., JAMA 2009 — Tracking trials from registration to publication",
          timeline: [
            { year: "The Method", text: "Ross identified all trials registered on ClinicalTrials.gov in 2002. Followed them for 5 years. Did they get published?", type: "normal" },
            { year: "The Findings", text: "Of 677 registered trials, only 46% published within 5 years. Positive trials: 61% published. Negative/null trials: 34% published.", type: "buried" },
            { year: "The Gap", text: "Industry-funded trials: 40% published. NIH-funded: 56%. Academic non-profit: 56%. Industry was worst at publishing.", type: "buried" },
            { year: "The Implication", text: "Registries expose what publication counts miss. The evidence base visible to doctors is less than half the evidence base that exists.", type: "revealed" }
          ],
          realData: {
            registered: "677 trials in 2002",
            published5yr: "46% published within 5 years",
            positivePublished: "61%",
            negativePublished: "34%",
            industryPublished: "40%",
            academicPublished: "56%"
          }
        }
      },
      {
        type: 'content',
        content: {
          title: "Trial Registry Searching",
          sections: [
            {
              heading: "Key Registries",
              items: [
                "ClinicalTrials.gov — Largest, US-based, required for many trials",
                "ISRCTN — International, especially European trials",
                "EU Clinical Trials Register — European Medicines Agency database",
                "WHO ICTRP — Search portal for multiple registries worldwide",
                "Disease-specific registries (e.g., oncology, cardiovascular)"
              ]
            },
            {
              heading: "What to Look For",
              items: [
                "COMPLETED trials with no published results",
                "Trials where 'completion date' was years ago",
                "Trials listed as 'terminated' — why?",
                "Discrepancies: registered primary outcome ≠ published primary outcome"
              ]
            },
            {
              heading: "Search Strategy",
              items: [
                "Search your drug/intervention in registry",
                "Filter for completed/terminated trials",
                "Cross-reference with your meta-analysis: which trials did you miss?",
                "Contact trialists for unpublished data"
              ]
            }
          ]
        }
      },
      {
        type: 'tool-registry',
        content: {
          id: 'registry-tracker',
          title: "Registry Gap Finder",
          description: "Compare registered vs. published trials to identify potentially missing studies."
        }
      },
      {
        type: 'rhetoric',
        content: {
          question: "Have you not considered that of all the trials ever started, nearly HALF are never published? That the graveyard of science holds as many studies as the library?"
        }
      },
      {
        type: 'case-file',
        content: {
          caseNumber: "CASE 5B",
          title: "AllTrials: The Movement to Open the Vaults",
          source: "AllTrials Campaign + Goldacre, Bad Pharma, 2012",
          timeline: [
            { year: "2012", text: "Ben Goldacre publishes 'Bad Pharma.' Documents systematic suppression across the industry. Calls for transparency.", type: "normal" },
            { year: "2013", text: "AllTrials campaign launches: 'All trials registered, all results reported.' Within months, 85,000 individuals and 600 organizations sign on.", type: "normal" },
            { year: "The Resistance", text: "Industry initially resists. Argues: proprietary data, competitive advantage, patient privacy. But pressure mounts.", type: "buried" },
            { year: "2015", text: "EMA adopts Policy 0070: clinical trial data will be published. GSK commits to sharing trial data. The tide begins to turn.", type: "revealed" },
            { year: "The Progress", text: "ClinicalTrials.gov now requires results reporting within 1 year. But enforcement is weak. As of 2023, ~30% of trials still don't report results on time.", type: "revealed" }
          ],
          realData: {
            campaignSignatures: "85,000+ individuals, 600+ organizations",
            currentCompliance: "~70% of trials report results within required timeframe",
            remainingGap: "~30% still don't comply",
            enforcement: "Limited — fines rarely applied",
            progress: "Significant but incomplete"
          }
        }
      },
      {
        type: 'decision-tree',
        content: {
          title: "The Stonewalled Researcher",
          situation: "You're conducting a Cochrane review. You've identified 5 unpublished industry trials on ClinicalTrials.gov. You've emailed the company three times over 6 months. No response. The company's published trials show strong efficacy. You strongly suspect the unpublished trials are negative. What do you do?",
          nodes: [
            {
              id: 'start',
              question: "The company won't share data. How do you proceed?",
              branches: [
                { id: 'a', text: "Publish the review with only published data", nextNode: 'publish_incomplete' },
                { id: 'b', text: "Escalate — formal data request through Cochrane", nextNode: 'escalate' },
                { id: 'c', text: "Try alternative routes — FOIA, EMA, litigation documents", nextNode: 'alternatives' }
              ]
            },
            {
              id: 'publish_incomplete',
              type: 'outcome',
              consequence: 'bad',
              title: "The Incomplete Truth",
              text: "Your review shows strong efficacy based on published trials. But you know 5 unpublished trials exist. You mention them in 'Limitations' but proceed anyway. Your review is cited by guidelines. The drug is widely adopted. Years later, when the unpublished data emerges, your review is discredited. You contributed to the distortion you were trying to assess.",
              realCase: "Several Cochrane reviews have been criticized for proceeding despite known unpublished trials. The pressure to publish can override scientific caution."
            },
            {
              id: 'escalate',
              question: "You escalate through Cochrane's formal channels. The company responds with 'summary data' but not individual patient data. The summary shows 'similar results to published trials.' Do you trust it?",
              branches: [
                { id: 'd', text: "Accept the summary — it's better than nothing", nextNode: 'accept_summary' },
                { id: 'e', text: "Demand full data or document the refusal", nextNode: 'demand_full' }
              ]
            },
            {
              id: 'accept_summary',
              type: 'outcome',
              consequence: 'neutral',
              title: "The Limited Victory",
              text: "You include the company's summary data. It shows modest effects, smaller than published trials. Your review now has more data — but you can't verify the company's summary. You note: 'Unpublished data provided by manufacturer; individual patient data not available for independent analysis.' You've documented the limitation transparently.",
              realCase: "Many reviews accept summary data from manufacturers. It's better than nothing, but independent verification isn't possible."
            },
            {
              id: 'demand_full',
              type: 'outcome',
              consequence: 'good',
              title: "The Documented Refusal",
              text: "The company refuses full data. You document every request, every refusal. Your review states: 'Manufacturer declined to provide individual patient data for 5 trials despite repeated requests. Summary data offered but not independently verifiable. Published evidence may overestimate efficacy.' This transparency is scientifically honest and puts the burden where it belongs.",
              realCase: "Cochrane's Tamiflu review documented years of Roche's refusals. This documentation eventually contributed to regulatory pressure for data release."
            },
            {
              id: 'alternatives',
              question: "You file a FOIA request to FDA. Six months later, you receive clinical study reports with some redactions. What do you find?",
              branches: [
                { id: 'f', text: "Unpublished trials were indeed negative — your suspicion confirmed", nextNode: 'confirmed_negative' },
                { id: 'g', text: "Unpublished trials were positive — you were wrong to suspect", nextNode: 'wrong_suspicion' }
              ]
            },
            {
              id: 'confirmed_negative',
              type: 'outcome',
              consequence: 'good',
              title: "The Truth Recovered",
              text: "The FDA data reveals: 3 of 5 unpublished trials showed no significant effect. Combined with published trials, the pooled effect drops from d=0.45 to d=0.22. Your review now reflects reality, not marketing. You've demonstrated why persistence in data hunting matters. The extra 6 months of work prevented years of overestimation.",
              realCase: "This is exactly what Turner found with antidepressants and what Jefferson found with Tamiflu. The persistence paid off."
            },
            {
              id: 'wrong_suspicion',
              type: 'outcome',
              consequence: 'neutral',
              title: "The Honest Reassurance",
              text: "The FDA data shows the unpublished trials were actually positive, similar to published results. Your suspicion was wrong. But you've now verified this independently. Your review is STRONGER because you checked. You report: 'Unpublished trials obtained via FOIA; results consistent with published trials.' Skepticism that's verified is still valuable skepticism.",
              realCase: "Not every unpublished trial is negative. But the only way to know is to obtain the data. Verification is always worthwhile."
            }
          ]
        }
      },
      {
        type: 'case-file',
        content: {
          caseNumber: "CASE 5D",
          title: "The FOIA Route: Obtaining FDA Data",
          source: "Multiple cases — Learning from Turner, Jureidini, and others",
          timeline: [
            { year: "The Problem", text: "Manufacturers submit complete trial data to FDA. But FDA isn't required to make it public. Most data stays confidential.", type: "normal" },
            { year: "The Strategy", text: "Freedom of Information Act (FOIA) requests can pry open FDA files. Request clinical study reports (CSRs), medical reviews, statistical reviews.", type: "normal" },
            { year: "The Reality", text: "FOIA requests take 6-24 months. Data is often redacted. But persistent requesters have uncovered crucial unpublished data.", type: "normal" },
            { year: "Turner's Approach", text: "Turner obtained FDA drug approval packages for 12 antidepressants. These contained ALL submitted trial data — published and unpublished. This enabled his landmark NEJM study.", type: "revealed" },
            { year: "The Lesson", text: "Regulatory data is the gold standard. It captures what was submitted for approval, not what was selectively published.", type: "revealed" }
          ],
          realData: {
            typicalFOIAtime: "6-24 months",
            successRate: "Variable — depends on request specificity",
            dataQuality: "CSRs contain far more detail than publications",
            alternatives: "EMA provides some data proactively; Canada, Australia have similar processes"
          }
        }
      },
      {
        type: 'content',
        content: {
          title: "Grey Literature Sources",
          sections: [
            {
              heading: "Conference Abstracts",
              items: [
                "Many studies present at conferences but never publish in full",
                "Search conference proceedings for your topic",
                "Positive and negative results may both appear at conferences",
                "Watch out: abstracts may have limited data quality"
              ]
            },
            {
              heading: "Dissertations and Theses",
              items: [
                "ProQuest Dissertations — extensive database",
                "OpenDOAR — repository search",
                "Students may publish null findings that wouldn't survive peer review",
                "Often contain pilot studies or unpublished substudies"
              ]
            },
            {
              heading: "Regulatory Documents",
              items: [
                "FDA approval packages (drugs.fda.gov)",
                "EMA public assessment reports (ema.europa.eu)",
                "NICE technology appraisals (UK)",
                "PBAC public summary documents (Australia)"
              ]
            },
            {
              heading: "Litigation Documents",
              items: [
                "Drug litigation (Vioxx, Neurontin, SSRIs) unsealed internal documents",
                "Drug Industry Document Archive (DIDA) at UCSF",
                "PLoS Medicine often publishes analyses of litigation documents"
              ]
            }
          ]
        }
      },
      {
        type: 'decision-tree',
        content: {
          title: "The Missing Data Dilemma",
          situation: "Your meta-analysis finds 15 published trials. A registry search reveals 8 more completed trials with no publications. You contact the trialists: 3 respond with 'negative results, not interesting enough to publish.' 5 don't respond. What do you do?",
          nodes: [
            {
              id: 'start',
              question: "You've found 8 unpublished trials. How do you proceed?",
              branches: [
                { id: 'a', text: "Proceed with the 15 published trials — unpublished data is unavailable", nextNode: 'ignore' },
                { id: 'b', text: "Try harder to obtain the unpublished data", nextNode: 'pursue' },
                { id: 'c', text: "Report both analyses: with 15 trials, and with imputation for the 8 missing", nextNode: 'dual' }
              ]
            },
            {
              id: 'ignore',
              type: 'outcome',
              consequence: 'bad',
              title: "The Willful Blindness",
              text: "You now KNOW 8 unpublished trials exist and at least 3 are likely negative. Publishing only the 15 published trials perpetuates the bias. You've identified the graveyard but walked away. Your meta-analysis will overestimate efficacy, potentially harming patients.",
              realCase: "Reviewers who identify unpublished trials and then ignore them cannot claim ignorance. Best practice requires documenting these trials and their likely impact."
            },
            {
              id: 'pursue',
              question: "You send follow-up emails to non-responders. You file FOIA requests for 2 trials that were FDA-regulated. You search for conference abstracts. What do you obtain?",
              branches: [
                { id: 'd', text: "Full data for 2 trials, conference abstracts for 3 more", nextNode: 'partial' },
                { id: 'e', text: "Nothing after 6 months of effort", nextNode: 'nothing' }
              ]
            },
            {
              id: 'partial',
              type: 'outcome',
              consequence: 'good',
              title: "The Expanded Evidence Base",
              text: "You now have 17 trials with full data + 3 with abstract-level data. Primary analysis uses 17. Sensitivity analysis adds 3 abstract-level estimates. You report: 'Of 23 known trials, 15 were published. We obtained data for 5 additional trials (3 negative). Effect reduced from 0.45 to 0.34.' You've documented the bias and partially corrected it.",
              realCase: "This level of effort — contacting trialists, FOIA, conference searches — is considered best practice for Cochrane reviews on important questions."
            },
            {
              id: 'nothing',
              type: 'outcome',
              consequence: 'neutral',
              title: "The Documented Failure",
              text: "You've exhausted reasonable options. Your review reports: 'We identified 8 unpublished completed trials (33% of known evidence base). Despite multiple contacts and FOIA requests, data could not be obtained. Three trialists confirmed negative results. Our effect estimate is likely inflated.' This is transparent and appropriately cautious.",
              realCase: "Documenting failed attempts to obtain data is valuable — it alerts readers to bias and creates a record for future investigators."
            },
            {
              id: 'dual',
              type: 'outcome',
              consequence: 'neutral',
              title: "The Sensitivity Approach",
              text: "You report published analysis (15 trials, effect=0.45) and a 'worst case' sensitivity analysis assuming the 8 missing trials had null effects (23 trials, effect=0.28). This bounds the plausible effect. You note: 'True effect likely lies between these estimates, probably closer to lower bound given evidence that missing trials had negative results.'",
              realCase: "Sensitivity analysis for missing data is a valid approach, but it should be noted that this is simulation, not data recovery."
            }
          ]
        }
      },
      {
        type: 'clinical-guide',
        content: {
          title: "The Evidence Hunter's Checklist",
          items: [
            "REGISTRIES: Search ClinicalTrials.gov, ISRCTN, WHO ICTRP for completed unpublished trials",
            "CONTACT TRIALISTS: Email corresponding authors of missing trials — many will share data",
            "REGULATORY DATA: FOIA requests to FDA, EMA public assessment reports",
            "CONFERENCES: Search society meeting abstracts (often on Embase)",
            "DISSERTATIONS: ProQuest, institutional repositories",
            "LITIGATION: Drug Industry Document Archive for specific drugs",
            "DOCUMENT EVERYTHING: Record what you searched, what you found, what you couldn't get",
            "REPORT GAPS: Even failed searches are informative — report the missing trials you found"
          ]
        }
      },
      {
        type: 'contrast',
        content: {
          title: "Two Researchers Face the Same Missing Data",
          darkSide: {
            header: "Researcher A: The Pragmatist",
            items: [
              "Finds 8 unpublished trials on registry",
              "Sends one email to each trialist",
              "Waits 2 weeks, gets no response",
              "Proceeds with published data only",
              "Reports 'comprehensive search performed'"
            ],
            consequence: "Result: Meta-analysis published showing strong effect (d=0.45). Guidelines cite it. Two years later, unpublished trials surface showing true effect d=0.22. Guidelines have to be revised."
          },
          lightSide: {
            header: "Researcher B: The Detective",
            items: [
              "Finds same 8 unpublished trials",
              "Sends 3 follow-up emails over 3 months",
              "Files FOIA requests for FDA-regulated trials",
              "Searches conference abstracts manually",
              "Obtains 5 of 8 datasets (3 negative)"
            ],
            consequence: "Result: Meta-analysis published showing modest effect (d=0.28) with full transparency about missing data. Guidelines cite conservative estimate. No future revision needed."
          }
        }
      },
      {
        type: 'decision-tree',
        content: {
          title: "The Guideline Writer's Dilemma",
          situation: "You're writing clinical guidelines for a treatment. The meta-analysis shows benefit (OR 0.70, p=0.001), but Egger's test is significant (p=0.03) and you've identified 6 unpublished trials on registries. The treatment is already widely used. What do you recommend?",
          nodes: [
            {
              id: 'start',
              question: "The evidence shows efficacy but likely publication bias. What goes in your guideline?",
              branches: [
                { id: 'a', text: "Strong recommendation — the meta-analysis shows clear benefit", nextNode: 'strong' },
                { id: 'b', text: "Conditional recommendation with caveats about bias concerns", nextNode: 'conditional' },
                { id: 'c', text: "Await further evidence — current evidence is unreliable", nextNode: 'await' }
              ]
            },
            {
              id: 'strong',
              type: 'outcome',
              consequence: 'bad',
              title: "The Overcommitted Guideline",
              text: "Your strong recommendation drives widespread adoption. But the true effect (including unpublished data) is much weaker than published evidence suggested. Patients receive a treatment with marginal benefit but real harms. When the truth emerges, your guideline's credibility is damaged.",
              realCase: "This pattern played out with Tamiflu — strong guideline recommendations based on biased published evidence, billions spent on stockpiles, then Cochrane's full-data analysis showed minimal benefit."
            },
            {
              id: 'conditional',
              question: "You write a conditional recommendation. How do you communicate the uncertainty?",
              branches: [
                { id: 'd', text: "Note 'low certainty evidence' using GRADE, mention bias concerns briefly", nextNode: 'grade' },
                { id: 'e', text: "Full transparency: report both published and bias-adjusted estimates, explain missing trials", nextNode: 'transparent' }
              ]
            },
            {
              id: 'grade',
              type: 'outcome',
              consequence: 'neutral',
              title: "The Standard Approach",
              text: "You downgrade for publication bias per GRADE. Your recommendation reads: 'Conditional recommendation, low certainty evidence.' But many readers don't understand what this means. Clinicians may still interpret it as 'probably works.' The nuance is lost.",
              realCase: "Studies show that GRADE certainty ratings are often misinterpreted. 'Low certainty' doesn't communicate the degree of concern adequately."
            },
            {
              id: 'transparent',
              type: 'outcome',
              consequence: 'good',
              title: "The Fully Informed Guideline",
              text: "Your guideline states: 'Published trials suggest OR 0.70. However, we identified 6 unpublished trials and funnel plot asymmetry suggests the true effect may be weaker. Adjusted estimates range from OR 0.70-0.85. Until full data are available, benefits should not be overstated.' Clinicians can make informed decisions.",
              realCase: "This transparent approach is increasingly recommended. The 2023 PRISMA-P guidelines emphasize reporting all bias assessments and their implications."
            },
            {
              id: 'await',
              type: 'outcome',
              consequence: 'neutral',
              title: "The Conservative Stance",
              text: "Your guideline states: 'Insufficient evidence due to likely publication bias.' But the treatment is already widely used. Clinicians continue prescribing without guidance. Your conservative stance may be scientifically correct but practically unhelpful. Sometimes imperfect guidance is better than no guidance.",
              realCase: "There's tension between waiting for perfect evidence and providing timely guidance. The key is transparent uncertainty communication, not silence."
            }
          ]
        }
      },
      {
        type: 'oath',
        content: {
          header: "The Evidence Hunter's Oath",
          text: "I will not stop at the published literature.<br><strong>I will search the registries, contact the trialists, petition the regulators.</strong><br><br>I will document my search — what I found and what I could not find.<br>For the studies I cannot obtain are as important as those I can.<br><br>The buried evidence has a voice.<br><strong>I will be the one who listens.</strong>"
        }
      },
      {
        type: 'cycle-return',
        content: {
          principle: "Better to find one buried study than to impute ten imaginary ones. The detective who searches the registry is worth a hundred who only run statistics."
        }
      },
      {
        type: 'quiz',
        content: {
          question: "You find that 40% of registered trials for your intervention have no published results 5 years after completion. This most likely indicates:",
          options: [
            { id: 'a', text: "The trials are still ongoing", correct: false },
            { id: 'b', text: "The results were negative or uninteresting and weren't published", correct: true },
            { id: 'c', text: "The registry information is incorrect", correct: false },
            { id: 'd', text: "The trials were published under different names", correct: false }
          ],
          explanation: "Ross et al. found that non-publication 5 years after trial completion is strongly associated with negative/null results. Positive trials are published faster and more often. While some explanation (name changes, delayed publication) may apply to individual trials, systematic non-publication at this rate indicates publication bias. The published literature for this intervention is likely inflated."
        }
      },
      {
        type: 'protagonist-story',
        content: {
          name: "Dr. Tom Jefferson",
          role: "Cochrane Researcher and Evidence Hunter",
          narrative: "Tom Jefferson spent years trying to get the complete clinical trial data for Tamiflu (oseltamivir). Despite Roche's claims of efficacy, when Jefferson and the Cochrane team finally obtained the full clinical study reports (35,000+ pages) through regulatory requests and persistent advocacy, they found the drug's benefits were far more modest than published papers suggested, and harms were understated.",
          quote: "We had to file 67 separate requests to regulators across multiple countries. The company fought us at every turn. But the data they didn't want us to see told a very different story than the data they published.",
          impact: "The Cochrane oseltamivir review changed global stockpiling recommendations and sparked reform in clinical trial transparency. It proved that persistent evidence hunting can overturn established medical consensus."
        }
      },
      {
        type: 'key-takeaways',
        content: {
          takeaways: [
            "ClinicalTrials.gov and WHO ICTRP reveal what was started vs what was published",
            "FOIA/EMA requests can access full clinical study reports (not just journal abstracts)",
            "Contact trialists directly — response rates are ~50% when asking politely for unpublished data",
            "Grey literature (conference abstracts, dissertations, regulatory documents) contains valuable hidden evidence",
            "Document your search strategy — what you couldn't find is as important as what you found"
          ],
          actionItem: "Before your next systematic review, add 'registry search' and 'trialist contact' as mandatory steps in your protocol. Budget time for regulatory requests."
        }
      }
    ]
  },

  // MODULE 6: THE CAPSTONE
  {
    id: 6,
    title: "The Capstone",
    subtitle: "Integration",
    estimatedMinutes: 30,
    slides: [
      {
        type: 'learning-objectives',
        content: {
          intro: "By the end of this module, you will be able to:",
          objectives: [
            "Integrate all publication bias detection methods into a coherent assessment",
            "Apply the Five Principles of the Publication Bias Detective",
            "Make ethical decisions when encountering evidence of suppression",
            "Communicate uncertainty about publication bias to patients and colleagues",
            "Develop a personal action plan for addressing publication bias in your work"
          ]
        }
      },
      {
        type: 'title',
        content: {
          title: "The Capstone",
          subtitle: "The Complete Investigation",
          text: "You have learned to see the hidden, test the suspicious, adjust the estimate, and hunt the buried. Now bring these skills together."
        }
      },
      {
        type: 'content',
        content: {
          title: "The Five Principles of the Publication Bias Detective",
          sections: [
            {
              heading: "I. The Absence Principle",
              items: ["The absence of evidence is not evidence of absence — it may be evidence of suppression."]
            },
            {
              heading: "II. The Visibility Principle",
              items: ["What is hidden shapes belief as powerfully as what is shown."]
            },
            {
              heading: "III. The Asymmetry Principle",
              items: ["The funnel reveals what the forest conceals — the shape of what was published, and the shadow of what was not."]
            },
            {
              heading: "IV. The Uncertainty Principle",
              items: ["The eye suspects, but the test quantifies. Yet no test can see what truly happened — only what the data suggest."]
            },
            {
              heading: "V. The Recovery Principle",
              items: ["Better to find one buried study than to impute ten imaginary ones."]
            }
          ]
        }
      },
      {
        type: 'case-file',
        content: {
          caseNumber: "FINAL CASE",
          title: "The Complete Investigation: Oseltamivir (Tamiflu)",
          source: "Jefferson et al., Cochrane 2014 — The 4-Year Battle for Hidden Data",
          timeline: [
            { year: "2009", text: "Cochrane begins review of neuraminidase inhibitors (Tamiflu, Relenza). Published trials suggest efficacy. Governments stockpile $billions worth.", type: "normal" },
            { year: "The Suspicion", text: "Cochrane authors notice: 60% of patient data came from unpublished manufacturer trials. Published papers were ghostwritten. Data requests denied.", type: "normal" },
            { year: "2009-2012", text: "BMJ campaign: 'Open Data.' Repeated requests to Roche for clinical study reports. Years of refusals and negotiations.", type: "buried" },
            { year: "2013", text: "EMA grants access to regulatory documents. Roche finally releases 77 clinical study reports — 22,000 pages.", type: "revealed" },
            { year: "The Truth", text: "Full data showed: Tamiflu reduced symptom duration by ~17 hours (not 'days'). No evidence for pneumonia prevention (the claimed hospital benefit). Increased nausea/vomiting. WHO downgrades from 'essential' to 'complementary.'", type: "revealed" }
          ],
          realData: {
            publishedClaim: "Reduces pneumonia and hospitalizations",
            fullDataReality: "No evidence for pneumonia prevention",
            symptomBenefit: "~17 hours symptom reduction",
            harms: "Increased nausea, vomiting, headache",
            stockpileWaste: "Billions in government stockpiles of overstated benefit"
          }
        }
      },
      {
        type: 'statistic-card',
        content: {
          value: "4 Years",
          label: "to obtain clinical study reports that should have been public",
          context: "The delay cost billions in misallocated pandemic preparedness"
        }
      },
      {
        type: 'decision-tree',
        content: {
          title: "Reading a Meta-Analysis: The Bias Detective's Checklist",
          situation: "A colleague sends you a meta-analysis showing that a new intervention significantly reduces mortality (OR 0.65, 95% CI 0.52-0.81, p<0.001). They want to change clinical practice based on this. Before agreeing, what do you check?",
          nodes: [
            {
              id: 'start',
              question: "The meta-analysis shows impressive results. What's your first question?",
              branches: [
                { id: 'a', text: "How many studies were included?", nextNode: 'studies' },
                { id: 'b', text: "Was publication bias assessed?", nextNode: 'bias_check' },
                { id: 'c', text: "Were trial registries searched for unpublished trials?", nextNode: 'registry' }
              ]
            },
            {
              id: 'studies',
              question: "The meta-analysis includes 8 studies. What does this mean for bias assessment?",
              branches: [
                { id: 'd', text: "Too few for reliable Egger's test — visual assessment only", nextNode: 'few_studies' },
                { id: 'e', text: "Enough for full bias assessment", nextNode: 'wrong_enough' }
              ]
            },
            {
              id: 'few_studies',
              type: 'outcome',
              consequence: 'good',
              title: "Correctly Identified the Limitation",
              text: "With only 8 studies, statistical tests for publication bias (Egger's, Begg's) have very low power. A non-significant test does NOT mean no bias. You should rely more on: (1) Visual funnel plot assessment, (2) Registry searches for unpublished trials, (3) Assessment of whether all studies are positive (suspicious). Statistical tests can neither confirm nor rule out bias.",
              realCase: "Cochrane guidance states that tests for funnel plot asymmetry should not be used when there are fewer than 10 studies."
            },
            {
              id: 'wrong_enough',
              type: 'outcome',
              consequence: 'bad',
              title: "Overconfident in Tests",
              text: "8 studies is below the recommended minimum of 10 for Egger's test. With so few studies, the test has high false negative rates — it will often miss real bias. Concluding 'no bias' from a non-significant test with 8 studies is not justified. You need to use other methods.",
              realCase: "Simulations show that Egger's test has only ~50% power to detect moderate bias with 10 studies, and even less with fewer."
            },
            {
              id: 'bias_check',
              question: "The methods section says 'Publication bias was assessed using Egger's test (p=0.34)'. What's your concern?",
              branches: [
                { id: 'f', text: "Good — they tested for bias and found none", nextNode: 'false_assurance' },
                { id: 'g', text: "A non-significant test doesn't prove no bias — what else did they do?", nextNode: 'deeper' }
              ]
            },
            {
              id: 'false_assurance',
              type: 'outcome',
              consequence: 'bad',
              title: "The False Assurance",
              text: "A non-significant Egger's test does NOT prove absence of bias. It means the test failed to detect asymmetry — which could be because there's no bias, OR because the test lacked power, OR because bias exists but isn't reflected in asymmetry. You need additional information: funnel plot inspection, registry search, assessment of study characteristics.",
              realCase: "Many meta-analyses report only Egger's p-value without funnel plots or registry searches. This is insufficient for bias assessment."
            },
            {
              id: 'deeper',
              type: 'outcome',
              consequence: 'good',
              title: "The Appropriate Skepticism",
              text: "You ask the right follow-up questions: Did they search trial registries? Did they show the funnel plot? Did they compare industry vs. independent trials? Did they contact authors of conference abstracts that never became papers? A single statistical test is the minimum, not the full assessment.",
              realCase: "Best practice includes: visual funnel plot, statistical tests, registry search, comparison by funding source, and contact with trialists."
            },
            {
              id: 'registry',
              type: 'outcome',
              consequence: 'good',
              title: "The Detective's First Question",
              text: "Registry searches are the most direct way to identify missing evidence. You check: Did the authors search ClinicalTrials.gov? Did they report how many registered trials had no published results? Did they try to obtain unpublished data? If they didn't search registries, the bias assessment is incomplete regardless of statistical tests.",
              realCase: "Turner's landmark study showed that registry searches can identify substantial unpublished evidence that statistical tests cannot detect."
            }
          ]
        }
      },
      {
        type: 'contrast',
        content: {
          title: "Two Readers of the Same Meta-Analysis",
          darkSide: {
            header: "The Uncritical Reader",
            items: [
              "Sees: 'OR 0.65, p<0.001, significant'",
              "Checks: 'Egger's p=0.34, no bias detected'",
              "Concludes: 'Strong evidence, change practice'",
              "Skips: Funnel plot, registry section, limitations",
              "Tells colleagues: 'The meta-analysis proves it works'"
            ],
            consequence: "Result: Adopts treatment based on inflated evidence. Later learns unpublished trials showed null effects. Has to explain to patients why the 'proven' treatment didn't help them."
          },
          lightSide: {
            header: "The Publication Bias Detective",
            items: [
              "Sees same numbers, asks: 'What's missing?'",
              "Examines funnel plot: 'Gap in bottom-left'",
              "Checks registry search: 'None reported'",
              "Notes: 'All 8 trials industry-funded, all positive'",
              "Tells colleagues: 'Likely inflated, await independent data'"
            ],
            consequence: "Result: Maintains appropriate uncertainty. When full data emerge showing weaker effect, no surprise. Patients received honest communication about uncertainty from the start."
          }
        }
      },
      {
        type: 'oath',
        content: {
          header: "By the Patients Who Trusted the Evidence",
          text: "For every inflated effect size, there was a patient who expected more benefit than they received.<br><br>For every buried negative trial, there was a patient who received a treatment that did not work.<br><br>For every spin, there was a doctor who believed what they read.<br><br><strong>The detective remembers: Numbers are not abstractions. They guide treatment. They shape lives.</strong><br><br>Vigilance in evidence assessment is not pedantry — it is care."
        }
      },
      {
        type: 'case-file',
        content: {
          caseNumber: "MEMORIAL CASE",
          title: "The Faces Behind the Numbers",
          source: "Multiple sources — The Human Cost of Publication Bias",
          timeline: [
            { year: "Reboxetine", text: "Patients took a drug that appeared effective in publications but showed no benefit in the complete data. Years of treatment with a placebo effect, plus side effects, while better options existed.", type: "buried" },
            { year: "Vioxx", text: "26,000-55,000 excess deaths. Heart attacks in people who trusted their doctor, who trusted the published literature, which was missing the safety signal.", type: "buried" },
            { year: "Study 329", text: "Children given paroxetine based on a ghostwritten paper claiming safety. Suicidal events increased 8-fold, but this was hidden. Adolescents harmed by a paper that lied.", type: "buried" },
            { year: "DECREASE", text: "~10,000 deaths per year in Europe from guidelines based on fabricated data. Patients given beta-blockers before surgery because a fraudulent researcher invented the evidence.", type: "buried" },
            { year: "Avandia", text: "83,000 excess heart attacks. Seven years of prescribing while the company knew the cardiovascular risk. The published literature showed nothing wrong.", type: "buried" }
          ],
          realData: {
            totalEstimatedDeaths: "100,000+ from cases in this course alone",
            commonThread: "Published evidence that was systematically incomplete",
            responsibility: "Distributed — companies, journals, regulators, researchers",
            prevention: "Vigilant detection, transparency demands, systematic searching"
          }
        }
      },
      {
        type: 'death-toll',
        content: {
          number: "100,000+",
          label: "Conservative estimate of deaths from the cases covered in this course",
          source: "Vioxx (26-55k) + DECREASE (~10k/yr × several years) + Avandia (unknown fraction of 83k MIs) + others"
        }
      },
      {
        type: 'decision-tree',
        content: {
          title: "The Next Step: What Will You Do?",
          situation: "You have completed this course. You can now see publication bias, test for it, adjust for it, and hunt for hidden evidence. But knowledge without action changes nothing. What will you do with what you've learned?",
          nodes: [
            {
              id: 'start',
              question: "You've learned the skills of the publication bias detective. How will you use them?",
              branches: [
                { id: 'a', text: "In my own research — I'll be more vigilant about bias in literature I read", nextNode: 'personal' },
                { id: 'b', text: "As a reviewer — I'll demand better bias assessment in papers I review", nextNode: 'reviewer' },
                { id: 'c', text: "As an advocate — I'll push for transparency in my institution/field", nextNode: 'advocate' }
              ]
            },
            {
              id: 'personal',
              question: "You commit to personal vigilance. How will you implement this?",
              branches: [
                { id: 'd', text: "Check funnel plots and bias assessments in every meta-analysis I read", nextNode: 'personal_good' },
                { id: 'e', text: "Search registries when making treatment decisions based on published evidence", nextNode: 'personal_great' }
              ]
            },
            {
              id: 'personal_good',
              type: 'outcome',
              consequence: 'good',
              title: "The Informed Consumer",
              text: "You become a critical reader of evidence. When a meta-analysis claims strong effects, you check: How many studies? Funnel plot shape? Registry search? This protects your patients from inflated claims. One alert clinician at a time, the distortion loses power.",
              realCase: "Individual vigilance matters. If more readers had questioned the reboxetine meta-analyses, the drug might have been scrutinized earlier."
            },
            {
              id: 'personal_great',
              type: 'outcome',
              consequence: 'good',
              title: "The Active Investigator",
              text: "Before changing practice, you search ClinicalTrials.gov yourself. You find unpublished trials that meta-analyses missed. You email trialists for data. You become the detective this course trained you to be. Your patients receive care based on the complete evidence, not just the published slice.",
              realCase: "Clinicians who check registries before adopting new treatments are rare but invaluable. They catch problems before guidelines do."
            },
            {
              id: 'reviewer',
              question: "As a peer reviewer, you can shape what gets published. What will you require?",
              branches: [
                { id: 'f', text: "Demand funnel plots and Egger's tests in all meta-analyses", nextNode: 'reviewer_minimum' },
                { id: 'g', text: "Require registry searches and documentation of unpublished trials", nextNode: 'reviewer_thorough' }
              ]
            },
            {
              id: 'reviewer_minimum',
              type: 'outcome',
              consequence: 'neutral',
              title: "The Statistical Gatekeeper",
              text: "You require bias assessment in every meta-analysis you review. Authors now include funnel plots. But without registry searches, statistical tests only detect a fraction of the problem. You've raised the minimum bar — a meaningful contribution — but the deeper problem remains.",
              realCase: "Many journals now require bias assessment. Compliance has improved. But quality of assessment varies widely."
            },
            {
              id: 'reviewer_thorough',
              type: 'outcome',
              consequence: 'good',
              title: "The Thorough Gatekeeper",
              text: "You require: (1) Registry search with documentation of found/not found trials, (2) Contact attempts with trialists, (3) Comparison of published vs. registry-reported outcomes, (4) GRADE assessment incorporating bias risk. You reject meta-analyses that claim 'no publication bias' based on Egger's test alone. Standards rise.",
              realCase: "Cochrane's standards have raised the bar for systematic reviews globally. Individual reviewers enforcing high standards create systemic change."
            },
            {
              id: 'advocate',
              question: "You want to push for systemic transparency. Where will you focus your advocacy?",
              branches: [
                { id: 'h', text: "Support AllTrials and mandatory results reporting", nextNode: 'advocate_policy' },
                { id: 'i', text: "Push my institution to adopt data sharing policies", nextNode: 'advocate_local' },
                { id: 'j', text: "Train others — spread these skills to colleagues and students", nextNode: 'advocate_teach' }
              ]
            },
            {
              id: 'advocate_policy',
              type: 'outcome',
              consequence: 'good',
              title: "The Policy Advocate",
              text: "You sign AllTrials. You write to legislators about trial transparency. You support FDAAA enforcement. You're one voice among thousands — but thousands of voices create political will. The 2007 law requiring results reporting happened because advocates demanded it. The next improvement needs you.",
              realCase: "AllTrials gathered 90,000+ signatures and influenced EMA policy. Individual voices aggregate into political force."
            },
            {
              id: 'advocate_local',
              type: 'outcome',
              consequence: 'good',
              title: "The Institutional Champion",
              text: "You push your hospital/university to require data sharing for all trials conducted there. You advocate for pre-registration policies. You work with the IRB to include transparency requirements. One institution at a time, the culture shifts. When everyone around you expects transparency, suppression becomes harder.",
              realCase: "Many academic medical centers now require pre-registration and results reporting. These policies emerged from internal advocacy."
            },
            {
              id: 'advocate_teach',
              type: 'outcome',
              consequence: 'good',
              title: "The Multiplier",
              text: "You teach this course to your residents. You present at grand rounds. You write blog posts explaining funnel plots. Every person you train becomes another detective. The skills spread exponentially. One teacher creates hundreds of vigilant readers. This is how paradigms shift — one learner at a time, until critical mass is reached.",
              realCase: "The evidence-based medicine movement spread through teaching. Publication bias awareness is spreading the same way. You can accelerate it."
            }
          ]
        }
      },
      {
        type: 'contrast',
        content: {
          title: "Two Futures",
          darkSide: {
            header: "The Future of Continued Silence",
            items: [
              "Researchers continue hiding negative trials",
              "Journals continue rejecting null results",
              "Meta-analyses continue to inflate effects",
              "Guidelines continue to be based on incomplete evidence",
              "Patients continue receiving treatments that don't work",
              "The next Vioxx happens, and the next, and the next"
            ],
            consequence: "The future if nothing changes. The cycle of suppression and harm continues. Knowledge of publication bias remains academic, not actionable."
          },
          lightSide: {
            header: "The Future of Vigilant Detection",
            items: [
              "Detectives check every meta-analysis for bias",
              "Reviewers demand registry searches before acceptance",
              "Clinicians verify evidence before changing practice",
              "Advocates push for transparency at every level",
              "Teachers spread the skills of detection",
              "The cost of suppression rises until it exceeds the benefit"
            ],
            consequence: "The future if YOU act. Each detective, each reviewer, each advocate shifts the equilibrium. Publication bias becomes harder, riskier, less profitable. Truth finds light."
          }
        }
      },
      {
        type: 'oath',
        content: {
          header: "The Final Commitment",
          text: "I have learned to see what is hidden.<br>I have learned to test my suspicions.<br>I have learned to hunt for buried evidence.<br><br><strong>I will not let this knowledge remain unused.</strong><br><br>I will check the funnels. I will search the registries.<br>I will ask the questions no one wants asked.<br>I will document what I find and what I cannot find.<br><br><strong>I will be the detective the evidence needs.</strong>"
        }
      },
      {
        type: 'principle',
        content: {
          number: "OATH",
          text: "I will not accept the published literature as truth without investigation.\n\nI will look for what is hidden as carefully as I examine what is shown.\n\nI will test my suspicions statistically, but never mistake the test for certainty.\n\nI will hunt for buried evidence rather than impute imaginary studies.\n\nI will report what I find and what I cannot find — both are evidence.\n\nI will remember that behind every missing study are patients whose treatment was decided on incomplete evidence."
        }
      },
      {
        type: 'rhetoric',
        content: {
          question: "And when you have learned all this — when you can see the funnel's asymmetry, hear the statistical tests' whispers, and hunt through registries like a detective through archives — what will you do with this knowledge? Will you be silent, or will you speak?"
        }
      },
      {
        type: 'cycle-return',
        content: {
          principle: "You came to learn detection. You leave knowing that detection is only the beginning. The detective who finds the truth must also fight to make it known. The evidence that never saw light — can only heal when you bring it into day."
        }
      },
      {
        type: 'redemption-story',
        content: {
          title: "Johnson & Johnson's DePuy Hip Implant Recall",
          narrative: "Not all stories of hidden data end in regulatory punishment. In 2010, Johnson & Johnson voluntarily recalled its DePuy ASR hip replacement system after internal analysis revealed higher-than-expected failure rates. While critics noted the recall came late (after ~93,000 implants), the company ultimately shared its internal data, funded revision surgeries, and established a patient monitoring registry. The DePuy case shows that companies CAN choose transparency when internal evidence shows harm — and that this path, while costly, is less destructive than prolonged concealment.",
          lesson: "Transparency after discovery of harm, while imperfect, limits damage and begins rebuilding trust. The contrast with Vioxx (where Merck allegedly concealed data for years) shows two possible corporate responses to uncomfortable evidence. Both are costly, but one preserves scientific integrity."
        }
      },
      {
        type: 'practice-case',
        content: {
          title: "Applying Your Skills",
          scenario: "You're reviewing a meta-analysis of a new diabetes drug. The authors report OR = 0.65 (95% CI: 0.52-0.81) for cardiovascular events, based on 12 trials. They state 'Egger's test was non-significant (p=0.34), indicating no publication bias.' The funnel plot shows slight asymmetry in the lower-left. Registry search shows 18 trials were registered for this drug.",
          data: {
            headers: ["Study", "Effect (log OR)", "SE", "Published"],
            rows: [
              ["ADVANCE-1", "-0.52", "0.15", "Yes"],
              ["CARDIO-2", "-0.48", "0.18", "Yes"],
              ["SAFE-3", "-0.35", "0.22", "Yes"],
              ["TRIAL-4", "-0.61", "0.12", "Yes"],
              ["MULTI-5", "-0.28", "0.25", "Yes"],
              ["PILOT-6", "-0.41", "0.20", "Yes"],
              ["REG-7 to REG-18", "???", "???", "No (6 registered, no results)"]
            ]
          },
          questions: [
            "What concerns does the registry search raise?",
            "Why is the non-significant Egger's test NOT reassuring?",
            "What would you recommend before accepting this effect estimate?"
          ],
          answers: [
            "18 registered trials but only 12 published = 33% missing. This gap strongly suggests selective publication. The 6 missing trials likely had less favorable results.",
            "Egger's test has low power with 12 studies. A non-significant result doesn't rule out bias — it means the test couldn't detect it. Visual asymmetry is present. The combination of visual asymmetry + registry gap is more concerning than Egger's test is reassuring.",
            "Contact investigators of the 6 unpublished trials. File requests for regulatory data. Run trim-and-fill and PET-PEESE as sensitivity analyses. Downgrade certainty in GRADE assessment. Do NOT accept the point estimate as reliable."
          ]
        }
      },
      {
        type: 'printable-checklist',
        content: {
          title: "Publication Bias Assessment Checklist",
          sections: [
            {
              heading: "1. Visual Assessment",
              items: [
                "Examine funnel plot for symmetry",
                "Note location of any gaps (significance regions?)",
                "Check if small studies cluster on one side",
                "Consider contour-enhanced funnel if available"
              ]
            },
            {
              heading: "2. Statistical Tests",
              items: [
                "Report Egger's test with p-value (threshold: p<0.10)",
                "Note number of studies (tests unreliable with <10)",
                "Report Begg's test if available",
                "Check if visual and statistical findings agree"
              ]
            },
            {
              heading: "3. Registry Search",
              items: [
                "Search ClinicalTrials.gov for intervention",
                "Search WHO ICTRP for international trials",
                "Compare registered vs. published trial count",
                "Document completion dates of unpublished trials"
              ]
            },
            {
              heading: "4. Additional Investigation",
              items: [
                "Contact trialists for unpublished data",
                "Search conference abstracts and grey literature",
                "Check regulatory documents (FDA, EMA)",
                "Compare published outcomes to registered outcomes"
              ]
            },
            {
              heading: "5. Sensitivity Analysis",
              items: [
                "Run trim-and-fill and report adjusted estimate",
                "Run PET-PEESE if 10+ studies available",
                "Calculate Fail-Safe N as heuristic",
                "Consider selection model if appropriate"
              ]
            },
            {
              heading: "6. Interpretation & Reporting",
              items: [
                "Document all searches (dates, terms, results)",
                "Report what was NOT found as well as what was",
                "Adjust GRADE certainty based on bias assessment",
                "State conclusions cautiously if bias suspected"
              ]
            }
          ]
        }
      },
      {
        type: 'content',
        content: {
          title: "Reporting Standards: PRISMA-PB and PROSPERO",
          sections: [
            {
              heading: "PRISMA Extension for Publication Bias (PRISMA-PB)",
              items: [
                "Checklist item 15: Describe methods used to assess risk of bias due to missing results",
                "Checklist item 22: Present assessments of risk of bias due to missing results",
                "Requires explicit statement about registry searches conducted",
                "Must report number of studies found vs. number included with reasons"
              ]
            },
            {
              heading: "PROSPERO Registration",
              items: [
                "Register your systematic review BEFORE starting searches",
                "Pre-specify your publication bias assessment methods",
                "Prevents selective reporting of bias assessments (ironic!)",
                "Available free at: crd.york.ac.uk/prospero"
              ]
            },
            {
              heading: "GRADE Assessment for Publication Bias",
              items: [
                "Rate DOWN one level if publication bias strongly suspected",
                "Consider: funnel asymmetry, registry gaps, industry funding pattern",
                "Document reasoning in GRADE evidence profile",
                "Even with bias-corrected estimates, uncertainty warrants downgrade"
              ]
            }
          ]
        }
      },
      {
        type: 'patient-communication',
        content: {
          scenario: "A patient wants to STOP a medication after reading online that studies were 'hidden' or 'biased'.",
          script: "I understand your concern — you've read that some studies may not have been published, and that's a real issue in medicine. Let me explain what we know: while publication bias can inflate how well drugs appear to work, it doesn't mean treatments don't work at all. For your medication specifically, we have [X evidence]. The benefits we've seen in your case — [specific improvements] — are real. Let's review together whether continuing makes sense for you, but I wouldn't recommend stopping abruptly based on general concerns about bias.",
          keyPoints: [
            "Validate the concern — publication bias IS real",
            "Distinguish between inflated effects vs. no effects",
            "Ground discussion in patient's specific experience",
            "Avoid dismissing patient's research efforts",
            "Offer shared decision-making, not paternalism"
          ]
        }
      },
      {
        type: 'patient-communication',
        content: {
          scenario: "A colleague recommends a new treatment based on a meta-analysis. You notice the funnel plot is asymmetric and registry shows missing trials.",
          script: "Thanks for sharing this — it's an interesting option. I took a look at the meta-analysis and noticed a few things that give me pause. The funnel plot shows some asymmetry in the lower-left, and when I checked ClinicalTrials.gov, I found [X] registered trials that don't appear in the analysis. That pattern often indicates publication bias. The effect might be real, but probably smaller than the 40% reduction they report. Want to look at the registry data together? I think we should be cautious about changing our practice based on this until we understand what's missing.",
          keyPoints: [
            "Lead with appreciation, not criticism",
            "Be specific about what you found (not vague skepticism)",
            "Offer to review evidence together (collaborative)",
            "Don't say 'the study is wrong' — say 'the effect might be inflated'",
            "Suggest appropriate caution, not rejection"
          ]
        }
      },
      {
        type: 'content',
        content: {
          title: "Questions Patients Can Ask Their Doctor",
          sections: [
            {
              heading: "About Treatment Evidence",
              items: [
                "How many studies support this treatment? Were they all published?",
                "Did the drug company fund the studies? Were there independent trials?",
                "Is this recommendation based on a systematic review? Did they check for publication bias?",
                "What's the number needed to treat? Is that based on all studies or just published ones?"
              ]
            },
            {
              heading: "About Uncertainty",
              items: [
                "How confident are you in this recommendation?",
                "Could the benefit be smaller than the studies suggest?",
                "Are there treatments with better evidence quality?",
                "What would change your recommendation?"
              ]
            },
            {
              heading: "About Shared Decision-Making",
              items: [
                "Given the uncertainty, what are my options?",
                "What would you do if you were in my situation?",
                "Can we try this and reassess in [timeframe]?",
                "What should I watch for that would tell us it's not working?"
              ]
            }
          ]
        }
      },
      {
        type: 'quiz',
        content: {
          question: "POST-ASSESSMENT: A meta-analysis shows Drug X reduces mortality by 35% (OR 0.65, p<0.001). Egger's test is non-significant (p=0.28) with 8 studies. Registry shows 12 trials were registered. What's your assessment?",
          options: [
            { id: 'a', text: "Strong evidence — significant effect and no publication bias detected", correct: false },
            { id: 'b', text: "Uncertain — Egger's test underpowered, registry gap concerning, effect may be inflated", correct: true },
            { id: 'c', text: "Invalid — the meta-analysis should be rejected entirely", correct: false },
            { id: 'd', text: "More studies needed before any conclusion", correct: false }
          ],
          explanation: "Correct! Multiple red flags here: (1) Egger's test with only 8 studies has very low power — non-significant doesn't mean no bias; (2) 12 registered trials but only 8 published = 33% missing, suggesting selective publication; (3) The 35% effect may be inflated. You should: search for the 4 missing trials, run sensitivity analyses (trim-and-fill, PET-PEESE), and interpret with caution. Compare your answer to the pre-assessment — you've learned to see beyond p-values!"
        }
      },
      {
        type: 'key-takeaways',
        content: {
          takeaways: [
            "The Five Principles: Absence, Visibility, Asymmetry, Uncertainty, Action",
            "Detection alone is not enough — evidence must be acted upon and shared",
            "Every role matters: reader, reviewer, advocate, teacher",
            "Systemic change happens through accumulated individual actions",
            "The detective who finds truth must also fight to make it known"
          ],
          actionItem: "Before leaving this course, choose ONE concrete action: will you check funnel plots, demand registry searches, advocate for transparency, or teach others? Make a commitment and follow through."
        }
      }
    ]
  },

  // MODULE 7: CHRONICLES OF HIDDEN EVIDENCE
  {
    id: 7,
    title: "Chronicles of Hidden Evidence",
    subtitle: "Real Cases, Real Decisions",
    estimatedMinutes: 35,
    slides: [
      {
        type: 'learning-objectives',
        content: {
          intro: "By the end of this module, you will be able to:",
          objectives: [
            "Analyze 5 landmark cases of publication bias using real data",
            "Make clinical decisions when facing incomplete evidence",
            "Recognize patterns of data suppression across different therapeutic areas",
            "Apply the two-path framework to evaluate consequences of action vs. inaction",
            "Internalize the refrain: The funnel sees what words conceal"
          ]
        }
      },
      {
        type: 'title',
        content: {
          title: "Chronicles of Hidden Evidence",
          subtitle: "Five Stories from the Archives",
          text: "Each story begins with a question. Each presents a choice. Each reveals what was concealed. These are not hypotheticals — they happened. The patients were real. The data was buried. The funnel would have told the truth."
        }
      },
      {
        type: 'principle',
        content: {
          number: "VI",
          text: "The funnel sees what words conceal."
        }
      },

      // STORY 1: THE PAROXETINE DECEPTION (Study 329)
      {
        type: 'story',
        content: {
          storyNumber: 1,
          title: "The Paroxetine Deception",
          caseId: "Study 329",
          opening: "Have you considered what happens when the published record lies?",
          stats: {
            header: "The Hidden Data",
            items: [
              { value: "275", label: "Adolescents enrolled" },
              { value: "11", label: "Suicide events on paroxetine" },
              { value: "2", label: "Suicide events on placebo" },
              { value: "14", label: "Years until truth emerged" }
            ]
          },
          scenario: {
            title: "The Decision Point",
            text: "The year is 2002. You are a prescribing physician. A depressed teenager sits before you. The journal article on your desk — published in the prestigious Journal of the American Academy of Child & Adolescent Psychiatry — concludes that paroxetine is 'generally well tolerated and effective' for adolescent depression. You have two paths before you."
          },
          pathA: {
            header: "Path A: Trust the Published Paper",
            action: "You prescribe paroxetine based on the peer-reviewed evidence",
            steps: [
              "The published paper shows efficacy on some measures",
              "Safety section mentions some events but appears reassuring",
              "You write the prescription with confidence",
              "Three weeks later, the patient attempts suicide"
            ],
            consequence: "You followed the evidence. But the evidence was incomplete. The paper you trusted was ghostwritten. The lead 'author' had not seen the raw data. The suicide signal — 5.5 times higher on paroxetine — was hidden in the fine print and statistics."
          },
          pathB: {
            header: "Path B: Question the Missing Data",
            action: "You notice discrepancies and dig deeper",
            steps: [
              "You check the trial registry — the primary outcomes changed",
              "You notice the authors are consultants to the manufacturer",
              "You request the clinical study report from the FDA",
              "You discover 11 suicide-related events vs. 2 on placebo"
            ],
            consequence: "You chose caution. You prescribed an alternative. Years later, when the truth emerged, you understood why your skepticism saved lives. But in 2002, this path required extraordinary vigilance — the system was designed to hide."
          },
          revelation: {
            header: "The Revelation",
            text: "It took 14 years for the full data to emerge. The paper was ghostwritten by a medical communications company. The named 'author' — a prominent academic — had not analyzed the data. The study actually showed paroxetine was neither safe nor effective. The restoring of Study 329 by RIAT researchers in 2015 exposed one of the greatest publication frauds in psychiatric history.",
            detail: "Source: Le Noury et al. BMJ 2015; Restoring Study 329"
          },
          refrain: "The funnel sees what words conceal."
        }
      },

      // STORY 2: THE REBOXETINE FUNNEL
      {
        type: 'story',
        content: {
          storyNumber: 2,
          title: "The Reboxetine Funnel",
          caseId: "NICE Submission / Eyding 2010",
          opening: "What appears when you plot effect against precision?",
          stats: {
            header: "The Magnitude of Suppression",
            items: [
              { value: "0.56", label: "Published effect size (SMD)" },
              { value: "0.07", label: "True effect size (with unpublished)" },
              { value: "74%", label: "Patient data suppressed" },
              { value: "8", label: "Trials never published" }
            ]
          },
          scenario: {
            title: "The Decision Point",
            text: "You are a health technology assessment analyst reviewing reboxetine for national reimbursement. The published meta-analysis shows a standardized mean difference of 0.56 — a moderate-to-large effect. The manufacturer wants approval. Millions in revenue depend on your recommendation. But something bothers you about the funnel plot."
          },
          pathA: {
            header: "Path A: Accept the Published Literature",
            action: "You recommend approval based on available evidence",
            steps: [
              "Published trials consistently show benefit",
              "The effect size appears clinically meaningful",
              "You write a positive assessment",
              "Reboxetine is approved and widely prescribed"
            ],
            consequence: "Patients receive a drug that published evidence supported. But those patients experience no real benefit — because the published evidence was only 26% of the total. The 74% that showed no effect was hidden in company files."
          },
          pathB: {
            header: "Path B: Demand Unpublished Data",
            action: "You invoke your authority to require all trial data",
            steps: [
              "You notice all published trials are industry-sponsored",
              "You formally request unpublished trial data from Pfizer",
              "You plot ALL data on the funnel — the asymmetry appears",
              "The true effect is 0.07: clinically meaningless"
            ],
            consequence: "Your demand for transparency reveals the deception. The drug's benefit is not proven. Your recommendation protects patients from an ineffective treatment. This is exactly what IQWiG did — and reboxetine was subsequently withdrawn or restricted in several countries."
          },
          revelation: {
            header: "The Revelation",
            text: "When Eyding and colleagues obtained all trial data, the truth was stark: 2,256 patients in 8 trials had been hidden. The published literature — the 'evidence' — was a curated selection designed to show what did not exist. The funnel plot of all data showed what the published plot concealed: a symmetric distribution around zero.",
            detail: "Source: Eyding et al. BMJ 2010"
          },
          refrain: "The funnel sees what words conceal."
        }
      },

      // STORY 3: THE GABAPENTIN GHOST
      {
        type: 'story',
        content: {
          storyNumber: 3,
          title: "The Gabapentin Ghost",
          caseId: "Pfizer's Hidden Trials",
          opening: "How many trials can hide in plain sight?",
          stats: {
            header: "The Registry Gap",
            items: [
              { value: "12", label: "Trials registered" },
              { value: "8", label: "Trials published" },
              { value: "4", label: "Trials with no benefit — hidden" },
              { value: "$430M", label: "Settlement for fraud" }
            ]
          },
          scenario: {
            title: "The Decision Point",
            text: "You are writing a systematic review on gabapentin for neuropathic pain. Your literature search returns 8 published trials, all showing benefit. The Cochrane methodology is clear: you must also search trial registries. When you do, you find 12 trials were registered. Four trials have vanished."
          },
          pathA: {
            header: "Path A: Review Only Published Literature",
            action: "You complete your review with the 8 available trials",
            steps: [
              "Your meta-analysis shows gabapentin is effective",
              "The forest plot shows consistent benefit across trials",
              "You conclude gabapentin works for neuropathic pain",
              "Guidelines cite your review; prescriptions increase"
            ],
            consequence: "Your review becomes part of the evidence base. But it is built on sand — 33% of the trials were missing. The 4 unpublished trials showed no benefit. Your honest work perpetuates a distorted truth because you accepted the published record as complete."
          },
          pathB: {
            header: "Path B: Hunt the Missing Trials",
            action: "You pursue the 4 missing trials through every channel",
            steps: [
              "You contact Pfizer requesting trial data — refused",
              "You file a Freedom of Information request to FDA",
              "You find internal documents from litigation discovery",
              "The 4 missing trials show no benefit: the effect disappears"
            ],
            consequence: "Your persistence reveals the publication bias. Your review includes a prominent warning about missing data. Your conclusions are appropriately uncertain. When the Pfizer settlement documents later emerge, your caution is vindicated. The 4 trials showed exactly what you suspected: nothing."
          },
          revelation: {
            header: "The Revelation",
            text: "Internal Pfizer documents revealed explicit suppression strategy. One email stated: 'We have to be careful about what we publish.' Draft manuscripts were prepared only for trials where data 'should be positive.' The company paid $430 million in settlements — but had already earned $2.7 billion from off-label promotion. The penalty was the cost of doing business.",
            detail: "Source: Steinman et al. JAMA 2006; DOJ Settlement 2004"
          },
          refrain: "The funnel sees what words conceal."
        }
      },

      // STORY 4: THE TAMIFLU BILLIONS
      {
        type: 'story',
        content: {
          storyNumber: 4,
          title: "The Tamiflu Billions",
          caseId: "Cochrane Oseltamivir Review",
          opening: "What is the cost of hidden data?",
          stats: {
            header: "The Scale of Investment",
            items: [
              { value: "$9B", label: "Global stockpile spending" },
              { value: "61%", label: "Published reduction in complications" },
              { value: "22,000", label: "Pages of hidden CSRs" },
              { value: "5", label: "Years to obtain data" }
            ]
          },
          scenario: {
            title: "The Decision Point",
            text: "You advise a health ministry on pandemic preparedness. It is 2009. Swine flu is spreading. Published meta-analyses show Tamiflu reduces influenza complications by 61%. Governments worldwide are stockpiling. Your minister asks: should we spend billions on Tamiflu? The evidence seems clear."
          },
          pathA: {
            header: "Path A: Trust the Published Meta-Analyses",
            action: "You recommend stockpiling based on published evidence",
            steps: [
              "The meta-analyses are published in respected journals",
              "The 61% reduction sounds substantial",
              "You recommend $500 million in stockpile purchases",
              "The drugs sit in warehouses; the pandemic wanes"
            ],
            consequence: "Your recommendation followed the evidence that was available. But that evidence was based on published trials — and 60% of patient data came from unpublished manufacturer trials. The real effect on hospitalizations? Not significant. Your country spent hundreds of millions on drugs of uncertain benefit while other health needs went unfunded."
          },
          pathB: {
            header: "Path B: Demand Clinical Study Reports",
            action: "You delay the decision until you see all data",
            steps: [
              "You notice published trials cite unpublished manufacturer data",
              "You support the BMJ's campaign for full data release",
              "You wait as Cochrane spends 5 years pursuing Roche",
              "Finally: 77 clinical study reports, 22,000 pages"
            ],
            consequence: "Your patience is rewarded with truth. Tamiflu reduces symptom duration by 17 hours — not 'days' as marketed. No evidence it prevents pneumonia or hospitalization. It causes nausea and vomiting. Your recommendation: do not stockpile at pandemic scale. WHO downgrades it from 'essential' to 'complementary' medicine."
          },
          revelation: {
            header: "The Revelation",
            text: "The Cochrane review took 5 years because Roche refused to release Clinical Study Reports. When finally obtained through regulatory channels, 22,000 pages revealed what 10 years of published papers concealed: the benefit was marginal, the harms understated, the hospitalization claim unfounded. Billions in public money had been allocated based on incomplete evidence.",
            detail: "Source: Jefferson et al. Cochrane 2014; BMJ Open Data Campaign"
          },
          refrain: "The funnel sees what words conceal."
        }
      },

      // STORY 5: THE ANTIDEPRESSANT LANDSCAPE
      {
        type: 'story',
        content: {
          storyNumber: 5,
          title: "The Antidepressant Landscape",
          caseId: "Turner et al. NEJM 2008",
          opening: "What if you could see what the FDA saw?",
          stats: {
            header: "The Published vs. Actual Record",
            items: [
              { value: "74", label: "Trials in FDA database" },
              { value: "94%", label: "Published as positive" },
              { value: "51%", label: "Actually positive per FDA" },
              { value: "0.15", label: "True effect size (vs. 0.37 published)" }
            ]
          },
          scenario: {
            title: "The Decision Point",
            text: "You are updating national depression treatment guidelines. The published literature overwhelmingly supports antidepressant efficacy — 94% of published trials are positive. Effect sizes appear substantial. But you have access to something rare: the FDA's internal review documents. You can see what the journals did not print."
          },
          pathA: {
            header: "Path A: Follow the Published Literature",
            action: "You write guidelines based on journal publications",
            steps: [
              "Your literature review finds robust evidence",
              "Effect size meta-analysis shows d = 0.37",
              "You recommend antidepressants as first-line treatment",
              "Patients and clinicians expect substantial benefit"
            ],
            consequence: "Your guidelines set expectations that often are not met. Patients try antidepressants expecting the large effects the literature suggests. When improvement is modest, they feel like failures. Clinicians question their skills. The mismatch between published promise and lived reality creates confusion, non-adherence, and therapeutic nihilism."
          },
          pathB: {
            header: "Path B: Incorporate FDA Review Data",
            action: "You analyze all trials — published and unpublished",
            steps: [
              "You obtain FDA review documents for 12 antidepressants",
              "You discover 36 trials were negative or questionable",
              "Of those 36, only 14 were published — and 11 were spun positive",
              "True effect size: 0.15 (small, not 0.37)"
            ],
            consequence: "Your guidelines are honest about modest efficacy. They recommend antidepressants while acknowledging that benefits are real but smaller than published literature suggests. Patients have accurate expectations. Shared decision-making is possible because the truth is known. When improvement occurs, it is recognized; when it doesn't, alternatives are discussed without shame."
          },
          revelation: {
            header: "The Revelation",
            text: "Erick Turner's landmark study did what no one before had done: compare the FDA's complete record to the published literature. The result was devastating: selective publication inflated apparent efficacy by 32%. The published literature was not the evidence — it was a filtered, biased selection of the evidence. Turner's paper changed how we understand psychiatric drug trials forever.",
            detail: "Source: Turner et al. NEJM 2008"
          },
          refrain: "The funnel sees what words conceal."
        }
      },

      // SYNTHESIS SLIDE
      {
        type: 'content',
        content: {
          title: "The Pattern Across All Five Stories",
          sections: [
            {
              heading: "What Was Hidden",
              items: [
                "Suicide events in adolescents (Study 329)",
                "74% of patient data showing no benefit (Reboxetine)",
                "4 negative trials out of 12 registered (Gabapentin)",
                "22,000 pages of clinical study reports (Tamiflu)",
                "36 negative or questionable trials out of 74 (Antidepressants)"
              ]
            },
            {
              heading: "Who Hid It",
              items: [
                "Pharmaceutical companies with financial interests",
                "Medical communication firms ghostwriting papers",
                "Academic 'authors' who lent their names without seeing data",
                "Journals that preferentially published positive results",
                "Regulators who held data but did not require public release"
              ]
            },
            {
              heading: "What Would Have Revealed It",
              items: [
                "Trial registry searches comparing registered to published",
                "Funnel plots showing asymmetric distributions",
                "Freedom of Information requests to regulatory agencies",
                "Comparison of published outcomes to pre-registered outcomes",
                "Persistent demands for Clinical Study Reports"
              ]
            }
          ]
        }
      },

      // DECISION TREE SYNTHESIS
      {
        type: 'decision-tree',
        content: {
          title: "The Two Paths: A Universal Pattern",
          situation: "In each story, someone faced a choice. The evidence before them seemed clear. The published record pointed one way. But the complete truth pointed another. The detective asks: What would I have done?",
          nodes: [
            {
              id: 'start',
              question: "You encounter published evidence supporting a treatment. All visible trials are positive. Effect sizes are impressive. What is your first response?",
              branches: [
                { id: 'a', text: "Accept the evidence and act on it — published = peer-reviewed = reliable", nextNode: 'naive' },
                { id: 'b', text: "Ask: What might be missing? Check registries, request unpublished data", nextNode: 'vigilant' }
              ]
            },
            {
              id: 'naive',
              type: 'outcome',
              consequence: 'bad',
              title: "The Path of Trust",
              text: "You acted on what was visible. In the five cases you studied: you would have prescribed paroxetine to suicidal adolescents; recommended reboxetine that doesn't work; endorsed gabapentin for conditions it doesn't help; stockpiled billions in marginally effective Tamiflu; and set unrealistic expectations for antidepressants. Every published record seemed solid. Every one was incomplete.",
              realCase: "This was the default path for medicine for decades. Most guidelines, most prescribing decisions, most patient expectations were built on published literature that systematically overstated benefit."
            },
            {
              id: 'vigilant',
              type: 'outcome',
              consequence: 'good',
              title: "The Path of the Detective",
              text: "You questioned what was missing. In each case, the answer was the same: hidden data that reversed or substantially weakened the conclusion. Your skepticism was not cynicism — it was protection. The patients whose lives depended on your decisions were served by your vigilance. The funnel plot, the registry search, the FOIA request — these are not academic exercises. They are shields.",
              realCase: "Every major case of publication bias was eventually exposed by individuals who refused to accept the published record as complete. They asked: where is the rest of the data?"
            }
          ]
        }
      },

      // THE REFRAIN
      {
        type: 'oath',
        content: {
          header: "The Refrain of the Publication Bias Detective",
          text: "In Paroxetine, the paper said 'safe' — <strong>the funnel sees what words conceal.</strong><br><br>In Reboxetine, the published effect was 0.56 — <strong>the funnel sees what words conceal.</strong><br><br>In Gabapentin, four trials vanished — <strong>the funnel sees what words conceal.</strong><br><br>In Tamiflu, billions were spent on hidden data — <strong>the funnel sees what words conceal.</strong><br><br>In antidepressants, 94% positive became 51% — <strong>the funnel sees what words conceal.</strong><br><br>What words conceal, the detective reveals."
        }
      },

      // KEY TAKEAWAYS
      {
        type: 'key-takeaways',
        content: {
          takeaways: [
            "Publication bias is not an abstract statistical concept — it has body counts",
            "Every case followed the same pattern: financial incentive → selective publication → patient harm",
            "The tools of detection (registry search, funnel plot, FOIA) would have revealed the truth in every case",
            "The choice at every decision point was: trust vs. verify",
            "The funnel sees what words conceal — but only if you choose to look"
          ],
          actionItem: "The next time you read a meta-analysis showing impressive effects, ask yourself: Which of the five stories does this most resemble? Then check the registry. Then look at the funnel. Then decide."
        }
      },

      // FINAL PRINCIPLE
      {
        type: 'cycle-return',
        content: {
          principle: "You have now walked through five chronicles of hidden evidence. In each, the published record lied — not through fabrication, but through omission. In each, patients were harmed by treatments that appeared effective but were not. In each, the funnel plot — that simple scatter of effect against precision — would have shown the asymmetry, the gap, the missing mass of hidden truth. Remember: The funnel sees what words conceal. See what it shows you."
        }
      }
    ]
  }
];

// ============================================================
// INTERACTIVE TOOLS
// ============================================================

// Basic Funnel Plot Tool
function renderFunnelTool(containerId) {
  const container = document.getElementById(containerId);
  if (!container) return;

  container.innerHTML = `
    <div class="tool-controls">
      <div class="tool-control">
        <label>True Effect Size</label>
        <input type="range" id="trueEffect" min="-1" max="1" step="0.1" value="0.3" oninput="updateFunnelPlot()">
        <span id="trueEffectVal">0.3</span>
      </div>
      <div class="tool-control">
        <label>Publication Bias</label>
        <select id="biasLevel" onchange="updateFunnelPlot()">
          <option value="none">None</option>
          <option value="mild">Mild</option>
          <option value="moderate" selected>Moderate</option>
          <option value="severe">Severe</option>
        </select>
      </div>
      <div class="tool-control">
        <label>Number of Studies</label>
        <input type="range" id="numStudies" min="10" max="50" step="5" value="25" oninput="updateFunnelPlot()">
        <span id="numStudiesVal">25</span>
      </div>
    </div>
    <div id="funnelPlotArea" class="plot-area"></div>
    <div id="funnelStats" style="margin-top:1rem;padding:1rem;background:rgba(0,0,0,0.2);border-radius:8px;"></div>
  `;

  updateFunnelPlot();
}

function updateFunnelPlot() {
  const trueEffect = parseFloat(document.getElementById('trueEffect').value);
  const biasLevel = document.getElementById('biasLevel').value;
  const numStudies = parseInt(document.getElementById('numStudies').value);

  document.getElementById('trueEffectVal').textContent = trueEffect.toFixed(1);
  document.getElementById('numStudiesVal').textContent = numStudies;

  // Generate studies
  const studies = [];
  const biasProb = { none: 0, mild: 0.3, moderate: 0.5, severe: 0.7 };
  const suppressProb = biasProb[biasLevel];

  for (let i = 0; i < numStudies * 2; i++) {
    const se = 0.1 + Math.random() * 0.4; // SE between 0.1 and 0.5
    const effect = trueEffect + (Math.random() - 0.5) * se * 4; // scatter around true effect
    const z = effect / se;
    const pval = 2 * (1 - normalCDF(Math.abs(z)));

    // Publication bias: suppress non-significant negative small studies
    const isNegative = effect < trueEffect * 0.5;
    const isSmall = se > 0.25;
    const isNonSig = pval > 0.05;

    const suppress = isNegative && isSmall && isNonSig && Math.random() < suppressProb;

    if (!suppress && studies.length < numStudies) {
      studies.push({ effect, se, pval, suppressed: false });
    }
  }

  // Calculate pooled effect
  const weights = studies.map(s => 1 / (s.se * s.se));
  const sumW = weights.reduce((a, b) => a + b, 0);
  const pooledEffect = studies.reduce((sum, s, i) => sum + weights[i] * s.effect, 0) / sumW;

  // Max SE for contours
  const maxSE = Math.max(...studies.map(s => s.se)) * 1.1;
  const z_05 = 1.96;

  // Create traces
  const studyTrace = {
    x: studies.map(s => s.effect),
    y: studies.map(s => s.se),
    mode: 'markers',
    type: 'scatter',
    marker: {
      size: 10,
      color: studies.map(s => s.pval < 0.05 ? '#3b82f6' : '#94a3b8'),
      line: { color: '#ffffff', width: 1 }
    },
    text: studies.map((s, i) => `Study ${i+1}<br>Effect: ${s.effect.toFixed(2)}<br>SE: ${s.se.toFixed(2)}<br>p: ${s.pval.toFixed(3)}`),
    hoverinfo: 'text',
    name: 'Studies'
  };

  const pooledLine = {
    x: [pooledEffect, pooledEffect],
    y: [0, maxSE],
    mode: 'lines',
    line: { color: '#d4af37', width: 2, dash: 'dash' },
    name: 'Pooled Effect'
  };

  const trueLine = {
    x: [trueEffect, trueEffect],
    y: [0, maxSE],
    mode: 'lines',
    line: { color: '#22c55e', width: 2, dash: 'dot' },
    name: 'True Effect'
  };

  // Contour lines
  const leftContour = {
    x: [pooledEffect, pooledEffect - z_05 * maxSE],
    y: [0, maxSE],
    mode: 'lines',
    line: { color: 'rgba(124,58,237,0.5)', width: 1, dash: 'dot' },
    showlegend: false
  };

  const rightContour = {
    x: [pooledEffect, pooledEffect + z_05 * maxSE],
    y: [0, maxSE],
    mode: 'lines',
    line: { color: 'rgba(124,58,237,0.5)', width: 1, dash: 'dot' },
    showlegend: false
  };

  Plotly.newPlot('funnelPlotArea', [studyTrace, pooledLine, trueLine, leftContour, rightContour], {
    title: 'Funnel Plot',
    xaxis: { title: 'Effect Size', zeroline: true },
    yaxis: { title: 'Standard Error', autorange: 'reversed' },
    showlegend: true,
    legend: { x: 1.02, y: 1 },
    paper_bgcolor: 'rgba(0,0,0,0)',
    plot_bgcolor: 'rgba(0,0,0,0.2)',
    font: { color: '#f5f5f0' }
  }, { responsive: true });

  // Stats
  const inflation = trueEffect !== 0 ? ((pooledEffect - trueEffect) / trueEffect * 100).toFixed(1) : 'N/A';
  const biasDesc = biasLevel === 'none' ? 'no' : biasLevel;
  const asymmetryDesc = biasLevel === 'none' ? 'symmetric (no gaps)' :
    biasLevel === 'mild' ? 'slightly asymmetric with minor gap in lower-left' :
    biasLevel === 'moderate' ? 'moderately asymmetric with visible gap in lower-left' :
    'severely asymmetric with large gap in lower-left (missing small negative studies)';

  document.getElementById('funnelStats').innerHTML = `
    <div class="chart-description" aria-live="polite">
      Funnel plot showing ${numStudies} studies. True effect: ${trueEffect.toFixed(2)}.
      Observed pooled effect: ${pooledEffect.toFixed(2)} (${inflation === 'N/A' ? 'true effect is zero' : inflation > 0 ? inflation + '% inflation' : 'no inflation'}).
      Publication bias level: ${biasDesc}. Plot appears ${asymmetryDesc}.
    </div>
    <button onclick="this.previousElementSibling.classList.toggle('chart-description-visible')"
            style="font-size:0.75rem;padding:0.25rem 0.5rem;margin-bottom:0.75rem;background:rgba(255,255,255,0.1);border:1px solid rgba(255,255,255,0.2);border-radius:4px;color:var(--cream);cursor:pointer;">
      Toggle Chart Description (Screen Reader)
    </button>
    <div style="display:grid;grid-template-columns:repeat(3,1fr);gap:1rem;text-align:center;">
      <div>
        <div style="color:#22c55e;font-size:1.5rem;font-weight:bold;">${trueEffect.toFixed(2)}</div>
        <div style="font-size:0.8rem;color:rgba(255,255,255,0.6);">True Effect</div>
      </div>
      <div>
        <div style="color:#d4af37;font-size:1.5rem;font-weight:bold;">${pooledEffect.toFixed(2)}</div>
        <div style="font-size:0.8rem;color:rgba(255,255,255,0.6);">Observed (Pooled)</div>
      </div>
      <div>
        <div style="color:${inflation === 'N/A' ? '#888' : inflation > 10 ? '#dc2626' : '#16a34a'};font-size:1.5rem;font-weight:bold;">${inflation === 'N/A' ? 'N/A' : (inflation > 0 ? '+' : '') + inflation + '%'}</div>
        <div style="font-size:0.8rem;color:rgba(255,255,255,0.6);">Inflation</div>
      </div>
    </div>
  `;
}

// Contour-Enhanced Funnel Plot
function renderContourTool(containerId) {
  const container = document.getElementById(containerId);
  if (!container) return;

  container.innerHTML = `
    <div class="tool-controls">
      <div class="tool-control">
        <label>Show Contours</label>
        <select id="showContours" onchange="updateContourPlot()">
          <option value="yes" selected>Yes</option>
          <option value="no">No</option>
        </select>
      </div>
      <div class="tool-control">
        <label>Bias Pattern</label>
        <select id="biasPattern" onchange="updateContourPlot()">
          <option value="none">No Bias (Symmetric)</option>
          <option value="pubBias" selected>Publication Bias</option>
          <option value="heterogeneity">Heterogeneity</option>
        </select>
      </div>
    </div>
    <div id="contourPlotArea" class="plot-area"></div>
    <div id="contourInterpret" style="margin-top:1rem;padding:1rem;background:rgba(0,0,0,0.2);border-radius:8px;"></div>
  `;

  updateContourPlot();
}

function updateContourPlot() {
  const showContours = document.getElementById('showContours').value === 'yes';
  const biasPattern = document.getElementById('biasPattern').value;

  // Generate data based on pattern
  const studies = [];
  const trueEffect = 0.3;

  for (let i = 0; i < 30; i++) {
    let se, effect;

    if (biasPattern === 'none') {
      se = 0.1 + Math.random() * 0.35;
      effect = trueEffect + (Math.random() - 0.5) * se * 3;
    } else if (biasPattern === 'pubBias') {
      se = 0.1 + Math.random() * 0.35;
      effect = trueEffect + (Math.random() - 0.5) * se * 3;
      const z = effect / se;
      const pval = 2 * (1 - normalCDF(Math.abs(z)));
      if (effect < 0 && se > 0.2 && pval > 0.05 && Math.random() < 0.7) continue;
    } else { // heterogeneity
      se = 0.1 + Math.random() * 0.35;
      // Small studies have larger effects
      effect = trueEffect + (se > 0.25 ? 0.2 : 0) + (Math.random() - 0.5) * se * 2;
    }

    studies.push({ effect, se });
  }

  const maxSE = Math.max(...studies.map(s => s.se)) * 1.1;
  const pooledEffect = studies.reduce((s, st) => s + st.effect, 0) / studies.length;

  const traces = [];

  // Contour shading
  if (showContours) {
    // p > 0.05 region (non-significant)
    traces.push({
      x: [pooledEffect - 1.96 * maxSE, pooledEffect, pooledEffect + 1.96 * maxSE, pooledEffect - 1.96 * maxSE],
      y: [maxSE, 0, maxSE, maxSE],
      fill: 'toself',
      fillcolor: 'rgba(124,58,237,0.1)',
      line: { color: 'rgba(124,58,237,0.3)' },
      name: 'p < 0.05',
      showlegend: true
    });
  }

  // Studies
  traces.push({
    x: studies.map(s => s.effect),
    y: studies.map(s => s.se),
    mode: 'markers',
    type: 'scatter',
    marker: { size: 10, color: '#3b82f6', line: { color: '#fff', width: 1 } },
    name: 'Studies'
  });

  // Pooled line
  traces.push({
    x: [pooledEffect, pooledEffect],
    y: [0, maxSE],
    mode: 'lines',
    line: { color: '#d4af37', width: 2, dash: 'dash' },
    name: 'Pooled'
  });

  Plotly.newPlot('contourPlotArea', traces, {
    title: 'Contour-Enhanced Funnel Plot',
    xaxis: { title: 'Effect Size' },
    yaxis: { title: 'Standard Error', autorange: 'reversed' },
    showlegend: true,
    paper_bgcolor: 'rgba(0,0,0,0)',
    plot_bgcolor: 'rgba(0,0,0,0.2)',
    font: { color: '#f5f5f0' }
  }, { responsive: true });

  const interpretations = {
    none: "Symmetric funnel. No evidence of publication bias or small-study effects.",
    pubBias: "Asymmetric funnel with gap in bottom-left (non-significant region). This pattern suggests publication bias — small negative studies weren't published.",
    heterogeneity: "Asymmetric funnel with small studies showing larger effects. Could be publication bias OR genuine differences (sicker patients in small studies). Need clinical investigation."
  };

  document.getElementById('contourInterpret').innerHTML = `<strong>Interpretation:</strong> ${interpretations[biasPattern]}`;
}

// Egger's Test Tool
function renderEggerTool(containerId) {
  const container = document.getElementById(containerId);
  if (!container) return;

  container.innerHTML = `
    <div class="tool-description">Enter effect sizes and standard errors to calculate Egger's regression test.</div>
    <div class="tool-controls" style="flex-direction:column;">
      <textarea id="eggerData" rows="8" style="width:100%;background:rgba(0,0,0,0.3);color:#f5f5f0;border:1px solid rgba(255,255,255,0.2);border-radius:8px;padding:1rem;font-family:monospace;"># Effect, SE (one per line)
0.45, 0.12
0.32, 0.15
0.28, 0.18
0.51, 0.14
0.15, 0.22
0.38, 0.16
0.42, 0.13
0.55, 0.11
0.25, 0.19
0.33, 0.17</textarea>
      <button onclick="runEggerTest()" style="margin-top:1rem;padding:0.75rem 1.5rem;background:var(--teal);border:none;border-radius:8px;color:white;cursor:pointer;font-weight:600;">Run Egger's Test</button>
    </div>
    <div id="eggerResults" style="margin-top:1.5rem;"></div>
  `;
}

function runEggerTest() {
  const dataText = document.getElementById('eggerData').value;
  const lines = dataText.split('\n').filter(l => l.trim() && !l.startsWith('#'));

  const yi = [], sei = [];
  lines.forEach(line => {
    const parts = line.split(',').map(p => parseFloat(p.trim()));
    if (parts.length >= 2 && !isNaN(parts[0]) && !isNaN(parts[1])) {
      yi.push(parts[0]);
      sei.push(parts[1]);
    }
  });

  if (yi.length < 3) {
    document.getElementById('eggerResults').innerHTML = '<p style="color:#dc2626;">Need at least 3 studies for Egger\'s test.</p>';
    return;
  }

  // Weighted least squares regression
  const vi = sei.map(s => s * s);
  const wi = vi.map(v => 1 / v);
  const precision = sei.map(s => 1 / s);
  const zi = yi.map((y, i) => y / sei[i]);

  const k = yi.length;
  const sumW = wi.reduce((a, b) => a + b, 0);
  const sumWx = precision.reduce((sum, x, i) => sum + wi[i] * x, 0);
  const sumWy = zi.reduce((sum, y, i) => sum + wi[i] * y, 0);
  const sumWxy = precision.reduce((sum, x, i) => sum + wi[i] * x * zi[i], 0);
  const sumWx2 = precision.reduce((sum, x, i) => sum + wi[i] * x * x, 0);

  const det = sumW * sumWx2 - sumWx * sumWx;
  const b0 = (sumWx2 * sumWy - sumWx * sumWxy) / det; // intercept
  const b1 = (sumW * sumWxy - sumWx * sumWy) / det;   // slope

  const residuals = zi.map((z, i) => z - (b0 + b1 * precision[i]));
  const sse = residuals.reduce((sum, r, i) => sum + wi[i] * r * r, 0);
  const mse = sse / (k - 2);

  const var_b0 = mse * sumWx2 / det;
  const se_b0 = Math.sqrt(var_b0);
  const t_val = b0 / se_b0;
  const p_val = 2 * (1 - tCDF(Math.abs(t_val), k - 2));

  const significant = p_val < 0.1;

  document.getElementById('eggerResults').innerHTML = `
    <div class="statistic-card" style="background:${significant ? 'rgba(220,38,38,0.2)' : 'rgba(22,163,74,0.2)'};border-color:${significant ? 'rgba(220,38,38,0.4)' : 'rgba(22,163,74,0.4)'};">
      <div style="font-size:1.5rem;font-weight:bold;color:${significant ? '#dc2626' : '#22c55e'};">
        ${significant ? 'Significant Asymmetry Detected' : 'No Significant Asymmetry'}
      </div>
      <div style="margin-top:1rem;display:grid;grid-template-columns:repeat(3,1fr);gap:1rem;">
        <div>
          <div style="font-size:1.2rem;font-weight:bold;">${b0.toFixed(3)}</div>
          <div style="font-size:0.8rem;color:rgba(255,255,255,0.6);">Intercept (b0)</div>
        </div>
        <div>
          <div style="font-size:1.2rem;font-weight:bold;">${t_val.toFixed(2)}</div>
          <div style="font-size:0.8rem;color:rgba(255,255,255,0.6);">t-statistic</div>
        </div>
        <div>
          <div style="font-size:1.2rem;font-weight:bold;">${p_val.toFixed(4)}</div>
          <div style="font-size:0.8rem;color:rgba(255,255,255,0.6);">p-value</div>
        </div>
      </div>
    </div>
    <div style="margin-top:1rem;padding:1rem;background:rgba(0,0,0,0.2);border-radius:8px;">
      <strong>Interpretation:</strong> ${significant
        ? 'p < 0.10 suggests funnel plot asymmetry. This MAY indicate publication bias, but could also reflect heterogeneity or other small-study effects. Investigate further.'
        : 'p >= 0.10 does not suggest asymmetry. However, with ' + k + ' studies, the test has limited power. Absence of evidence is not evidence of absence.'}
    </div>
  `;
}

// Trim and Fill Tool
function renderTrimFillTool(containerId) {
  const container = document.getElementById(containerId);
  if (!container) return;

  container.innerHTML = `
    <div class="tool-controls">
      <div class="tool-control">
        <label>Show Original Only</label>
        <input type="checkbox" id="originalOnly" onchange="updateTrimFill()">
      </div>
      <div class="tool-control">
        <label>Asymmetry Level</label>
        <select id="asymLevel" onchange="updateTrimFill()">
          <option value="low">Low</option>
          <option value="moderate" selected>Moderate</option>
          <option value="high">High</option>
        </select>
      </div>
    </div>
    <div id="trimFillPlotArea" class="plot-area"></div>
    <div id="trimFillResults" style="margin-top:1rem;padding:1rem;background:rgba(0,0,0,0.2);border-radius:8px;"></div>
  `;

  updateTrimFill();
}

function updateTrimFill() {
  const originalOnly = document.getElementById('originalOnly').checked;
  const asymLevel = document.getElementById('asymLevel').value;

  const trueEffect = 0.25;
  const suppressProb = { low: 0.2, moderate: 0.5, high: 0.8 }[asymLevel];

  const observed = [];
  for (let i = 0; i < 40; i++) {
    const se = 0.08 + Math.random() * 0.35;
    const effect = trueEffect + (Math.random() - 0.5) * se * 3.5;
    const z = effect / se;
    const pval = 2 * (1 - normalCDF(Math.abs(z)));

    if (effect < 0.1 && se > 0.2 && pval > 0.05 && Math.random() < suppressProb) continue;
    observed.push({ effect, se });
  }

  // Simple trim-and-fill simulation
  const weights = observed.map(s => 1 / (s.se * s.se));
  const sumW = weights.reduce((a, b) => a + b, 0);
  const pooledObs = observed.reduce((sum, s, i) => sum + weights[i] * s.effect, 0) / sumW;

  // Find asymmetric studies and create mirror images
  const imputed = [];
  if (!originalOnly) {
    observed.forEach(s => {
      if (s.effect < pooledObs - 0.1 && s.se > 0.2) return; // keep these
      if (s.effect > pooledObs + 0.15 && s.se > 0.2) {
        // Impute mirror image
        const mirrorEffect = 2 * pooledObs - s.effect;
        imputed.push({ effect: mirrorEffect, se: s.se });
      }
    });
  }

  const allStudies = [...observed, ...imputed];
  const allWeights = allStudies.map(s => 1 / (s.se * s.se));
  const sumAllW = allWeights.reduce((a, b) => a + b, 0);
  const pooledAdj = allStudies.reduce((sum, s, i) => sum + allWeights[i] * s.effect, 0) / sumAllW;

  const maxSE = Math.max(...allStudies.map(s => s.se)) * 1.1;

  const traces = [
    {
      x: observed.map(s => s.effect),
      y: observed.map(s => s.se),
      mode: 'markers',
      marker: { size: 10, color: '#3b82f6', line: { color: '#fff', width: 1 } },
      name: 'Observed'
    }
  ];

  if (!originalOnly && imputed.length > 0) {
    traces.push({
      x: imputed.map(s => s.effect),
      y: imputed.map(s => s.se),
      mode: 'markers',
      marker: { size: 10, color: 'rgba(212,175,55,0)', symbol: 'circle-open', line: { color: '#d4af37', width: 2 } },
      name: 'Imputed (Trim-Fill)'
    });
  }

  traces.push({
    x: [pooledObs, pooledObs],
    y: [0, maxSE],
    mode: 'lines',
    line: { color: '#3b82f6', width: 2, dash: 'dash' },
    name: 'Original Pooled'
  });

  if (!originalOnly) {
    traces.push({
      x: [pooledAdj, pooledAdj],
      y: [0, maxSE],
      mode: 'lines',
      line: { color: '#d4af37', width: 2 },
      name: 'Adjusted Pooled'
    });
  }

  Plotly.newPlot('trimFillPlotArea', traces, {
    title: 'Trim and Fill Analysis',
    xaxis: { title: 'Effect Size' },
    yaxis: { title: 'Standard Error', autorange: 'reversed' },
    showlegend: true,
    paper_bgcolor: 'rgba(0,0,0,0)',
    plot_bgcolor: 'rgba(0,0,0,0.2)',
    font: { color: '#f5f5f0' }
  }, { responsive: true });

  const change = ((pooledAdj - pooledObs) / pooledObs * 100).toFixed(1);
  document.getElementById('trimFillResults').innerHTML = `
    <div style="display:grid;grid-template-columns:repeat(3,1fr);gap:1rem;text-align:center;">
      <div>
        <div style="font-size:1.3rem;font-weight:bold;color:#3b82f6;">${pooledObs.toFixed(3)}</div>
        <div style="font-size:0.8rem;color:rgba(255,255,255,0.6);">Original Effect</div>
      </div>
      <div>
        <div style="font-size:1.3rem;font-weight:bold;color:#d4af37;">${pooledAdj.toFixed(3)}</div>
        <div style="font-size:0.8rem;color:rgba(255,255,255,0.6);">Adjusted Effect</div>
      </div>
      <div>
        <div style="font-size:1.3rem;font-weight:bold;">${imputed.length}</div>
        <div style="font-size:0.8rem;color:rgba(255,255,255,0.6);">Imputed Studies</div>
      </div>
    </div>
    <div style="margin-top:1rem;font-size:0.9rem;color:rgba(255,255,255,0.7);">
      Effect changed by ${change}% after trim-and-fill adjustment.
      <em>Note: Imputed studies are statistical estimates, not real recovered data.</em>
    </div>
  `;
}

// P-Curve Tool
function renderPCurveTool(containerId) {
  const container = document.getElementById(containerId);
  if (!container) return;

  container.innerHTML = `
    <div class="tool-description">Enter p-values from significant studies (p < 0.05) to analyze the p-curve.</div>
    <div class="tool-controls" style="flex-direction:column;">
      <textarea id="pcurveData" rows="6" style="width:100%;background:rgba(0,0,0,0.3);color:#f5f5f0;border:1px solid rgba(255,255,255,0.2);border-radius:8px;padding:1rem;font-family:monospace;"># Enter p-values (p < 0.05), one per line
0.001
0.012
0.003
0.045
0.028
0.015
0.008
0.041
0.022
0.009</textarea>
      <button onclick="runPCurve()" style="margin-top:1rem;padding:0.75rem 1.5rem;background:var(--teal);border:none;border-radius:8px;color:white;cursor:pointer;font-weight:600;">Analyze P-Curve</button>
    </div>
    <div id="pcurvePlotArea" class="plot-area" style="min-height:300px;"></div>
    <div id="pcurveResults" style="margin-top:1rem;"></div>
  `;
}

function runPCurve() {
  const dataText = document.getElementById('pcurveData').value;
  const pvals = dataText.split('\n')
    .map(l => parseFloat(l.trim()))
    .filter(p => !isNaN(p) && p > 0 && p < 0.05);

  if (pvals.length < 5) {
    document.getElementById('pcurveResults').innerHTML = '<p style="color:#dc2626;">Need at least 5 significant p-values.</p>';
    return;
  }

  // Bin p-values
  const bins = [0, 0.01, 0.02, 0.03, 0.04, 0.05];
  const counts = [0, 0, 0, 0, 0];
  pvals.forEach(p => {
    for (let i = 0; i < 5; i++) {
      if (p > bins[i] && p <= bins[i + 1]) counts[i]++;
    }
  });

  // Expected under null (uniform)
  const expected = pvals.length / 5;

  const trace = {
    x: ['0-.01', '.01-.02', '.02-.03', '.03-.04', '.04-.05'],
    y: counts,
    type: 'bar',
    marker: { color: '#3b82f6' },
    name: 'Observed'
  };

  const expectedTrace = {
    x: ['0-.01', '.01-.02', '.02-.03', '.03-.04', '.04-.05'],
    y: [expected, expected, expected, expected, expected],
    type: 'scatter',
    mode: 'lines',
    line: { color: '#dc2626', dash: 'dash', width: 2 },
    name: 'Expected (Null)'
  };

  Plotly.newPlot('pcurvePlotArea', [trace, expectedTrace], {
    title: 'P-Curve Distribution',
    xaxis: { title: 'P-value Range' },
    yaxis: { title: 'Count' },
    paper_bgcolor: 'rgba(0,0,0,0)',
    plot_bgcolor: 'rgba(0,0,0,0.2)',
    font: { color: '#f5f5f0' }
  }, { responsive: true });

  // Simple skewness assessment
  const below025 = pvals.filter(p => p < 0.025).length;
  const above025 = pvals.filter(p => p >= 0.025).length;
  const isRightSkewed = below025 > above025 * 1.5;
  const isFlat = Math.abs(below025 - above025) < pvals.length * 0.2;
  const isLeftSkewed = above025 > below025 * 1.5;

  let interpretation, color;
  if (isRightSkewed) {
    interpretation = "RIGHT-SKEWED: Many p-values well below 0.025. This suggests TRUE evidential value — a real effect exists.";
    color = '#22c55e';
  } else if (isLeftSkewed) {
    interpretation = "LEFT-SKEWED: Excess p-values near 0.05. This suggests P-HACKING or selective reporting.";
    color = '#dc2626';
  } else {
    interpretation = "FLAT: P-values roughly uniform. This suggests either NO TRUE EFFECT or severely underpowered studies.";
    color = '#f59e0b';
  }

  document.getElementById('pcurveResults').innerHTML = `
    <div class="statistic-card" style="border-color:${color}40;background:${color}20;">
      <div style="font-size:1.2rem;font-weight:bold;color:${color};">${interpretation}</div>
      <div style="margin-top:1rem;font-size:0.9rem;">
        P < 0.025: ${below025} studies (${(below025/pvals.length*100).toFixed(0)}%) |
        P >= 0.025: ${above025} studies (${(above025/pvals.length*100).toFixed(0)}%)
      </div>
    </div>
  `;
}

// Utility functions
function normalCDF(x) {
  const a1 =  0.254829592, a2 = -0.284496736, a3 = 1.421413741;
  const a4 = -1.453152027, a5 = 1.061405429, p = 0.3275911;
  const sign = x < 0 ? -1 : 1;
  x = Math.abs(x) / Math.sqrt(2);
  const t = 1.0 / (1.0 + p * x);
  const y = 1.0 - (((((a5 * t + a4) * t) + a3) * t + a2) * t + a1) * t * Math.exp(-x * x);
  return 0.5 * (1.0 + sign * y);
}

// First set of tCDF/incompleteBeta/betaCF/lgamma removed (duplicate of lines below with different arg order)
// The canonical versions with correct negative-t handling are defined after the Failsafe N tool.

// Failsafe N Calculator Tool
function renderFailsafeTool(containerId) {
  const container = document.getElementById(containerId);
  if (!container) return;

  container.innerHTML = `
    <div class="tool-description">Calculate Rosenthal's Fail-Safe N — the number of null studies needed to make your result non-significant.</div>
    <div class="tool-controls" style="flex-direction:column;">
      <div style="display:grid;grid-template-columns:1fr 1fr;gap:1rem;">
        <div class="tool-control">
          <label>Number of Studies (k)</label>
          <input type="number" id="failsafeK" value="15" min="2" max="200" style="width:100%;">
        </div>
        <div class="tool-control">
          <label>Mean Z-score (or enter individual z below)</label>
          <input type="number" id="failsafeMeanZ" value="2.5" step="0.1" style="width:100%;">
        </div>
      </div>
      <div class="tool-control" style="margin-top:1rem;">
        <label>OR enter individual Z-scores (comma-separated):</label>
        <input type="text" id="failsafeZscores" placeholder="2.1, 3.4, 1.8, 2.9, ..." style="width:100%;">
      </div>
      <button onclick="runFailsafeN()" style="margin-top:1rem;padding:0.75rem 1.5rem;background:var(--teal);border:none;border-radius:8px;color:white;cursor:pointer;font-weight:600;">Calculate Fail-Safe N</button>
    </div>
    <div id="failsafeResults" style="margin-top:1.5rem;"></div>
  `;
}

function runFailsafeN() {
  let k, sumZ, meanZ;

  const zScoresInput = document.getElementById('failsafeZscores').value.trim();

  if (zScoresInput) {
    const zScores = zScoresInput.split(',').map(z => parseFloat(z.trim())).filter(z => !isNaN(z));
    k = zScores.length;
    sumZ = zScores.reduce((a, b) => a + b, 0);
    meanZ = sumZ / k;
  } else {
    k = parseInt(document.getElementById('failsafeK').value);
    meanZ = parseFloat(document.getElementById('failsafeMeanZ').value);
    sumZ = k * meanZ;
  }

  if (k < 2) {
    document.getElementById('failsafeResults').innerHTML = '<p style="color:#dc2626;">Need at least 2 studies.</p>';
    return;
  }

  // Rosenthal's Fail-Safe N formula: N = (sum(Z) / 1.645)^2 - k
  // Or equivalently: N = k * (meanZ / 1.645)^2 - k
  const criticalZ = 1.645; // one-tailed p = 0.05
  const failsafeN = Math.max(0, Math.pow(sumZ / criticalZ, 2) - k);
  const roundedN = Math.ceil(failsafeN);

  // Interpretation thresholds
  const threshold5k1 = 5 * k + 10; // Rosenthal's rule: N > 5k + 10 is robust
  const isRobust = roundedN > threshold5k1;

  const robustColor = isRobust ? '#22c55e' : '#dc2626';
  const robustText = isRobust
    ? `ROBUST: Fail-Safe N (${roundedN}) exceeds 5k + 10 (${threshold5k1}). Would need ${roundedN} null studies to nullify the effect.`
    : `FRAGILE: Fail-Safe N (${roundedN}) is less than 5k + 10 (${threshold5k1}). Result may be vulnerable to publication bias.`;

  document.getElementById('failsafeResults').innerHTML = `
    <div class="statistic-card" style="border-color:${robustColor}40;background:${robustColor}20;">
      <div style="font-size:3rem;font-weight:bold;color:${robustColor};">${roundedN}</div>
      <div style="font-size:1rem;margin-top:0.5rem;">Fail-Safe N (Rosenthal)</div>
    </div>
    <div style="margin-top:1rem;padding:1rem;background:rgba(0,0,0,0.2);border-radius:8px;">
      <strong style="color:${robustColor};">${robustText}</strong>
      <div style="margin-top:1rem;font-size:0.9rem;color:rgba(255,255,255,0.7);">
        <strong>Interpretation:</strong> ${roundedN} unpublished null studies would need to exist in file drawers to reduce your meta-analytic effect to non-significance.
      </div>
      <div style="margin-top:0.75rem;font-size:0.85rem;color:rgba(255,255,255,0.5);">
        <strong>Caveat:</strong> Fail-Safe N is criticized for assuming missing studies have exactly zero effect. Modern methods (selection models, trim-and-fill) are preferred. Use Fail-Safe N as a quick heuristic, not definitive evidence.
      </div>
    </div>
    <div style="margin-top:1rem;padding:1rem;background:rgba(124,58,237,0.1);border-radius:8px;font-size:0.85rem;">
      <strong>Formula:</strong> N = (ΣZ / 1.645)² - k = (${sumZ.toFixed(2)} / 1.645)² - ${k} = ${failsafeN.toFixed(1)}
    </div>
  `;
}

// PET-PEESE Calculator Tool
function renderPetPeeseTool(containerId) {
  const container = document.getElementById(containerId);
  if (!container) return;

  container.innerHTML = `
    <div class="tool-description">Calculate PET-PEESE bias-corrected effect estimates from your meta-analysis data.</div>
    <div style="margin:1rem 0;">
      <label style="display:block;margin-bottom:0.5rem;color:var(--gold);">Enter study data (one per line: effect, SE)</label>
      <textarea id="petpeeseData" rows="8" placeholder="0.45, 0.12
0.32, 0.15
0.58, 0.18
0.21, 0.22
0.67, 0.11" style="width:100%;padding:0.75rem;background:rgba(0,0,0,0.3);border:1px solid var(--gold);border-radius:8px;color:white;font-family:monospace;"></textarea>
      <p style="font-size:0.8rem;color:rgba(255,255,255,0.5);margin-top:0.5rem;">Format: effect size, standard error (comma separated, one study per line)</p>
    </div>
    <button onclick="runPetPeese()" style="padding:0.75rem 1.5rem;background:var(--purple);border:none;border-radius:8px;color:white;cursor:pointer;font-weight:600;">Calculate PET-PEESE</button>
    <div id="petpeeseResults" style="margin-top:1.5rem;"></div>
  `;
}

function runPetPeese() {
  const dataText = document.getElementById('petpeeseData').value.trim();
  const lines = dataText.split('\n').filter(l => l.trim());

  if (lines.length < 5) {
    document.getElementById('petpeeseResults').innerHTML = '<p style="color:#dc2626;">Need at least 5 studies for reliable PET-PEESE estimates.</p>';
    return;
  }

  // Parse data
  const studies = [];
  for (const line of lines) {
    const [effect, se] = line.split(',').map(v => parseFloat(v.trim()));
    if (!isNaN(effect) && !isNaN(se) && se > 0) {
      studies.push({ effect, se, var: se * se });
    }
  }

  if (studies.length < 5) {
    document.getElementById('petpeeseResults').innerHTML = '<p style="color:#dc2626;">Could not parse enough valid data. Check format.</p>';
    return;
  }

  const k = studies.length;

  // Calculate weighted means for reference
  const weights = studies.map(s => 1 / s.var);
  const sumW = weights.reduce((a, b) => a + b, 0);
  const naiveEffect = studies.reduce((sum, s, i) => sum + weights[i] * s.effect, 0) / sumW;

  // PET: effect = b0 + b1 * SE (weighted by 1/variance)
  // Simple weighted least squares
  const meanSE = studies.reduce((sum, s, i) => sum + weights[i] * s.se, 0) / sumW;
  const ssxx_pet = studies.reduce((sum, s, i) => sum + weights[i] * Math.pow(s.se - meanSE, 2), 0);
  const ssxy_pet = studies.reduce((sum, s, i) => sum + weights[i] * (s.se - meanSE) * (s.effect - naiveEffect), 0);
  const b1_pet = ssxy_pet / ssxx_pet;
  const b0_pet = naiveEffect - b1_pet * meanSE;

  // Calculate SE of intercept for PET (proper WLS: Var(b0) = MSE * sum(w*x^2) / det)
  const residuals_pet = studies.map(s => s.effect - (b0_pet + b1_pet * s.se));
  const mse_pet = residuals_pet.reduce((sum, r, i) => sum + weights[i] * r * r, 0) / (k - 2);
  const sumWx2_pet = studies.reduce((sum, s, i) => sum + weights[i] * s.se * s.se, 0);
  const sumWx_pet = studies.reduce((sum, s, i) => sum + weights[i] * s.se, 0);
  const det_pet = sumW * sumWx2_pet - sumWx_pet * sumWx_pet;
  const se_b0_pet = Math.sqrt(mse_pet * sumWx2_pet / det_pet);
  const t_pet = b0_pet / se_b0_pet;
  const p_pet = 2 * (1 - tCDF(Math.abs(t_pet), k - 2));

  // PEESE: effect = b0 + b1 * variance
  const meanVar = studies.reduce((sum, s, i) => sum + weights[i] * s.var, 0) / sumW;
  const ssxx_peese = studies.reduce((sum, s, i) => sum + weights[i] * Math.pow(s.var - meanVar, 2), 0);
  const ssxy_peese = studies.reduce((sum, s, i) => sum + weights[i] * (s.var - meanVar) * (s.effect - naiveEffect), 0);
  const b1_peese = ssxy_peese / ssxx_peese;
  const b0_peese = naiveEffect - b1_peese * meanVar;

  // Calculate SE of intercept for PEESE (proper WLS)
  const residuals_peese = studies.map(s => s.effect - (b0_peese + b1_peese * s.var));
  const mse_peese = residuals_peese.reduce((sum, r, i) => sum + weights[i] * r * r, 0) / (k - 2);
  const sumWx2_peese = studies.reduce((sum, s, i) => sum + weights[i] * s.var * s.var, 0);
  const sumWx_peese = studies.reduce((sum, s, i) => sum + weights[i] * s.var, 0);
  const det_peese = sumW * sumWx2_peese - sumWx_peese * sumWx_peese;
  const se_b0_peese = Math.sqrt(mse_peese * sumWx2_peese / det_peese);

  // Conditional estimator: Use PET to test, PEESE to estimate
  const petSignificant = p_pet < 0.10;
  const conditionalEffect = petSignificant ? b0_peese : b0_pet;
  const conditionalLabel = petSignificant ? 'PEESE (true effect likely exists)' : 'PET (no evidence for true effect)';

  // Calculate percent reduction
  const reduction = ((naiveEffect - conditionalEffect) / naiveEffect * 100).toFixed(1);

  document.getElementById('petpeeseResults').innerHTML = `
    <div style="display:grid;grid-template-columns:repeat(3,1fr);gap:1rem;margin-bottom:1.5rem;">
      <div style="padding:1rem;background:rgba(59,130,246,0.2);border-radius:8px;text-align:center;">
        <div style="font-size:1.8rem;font-weight:bold;color:#3b82f6;">${naiveEffect.toFixed(3)}</div>
        <div style="font-size:0.85rem;">Naive (Uncorrected)</div>
      </div>
      <div style="padding:1rem;background:rgba(168,85,247,0.2);border-radius:8px;text-align:center;">
        <div style="font-size:1.8rem;font-weight:bold;color:#a855f7;">${b0_pet.toFixed(3)}</div>
        <div style="font-size:0.85rem;">PET Intercept</div>
        <div style="font-size:0.75rem;color:rgba(255,255,255,0.5);">p = ${p_pet.toFixed(3)}</div>
      </div>
      <div style="padding:1rem;background:rgba(236,72,153,0.2);border-radius:8px;text-align:center;">
        <div style="font-size:1.8rem;font-weight:bold;color:#ec4899;">${b0_peese.toFixed(3)}</div>
        <div style="font-size:0.85rem;">PEESE Intercept</div>
      </div>
    </div>

    <div style="padding:1.5rem;background:rgba(34,197,94,0.2);border:2px solid rgba(34,197,94,0.4);border-radius:12px;margin-bottom:1.5rem;">
      <div style="font-size:0.9rem;color:#4ade80;margin-bottom:0.5rem;">CONDITIONAL ESTIMATE (Recommended)</div>
      <div style="font-size:2.5rem;font-weight:bold;color:#22c55e;">${conditionalEffect.toFixed(3)}</div>
      <div style="font-size:0.9rem;margin-top:0.5rem;">${conditionalLabel}</div>
      <div style="font-size:0.85rem;color:rgba(255,255,255,0.6);margin-top:0.5rem;">
        Bias correction: ${reduction > 0 ? reduction + '% reduction' : Math.abs(reduction) + '% increase'} from naive estimate
      </div>
    </div>

    <div style="padding:1rem;background:rgba(0,0,0,0.2);border-radius:8px;font-size:0.9rem;">
      <strong>Interpretation:</strong><br>
      ${petSignificant
        ? `PET intercept is significant (p=${p_pet.toFixed(3)} < 0.10), suggesting a true effect exists after accounting for bias. Use PEESE estimate (${b0_peese.toFixed(3)}) as the bias-corrected effect.`
        : `PET intercept is not significant (p=${p_pet.toFixed(3)} >= 0.10), suggesting no reliable evidence for a true effect after accounting for publication bias. The apparent effect may be largely due to bias.`
      }
    </div>

    <div style="margin-top:1rem;padding:1rem;background:rgba(124,58,237,0.1);border-radius:8px;font-size:0.8rem;color:rgba(255,255,255,0.6);">
      <strong>Technical notes:</strong> PET-PEESE uses weighted least squares with inverse-variance weights. The two-step conditional estimator tests for true effect with PET (threshold p<0.10), then uses PEESE if effect exists. With ${k} studies, these estimates have ${k < 10 ? 'limited' : 'moderate'} reliability.
    </div>
  `;
}

// Simple t-distribution CDF approximation
function tCDF(t, df) {
  const x = df / (df + t * t);
  const a = df / 2;
  const b = 0.5;
  // Incomplete beta function approximation
  if (t < 0) return 0.5 * incompleteBeta(x, a, b);
  return 1 - 0.5 * incompleteBeta(x, a, b);
}

function incompleteBeta(x, a, b) {
  // Simple approximation using continued fraction
  const bt = Math.exp(
    lgamma(a + b) - lgamma(a) - lgamma(b) + a * Math.log(x) + b * Math.log(1 - x)
  );
  if (x < (a + 1) / (a + b + 2)) {
    return bt * betacf(x, a, b) / a;
  }
  return 1 - bt * betacf(1 - x, b, a) / b;
}

function betacf(x, a, b) {
  const maxIt = 100;
  const eps = 1e-8;
  let qab = a + b;
  let qap = a + 1;
  let qam = a - 1;
  let c = 1;
  let d = 1 - qab * x / qap;
  if (Math.abs(d) < 1e-30) d = 1e-30;
  d = 1 / d;
  let h = d;
  for (let m = 1; m <= maxIt; m++) {
    let m2 = 2 * m;
    let aa = m * (b - m) * x / ((qam + m2) * (a + m2));
    d = 1 + aa * d;
    if (Math.abs(d) < 1e-30) d = 1e-30;
    c = 1 + aa / c;
    if (Math.abs(c) < 1e-30) c = 1e-30;
    d = 1 / d;
    h *= d * c;
    aa = -(a + m) * (qab + m) * x / ((a + m2) * (qap + m2));
    d = 1 + aa * d;
    if (Math.abs(d) < 1e-30) d = 1e-30;
    c = 1 + aa / c;
    if (Math.abs(c) < 1e-30) c = 1e-30;
    d = 1 / d;
    let del = d * c;
    h *= del;
    if (Math.abs(del - 1) < eps) break;
  }
  return h;
}

function lgamma(x) {
  const c = [76.18009172947146, -86.50532032941677, 24.01409824083091,
    -1.231739572450155, 0.001208650973866179, -0.000005395239384953];
  let y = x;
  let tmp = x + 5.5;
  tmp -= (x + 0.5) * Math.log(tmp);
  let ser = 1.000000000190015;
  for (let j = 0; j < 6; j++) ser += c[j] / ++y;
  return -tmp + Math.log(2.5066282746310005 * ser / x);
}

// Registry Gap Tool (placeholder visualization)
function renderRegistryTool(containerId) {
  const container = document.getElementById(containerId);
  if (!container) return;

  container.innerHTML = `
    <div style="text-align:center;padding:2rem;">
      <div style="font-size:4rem;margin-bottom:1rem;">🔍</div>
      <h3 style="color:var(--gold);margin-bottom:1rem;">Registry Gap Analysis</h3>
      <p style="color:rgba(255,255,255,0.7);margin-bottom:2rem;">Compare registered vs. published trials to identify evidence gaps.</p>
      <div style="display:grid;grid-template-columns:1fr 1fr;gap:2rem;text-align:center;">
        <div style="padding:1.5rem;background:rgba(59,130,246,0.2);border-radius:12px;border:1px solid rgba(59,130,246,0.4);">
          <div style="font-size:2.5rem;font-weight:bold;color:#3b82f6;">23</div>
          <div>Registered Trials</div>
        </div>
        <div style="padding:1.5rem;background:rgba(22,163,74,0.2);border-radius:12px;border:1px solid rgba(22,163,74,0.4);">
          <div style="font-size:2.5rem;font-weight:bold;color:#22c55e;">15</div>
          <div>Published Results</div>
        </div>
      </div>
      <div style="margin-top:2rem;padding:1.5rem;background:rgba(220,38,38,0.2);border-radius:12px;border:1px solid rgba(220,38,38,0.4);">
        <div style="font-size:2rem;font-weight:bold;color:#dc2626;">8 Missing</div>
        <div>Trials completed but never published (35%)</div>
      </div>
      <p style="margin-top:1.5rem;font-size:0.9rem;color:rgba(255,255,255,0.5);">
        Search ClinicalTrials.gov for your intervention to identify potential missing studies.
      </p>
    </div>
  `;
}

// ============================================================
// CORE COURSE FUNCTIONALITY
// ============================================================
const STORAGE_KEY = 'publicationBiasDetective_v1';

let state = {
  currentModule: 0,
  currentSlide: 0,
  completedModules: [],
  certificateShown: false
};

function loadState() {
  try {
    const saved = localStorage.getItem(STORAGE_KEY);
    if (saved) state = { ...state, ...JSON.parse(saved) };
  } catch (e) {
    console.warn('Corrupt state, using defaults');
  }
}

function saveState() {
  localStorage.setItem(STORAGE_KEY, JSON.stringify(state));
}

function initCourse() {
  loadState();
  renderModuleList();
  renderSlide();
  updateProgress();

  // Keyboard navigation handled by setupKeyboardNavigation() — no duplicate listener here
}

function renderModuleList() {
  const list = document.getElementById('moduleList');
  list.innerHTML = modules.map((m, i) => `
    <div class="module-item ${i === state.currentModule ? 'active' : ''} ${state.completedModules.includes(i) ? 'completed' : ''}"
         onclick="goToModule(${i})">
      <div class="module-number">${i}</div>
      <div class="module-info">
        <div class="module-title">${m.title}</div>
        <div class="module-subtitle">${m.subtitle}</div>
        ${m.estimatedMinutes ? `<div class="module-time">${m.estimatedMinutes} min</div>` : ''}
      </div>
    </div>
  `).join('');
}

function renderSlide() {
  const module = modules[state.currentModule];
  const slide = module.slides[state.currentSlide];
  const container = document.getElementById('main-content');

  document.getElementById('moduleIndicator').textContent = `Case File ${module.id}: ${module.title}`;
  document.getElementById('slideCounter').textContent = `${state.currentSlide + 1} / ${module.slides.length}`;

  container.innerHTML = `<div class="slide active animate-in">${renderSlideContent(slide)}</div>`;

  document.getElementById('prevBtn').disabled = state.currentSlide === 0;
  document.getElementById('nextBtn').disabled = state.currentSlide === module.slides.length - 1;

  // Initialize tools
  setTimeout(() => {
    if (slide.type === 'tool-funnel') renderFunnelTool(slide.content.id);
    if (slide.type === 'tool-contour') renderContourTool(slide.content.id);
    if (slide.type === 'tool-egger') renderEggerTool(slide.content.id);
    if (slide.type === 'tool-trimfill') renderTrimFillTool(slide.content.id);
    if (slide.type === 'tool-petpeese') renderPetPeeseTool(slide.content.id);
    if (slide.type === 'tool-pcurve') renderPCurveTool(slide.content.id);
    if (slide.type === 'tool-registry') renderRegistryTool(slide.content.id);
    if (slide.type === 'tool-failsafe') renderFailsafeTool(slide.content.id);
  }, 100);
}

function renderSlideContent(slide) {
  switch(slide.type) {
    case 'title':
      const isMainTitle = slide.content.title === "Publication Bias Detective";
      const readingLevelHtml = isMainTitle ? `
        <div style="margin-top:1.5rem;">
          <span class="reading-level">Reading Level: Graduate/Professional</span>
        </div>
        <p style="font-size:0.85rem;color:rgba(255,255,255,0.5);margin-top:0.75rem;">
          Total Course Time: ~3 hours | Best for: Researchers, Clinicians, Systematic Reviewers
        </p>
      ` : '';
      return `<div style="text-align:center;padding:3rem;">
        <h1 class="slide-title" style="font-size:2.5rem;border:none;">${slide.content.title}</h1>
        <p style="font-size:1.3rem;color:var(--gold);margin-bottom:1.5rem;">${slide.content.subtitle}</p>
        <p style="font-size:1.1rem;opacity:0.8;max-width:600px;margin:0 auto;">${slide.content.text}</p>
        ${readingLevelHtml}
      </div>`;

    case 'principle':
      return `<div class="principle-display">
        <div class="principle-number">${slide.content.number}</div>
        <p class="principle-text">"${slide.content.text}"</p>
      </div>`;

    case 'rhetoric':
      return `<div class="rhetoric-question">${slide.content.question}</div>`;

    case 'case-file':
      return `<div class="case-file">
        <div class="case-file-header">
          <span class="case-number">${slide.content.caseNumber}</span>
          <div>
            <div class="case-title">${slide.content.title}</div>
            <div class="case-source">${slide.content.source}</div>
          </div>
        </div>
        <div class="evidence-timeline">
          ${slide.content.timeline.map(e => `
            <div class="timeline-event ${e.type || ''}">
              <div class="timeline-year">${e.year}</div>
              <div class="timeline-text">${e.text}</div>
            </div>
          `).join('')}
        </div>
        ${slide.content.realData ? `
          <div style="margin-top:1.5rem;padding:1rem;background:rgba(0,0,0,0.2);border-radius:8px;">
            <strong style="color:var(--gold);">Evidence Summary:</strong>
            <div style="display:grid;grid-template-columns:repeat(2,1fr);gap:0.5rem;margin-top:0.75rem;">
              ${Object.entries(slide.content.realData).map(([k,v]) => `
                <div><span style="color:rgba(255,255,255,0.6);">${k}:</span> ${v}</div>
              `).join('')}
            </div>
          </div>
        ` : ''}
      </div>`;

    case 'statistic-card':
      return `<div class="statistic-card">
        <div class="statistic-value">${slide.content.value}</div>
        <div class="statistic-label">${slide.content.label}</div>
        <div class="statistic-context">${slide.content.context}</div>
      </div>`;

    case 'death-toll':
      return `<div class="death-toll">
        <div class="death-toll-number">${slide.content.number}</div>
        <div class="death-toll-label">${slide.content.label}</div>
        <div class="death-toll-source">${slide.content.source}</div>
      </div>`;

    case 'oath':
      return `<div class="oath-box">
        <div class="oath-header">${slide.content.header}</div>
        <div class="oath-text">${slide.content.text}</div>
      </div>`;

    case 'contrast':
      return `<div>
        <h2 class="slide-title">${slide.content.title}</h2>
        <div class="contrast-box">
          <div class="contrast-side dark">
            <div class="contrast-header">${slide.content.darkSide.header}</div>
            <ul class="contrast-items">
              ${slide.content.darkSide.items.map(i => `<li>${i}</li>`).join('')}
            </ul>
            <div class="contrast-consequence">${slide.content.darkSide.consequence}</div>
          </div>
          <div class="contrast-side light">
            <div class="contrast-header">${slide.content.lightSide.header}</div>
            <ul class="contrast-items">
              ${slide.content.lightSide.items.map(i => `<li>${i}</li>`).join('')}
            </ul>
            <div class="contrast-consequence">${slide.content.lightSide.consequence}</div>
          </div>
        </div>
      </div>`;

    case 'content':
      return `<div>
        <h2 class="slide-title">${slide.content.title}</h2>
        ${slide.content.sections.map(s => `
          <div class="method-box">
            <h3>${s.heading}</h3>
            ${s.items ? `<ul>${s.items.map(i => `<li>${i}</li>`).join('')}</ul>` : ''}
          </div>
        `).join('')}
      </div>`;

    case 'decision-tree':
      return renderDecisionTree(slide.content);

    case 'clinical-guide':
      return `<div class="clinical-guide">
        <h3>${slide.content.title}</h3>
        <ul>${slide.content.items.map(i => `<li>${i}</li>`).join('')}</ul>
      </div>`;

    case 'cycle-return':
      return `<div class="cycle-return">
        <p style="font-size:0.8rem;color:var(--gold);text-transform:uppercase;margin-bottom:0.5rem;">Return to the Principle</p>
        <p class="principle-recall">"${slide.content.principle}"</p>
      </div>`;

    case 'quiz':
      return renderQuiz(slide.content);

    case 'tool-funnel':
    case 'tool-contour':
    case 'tool-egger':
    case 'tool-trimfill':
    case 'tool-pcurve':
    case 'tool-registry':
    case 'tool-failsafe':
    case 'tool-petpeese':
      return `<div class="tool-panel">
        <div class="tool-header">
          <span class="tool-icon">🔧</span>
          <span class="tool-title">${slide.content.title}</span>
        </div>
        <p class="tool-description">${slide.content.description}</p>
        <div id="${slide.content.id}"></div>
      </div>`;

    case 'learning-objectives':
      return `<div class="learning-objectives">
        <div class="learning-objectives-header">
          <span class="objectives-icon">🎯</span>
          <span>Learning Objectives</span>
        </div>
        <p style="margin-bottom:1rem;opacity:0.9;">${slide.content.intro || 'By the end of this module, you will be able to:'}</p>
        <ul>
          ${slide.content.objectives.map(obj => `<li>${obj}</li>`).join('')}
        </ul>
      </div>`;

    case 'key-takeaways':
      return `<div class="key-takeaways">
        <div class="key-takeaways-header">
          <span class="takeaways-icon">✅</span>
          <span>Key Takeaways</span>
        </div>
        <ul>
          ${slide.content.takeaways.map(t => `<li>${t}</li>`).join('')}
        </ul>
        ${slide.content.actionItem ? `
          <div class="action-item">
            <strong>Action Item:</strong> ${slide.content.actionItem}
          </div>
        ` : ''}
      </div>`;

    case 'common-mistakes':
      return `<div class="common-mistakes">
        <div class="mistakes-header">
          <span class="mistakes-icon">⚠️</span>
          <span>Common Mistakes to Avoid</span>
        </div>
        <ul>
          ${slide.content.mistakes.map(m => `<li><strong>${m.mistake}:</strong> ${m.correction}</li>`).join('')}
        </ul>
      </div>`;

    case 'patient-communication':
      return `<div class="patient-communication">
        <div class="communication-header">
          <span class="communication-icon">💬</span>
          <span>Patient Communication Script</span>
        </div>
        <div class="scenario">${slide.content.scenario}</div>
        <div class="script-box">
          <div class="script-label">What to say:</div>
          <div class="script-text">"${slide.content.script}"</div>
        </div>
        ${slide.content.keyPoints ? `
          <div class="key-points">
            <strong>Key communication points:</strong>
            <ul>${slide.content.keyPoints.map(p => `<li>${p}</li>`).join('')}</ul>
          </div>
        ` : ''}
      </div>`;

    case 'protagonist-story':
      return `<div class="protagonist-story">
        <div class="protagonist-header">
          <div class="protagonist-name">${slide.content.name}</div>
          <div class="protagonist-role">${slide.content.role}</div>
        </div>
        <div class="protagonist-narrative">${slide.content.narrative}</div>
        ${slide.content.quote ? `
          <blockquote class="protagonist-quote">"${slide.content.quote}"</blockquote>
        ` : ''}
        ${slide.content.impact ? `
          <div class="protagonist-impact">
            <strong>Impact:</strong> ${slide.content.impact}
          </div>
        ` : ''}
      </div>`;

    case 'legal-disclaimer':
      return `<div class="legal-disclaimer">
        <div class="disclaimer-header">
          <span class="disclaimer-icon">⚖️</span>
          <span>Important Legal Notice</span>
        </div>
        <div class="disclaimer-text">${slide.content.text}</div>
        ${slide.content.resources ? `
          <div class="disclaimer-resources">
            <strong>Resources:</strong>
            <ul>${slide.content.resources.map(r => `<li><a href="${r.url}" target="_blank">${r.name}</a></li>`).join('')}</ul>
          </div>
        ` : ''}
      </div>`;

    case 'printable-checklist':
      return `<div class="printable-checklist">
        <div class="checklist-header">
          <span class="checklist-icon">📋</span>
          <span>${slide.content.title}</span>
        </div>
        <p class="print-instruction">Print this checklist to use when reading meta-analyses</p>
        ${slide.content.sections.map(section => `
          <div class="checklist-section">
            <h4>${section.heading}</h4>
            <ul>
              ${section.items.map(item => `<li><input type="checkbox" class="checklist-box"> ${item}</li>`).join('')}
            </ul>
          </div>
        `).join('')}
        <button class="print-btn" onclick="window.print()">🖨️ Print Checklist</button>
      </div>`;

    case 'practice-case':
      return `<div class="practice-case">
        <div class="practice-header">
          <span class="practice-icon">🔬</span>
          <span>Practice Case: ${slide.content.title}</span>
        </div>
        <div class="case-scenario">${slide.content.scenario}</div>
        ${slide.content.data ? `
          <div class="sample-data">
            <h4>Sample Data:</h4>
            <table class="data-table">
              <thead><tr>${slide.content.data.headers.map(h => `<th>${h}</th>`).join('')}</tr></thead>
              <tbody>${slide.content.data.rows.map(row => `<tr>${row.map(cell => `<td>${cell}</td>`).join('')}</tr>`).join('')}</tbody>
            </table>
          </div>
        ` : ''}
        <div class="practice-questions">
          <h4>Questions to consider:</h4>
          <ol>${slide.content.questions.map(q => `<li>${q}</li>`).join('')}</ol>
        </div>
        ${slide.content.answers ? `
          <details class="answers-reveal">
            <summary>Reveal Answers</summary>
            <ol>${slide.content.answers.map(a => `<li>${a}</li>`).join('')}</ol>
          </details>
        ` : ''}
      </div>`;

    case 'pre-assessment':
      return `<div class="pre-assessment">
        <div class="assessment-header">
          <span class="assessment-icon">📝</span>
          <span>Pre-Assessment: Test Your Current Knowledge</span>
        </div>
        <p>${slide.content.intro}</p>
        <div id="preAssessmentQuiz"></div>
      </div>`;

    case 'redemption-story':
      return `<div class="redemption-story">
        <div class="redemption-header">
          <span class="redemption-icon">🌟</span>
          <span>A Different Path: ${slide.content.title}</span>
        </div>
        <div class="redemption-narrative">${slide.content.narrative}</div>
        <div class="redemption-lesson">
          <strong>The Lesson:</strong> ${slide.content.lesson}
        </div>
      </div>`;

    case 'story':
      return `<div class="story-container">
        <div class="story-opening">${slide.content.opening}</div>

        <div style="display:flex;align-items:center;gap:1rem;margin-bottom:1.5rem;">
          <span style="background:var(--evidence-red);color:white;padding:0.5rem 1rem;border-radius:4px;font-weight:700;font-size:0.8rem;text-transform:uppercase;">Story ${slide.content.storyNumber}</span>
          <div>
            <h2 style="font-family:'Cormorant Garamond',serif;font-size:1.8rem;color:var(--gold);margin:0;">${slide.content.title}</h2>
            <p style="font-size:0.85rem;color:rgba(255,255,255,0.6);margin:0;">${slide.content.caseId}</p>
          </div>
        </div>

        <div class="stats-box">
          <div class="stats-box-header">
            <span style="font-size:1.2rem;">📊</span>
            ${slide.content.stats.header}
          </div>
          ${slide.content.stats.items.map(item => `
            <div class="stat-item">
              <div class="stat-value">${item.value}</div>
              <div class="stat-label">${item.label}</div>
            </div>
          `).join('')}
        </div>

        <div class="interactive-decision-tree">
          <div class="decision-scenario">
            <div class="decision-scenario-title">${slide.content.scenario.title}</div>
            <p style="margin:0;line-height:1.7;">${slide.content.scenario.text}</p>
          </div>

          <div class="decision-path path-a" tabindex="0" role="button" onclick="this.classList.toggle('expanded')" onkeydown="if(event.key==='Enter'||event.key===' '){event.preventDefault();this.classList.toggle('expanded');}">
            <div class="path-header">
              <span style="font-size:1.2rem;">❌</span>
              ${slide.content.pathA.header}
              <span class="path-arrow">→</span>
            </div>
            <p style="margin:0.5rem 0;font-style:italic;color:rgba(255,255,255,0.8);">${slide.content.pathA.action}</p>
            <div class="story-timeline" style="margin:1rem 0;">
              ${slide.content.pathA.steps.map((step, i) => `
                <div class="timeline-step ${i === slide.content.pathA.steps.length - 1 ? 'danger' : ''}">
                  <div class="step-label">Step ${i + 1}</div>
                  <div class="step-content">${step}</div>
                </div>
              `).join('')}
            </div>
            <div class="path-consequence">
              <strong style="color:#fca5a5;">Consequence:</strong> ${slide.content.pathA.consequence}
            </div>
          </div>

          <div class="decision-path path-b" tabindex="0" role="button" onclick="this.classList.toggle('expanded')" onkeydown="if(event.key==='Enter'||event.key===' '){event.preventDefault();this.classList.toggle('expanded');}">
            <div class="path-header">
              <span style="font-size:1.2rem;">✓</span>
              ${slide.content.pathB.header}
              <span class="path-arrow">→</span>
            </div>
            <p style="margin:0.5rem 0;font-style:italic;color:rgba(255,255,255,0.8);">${slide.content.pathB.action}</p>
            <div class="story-timeline" style="margin:1rem 0;">
              ${slide.content.pathB.steps.map((step, i) => `
                <div class="timeline-step ${i === slide.content.pathB.steps.length - 1 ? 'success' : ''}">
                  <div class="step-label">Step ${i + 1}</div>
                  <div class="step-content">${step}</div>
                </div>
              `).join('')}
            </div>
            <div class="path-consequence">
              <strong style="color:#86efac;">Consequence:</strong> ${slide.content.pathB.consequence}
            </div>
          </div>
        </div>

        <div class="revelation-box">
          <div class="revelation-header">✦ ${slide.content.revelation.header} ✦</div>
          <p class="revelation-text">${slide.content.revelation.text}</p>
          <p class="revelation-detail">${slide.content.revelation.detail}</p>
        </div>

        <div class="story-refrain">
          <p>"${slide.content.refrain}"</p>
        </div>
      </div>`;

    default:
      return `<p>Unknown slide type: ${slide.type}</p>`;
  }
}

// Store current decision tree nodes to avoid XSS risk from inline JSON
let currentDecisionNodes = [];

function renderDecisionTree(content) {
  // Store nodes in module-level variable for safe access
  currentDecisionNodes = content.nodes;
  return `<div class="decision-tree">
    <div class="decision-title">${content.title}</div>
    <div class="decision-situation">${content.situation}</div>
    <div id="decisionContent" aria-live="polite" aria-atomic="true">${renderDecisionNode(content.nodes[0])}</div>
  </div>`;
}

function renderDecisionNode(node) {
  if (node.type === 'outcome') {
    return `<div class="decision-outcome ${node.consequence}">
      <div class="outcome-title">${node.title}</div>
      <div class="outcome-text">${node.text}</div>
      <div class="outcome-case">${node.realCase}</div>
    </div>`;
  }

  return `<div class="decision-node">
    <div class="decision-question">${node.question}</div>
    <div class="decision-branches">
      ${node.branches.map(b => `
        <button class="decision-branch" data-next-node="${b.nextNode}" onclick="selectDecisionBranch(this.dataset.nextNode)" tabindex="0">
          ${b.text}
        </button>
      `).join('')}
    </div>
  </div>`;
}

function selectDecisionBranch(nodeId) {
  const node = currentDecisionNodes.find(n => n.id === nodeId);
  if (node) {
    document.getElementById('decisionContent').innerHTML = renderDecisionNode(node);
  }
}

function renderQuiz(content) {
  const quizKey = `${state.currentModule}-${state.currentSlide}`;
  return `<div class="quiz-container">
    <div class="quiz-question">${content.question}</div>
    <div class="quiz-options">
      ${content.options.map(opt => `
        <div class="quiz-option" data-id="${opt.id}" onclick="selectQuizOption('${opt.id}', ${opt.correct}, this)">
          ${opt.text}
        </div>
      `).join('')}
    </div>
    <div class="quiz-explanation">${content.explanation}</div>
  </div>`;
}

function selectQuizOption(id, correct, element) {
  document.querySelectorAll('.quiz-option').forEach(o => {
    o.style.pointerEvents = 'none';
    const module = modules[state.currentModule];
    const slide = module.slides[state.currentSlide];
    const opt = slide.content.options.find(op => op.id === o.dataset.id);
    if (opt?.correct) o.classList.add('correct');
  });
  if (!correct) element.classList.add('incorrect');
  document.querySelector('.quiz-explanation').classList.add('visible');
}

function prevSlide() {
  if (state.currentSlide > 0) {
    state.currentSlide--;
    renderSlide();
    saveState();
  }
}

function nextSlide() {
  const module = modules[state.currentModule];
  if (state.currentSlide < module.slides.length - 1) {
    state.currentSlide++;
    renderSlide();
    saveState();
    checkCourseCompletion();
  }
}

function goToModule(index) {
  if (index !== state.currentModule) {
    if (state.currentSlide === modules[state.currentModule].slides.length - 1 &&
        !state.completedModules.includes(state.currentModule)) {
      state.completedModules.push(state.currentModule);
    }
    state.currentModule = index;
    state.currentSlide = 0;
    renderModuleList();
    renderSlide();
    updateProgress();
    saveState();
  }
}

function updateProgress() {
  const percent = Math.round((state.completedModules.length / modules.length) * 100);
  document.getElementById('progressPercent').textContent = `${percent}%`;
  document.getElementById('progressFill').style.width = `${percent}%`;
}

function openGlossary() {
  document.getElementById('glossaryOverlay').classList.add('open');
  renderGlossary();
}

function closeGlossary() {
  document.getElementById('glossaryOverlay').classList.remove('open');
}

function renderGlossary(filter = '') {
  const filtered = glossaryTerms.filter(t =>
    t.term.toLowerCase().includes(filter.toLowerCase()) ||
    t.def.toLowerCase().includes(filter.toLowerCase())
  );
  document.getElementById('glossaryContent').innerHTML = filtered.map(t => `
    <div class="glossary-term">
      <strong style="color:var(--gold);">${t.term}</strong><br>
      <span style="color:rgba(255,255,255,0.7);">${t.def}</span>
    </div>
  `).join('');
}

function filterGlossary() {
  renderGlossary(document.getElementById('glossarySearch').value);
}

// ============================================================
// THEME TOGGLE (Dark/Light Mode)
// ============================================================
function toggleTheme() {
  const body = document.body;
  const toggle = document.getElementById('themeToggle');
  const isLight = body.classList.toggle('light-mode');
  toggle.textContent = isLight ? '☀️' : '🌙';
  toggle.setAttribute('aria-label', isLight ? 'Switch to dark mode' : 'Switch to light mode');
  localStorage.setItem('pubBiasTheme', isLight ? 'light' : 'dark');
}

function loadTheme() {
  const saved = localStorage.getItem('pubBiasTheme');
  if (saved === 'light') {
    document.body.classList.add('light-mode');
    document.getElementById('themeToggle').textContent = '☀️';
  }
}

// ============================================================
// CERTIFICATE OF COMPLETION
// ============================================================
function checkCourseCompletion() {
  // Check if all modules are completed
  if (state.completedModules.length >= modules.length - 1) {
    // Check if on last slide of last module
    const lastModule = modules[modules.length - 1];
    if (state.currentModule === modules.length - 1 &&
        state.currentSlide === lastModule.slides.length - 1 &&
        !state.certificateShown) {
      state.certificateShown = true;
      saveState();
      setTimeout(() => {
        document.getElementById('nameInputModal').classList.add('open');
        document.getElementById('investigatorName').focus();
      }, 1000);
    }
  }
}

function generateCertificate() {
  const name = document.getElementById('investigatorName').value.trim();
  if (!name) {
    alert('Please enter your name to generate the certificate.');
    return;
  }

  // Close name input modal
  document.getElementById('nameInputModal').classList.remove('open');

  // Generate certificate ID
  const certId = 'PBD-' + Date.now().toString(36).toUpperCase() + Math.random().toString(36).substr(2, 4).toUpperCase();

  // Format date
  const date = new Date().toLocaleDateString('en-US', {
    year: 'numeric',
    month: 'long',
    day: 'numeric'
  });

  // Update certificate
  document.getElementById('certName').textContent = name;
  document.getElementById('certDate').textContent = `Completed on: ${date}`;
  document.getElementById('certId').textContent = `Certificate ID: ${certId}`;

  // Show certificate
  document.getElementById('certificateOverlay').classList.add('open');
}

function closeCertificate() {
  document.getElementById('certificateOverlay').classList.remove('open');
}

function printCertificate() {
  const cert = document.getElementById('certificateContainer');
  const printWindow = window.open('', '_blank');
  printWindow.document.write(`
    <!DOCTYPE html>
    <html>
    <head>
      <title>Publication Bias Detective - Certificate</title>
      <link href="https://fonts.googleapis.com/css2?family=Cormorant+Garamond:wght@400;600;700&family=Source+Sans+Pro:wght@400;600&display=swap" rel="stylesheet">
      <style>
        body {
          margin: 0; padding: 2rem;
          font-family: 'Source Sans Pro', sans-serif;
          display: flex; justify-content: center; align-items: center;
          min-height: 100vh; background: #f5f5f5;
        }
        .cert {
          background: linear-gradient(135deg, #fdf6e3 0%, #fff8dc 50%, #fdf6e3 100%);
          border: 8px double #d4af37;
          border-radius: 12px;
          padding: 3rem;
          max-width: 700px;
          text-align: center;
          position: relative;
        }
        .seal {
          position: absolute; top: -30px; left: 50%;
          transform: translateX(-50%);
          width: 60px; height: 60px;
          background: linear-gradient(135deg, #d4af37, #c5a028);
          border-radius: 50%;
          display: flex; align-items: center; justify-content: center;
          font-size: 1.8rem;
        }
        h1 {
          font-family: 'Cormorant Garamond', serif;
          font-size: 2.5rem; color: #1e3a5f;
          text-transform: uppercase; letter-spacing: 0.15em;
          margin-top: 1rem;
        }
        .subtitle { color: #666; margin-bottom: 1.5rem; }
        .body { font-size: 1.1rem; color: #333; line-height: 1.8; margin: 1.5rem 0; }
        .name {
          font-family: 'Cormorant Garamond', serif;
          font-size: 2rem; font-weight: 700; color: #991b1b;
          border-bottom: 2px solid #d4af37;
          display: inline-block; padding: 0 2rem 0.5rem; margin: 1rem 0;
        }
        .date { font-size: 0.9rem; color: #666; margin-top: 1.5rem; }
        .id { font-size: 0.75rem; color: #999; margin-top: 0.5rem; font-family: monospace; }
        @media print {
          body { background: white; }
          .cert { box-shadow: none; }
        }
      </style>
    </head>
    <body>
      <div class="cert">
        <div class="seal">🏆</div>
        <h1>Certificate of Completion</h1>
        <p class="subtitle">Publication Bias Detective Training Program</p>
        <div class="body">
          <p>This is to certify that</p>
          <div class="name">${document.getElementById('certName').textContent}</div>
          <p>has successfully completed the</p>
          <p><strong style="color: #1e3a5f; font-size: 1.2rem;">Publication Bias Detective Course</strong></p>
          <p>demonstrating proficiency in identifying, assessing, and mitigating publication bias in systematic reviews and meta-analyses.</p>
        </div>
        <div class="date">${document.getElementById('certDate').textContent}</div>
        <div class="id">${document.getElementById('certId').textContent}</div>
      </div>
    </body>
    </html>
  `);
  printWindow.document.close();
  setTimeout(() => printWindow.print(), 500);
}

// ============================================================
// PDF EXPORT FOR CHECKLIST
// ============================================================
function exportChecklistPDF() {
  const checklistContent = `
PUBLICATION BIAS DETECTION CHECKLIST
=====================================

BEFORE STARTING
[ ] Registered protocol (PROSPERO) with bias assessment plan
[ ] Pre-specified primary outcome
[ ] Comprehensive search strategy including grey literature

SEARCH EXECUTION
[ ] Multiple databases (PubMed, Embase, Cochrane, etc.)
[ ] ClinicalTrials.gov + WHO ICTRP for registered trials
[ ] Conference abstracts and dissertations
[ ] Contact authors for unpublished data
[ ] No language restrictions (or justify if restricted)

VISUAL ASSESSMENT
[ ] Funnel plot (if ≥10 studies)
[ ] Contour-enhanced funnel plot
[ ] Doi plot with LFK index

STATISTICAL TESTS
[ ] Egger's test (continuous outcomes)
[ ] Harbord's or Peters' test (binary outcomes)
[ ] Begg's rank correlation
[ ] Document: k = ___, Egger p = ___

SENSITIVITY ANALYSES
[ ] Trim-and-fill (report adjusted estimate)
[ ] PET-PEESE (report conditional estimate)
[ ] Selection models (3PSM if available)
[ ] Compare with registered trial results

REPORTING
[ ] PRISMA flow diagram with reasons for exclusion
[ ] Table comparing published vs. unpublished studies
[ ] GRADE assessment for publication bias
[ ] Plain-language summary of bias impact

INTERPRETATION TEMPLATE
"Publication bias assessment: [Visual inspection / Statistical tests]
[suggested / did not suggest] the presence of small-study effects.
Sensitivity analyses [adjusted the pooled estimate from X to Y /
did not substantially change the results]. The certainty of evidence
was [downgraded / not downgraded] for publication bias."
`;

  // Create and download text file
  const blob = new Blob([checklistContent], { type: 'text/plain' });
  const link = document.createElement('a');
  link.href = URL.createObjectURL(blob);
  link.download = 'publication-bias-checklist.txt';
  link.click();
  URL.revokeObjectURL(link.href);
}

// ============================================================
// SERVICE WORKER FOR OFFLINE ACCESS
// ============================================================
function registerServiceWorker() {
  if ('serviceWorker' in navigator) {
    window.addEventListener('load', () => {
      // Create inline service worker
      const swCode = `
const CACHE_NAME = 'pub-bias-detective-v1';
const urlsToCache = [
  './',
  './publication-bias-detective.html'
];

self.addEventListener('install', event => {
  event.waitUntil(
    caches.open(CACHE_NAME)
      .then(cache => cache.addAll(urlsToCache))
  );
});

self.addEventListener('fetch', event => {
  event.respondWith(
    caches.match(event.request)
      .then(response => {
        if (response) return response;
        return fetch(event.request).then(response => {
          if (!response || response.status !== 200) return response;
          const responseToCache = response.clone();
          caches.open(CACHE_NAME).then(cache => {
            cache.put(event.request, responseToCache);
          });
          return response;
        });
      })
  );
});
`;

      const blob = new Blob([swCode], { type: 'application/javascript' });
      const swUrl = URL.createObjectURL(blob);

      navigator.serviceWorker.register(swUrl)
        .then(reg => console.log('Service Worker registered for offline access'))
        .catch(err => console.log('Service Worker registration skipped:', err.message));
    });
  }
}

// ============================================================
// KEYBOARD NAVIGATION ENHANCEMENT
// ============================================================
function setupKeyboardNavigation() {
  document.addEventListener('keydown', (e) => {
    // Arrow key navigation for slides
    if (e.key === 'ArrowRight' || e.key === 'ArrowDown') {
      if (!e.target.matches('input, textarea, select')) {
        nextSlide();
      }
    } else if (e.key === 'ArrowLeft' || e.key === 'ArrowUp') {
      if (!e.target.matches('input, textarea, select')) {
        prevSlide();
      }
    } else if (e.key === 'Escape') {
      closeGlossary();
      closeCertificate();
      document.getElementById('nameInputModal').classList.remove('open');
    }
  });

  // Make module items keyboard focusable
  document.querySelectorAll('.module-item').forEach((item, index) => {
    item.setAttribute('tabindex', '0');
    item.setAttribute('role', 'button');
    item.addEventListener('keydown', (e) => {
      if (e.key === 'Enter' || e.key === ' ') {
        e.preventDefault();
        goToModule(index);
      }
    });
  });
}

// ============================================================
// SCORM/LMS COMPATIBILITY WRAPPER
// ============================================================
const SCORM = {
  initialized: false,

  init: function() {
    // Check for SCORM API
    if (typeof window.API !== 'undefined' || typeof window.API_1484_11 !== 'undefined') {
      const api = window.API_1484_11 || window.API;
      if (api) {
        api.Initialize('');
        this.initialized = true;
        // SCORM API initialized
      }
    }
    return this.initialized;
  },

  setProgress: function(percent) {
    if (!this.initialized) return;
    const api = window.API_1484_11 || window.API;
    if (api) {
      api.SetValue('cmi.progress_measure', (percent / 100).toFixed(2));
      api.Commit('');
    }
  },

  setComplete: function() {
    if (!this.initialized) return;
    const api = window.API_1484_11 || window.API;
    if (api) {
      api.SetValue('cmi.completion_status', 'completed');
      api.SetValue('cmi.success_status', 'passed');
      api.Commit('');
    }
  },

  terminate: function() {
    if (!this.initialized) return;
    const api = window.API_1484_11 || window.API;
    if (api) {
      api.Terminate('');
    }
  }
};

// Hook SCORM into progress updates
const originalUpdateProgress = updateProgress;
updateProgress = function() {
  originalUpdateProgress();
  const percent = Math.round((state.completedModules.length / modules.length) * 100);
  SCORM.setProgress(percent);
  if (percent >= 100) {
    SCORM.setComplete();
  }
};

// Initialize on page load
document.addEventListener('DOMContentLoaded', () => {
  loadTheme();
  SCORM.init();
  registerServiceWorker();
  setTimeout(setupKeyboardNavigation, 100);
});

// Terminate SCORM on page unload
window.addEventListener('beforeunload', () => {
  SCORM.terminate();
});

document.addEventListener('DOMContentLoaded', initCourse);
</script>

<!-- Floating Glossary Button (visible on mobile) -->
<button class="floating-glossary" onclick="openGlossary()" aria-label="Open Glossary">
  📖
</button>

</body>
</html>
