<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Observational Evidence: When RCTs Are Impossible</title>
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Cormorant+Garamond:wght@400;600;700&family=Source+Sans+Pro:wght@400;600&display=swap" rel="stylesheet">
  <script src="https://cdn.plot.ly/plotly-2.27.0.min.js"></script>
  <script>
if (typeof Plotly === 'undefined') {
  document.addEventListener('DOMContentLoaded', function() {
    document.querySelectorAll('[id*="plot"], [id*="chart"], .plotly-graph-div, .js-plotly-plot').forEach(function(el) {
      el.innerHTML = '<div style="padding:2rem;text-align:center;background:#2a2a4a;border:1px dashed #D4AF37;border-radius:8px;color:#FAF8F5;margin:1rem 0;"><p style="font-size:1.1rem;margin-bottom:0.5rem;">Interactive chart unavailable offline</p><p style="font-size:0.85rem;opacity:0.7;">Connect to the internet to load interactive Plotly.js visualizations</p></div>';
    });
  });
}
</script>
  <style>
:root {
  --navy: #1E2761;
  --deep-navy: #141B3D;
  --gold: #D4AF37;
  --cream: #FAF8F5;
  --red: #BF2D2D;
  --teal: #2D8B8B;
  --light-text: #718096;
  --green: #2D8B5F;
}

* {
  margin: 0;
  padding: 0;
  box-sizing: border-box;
}

body {
  font-family: 'Source Sans Pro', sans-serif;
  background: var(--cream);
  color: var(--navy);
  min-height: 100vh;
  display: flex;
}

/* Skip Link for Accessibility */
.skip-link {
  position: absolute;
  top: -40px;
  left: 0;
  background: var(--gold);
  color: var(--navy);
  padding: 8px 16px;
  z-index: 1000;
  font-weight: 600;
  text-decoration: none;
  border-radius: 0 0 8px 0;
}

.skip-link:focus {
  top: 0;
}

/* Hamburger Menu */
.hamburger {
  display: none;
  position: fixed;
  top: 1rem;
  left: 1rem;
  z-index: 1001;
  background: var(--navy);
  border: none;
  border-radius: 8px;
  padding: 12px;
  cursor: pointer;
  flex-direction: column;
  gap: 4px;
}

.hamburger span {
  display: block;
  width: 24px;
  height: 3px;
  background: var(--gold);
  border-radius: 2px;
  transition: transform 0.3s;
}

.sidebar-overlay {
  display: none;
  position: fixed;
  inset: 0;
  background: rgba(0,0,0,0.5);
  z-index: 999;
}

/* Sidebar */
.sidebar {
  width: 280px;
  background: var(--navy);
  padding: 2rem 1rem;
  display: flex;
  flex-direction: column;
  position: fixed;
  height: 100vh;
  overflow-y: auto;
  z-index: 1000;
}

.logo {
  font-family: 'Cormorant Garamond', serif;
  font-size: 1.3rem;
  color: var(--gold);
  margin-bottom: 0.5rem;
  text-align: center;
}

.tagline {
  font-size: 0.75rem;
  color: rgba(255,255,255,0.6);
  text-align: center;
  margin-bottom: 2rem;
  font-style: italic;
}

.nav-section {
  margin-bottom: 1.5rem;
}

.nav-label {
  font-size: 0.7rem;
  text-transform: uppercase;
  letter-spacing: 1px;
  color: rgba(255,255,255,0.4);
  margin-bottom: 0.75rem;
  padding-left: 0.5rem;
}

.module-item {
  display: flex;
  align-items: center;
  padding: 0.75rem;
  border-radius: 8px;
  cursor: pointer;
  transition: all 0.2s;
  margin-bottom: 0.25rem;
  border: none;
  background: transparent;
  width: 100%;
  text-align: left;
  font-family: inherit;
  font-size: inherit;
}

.module-item:hover {
  background: rgba(255,255,255,0.1);
}

.module-item.active {
  background: rgba(212, 175, 55, 0.2);
  border-left: 3px solid var(--gold);
}

.module-item.completed .module-number {
  background: var(--green);
}

.module-number {
  width: 28px;
  height: 28px;
  border-radius: 50%;
  background: rgba(255,255,255,0.2);
  display: flex;
  align-items: center;
  justify-content: center;
  font-size: 0.8rem;
  color: white;
  margin-right: 0.75rem;
  flex-shrink: 0;
}

.module-info {
  flex: 1;
  min-width: 0;
}

.module-title {
  font-size: 0.9rem;
  color: white;
  white-space: nowrap;
  overflow: hidden;
  text-overflow: ellipsis;
}

.module-subtitle {
  font-size: 0.7rem;
  color: rgba(255,255,255,0.5);
}

/* Main Content */
.main-content {
  flex: 1;
  margin-left: 280px;
  display: flex;
  flex-direction: column;
  min-height: 100vh;
}

.top-bar {
  display: flex;
  justify-content: space-between;
  align-items: center;
  padding: 1rem 2rem;
  background: white;
  border-bottom: 1px solid rgba(0,0,0,0.1);
  flex-wrap: wrap;
  gap: 1rem;
}

.progress-section {
  display: flex;
  align-items: center;
  gap: 1rem;
}

.progress-bar {
  width: 200px;
  height: 8px;
  background: rgba(0,0,0,0.1);
  border-radius: 4px;
  overflow: hidden;
}

.progress-fill {
  height: 100%;
  background: linear-gradient(90deg, var(--gold), var(--teal));
  border-radius: 4px;
  transition: width 0.3s;
}

.progress-text {
  font-size: 0.85rem;
  color: var(--light-text);
}

.points-display {
  display: flex;
  align-items: center;
  gap: 0.5rem;
  background: linear-gradient(135deg, var(--navy), #2a3a7d);
  color: var(--gold);
  padding: 0.5rem 1rem;
  border-radius: 20px;
  font-weight: 600;
}

.top-actions {
  display: flex;
  gap: 0.5rem;
}

.action-btn {
  padding: 0.5rem 1rem;
  border: 1px solid var(--navy);
  background: transparent;
  border-radius: 6px;
  cursor: pointer;
  font-size: 0.85rem;
  transition: all 0.2s;
}

.action-btn:hover {
  background: var(--navy);
  color: white;
}

/* Slide Container */
.slide-container {
  flex: 1;
  padding: 2rem;
  max-width: 900px;
  margin: 0 auto;
  width: 100%;
}

/* Slide Types */
.slide-title {
  text-align: center;
  padding: 4rem 2rem;
}

.slide-title h1 {
  font-family: 'Cormorant Garamond', serif;
  font-size: 3rem;
  color: var(--navy);
  margin-bottom: 1rem;
}

.slide-title .subtitle {
  font-size: 1.5rem;
  color: var(--gold);
  margin-bottom: 1rem;
}

.slide-title .description {
  font-size: 1.1rem;
  color: var(--light-text);
  max-width: 600px;
  margin: 0 auto;
}

/* Principle Display */
.principle-box {
  background: linear-gradient(135deg, var(--navy), #2a3a7d);
  border-radius: 16px;
  padding: 3rem;
  text-align: center;
  margin: 2rem 0;
}

.principle-box .number {
  font-size: 4rem;
  color: var(--gold);
  font-family: 'Cormorant Garamond', serif;
  line-height: 1;
}

.principle-box .text {
  font-size: 1.8rem;
  color: white;
  font-family: 'Cormorant Garamond', serif;
  margin-top: 1rem;
  font-style: italic;
}

/* Story Deep */
.story-deep {
  background: linear-gradient(135deg, rgba(191,45,45,0.08), rgba(30,39,97,0.12));
  border-left: 4px solid var(--red);
  border-radius: 0 16px 16px 0;
  padding: 1.5rem;
  margin: 1.5rem 0;
}

.story-label {
  font-size: 0.75rem;
  text-transform: uppercase;
  letter-spacing: 2px;
  color: var(--red);
  margin-bottom: 0.5rem;
  font-weight: 600;
}

.story-source {
  font-size: 0.8rem;
  color: var(--light-text);
  margin-bottom: 1rem;
  font-style: italic;
}

.timeline {
  position: relative;
  padding-left: 2rem;
  margin: 1.5rem 0;
}

.timeline::before {
  content: '';
  position: absolute;
  left: 0.5rem;
  top: 0;
  bottom: 0;
  width: 2px;
  background: linear-gradient(to bottom, var(--gold), var(--red), var(--green));
}

.timeline-event {
  position: relative;
  margin-bottom: 1rem;
  padding-left: 1rem;
}

.timeline-event::before {
  content: '';
  position: absolute;
  left: -1.5rem;
  top: 0.5rem;
  width: 10px;
  height: 10px;
  border-radius: 50%;
  background: var(--gold);
}

.timeline-event.crisis::before {
  background: var(--red);
}

.timeline-event.revelation::before {
  background: var(--green);
}

.timeline-year {
  font-weight: 600;
  color: var(--gold);
  font-size: 0.9rem;
}

.timeline-text {
  color: var(--navy);
  font-size: 0.95rem;
  margin-top: 0.25rem;
}

.real-data-card {
  background: white;
  border: 2px solid var(--gold);
  border-radius: 12px;
  padding: 1rem;
  margin: 1rem 0;
}

.real-data-card h4 {
  color: var(--gold);
  font-size: 0.8rem;
  text-transform: uppercase;
  letter-spacing: 1px;
  margin-bottom: 0.75rem;
  display: flex;
  align-items: center;
  gap: 0.5rem;
}

.real-data-card h4::before {
  content: 'üìä';
}

.data-grid {
  display: grid;
  grid-template-columns: repeat(auto-fit, minmax(120px, 1fr));
  gap: 0.75rem;
}

.data-item {
  text-align: center;
}

.data-value {
  font-size: 1.1rem;
  font-weight: 600;
  color: var(--navy);
}

.data-label {
  font-size: 0.75rem;
  color: var(--light-text);
}

.story-hook {
  background: rgba(212, 175, 55, 0.1);
  border-left: 3px solid var(--gold);
  padding: 1rem;
  margin-top: 1rem;
  font-style: italic;
  color: var(--navy);
}

/* Story Box - Real World Case Studies */
.story-box {
  background: linear-gradient(135deg, rgba(45,139,95,0.08), rgba(30,39,97,0.10));
  border-left: 4px solid var(--green);
  border-radius: 0 16px 16px 0;
  padding: 1.5rem;
  margin: 1.5rem 0;
  box-shadow: 0 2px 12px rgba(0,0,0,0.06);
}

.story-box-header {
  display: flex;
  align-items: center;
  gap: 0.75rem;
  margin-bottom: 1rem;
}

.story-box-icon {
  font-size: 1.5rem;
}

.story-box-title {
  font-family: 'Cormorant Garamond', serif;
  font-size: 1.3rem;
  color: var(--navy);
  font-weight: 600;
}

.story-box-source {
  font-size: 0.75rem;
  color: var(--light-text);
  font-style: italic;
  margin-bottom: 1rem;
  padding-bottom: 0.75rem;
  border-bottom: 1px solid rgba(0,0,0,0.08);
}

.story-box-content {
  color: var(--navy);
  line-height: 1.7;
  font-size: 0.95rem;
}

.story-box-content p {
  margin-bottom: 1rem;
}

.story-box-content p:last-child {
  margin-bottom: 0;
}

.story-box-lesson {
  background: rgba(212, 175, 55, 0.15);
  border-left: 3px solid var(--gold);
  padding: 1rem;
  margin-top: 1.25rem;
  border-radius: 0 8px 8px 0;
}

.story-box-lesson-label {
  font-size: 0.7rem;
  text-transform: uppercase;
  letter-spacing: 1.5px;
  color: var(--gold);
  font-weight: 700;
  margin-bottom: 0.5rem;
}

.story-box-lesson-text {
  color: var(--navy);
  font-weight: 500;
  font-size: 0.95rem;
  line-height: 1.5;
}

/* Content Box */
.content-box {
  background: white;
  border-radius: 12px;
  padding: 1.5rem;
  margin: 1rem 0;
  box-shadow: 0 2px 8px rgba(0,0,0,0.05);
}

.content-box h3 {
  font-family: 'Cormorant Garamond', serif;
  font-size: 1.5rem;
  color: var(--navy);
  margin-bottom: 1rem;
}

.content-section {
  margin-bottom: 1.25rem;
}

.content-section h4 {
  color: var(--teal);
  font-size: 1rem;
  margin-bottom: 0.5rem;
}

.content-section p {
  color: var(--navy);
  line-height: 1.6;
}

.content-section ul {
  list-style: none;
  padding-left: 0;
}

.content-section li {
  padding: 0.4rem 0;
  padding-left: 1.5rem;
  position: relative;
  color: var(--navy);
}

.content-section li::before {
  content: '‚Üí';
  position: absolute;
  left: 0;
  color: var(--gold);
}

/* Method Box */
.method-box {
  background: linear-gradient(135deg, rgba(45,139,139,0.08), rgba(30,39,97,0.08));
  border-left: 4px solid var(--teal);
  border-radius: 0 16px 16px 0;
  padding: 1.5rem;
  margin: 1.5rem 0;
}

.method-label {
  font-size: 0.75rem;
  text-transform: uppercase;
  letter-spacing: 2px;
  color: var(--teal);
  margin-bottom: 0.5rem;
  font-weight: 600;
}

.method-box h3 {
  font-family: 'Cormorant Garamond', serif;
  font-size: 1.5rem;
  color: var(--navy);
  margin-bottom: 1rem;
}

/* Quiz */
.quiz-container {
  background: white;
  border-radius: 12px;
  padding: 1.5rem;
  margin: 1rem 0;
  box-shadow: 0 2px 8px rgba(0,0,0,0.05);
}

.quiz-question {
  font-size: 1.1rem;
  color: var(--navy);
  margin-bottom: 1.5rem;
  font-weight: 600;
}

.quiz-options {
  display: flex;
  flex-direction: column;
  gap: 0.75rem;
}

.quiz-option {
  padding: 1rem;
  border: 2px solid rgba(0,0,0,0.1);
  border-radius: 8px;
  cursor: pointer;
  transition: all 0.2s;
  background: white;
  text-align: left;
  font-size: 1rem;
  font-family: inherit;
  color: var(--navy);
}

.quiz-option:hover {
  border-color: var(--gold);
  background: rgba(212, 175, 55, 0.05);
}

.quiz-option.selected {
  border-color: var(--navy);
  background: rgba(30, 39, 97, 0.05);
}

.quiz-option.correct {
  border-color: var(--green);
  background: rgba(45, 139, 95, 0.1);
}

.quiz-option.incorrect {
  border-color: var(--red);
  background: rgba(191, 45, 45, 0.1);
}

.quiz-feedback {
  margin-top: 1rem;
  padding: 1rem;
  border-radius: 8px;
  display: none;
}

.quiz-feedback.show {
  display: block;
}

.quiz-feedback.correct {
  background: rgba(45, 139, 95, 0.1);
  border-left: 3px solid var(--green);
}

.quiz-feedback.incorrect {
  background: rgba(191, 45, 45, 0.1);
  border-left: 3px solid var(--red);
}

/* Decision Tree */
.decision-tree {
  background: white;
  border-radius: 12px;
  padding: 1.5rem;
  margin: 1rem 0;
  box-shadow: 0 2px 8px rgba(0,0,0,0.05);
}

.decision-tree h3 {
  font-family: 'Cormorant Garamond', serif;
  font-size: 1.3rem;
  color: var(--navy);
  margin-bottom: 1rem;
}

.decision-scenario {
  background: rgba(212, 175, 55, 0.1);
  padding: 1rem;
  border-radius: 8px;
  margin-bottom: 1rem;
  font-style: italic;
}

.decision-situation {
  background: rgba(30, 39, 97, 0.05);
  padding: 1rem;
  border-radius: 8px;
  margin-bottom: 1rem;
}

.decision-question {
  font-weight: 600;
  color: var(--navy);
  margin-bottom: 1rem;
}

.decision-branches {
  display: flex;
  flex-direction: column;
  gap: 0.5rem;
}

.decision-branch {
  padding: 1rem;
  border: 2px solid rgba(0,0,0,0.1);
  border-radius: 8px;
  cursor: pointer;
  transition: all 0.2s;
  background: white;
  text-align: left;
  font-family: inherit;
  font-size: 0.95rem;
  color: var(--navy);
  min-height: 48px;
}

.decision-branch:hover {
  border-color: var(--gold);
  background: rgba(212, 175, 55, 0.05);
}

.decision-outcome {
  padding: 1.5rem;
  border-radius: 8px;
  margin-top: 1rem;
}

.decision-outcome.good {
  background: rgba(45, 139, 95, 0.1);
  border-left: 4px solid var(--green);
}

.decision-outcome.bad {
  background: rgba(191, 45, 45, 0.1);
  border-left: 4px solid var(--red);
}

.decision-outcome.neutral {
  background: rgba(212, 175, 55, 0.1);
  border-left: 4px solid var(--gold);
}

.decision-outcome h4 {
  font-family: 'Cormorant Garamond', serif;
  font-size: 1.2rem;
  margin-bottom: 0.5rem;
}

.decision-lesson {
  margin-top: 1rem;
  padding-top: 1rem;
  border-top: 1px solid rgba(0,0,0,0.1);
  font-style: italic;
}

.decision-history {
  display: flex;
  flex-wrap: wrap;
  gap: 0.5rem;
  margin-bottom: 1rem;
}

.history-step {
  background: var(--navy);
  color: white;
  padding: 0.25rem 0.75rem;
  border-radius: 12px;
  font-size: 0.8rem;
}

.undo-btn {
  background: transparent;
  border: 1px solid var(--red);
  color: var(--red);
  padding: 0.5rem 1rem;
  border-radius: 6px;
  cursor: pointer;
  font-size: 0.85rem;
  margin-bottom: 1rem;
}

.undo-btn:hover {
  background: var(--red);
  color: white;
}

/* Tool Container */
.tool-container {
  background: white;
  border-radius: 12px;
  padding: 1.5rem;
  margin: 1rem 0;
  box-shadow: 0 2px 8px rgba(0,0,0,0.05);
  border: 2px solid var(--teal);
}

.tool-container h3 {
  font-family: 'Cormorant Garamond', serif;
  font-size: 1.3rem;
  color: var(--teal);
  margin-bottom: 0.5rem;
}

.tool-description {
  color: var(--light-text);
  margin-bottom: 1rem;
}

.tool-inputs {
  display: grid;
  gap: 1rem;
  margin-bottom: 1rem;
}

.input-group {
  display: flex;
  flex-direction: column;
  gap: 0.25rem;
}

.input-group label {
  font-size: 0.85rem;
  font-weight: 600;
  color: var(--navy);
}

.input-group input, .input-group select, .input-group textarea {
  padding: 0.75rem;
  border: 1px solid rgba(0,0,0,0.2);
  border-radius: 6px;
  font-size: 1rem;
  font-family: inherit;
}

.input-group input:focus, .input-group select:focus, .input-group textarea:focus {
  outline: none;
  border-color: var(--teal);
}

.tool-btn {
  background: var(--teal);
  color: white;
  border: none;
  padding: 0.75rem 1.5rem;
  border-radius: 6px;
  cursor: pointer;
  font-size: 1rem;
  font-weight: 600;
  transition: background 0.2s;
}

.tool-btn:hover {
  background: #247070;
}

.tool-output {
  margin-top: 1rem;
  padding: 1rem;
  background: rgba(45, 139, 139, 0.05);
  border-radius: 8px;
  border: 1px solid rgba(45, 139, 139, 0.2);
}

.plot-area {
  min-height: 350px;
  background: white;
  border-radius: 8px;
  margin: 1rem 0;
}

/* Navigation */
.nav-buttons {
  display: flex;
  justify-content: space-between;
  padding: 1rem 2rem;
  background: white;
  border-top: 1px solid rgba(0,0,0,0.1);
}

.nav-btn {
  display: flex;
  align-items: center;
  gap: 0.5rem;
  padding: 0.75rem 1.5rem;
  border: none;
  border-radius: 8px;
  cursor: pointer;
  font-size: 1rem;
  font-weight: 600;
  transition: all 0.2s;
}

.nav-btn.prev {
  background: transparent;
  border: 2px solid var(--navy);
  color: var(--navy);
}

.nav-btn.prev:hover {
  background: var(--navy);
  color: white;
}

.nav-btn.next {
  background: var(--gold);
  color: var(--navy);
}

.nav-btn.next:hover {
  background: #c9a032;
}

.nav-btn:disabled {
  opacity: 0.5;
  cursor: not-allowed;
}

/* Focus States for Accessibility */
button:focus, .module-item:focus, .quiz-option:focus,
.decision-branch:focus, input:focus, select:focus, a:focus {
  outline: 3px solid var(--gold);
  outline-offset: 2px;
}

/* High Contrast Mode */
@media (prefers-contrast: high) {
  :root {
    --gold: #FFD700;
    --cream: #FFFFFF;
  }
}

/* Focus-visible styles for keyboard navigation */
:focus-visible {
  outline: 2px solid var(--gold, #D4AF37);
  outline-offset: 2px;
}

:focus:not(:focus-visible) {
  outline: none;
}

button:focus-visible,
a:focus-visible,
[role="button"]:focus-visible,
input:focus-visible,
select:focus-visible,
textarea:focus-visible {
  outline: 2px solid var(--gold, #D4AF37);
  outline-offset: 2px;
  box-shadow: 0 0 0 4px rgba(212, 175, 55, 0.3);
}

/* Reduced Motion */
@media (prefers-reduced-motion: reduce) {
  *, *::before, *::after {
    animation-duration: 0.01ms !important;
    transition-duration: 0.01ms !important;
  }
}

/* Screen Reader Only */
.sr-only {
  position: absolute;
  width: 1px;
  height: 1px;
  padding: 0;
  margin: -1px;
  overflow: hidden;
  clip: rect(0, 0, 0, 0);
  white-space: nowrap;
  border: 0;
}

/* Responsive Design */
@media (max-width: 768px) {
  .hamburger {
    display: flex;
  }

  .sidebar {
    transform: translateX(-100%);
    transition: transform 0.3s;
  }

  .sidebar.open {
    transform: translateX(0);
  }

  .sidebar-overlay.show {
    display: block;
  }

  .main-content {
    margin-left: 0;
  }

  .slide-title h1 {
    font-size: 2rem;
  }

  .principle-box .text {
    font-size: 1.4rem;
  }

  .top-bar {
    padding: 1rem;
  }

  .progress-bar {
    width: 120px;
  }

  .decision-branch {
    min-height: 48px;
  }

  .quiz-option {
    min-height: 48px;
  }
}

@media (max-width: 480px) {
  .sidebar {
    width: 100%;
  }

  .slide-container {
    padding: 1rem;
  }

  .story-deep, .method-box, .content-box {
    padding: 1rem;
  }

  .data-grid {
    grid-template-columns: 1fr 1fr;
  }

  .top-actions {
    width: 100%;
    justify-content: center;
  }
}

/* Time Estimates */
.time-estimate {
  color: var(--teal);
  font-weight: 600;
  font-size: 0.65rem;
}

.course-time {
  font-size: 0.8rem;
  color: var(--light-text);
  padding: 0.25rem 0.75rem;
  background: rgba(45, 139, 139, 0.1);
  border-radius: 12px;
}

/* Badge Notification */
.badge-notification {
  position: fixed;
  bottom: 2rem;
  right: 2rem;
  background: linear-gradient(135deg, var(--navy), #2a3a7d);
  border-radius: 16px;
  padding: 1rem 1.5rem;
  display: flex;
  align-items: center;
  gap: 1rem;
  box-shadow: 0 8px 32px rgba(0,0,0,0.3);
  z-index: 3000;
  transform: translateY(100px);
  opacity: 0;
  transition: all 0.5s cubic-bezier(0.34, 1.56, 0.64, 1);
}

.badge-notification.show {
  transform: translateY(0);
  opacity: 1;
}

.badge-icon {
  width: 48px;
  height: 48px;
  border-radius: 50%;
  display: flex;
  align-items: center;
  justify-content: center;
  font-size: 1.5rem;
  box-shadow: 0 4px 12px rgba(0,0,0,0.2);
}

.badge-info {
  color: white;
}

.badge-earned {
  font-size: 0.7rem;
  text-transform: uppercase;
  letter-spacing: 1px;
  color: var(--gold);
  margin-bottom: 0.25rem;
}

.badge-name {
  font-family: 'Cormorant Garamond', serif;
  font-size: 1.2rem;
  font-weight: 600;
}

/* Badge Grid in Modal */
.badge-grid {
  display: grid;
  grid-template-columns: repeat(auto-fill, minmax(140px, 1fr));
  gap: 1rem;
  margin-top: 1rem;
}

.badge-card {
  background: white;
  border-radius: 12px;
  padding: 1rem;
  text-align: center;
  border: 2px solid transparent;
  transition: all 0.3s;
}

.badge-card.earned {
  border-color: var(--gold);
  box-shadow: 0 4px 12px rgba(212, 175, 55, 0.2);
}

.badge-card.locked {
  opacity: 0.5;
  filter: grayscale(1);
}

.badge-card .badge-icon {
  width: 56px;
  height: 56px;
  margin: 0 auto 0.75rem;
  font-size: 1.75rem;
}

.badge-card .badge-name {
  color: var(--navy);
  font-size: 0.9rem;
  font-weight: 600;
  margin-bottom: 0.25rem;
}

.badge-card .badge-requirement {
  font-size: 0.75rem;
  color: var(--light-text);
}

/* Mastery Checkpoint */
.mastery-checkpoint {
  background: linear-gradient(135deg, rgba(45, 139, 95, 0.15), rgba(45, 139, 139, 0.1));
  border: 2px solid var(--green);
  border-radius: 16px;
  padding: 1.5rem;
  margin: 2rem 0;
  text-align: center;
}

.mastery-checkpoint h3 {
  color: var(--green);
  font-family: 'Cormorant Garamond', serif;
  font-size: 1.5rem;
  margin-bottom: 0.5rem;
}

.mastery-checkpoint .mastery-icon {
  font-size: 2.5rem;
  margin-bottom: 0.5rem;
}

.mastery-checkpoint p {
  color: var(--navy);
  font-size: 1rem;
  margin: 0;
}

.mastery-checkpoint .mastery-stats {
  display: flex;
  justify-content: center;
  gap: 2rem;
  margin-top: 1rem;
  padding-top: 1rem;
  border-top: 1px solid rgba(45, 139, 95, 0.3);
}

.mastery-stat {
  text-align: center;
}

.mastery-stat .stat-value {
  font-size: 1.5rem;
  font-weight: 700;
  color: var(--green);
}

.mastery-stat .stat-label {
  font-size: 0.75rem;
  color: var(--light-text);
  text-transform: uppercase;
  letter-spacing: 0.5px;
}

/* IPTW Deep Dive Box */
.iptw-deepdive {
  background: linear-gradient(135deg, rgba(212, 175, 55, 0.1), rgba(30, 39, 97, 0.08));
  border-left: 4px solid var(--gold);
  border-radius: 0 12px 12px 0;
  padding: 1.25rem;
  margin: 1rem 0;
}

.iptw-deepdive h4 {
  color: var(--gold);
  font-family: 'Cormorant Garamond', serif;
  font-size: 1.1rem;
  margin-bottom: 0.75rem;
}

.iptw-formula {
  font-family: monospace;
  background: rgba(30, 39, 97, 0.1);
  padding: 0.5rem 1rem;
  border-radius: 6px;
  margin: 0.5rem 0;
  color: var(--navy);
}
  </style>
</head>
<body>
  <a href="#main-content" class="skip-link">Skip to main content</a>

  <button class="hamburger" aria-label="Toggle navigation menu" aria-expanded="false">
    <span></span>
    <span></span>
    <span></span>
  </button>

  <div class="sidebar-overlay"></div>

  <nav class="sidebar" role="navigation" aria-label="Course modules">
    <a href="index.html" style="display:block;font-size:0.7rem;color:rgba(212,175,55,0.7);text-decoration:none;margin-bottom:0.5rem;padding:0.5rem 1rem 0;" onmouseover="this.style.color='#D4AF37'" onmouseout="this.style.color='rgba(212,175,55,0.7)'">&larr; Course Library</a>
    <div class="logo">Observational Evidence</div>
    <div class="tagline">When RCTs Are Impossible</div>

    <div class="nav-section">
      <div class="nav-label">Modules</div>
      <div id="module-nav"></div>
    </div>
  </nav>

  <main class="main-content" id="main-content">
    <div class="top-bar">
      <div class="progress-section">
        <div class="progress-bar">
          <div class="progress-fill" id="progress-fill" style="width: 0%"></div>
        </div>
        <span class="progress-text" id="progress-text">0% Complete</span>
      </div>
      <div class="points-display">
        <span id="points-display">0</span> XP
      </div>
      <div class="course-time">
        <span id="total-time">5h 30m total</span>
      </div>
      <div class="top-actions">
        <button class="action-btn" onclick="openBadges()">üèÜ Badges</button>
        <button class="action-btn" onclick="openGlossary()">Glossary</button>
        <button class="action-btn" onclick="openToolLibrary()">Tools</button>
      </div>
    </div>

    <div class="slide-container" id="slide-container"></div>
    <div id="slide-announce" class="sr-only" aria-live="polite"></div>

    <div class="nav-buttons">
      <button class="nav-btn prev" id="prev-btn" onclick="prevSlide()">
        <span>‚Üê</span> Previous
      </button>
      <button class="nav-btn next" id="next-btn" onclick="nextSlide()">
        Next <span>‚Üí</span>
      </button>
    </div>
  </main>

<script>
// Course Data
const STORAGE_KEY = 'observational-evidence-course-progress';

let currentModule = 0;
let currentSlide = 0;
let gameState = {
  points: 0,
  earnedBadges: [],
  toolsUsed: [],
  modulesCompleted: [],
  scenariosCompleted: {},
  decisionTrees: {}
};

// Badge Definitions with visual designs
const BADGES = {
  'bias-detective': { name: 'Bias Detective', icon: 'üîç', color: '#BF2D2D', requirement: 'Complete all bias modules' },
  'dag-master': { name: 'DAG Master', icon: 'üï∏Ô∏è', color: '#2D8B8B', requirement: 'Build 3 DAGs correctly' },
  'robins-ranger': { name: 'ROBINS Ranger', icon: 'üõ°Ô∏è', color: '#D4AF37', requirement: 'Complete 5 ROBINS-I assessments' },
  'story-scholar': { name: 'Story Scholar', icon: 'üìö', color: '#1e2761', requirement: 'Read all 16 case studies' },
  'decision-ace': { name: 'Decision Ace', icon: 'üéØ', color: '#2D8B5F', requirement: 'Complete all 19 decision trees' },
  'quiz-champion': { name: 'Quiz Champion', icon: 'üèÜ', color: '#9B59B6', requirement: 'Score 100% on all quizzes' },
  'methods-master': { name: 'Methods Master', icon: 'üéì', color: '#E67E22', requirement: 'Complete entire course' },
  'capstone-conqueror': { name: 'Capstone Conqueror', icon: 'üëë', color: '#C0392B', requirement: 'Complete all 3 capstone scenarios' }
};

const modules = [
  {
    id: 0,
    title: "The Opening",
    subtitle: "Why Observational Evidence Matters",
    principle: null,
    estimatedTime: "15 min",
    slides: [
      {
        type: 'title',
        content: {
          title: "Observational Evidence",
          subtitle: "When RCTs Are Impossible",
          text: "Learn to extract truth from messy real-world data through the stories of those who were fooled ‚Äî and those who saved lives without a single randomized trial."
        }
      },
      {
        type: 'story-deep',
        content: {
          label: "THE SALVATION: THALIDOMIDE ‚Äî WHEN OBSERVATION SAVED LIVES",
          source: "Lancet 1961; McBride | BMJ 1961; Lenz | No RCT existed",
          timeline: [
            { year: "1957", text: "Thalidomide marketed in Germany as 'completely safe' sedative. Sold over-the-counter. Pregnant women take it for morning sickness.", type: "normal" },
            { year: "1959-60", text: "Reports of peripheral neuropathy emerge. Company dismisses concerns. No systematic monitoring exists.", type: "normal" },
            { year: "Nov 1961", text: "Dr. William McBride in Australia notices pattern: mothers of babies with limb defects took thalidomide. He writes to Lancet.", type: "revelation" },
            { year: "Nov 1961", text: "Dr. Widukind Lenz in Germany independently identifies the same pattern through case-control reasoning.", type: "revelation" },
            { year: "Dec 1961", text: "Drug withdrawn worldwide. 10,000+ children affected. Two observant physicians saved countless more.", type: "crisis" },
            { year: "Legacy", text: "Modern pharmacovigilance born. FDA strengthened. The lesson: OBSERVATIONAL DATA can detect harms RCTs miss.", type: "revelation" }
          ],
          realData: {
            endpoint: "Phocomelia (limb defects)",
            drug: "Thalidomide exposure in first trimester",
            placebo: "No exposure",
            rr: "Case-control OR > 100",
            ci: "Unquestionable association",
            nnh: "~10,000 children affected"
          },
          hook: "THE HOOK: No RCT detected thalidomide's harm. Two physicians, using observational reasoning, saw a pattern and saved a generation. This course teaches you to see patterns ‚Äî and to know when they're real."
        }
      },
      {
        type: 'principle',
        content: {
          text: "‚è∏Ô∏è KEY INSIGHT: Thalidomide proves that observational evidence can SAVE lives. But HRT proves it can also DECEIVE. The question isn't whether to use observational data ‚Äî it's how to use it wisely."
        }
      },
      {
        type: 'content',
        content: {
          title: "When RCTs Are Impossible or Insufficient",
          sections: [
            {
              heading: "RCTs Cannot Answer These Questions:",
              items: [
                "Rare harms (need millions of patients, decades of follow-up)",
                "Long-term outcomes (RCTs rarely last >5 years)",
                "Real-world effectiveness (RCTs select ideal patients)",
                "Unethical randomization (can't randomize smoking, poverty)",
                "Historical questions (what happened before RCTs existed?)"
              ]
            },
            {
              heading: "Observational Data Can:",
              items: [
                "Detect rare adverse events (thalidomide, Vioxx)",
                "Track lifetime outcomes (Framingham, Nurses' Health)",
                "Study real-world populations (not just trial-eligible)",
                "Generate hypotheses for future RCTs",
                "Monitor post-marketing drug safety"
              ]
            }
          ]
        }
      },
      {
        type: 'content',
        content: {
          title: "The Seven Principles of Observational Evidence",
          sections: [
            {
              heading: "Your Guide Through This Course:",
              items: [
                "1. \"Association is not causation\" ‚Äî Confounding deceives",
                "2. \"Time flows one direction\" ‚Äî Temporality matters",
                "3. \"You see what you look for\" ‚Äî Selection bias hides",
                "4. \"Measurement shapes reality\" ‚Äî Information bias distorts",
                "5. \"Context determines meaning\" ‚Äî Effect modification exists",
                "6. \"Adjustment is not magic\" ‚Äî Residual confounding remains",
                "7. \"Replication builds confidence\" ‚Äî One study is never enough"
              ]
            }
          ]
        }
      },
      {
        type: 'content',
        content: {
          title: "How This Course Works",
          sections: [
            {
              heading: "Each Module Contains:",
              items: [
                "üìñ A STORY ‚Äî Real disasters and triumphs from observational research",
                "üîß THE METHOD ‚Äî How to do it correctly",
                "‚öôÔ∏è THE TOOL ‚Äî Interactive practice",
                "üîÄ THE SCENARIO ‚Äî Apply your judgment",
                "‚úÖ THE QUIZ ‚Äî Test your understanding"
              ]
            }
          ]
        }
      },
      {
        type: 'decision-tree',
        content: {
          id: 'rct-vs-obs-decision',
          title: "When Do You Need Observational Data?",
          situation: "You're a researcher deciding how to study a clinical question. For each scenario, decide: RCT or observational?",
          nodes: {
            start: {
              question: "SCENARIO: You want to study whether smoking causes lung cancer. What study design?",
              branches: [
                { text: "RCT ‚Äî randomize people to smoke or not smoke", nextNode: "rct_smoking_wrong" },
                { text: "Observational ‚Äî follow smokers and non-smokers over time", nextNode: "obs_smoking_correct" }
              ]
            },
            rct_smoking_wrong: {
              type: 'outcome',
              outcome: 'danger',
              title: "Ethically impossible!",
              text: "You cannot randomize people to smoke ‚Äî it would cause harm. This is precisely why observational evidence was essential for establishing smoking ‚Üí lung cancer. Doll and Hill used cohort studies because RCTs were unethical.",
              lesson: "When exposure CAUSES harm, randomization is unethical. Observational data is the only option."
            },
            obs_smoking_correct: {
              situation: "Correct! Smoking studies must be observational. NEXT SCENARIO:",
              question: "You want to know if a new diabetes drug reduces heart attacks. What design?",
              branches: [
                { text: "RCT ‚Äî randomize patients to drug vs placebo", nextNode: "rct_drug_correct" },
                { text: "Observational ‚Äî compare patients who chose the drug", nextNode: "obs_drug_partial" }
              ]
            },
            rct_drug_correct: {
              situation: "Ideal! But the RCT will take 5 years and 10,000 patients. Management wants an answer in 6 months using claims data. What do you say?",
              question: "Your response:",
              branches: [
                { text: "Do the observational study ‚Äî speed matters", nextNode: "speed_wrong" },
                { text: "Explain that observational data for this question will be confounded", nextNode: "explain_correct" }
              ]
            },
            obs_drug_partial: {
              type: 'outcome',
              outcome: 'partial',
              title: "Possible, but risky",
              text: "Observational studies of drug effects have severe confounding by indication ‚Äî sicker patients get the drug. You might find the drug CAUSES heart attacks simply because heart attack-prone patients are prescribed it. This is the lesson of HRT.",
              lesson: "For treatable conditions, RCTs are preferred when feasible. Observational drug studies require very careful design (active comparator, new user, target trial emulation)."
            },
            speed_wrong: {
              type: 'outcome',
              outcome: 'danger',
              title: "This is how HRT happened!",
              text: "The observational studies of HRT were done because they were faster and easier than RCTs. They gave the WRONG answer for 20 years. Speed without validity is worse than waiting.",
              lesson: "Fast wrong answers harm patients. If observational evidence is too biased, waiting for an RCT is better."
            },
            explain_correct: {
              type: 'outcome',
              outcome: 'success',
              title: "Excellent scientific judgment!",
              text: "You correctly identified that this question (drug ‚Üí cardiovascular outcome) is highly susceptible to confounding by indication. Observational evidence here would be unreliable. The RCT is worth the wait.",
              lesson: "Know when observational data CAN and CANNOT answer your question. Drug efficacy with confounding by indication is dangerous territory."
            }
          }
        }
      },
      {
        type: 'principle',
        content: {
          text: "‚ö†Ô∏è THE WARNING: As you learn observational methods, remember both faces of the coin. Thalidomide shows observation SAVES lives. But this course will also show how it COSTS lives when done carelessly. Stay humble. Stay skeptical. Stay curious."
        }
      }
    ]
  },
  {
    id: 1,
    title: "The Trap",
    subtitle: "Confounding",
    principle: 0,
    story: "HRT",
    estimatedTime: "25 min",
    slides: [
      {
        type: 'principle-display',
        content: {
          principle: "Association is not causation"
        }
      },
      {
        type: 'story-deep',
        content: {
          label: "THE DECEPTION: HRT ‚Äî WHEN 30 STUDIES LIED",
          source: "JAMA 2002; 288:321-333 | WHI Writing Group | PubMed: 12117397",
          timeline: [
            { year: "1960s-80s", text: "Observational studies consistently show HRT reduces CHD by 40-50%. Biological rationale compelling: estrogen improves lipids.", type: "normal" },
            { year: "1985", text: "Framingham: Women on HRT have 50% lower CHD risk. Millions of prescriptions written for 'cardioprotection.'", type: "normal" },
            { year: "1991", text: "Nurses' Health Study: RR 0.56 (95% CI 0.40-0.80) for CHD. 'Definitive' evidence. HRT becomes standard of care.", type: "normal" },
            { year: "1998", text: "HERS trial (first large RCT): HR 0.99 (0.81-1.22). NO BENEFIT. Dismissed as 'wrong population.'", type: "crisis" },
            { year: "Jul 2002", text: "WHI stopped for HARM. CHD HR 1.29 (1.02-1.63). Breast cancer increased. The 30+ studies were ALL WRONG.", type: "crisis" },
            { year: "The Truth", text: "Healthy user bias: Women who chose HRT were healthier, richer, more educated, exercised more. The 'benefit' was confounding.", type: "revelation" }
          ],
          realData: {
            endpoint: "Coronary heart disease",
            drug: "Observational: RR 0.56 (0.40-0.80)",
            placebo: "RCT (WHI): HR 1.29 (1.02-1.63)",
            rr: "OPPOSITE DIRECTIONS",
            ci: "Confounding flipped benefit to harm",
            nnh: "Millions of women misled for decades"
          },
          hook: "THE QUESTION: How can 30 observational studies, 40+ meta-analyses, and 'compelling' biological rationale all be wrong? Because they measured WHO TAKES HRT, not WHAT HRT DOES. The women who chose HRT were already healthier. Confounding is invisible ‚Äî until an RCT exposes it."
        }
      },
      {
        type: 'story-box',
        content: {
          icon: 'üíî',
          title: "The HRT Reversal: 20 Years of Wrong Answers",
          source: "Women's Health Initiative, JAMA 2002",
          paragraphs: [
            "For decades, observational studies showed women on hormone replacement therapy had 50% fewer heart attacks. The biological rationale was compelling: estrogen improves lipid profiles. Millions of women were prescribed HRT specifically for 'cardioprotection.'",
            "Then the Women's Health Initiative RCT (2002) delivered a shock: HRT actually INCREASED heart attacks by 29%. The trial was stopped early for harm.",
            "What went wrong? The observational studies suffered from 'healthy user bias.' Women who chose HRT were wealthier, more educated, more health-conscious, and more likely to exercise. They would have had fewer heart attacks regardless of HRT. The studies were measuring the TYPE of woman who took HRT, not what HRT actually did."
          ],
          lesson: "Confounding created a false signal that lasted 20 years and influenced millions of prescriptions. When you observe that users of something have better outcomes, always ask: are they better off BECAUSE of the treatment, or were they already different?"
        }
      },
      {
        type: 'principle',
        content: {
          text: "‚è∏Ô∏è KEY TAKEAWAY: HRT's 'benefit' wasn't from the drug ‚Äî it was from the type of woman who chose to take it. Confounders are variables that affect BOTH the exposure and the outcome. Unless you account for them, you're measuring the confounder, not the treatment."
        }
      },
      {
        type: 'content',
        content: {
          title: "What is Confounding?",
          sections: [
            {
              heading: "The Three Conditions for Confounding:",
              items: [
                "1. The confounder is associated with the EXPOSURE",
                "2. The confounder is associated with the OUTCOME",
                "3. The confounder is NOT on the causal pathway"
              ]
            },
            {
              heading: "HRT Example:",
              items: [
                "Confounder: Socioeconomic status / health consciousness",
                "Associated with exposure: Wealthy, educated women more likely to seek HRT",
                "Associated with outcome: Wealthy, educated women have lower CHD risk anyway",
                "Not on causal pathway: SES doesn't mediate HRT's biological effect",
                "Result: HRT appeared beneficial because HRT users were healthier to begin with"
              ]
            }
          ]
        }
      },
      {
        type: 'method',
        content: {
          label: "THE METHOD: IDENTIFYING CONFOUNDERS",
          title: "Thinking Causally",
          sections: [
            {
              heading: "Step 1: Draw a DAG (Directed Acyclic Graph)",
              text: "Visualize the causal relationships between exposure, outcome, and potential confounders. Arrows show causal direction."
            },
            {
              heading: "Step 2: Identify Backdoor Paths",
              text: "Any path from exposure to outcome that goes BACKWARD through a common cause is a confounding path that must be blocked."
            },
            {
              heading: "Step 3: Decide What to Adjust For",
              text: "Adjust for confounders (common causes). DON'T adjust for mediators (on the causal pathway) or colliders (common effects)."
            },
            {
              heading: "Step 4: Assess Residual Confounding",
              text: "Even after adjustment, unmeasured confounders remain. Sensitivity analysis can estimate their potential impact."
            }
          ]
        }
      },
      {
        type: 'tool',
        content: {
          id: 'dag-builder',
          title: "DAG Builder",
          description: "Build a Directed Acyclic Graph to visualize causal relationships and identify confounders"
        }
      },
      {
        type: 'story-box',
        content: {
          icon: '‚òï',
          title: "The Nurses' Health Study Coffee Paradox",
          source: "Nurses' Health Study, Multiple Publications 1980s-2000s",
          paragraphs: [
            "Early analyses of the Nurses' Health Study found a troubling link: coffee drinkers had higher rates of heart disease. Medical guidelines began warning against coffee consumption. The association seemed clear in the data.",
            "Then researchers noticed something: coffee drinkers smoked more. In that era, coffee and cigarettes went together. When smoking was properly adjusted for, the coffee-heart disease link vanished entirely.",
            "But the story didn't end there. Later studies with better methods and longer follow-up showed coffee might actually be PROTECTIVE against heart disease, type 2 diabetes, and certain cancers. The same dataset, analyzed with better confounding control, reached the opposite conclusion."
          ],
          lesson: "Confounding control isn't just important‚Äîit can completely reverse your conclusions. The coffee story shows how a harmful association can become null, then become protective, all from the same underlying data when analyzed with progressively better methods."
        }
      },
      {
        type: 'decision-tree',
        content: {
          id: 'confounding_decision_tree',
          title: "The Coffee Conundrum",
          situation: "You're analyzing observational data on coffee consumption and mortality. Your crude analysis shows coffee drinkers have 15% higher mortality (RR 1.15, p<0.01). A colleague suggests this proves coffee is harmful.",
          nodes: {
            start: {
              id: 'start',
              situation: "Before publishing 'COFFEE KILLS', you consider potential confounders. What's your first thought?",
              question: "Which confounder are you most concerned about?",
              branches: [
                { id: 'smoking', text: "Smoking ‚Äî coffee drinkers smoke more", nextNode: 'smoking_path' },
                { id: 'age', text: "Age ‚Äî older people drink more coffee", nextNode: 'age_path' },
                { id: 'no_confounder', text: "The association is real ‚Äî publish as is", nextNode: 'publish_crude' }
              ]
            },
            smoking_path: {
              id: 'smoking_path',
              situation: "You stratify by smoking status. Among non-smokers: RR 0.92 (0.85-0.99). Among smokers: RR 1.35 (1.20-1.52). The crude RR of 1.15 was confounded by smoking.",
              question: "What do you conclude?",
              branches: [
                { id: 'coffee_protective', text: "Coffee is actually protective (in non-smokers)", nextNode: 'protective_finding' },
                { id: 'more_analysis', text: "Need to adjust for more confounders before concluding", nextNode: 'multivariate' },
                { id: 'effect_modification', text: "This looks like effect modification, not just confounding", nextNode: 'effect_mod_insight' }
              ]
            },
            age_path: {
              id: 'age_path',
              situation: "You check age distribution. Mean age: coffee drinkers 58 years, non-drinkers 52 years. Older people drink more coffee AND have higher mortality. Classic confounding.",
              question: "How do you proceed?",
              branches: [
                { id: 'age_adjust', text: "Adjust for age and re-analyze", nextNode: 'age_adjusted' },
                { id: 'age_stratify', text: "Stratify by age groups", nextNode: 'age_stratified' }
              ]
            },
            publish_crude: {
              id: 'publish_crude',
              type: 'outcome',
              consequence: 'bad',
              title: "The Coffee Panic",
              text: "Your paper is published. Headlines: 'COFFEE INCREASES DEATH RISK BY 15%'. Three months later, another team adjusts for smoking ‚Äî finding coffee is protective. Your paper is criticized as a textbook example of confounding. Your credibility suffers.",
              lesson: "THE CONSEQUENCE: Every observational association has potential confounders. Publishing crude associations without considering confounding is not science ‚Äî it's speculation. The HRT story should have taught us this."
            },
            protective_finding: {
              id: 'protective_finding',
              type: 'outcome',
              consequence: 'neutral',
              title: "Partial Credit",
              text: "Adjusting for smoking reveals coffee's apparent protective effect. But other confounders remain: socioeconomic status, diet, exercise. The non-smokers who drink coffee may still differ from non-smokers who don't.",
              lesson: "THE GRADUAL REVEAL: Adjusting for one confounder is better than none, but rarely sufficient. Multiple confounders usually exist. Each adjustment can reveal new associations ‚Äî or new biases."
            },
            multivariate: {
              id: 'multivariate',
              situation: "You build a multivariate model adjusting for: smoking, age, BMI, alcohol, income, education, exercise. Adjusted RR: 0.88 (0.82-0.95). Coffee appears protective after accounting for measured confounders.",
              question: "Can you now conclude coffee prevents death?",
              branches: [
                { id: 'conclude_protective', text: "Yes ‚Äî the adjusted analysis is causal", nextNode: 'overclaiming' },
                { id: 'residual_confounding', text: "No ‚Äî unmeasured confounders may remain", nextNode: 'wise_conclusion' }
              ]
            },
            effect_mod_insight: {
              id: 'effect_mod_insight',
              type: 'outcome',
              consequence: 'good',
              title: "Sharp Thinking",
              text: "You noticed the effect differs BY smoking status (harmful in smokers, protective in non-smokers). This is effect modification ‚Äî the effect of coffee genuinely differs in subgroups. Reporting a single average effect would be misleading.",
              lesson: "THE PROTECTION: Confounding distorts the overall effect. Effect modification means the effect truly varies. In your paper, report stratum-specific effects: 'Coffee was associated with lower mortality in non-smokers (RR 0.92) but higher mortality in smokers (RR 1.35).'"
            },
            age_adjusted: {
              id: 'age_adjusted',
              situation: "After age adjustment: RR 1.02 (0.95-1.10). The association disappeared! Age was a strong confounder. But wait ‚Äî should you also adjust for smoking?",
              isEnding: true,
              outcome: 'neutral',
              lesson: "THE REPETITION: One confounder down, potentially many to go. Age adjustment removed most of the crude association. But comprehensive analysis requires considering ALL major confounders. The job isn't done."
            },
            age_stratified: {
              id: 'age_stratified',
              situation: "Age-stratified results: <50 years: RR 0.95. 50-65 years: RR 1.01. >65 years: RR 0.98. No age group shows significant association. The crude RR 1.15 was entirely due to age confounding.",
              isEnding: true,
              outcome: 'good',
              lesson: "THE REVELATION: Stratification lets you SEE the confounding. In every age stratum, coffee shows no association with mortality. The crude association was an artifact of age differences between coffee drinkers and non-drinkers."
            },
            overclaiming: {
              id: 'overclaiming',
              type: 'outcome',
              consequence: 'bad',
              title: "The Overconfident Conclusion",
              text: "You conclude 'coffee prevents death.' But unmeasured confounders remain: genetics, personality type, sleep quality, stress levels. The HRT studies also 'adjusted for everything' ‚Äî and were still wrong. Observational data, no matter how adjusted, cannot prove causation.",
              lesson: "THE WARNING: Adjustment reduces confounding but never eliminates it. There are always unmeasured confounders. Say 'associated with' not 'causes.' Say 'suggests' not 'proves.' Humility is not weakness ‚Äî it's honesty."
            },
            wise_conclusion: {
              id: 'wise_conclusion',
              type: 'outcome',
              consequence: 'good',
              title: "The Honest Conclusion",
              text: "Your paper states: 'After adjustment for measured confounders, coffee consumption was associated with lower mortality (RR 0.88, 0.82-0.95). However, residual confounding cannot be excluded. These findings are hypothesis-generating and require confirmation in randomized trials.'",
              lesson: "THE PROTECTION: This is honest science. You report the finding, acknowledge limitations, and don't overclaim. If coffee truly is protective, future studies will confirm it. If it's residual confounding, you haven't misled anyone."
            }
          }
        }
      },
      {
        type: 'quiz',
        content: {
          question: "The Nurses' Health Study found HRT users had 44% lower CHD risk (RR 0.56). The WHI RCT found HRT increased CHD risk by 29% (HR 1.29). What best explains this discrepancy?",
          options: [
            { id: 'a', text: "The RCT was wrong because it used different HRT formulations", correct: false },
            { id: 'b', text: "Confounding by healthy user characteristics in the observational study", correct: true },
            { id: 'c', text: "The observational study had more statistical power", correct: false },
            { id: 'd', text: "Effect modification by age of participants", correct: false }
          ],
          explanation: "Healthy user bias (confounding): Women who chose HRT were systematically healthier, more educated, and had better healthcare access. These factors independently reduce CHD risk. When an RCT randomized women regardless of these characteristics, the 'benefit' disappeared and harm emerged. This is the canonical example of confounding in epidemiology."
        }
      },
      {
        type: 'story-deep',
        content: {
          label: "THE REVERSAL: BETA-CAROTENE ‚Äî WHEN MECHANISM MET REALITY",
          source: "NEJM 1994 ATBC | NEJM 1996 CARET | Observational promise, RCT destruction",
          timeline: [
            { year: "1980s", text: "Observational studies consistently show people with high beta-carotene levels have lower cancer rates. Antioxidant hypothesis: beta-carotene neutralizes free radicals that cause cancer.", type: "normal" },
            { year: "Mechanism", text: "Compelling biology: oxidative stress ‚Üí DNA damage ‚Üí cancer. Antioxidants should prevent this. Prospective cohorts show 30-40% lower lung cancer in high beta-carotene consumers.", type: "normal" },
            { year: "1994 ATBC", text: "Finnish RCT of beta-carotene in smokers: INCREASED lung cancer by 18% (RR 1.18, 95% CI 1.03-1.36). 8% higher total mortality. Trial stopped for harm.", type: "crisis" },
            { year: "1996 CARET", text: "US RCT stopped 21 months early: 28% INCREASE in lung cancer (RR 1.28, 95% CI 1.04-1.57). 17% higher death rate. Two RCTs showed same harm.", type: "crisis" },
            { year: "The Explanation", text: "Confounding: People who eat vegetables are healthier overall. Beta-carotene was a MARKER of healthy diet, not the CAUSE of protection. Supplementing the chemical didn't help ‚Äî it may have hurt.", type: "revelation" },
            { year: "Lesson", text: "Biological plausibility is NOT evidence. Mechanism without randomization is storytelling. The body is complex ‚Äî isolated supplements don't reproduce whole-food benefits.", type: "revelation" }
          ],
          realData: {
            endpoint: "Lung cancer incidence",
            drug: "Beta-carotene supplements",
            placebo: "Placebo",
            rr: "Observational: RR ~0.70 | RCT ATBC: RR 1.18 | RCT CARET: RR 1.28",
            ci: "Observational WRONG direction",
            nnh: "Supplements INCREASED cancer, opposite of observational prediction"
          },
          hook: "THE HOOK: Beta-carotene was the 'perfect' hypothesis ‚Äî strong observational association, compelling mechanism, clear dose-response. And it was COMPLETELY WRONG. This is why we need RCTs, and why observational data showing protective effects of interventions must be treated with deep skepticism."
        }
      },
      {
        type: 'principle',
        content: {
          text: "‚ö†Ô∏è THE WARNING: Every observational finding of benefit should be treated as provisional until an RCT confirms it. HRT, beta-carotene, vitamin E, hormone replacement ‚Äî all showed 'benefit' observationally, all showed harm or null in RCTs. The pattern is clear: CONFOUNDING MAKES THINGS LOOK HELPFUL THAT AREN'T."
        }
      }
    ]
  },
  {
    id: 2,
    title: "The Designs",
    subtitle: "Study Architecture",
    principle: 1,
    story: "Framingham",
    estimatedTime: "20 min",
    slides: [
      {
        type: 'principle-display',
        content: {
          principle: "Time flows one direction"
        }
      },
      {
        type: 'story-deep',
        content: {
          label: "THE FOUNDATION: FRAMINGHAM ‚Äî 75 YEARS OF WATCHING",
          source: "Framingham Heart Study | Est. 1948 | 15,000+ participants across 3 generations",
          timeline: [
            { year: "1948", text: "NIH recruits 5,209 residents of Framingham, Massachusetts. Goal: understand cardiovascular disease. No one knows what 'risk factors' are yet.", type: "normal" },
            { year: "1960s", text: "First major findings: smoking, high cholesterol, high blood pressure linked to heart disease. The term 'risk factor' is coined.", type: "revelation" },
            { year: "1971", text: "Offspring Study begins: 5,124 children of original participants enrolled. Multigenerational follow-up starts.", type: "normal" },
            { year: "1988", text: "Landmark finding: HDL cholesterol is protective. Distinguishing 'good' from 'bad' cholesterol transforms cardiology.", type: "revelation" },
            { year: "2002", text: "Third Generation Study enrolls grandchildren. 75 years of continuous observation.", type: "normal" },
            { year: "Legacy", text: "Over 3,000 papers published. Risk prediction models used worldwide. Proof that cohort studies can change medicine.", type: "revelation" }
          ],
          realData: {
            endpoint: "Cardiovascular disease incidence and mortality",
            drug: "Prospective cohort design",
            placebo: "75+ years of follow-up",
            rr: "Identified smoking, cholesterol, BP, diabetes as risk factors",
            ci: "Risk prediction equations used globally",
            nnh: "Transformed preventive cardiology"
          },
          hook: "THE HOOK: Framingham didn't randomize anyone. It just watched ‚Äî carefully, systematically, for 75 years. It discovered that smoking causes heart disease, that cholesterol matters, that prevention is possible. Sometimes the most powerful studies are the most patient."
        }
      },
      {
        type: 'story-box',
        content: {
          icon: '‚ù§Ô∏è',
          title: "The Framingham Heart Study's 70-Year Legacy",
          source: "Framingham Heart Study | NIH National Heart, Lung, and Blood Institute | 1948-Present",
          paragraphs: [
            "In 1948, 5,209 residents of Framingham, Massachusetts enrolled in a study with no clear hypothesis. The researchers didn't know what they were looking for‚Äîthey just knew that heart disease was killing Americans and nobody understood why.",
            "Seventy-five years later, three generations of Framinghamers have taught us most of what we know about cardiovascular risk. LDL cholesterol. Smoking. Hypertension. Diabetes. Obesity. The Framingham Risk Score. The very concept of a 'risk factor' was invented here.",
            "No one was randomized. No intervention was tested. Researchers simply measured everything they could, then waited‚Äîand watched‚Äîfor decades. The study that invented modern cardiovascular epidemiology did so through patient, meticulous observation."
          ],
          lesson: "Some questions can only be answered by watching carefully over very long periods. Framingham proves that observational cohort studies, done rigorously over sufficient time, can transform medicine‚Äîeven without randomization."
        }
      },
      {
        type: 'content',
        content: {
          title: "The Three Major Observational Designs",
          sections: [
            {
              heading: "1. COHORT STUDY ‚Äî Follow Forward",
              items: [
                "Start with people who DON'T have the outcome",
                "Measure exposures at baseline",
                "Follow over time, count who develops outcome",
                "Calculate INCIDENCE rates and RISK ratios",
                "Strength: Temporal sequence clear (exposure before outcome)",
                "Weakness: Expensive, time-consuming, rare outcomes difficult"
              ]
            },
            {
              heading: "2. CASE-CONTROL STUDY ‚Äî Look Backward",
              items: [
                "Start with people who HAVE the outcome (cases)",
                "Match to people WITHOUT the outcome (controls)",
                "Look backward: what exposures did they have?",
                "Calculate ODDS ratios (cannot calculate RR directly)",
                "Strength: Efficient for rare outcomes",
                "Weakness: Recall bias, selection bias in choosing controls"
              ]
            },
            {
              heading: "3. CROSS-SECTIONAL STUDY ‚Äî Snapshot",
              items: [
                "Measure exposure and outcome at SAME TIME",
                "Cannot determine temporal sequence",
                "Calculate PREVALENCE ratios or odds ratios",
                "Strength: Quick, cheap, good for prevalence estimation",
                "Weakness: Cannot establish causation (chicken vs egg)"
              ]
            }
          ]
        }
      },
      {
        type: 'method',
        content: {
          label: "THE METHOD: CHOOSING YOUR DESIGN",
          title: "Matching Design to Question",
          sections: [
            {
              heading: "Use COHORT When:",
              text: "‚Ä¢ Exposure is common, outcome is common\n‚Ä¢ You can wait for outcomes to occur\n‚Ä¢ You want to calculate incidence/risk\n‚Ä¢ You need clear temporal sequence\n‚Ä¢ Example: Framingham (CVD risk factors)"
            },
            {
              heading: "Use CASE-CONTROL When:",
              text: "‚Ä¢ Outcome is RARE\n‚Ä¢ You need answers quickly\n‚Ä¢ Resources are limited\n‚Ä¢ Example: Thalidomide (rare birth defects)"
            },
            {
              heading: "Use CROSS-SECTIONAL When:",
              text: "‚Ä¢ You need prevalence, not incidence\n‚Ä¢ Resources are very limited\n‚Ä¢ Temporal sequence doesn't matter\n‚Ä¢ Example: Disease burden surveys"
            },
            {
              heading: "The Nested Designs:",
              text: "‚Ä¢ Nested case-control: Cases and controls from within a cohort\n‚Ä¢ Case-cohort: Random subcohort + all cases\n‚Ä¢ These combine efficiency of case-control with validity of cohort"
            }
          ]
        }
      },
      {
        type: 'content',
        content: {
          title: "Why Temporal Sequence Matters",
          sections: [
            {
              heading: "The Reverse Causation Trap:",
              items: [
                "Cross-sectional: Low BMI associated with cancer",
                "Interpretation A: Being thin causes cancer",
                "Interpretation B: Cancer causes weight loss (the truth)",
                "Without temporal data, you can't tell which came first"
              ]
            },
            {
              heading: "Cohort Advantage:",
              items: [
                "Measure BMI in healthy people",
                "Follow for 10 years",
                "See who develops cancer",
                "Now temporal sequence is clear: BMI preceded cancer",
                "But still can't prove causation (confounding possible)"
              ]
            }
          ]
        }
      },
      {
        type: 'quiz',
        content: {
          question: "Dr. McBride noticed that mothers of babies with limb defects had taken thalidomide. He compared them to mothers of healthy babies. What study design did he implicitly use?",
          options: [
            { id: 'a', text: "Cohort study ‚Äî following pregnant women forward", correct: false },
            { id: 'b', text: "Case-control study ‚Äî starting with affected babies (cases)", correct: true },
            { id: 'c', text: "Cross-sectional study ‚Äî measuring exposure and outcome simultaneously", correct: false },
            { id: 'd', text: "Randomized trial ‚Äî assigning thalidomide exposure", correct: false }
          ],
          explanation: "McBride started with the outcome (babies with phocomelia = cases), compared to babies without defects (controls), and looked backward at maternal exposures. This is the essence of case-control design ‚Äî efficient for rare outcomes, which is why it detected thalidomide so quickly."
        }
      },
      {
        type: 'story-deep',
        content: {
          label: "THE DELAYED HORROR: DES ‚Äî WHEN DAUGHTERS PAID FOR MOTHERS' MEDICINE",
          source: "NEJM 1971; Herbst et al | Cancer 1977 | Delayed harm 20+ years",
          timeline: [
            { year: "1940s-70s", text: "Diethylstilbestrol (DES) given to millions of pregnant women to prevent miscarriage. Based on observational 'evidence' and biological plausibility.", type: "normal" },
            { year: "1953", text: "RCT shows DES doesn't prevent miscarriage. Drug continues to be prescribed anyway ‚Äî 'it might help, can't hurt.'", type: "crisis" },
            { year: "1971", text: "Herbst notices cluster of vaginal clear cell adenocarcinoma in young women. EXTREMELY RARE cancer. Case-control study: 7/8 cases had DES-exposed mothers.", type: "revelation" },
            { year: "The Horror", text: "Harm appeared 15-25 YEARS after exposure. The daughters developed cancer, not the mothers. No RCT could have detected this.", type: "crisis" },
            { year: "Observational Power", text: "Only case-control design could link rare cancer to decades-old exposure. Cohort would have taken 30 years. RCT would have ended long before cancers appeared.", type: "revelation" },
            { year: "Lesson", text: "Some harms are DELAYED by decades. Some affect the NEXT GENERATION. Only observational epidemiology can detect them. This is why pharmacovigilance exists.", type: "revelation" }
          ],
          realData: {
            endpoint: "Clear cell adenocarcinoma of vagina/cervix",
            drug: "DES exposure in utero",
            placebo: "No DES exposure",
            rr: "OR = 40+ (case-control)",
            ci: "Extremely rare cancer in young women",
            nnh: "~1 in 1000 exposed daughters developed cancer"
          },
          hook: "THE HOOK: DES proves that harms can skip a generation and appear decades later. No RCT can follow outcomes for 25 years across generations. Case-control design was the ONLY way to detect this link. Observation wasn't just helpful ‚Äî it was the only option."
        }
      },
      {
        type: 'decision-tree',
        content: {
          id: 'study-design-choice',
          title: "Choose the Right Study Design",
          situation: "You're an epidemiologist facing different research questions. For each, choose the most appropriate observational design.",
          nodes: {
            start: {
              question: "QUESTION 1: A rare childhood leukemia (1 in 100,000) may be linked to living near power lines. Resources are limited. Which design?",
              branches: [
                { text: "Cohort study ‚Äî follow children near power lines", nextNode: "cohort_leukemia_wrong" },
                { text: "Case-control study ‚Äî start with leukemia cases, check residence", nextNode: "casecontrol_leukemia_correct" },
                { text: "Cross-sectional ‚Äî survey current residence and disease", nextNode: "cross_leukemia_wrong" }
              ]
            },
            cohort_leukemia_wrong: {
              type: 'outcome',
              outcome: 'danger',
              title: "Impractical for rare outcomes!",
              text: "With a 1 in 100,000 rate, you'd need to follow 1 MILLION children to expect just 10 cases. Cohort studies are terrible for rare outcomes. This would take decades and enormous resources.",
              lesson: "Rare outcome ‚Üí Case-control. You start with existing cases, which is efficient."
            },
            cross_leukemia_wrong: {
              type: 'outcome',
              outcome: 'danger',
              title: "Wrong for incidence questions!",
              text: "Cross-sectional measures prevalence (who HAS disease now), not incidence (who DEVELOPS disease). For cancer, you want to know about new cases. Cross-sectional also can't establish temporality ‚Äî did they live near power lines BEFORE cancer?",
              lesson: "Cross-sectional can't establish temporal sequence. Useless for cancer etiology."
            },
            casecontrol_leukemia_correct: {
              situation: "Excellent! Case-control is efficient for rare outcomes. QUESTION 2: You want to identify ALL risk factors for cardiovascular disease over 30 years. Which design?",
              question: "Choose:",
              branches: [
                { text: "Cohort study ‚Äî measure everything at baseline, follow for CVD", nextNode: "cohort_cvd_correct" },
                { text: "Case-control study ‚Äî find CVD cases, ask about past exposures", nextNode: "casecontrol_cvd_partial" }
              ]
            },
            cohort_cvd_correct: {
              situation: "Perfect! This is exactly what Framingham did. QUESTION 3: A new vaccine was introduced last month. Reports suggest it might cause a rare autoimmune reaction within 2 weeks of vaccination. Best design?",
              question: "Choose:",
              branches: [
                { text: "Case-control ‚Äî find autoimmune cases, check vaccination status", nextNode: "casecontrol_vaccine_partial" },
                { text: "Self-controlled case series ‚Äî compare each person's risk during exposed vs unexposed time", nextNode: "sccs_vaccine_correct" }
              ]
            },
            casecontrol_cvd_partial: {
              type: 'outcome',
              outcome: 'partial',
              title: "Possible, but limited",
              text: "Case-control can study CVD risk factors, but suffers from recall bias (cases remember exposures differently) and can only study one outcome at a time. Cohort allows you to study MULTIPLE outcomes and get accurate exposure measurement at baseline.",
              lesson: "For comprehensive risk factor identification with accurate exposure measurement, cohort is preferred."
            },
            casecontrol_vaccine_partial: {
              type: 'outcome',
              outcome: 'partial',
              title: "Works, but there's a better option",
              text: "Case-control would work, but is vulnerable to healthy vaccinee bias (healthier people get vaccinated). For acute reactions to vaccines with defined risk windows, self-controlled designs eliminate between-person confounding.",
              lesson: "Self-controlled designs are powerful for acute reactions with clear temporal windows."
            },
            sccs_vaccine_correct: {
              type: 'outcome',
              outcome: 'success',
              title: "Excellent choice!",
              text: "Self-controlled case series compares each person's risk during the 2-week post-vaccination window to their baseline period. All between-person confounders (age, health status, genetics) are automatically controlled because each person is their own control.",
              lesson: "SCCS was crucial in vaccine safety studies, including debunking the MMR-autism myth. It's powerful when risk windows are well-defined."
            }
          }
        }
      },
      {
        type: 'principle',
        content: {
          text: "‚ö†Ô∏è THE WARNING: No study design is perfect. Cohort studies need time and resources. Case-control studies suffer recall bias. Cross-sectional can't establish temporality. Self-controlled designs can't handle time-varying confounders. KNOW YOUR DESIGN'S WEAKNESSES before trusting its results."
        }
      },
      {
        type: 'principle',
        content: {
          text: "üéØ PROGRESS CHECK: You've completed the foundations. You understand WHY observational evidence matters (Module 0), HOW confounding deceives (Module 1), and WHICH study designs exist (Module 2). Now we go deeper: DAGs for causal reasoning, specific biases, and the tools to handle them."
        }
      }
    ]
  },
  // MODULE 3: THE CONFOUNDERS (DAGs and Causal Diagrams)
  {
    id: 3,
    title: "The Confounders",
    subtitle: "DAGs & Causal Thinking",
    principle: 5,
    estimatedTime: "25 min",
    slides: [
      {
        type: 'principle-display',
        content: {
          principle: "Adjustment is not magic"
        }
      },
      {
        type: 'story-deep',
        content: {
          label: "THE PARADOX: OBESITY AND MORTALITY ‚Äî WHEN ADJUSTMENT KILLED",
          source: "JAMA 2005; Flegal et al | Epidemiology wars | Multiple analyses",
          timeline: [
            { year: "2005", text: "CDC study: Overweight (BMI 25-30) associated with LOWER mortality than normal weight. Headlines declare 'fat is healthy.'", type: "normal" },
            { year: "2005-10", text: "Scientists divided: Some see 'obesity paradox,' others see confounding and collider bias. Adjustment strategies differ dramatically.", type: "crisis" },
            { year: "Key Issue", text: "Should we adjust for smoking? Smokers are thin AND die early. Adjusting for smoking makes overweight look worse (correct). NOT adjusting makes it look protective (wrong).", type: "revelation" },
            { year: "Another Issue", text: "Should we adjust for diseases caused by obesity? Diabetes, heart disease are MEDIATORS. Adjusting blocks the causal path we want to estimate.", type: "revelation" },
            { year: "Resolution", text: "Different DAG assumptions ‚Üí different adjustment strategies ‚Üí different conclusions. The DAG isn't optional ‚Äî it determines the answer.", type: "revelation" },
            { year: "Lesson", text: "You MUST draw your causal assumptions explicitly. Otherwise you're adjusting blindly, and you'll get whatever answer your (unstated) assumptions dictate.", type: "revelation" }
          ],
          realData: {
            endpoint: "All-cause mortality",
            drug: "Overweight (BMI 25-30)",
            placebo: "Normal weight (BMI 18.5-25)",
            rr: "HR 0.88 (unadjusted) to 1.20+ (smoking-adjusted)",
            ci: "Conclusion flips based on adjustment",
            nnh: "Public health messaging chaos"
          },
          hook: "THE HOOK: The same data, analyzed by competent scientists, gave opposite answers. Not because anyone cheated ‚Äî but because they had different causal models in their heads. DAGs make those models explicit."
        }
      },
      {
        type: 'principle',
        content: {
          text: "‚è∏Ô∏è KEY INSIGHT: Adjustment isn't just 'controlling for variables.' Each variable you adjust for makes a causal CLAIM. Adjust for a confounder ‚Üí blocks bias. Adjust for a mediator ‚Üí blocks the effect you want. Adjust for a collider ‚Üí CREATES bias. A DAG forces you to state your claims explicitly."
        }
      },
      {
        type: 'content',
        content: {
          title: "What Is a DAG?",
          sections: [
            {
              heading: "Directed Acyclic Graph",
              items: [
                "DIRECTED: Arrows show causal direction (cause ‚Üí effect)",
                "ACYCLIC: No loops ‚Äî you can't cause your own cause",
                "GRAPH: Visual network of variables and relationships",
                "Purpose: Makes causal assumptions EXPLICIT and testable"
              ]
            },
            {
              heading: "Three Types of Variables:",
              items: [
                "CONFOUNDER: Common cause of exposure and outcome (adjust FOR it)",
                "MEDIATOR: On the causal pathway from exposure to outcome (DON'T adjust)",
                "COLLIDER: Common effect of two variables (DON'T adjust ‚Äî creates bias)"
              ]
            }
          ]
        }
      },
      {
        type: 'method',
        content: {
          label: "THE METHOD: READING A DAG",
          title: "Backdoor Paths and Adjustment",
          sections: [
            {
              heading: "Step 1: Identify Your Question",
              text: "What is the causal effect of EXPOSURE on OUTCOME? Draw a direct arrow from exposure ‚Üí outcome. This is what you want to estimate."
            },
            {
              heading: "Step 2: Find Backdoor Paths",
              text: "A backdoor path goes backward out of exposure (against the arrow) through any path to outcome. Example: Exposure ‚Üê Confounder ‚Üí Outcome. This creates spurious association."
            },
            {
              heading: "Step 3: Block Backdoor Paths",
              text: "Adjust for variables that block all backdoor paths. Usually this means adjusting for confounders. But NEVER adjust for colliders ‚Äî this OPENS paths."
            },
            {
              heading: "Step 4: Check for Collider Bias",
              text: "A collider is a common effect: A ‚Üí Collider ‚Üê B. Conditioning on a collider creates association between A and B even if none exists. Classic trap: Adjusting for 'hospitalization' in hospital-based studies."
            }
          ]
        }
      },
      {
        type: 'content',
        content: {
          title: "The Collider Trap: Berkson's Paradox",
          sections: [
            {
              heading: "The Classic Example:",
              items: [
                "Question: Does diabetes cause respiratory disease?",
                "Hospital-based study: Among hospitalized patients, diabetes is NEGATIVELY associated with respiratory disease",
                "Population-based study: No association",
                "Why? Hospitalization is a COLLIDER ‚Äî both diabetes and respiratory disease cause hospitalization"
              ]
            },
            {
              heading: "The Mechanism:",
              items: [
                "Among hospitalized patients, if someone DOESN'T have diabetes, they must have respiratory disease (otherwise why hospitalized?)",
                "This creates artificial negative association",
                "Adjusting for hospitalization (conditioning on the collider) INDUCED bias that didn't exist in the population"
              ]
            },
            {
              heading: "Modern Examples:",
              items: [
                "COVID severity paradox: Smokers seemed protected because hospitalized non-smokers had other severe conditions",
                "Obesity paradox in heart failure: Sicker thin patients, healthier obese patients selected into studies",
                "If it seems paradoxical, look for a collider"
              ]
            }
          ]
        }
      },
      {
        type: 'story-box',
        content: {
          icon: 'üß¨',
          title: "The UK Biobank Collider Problem",
          source: "UK Biobank | Nature Communications 2020 | COVID-19 Studies",
          paragraphs: [
            "UK Biobank is a treasure‚Äî500,000 participants with genetic and health data. But participants are systematically different from the UK average: healthier, wealthier, and more educated. This is selection into a study.",
            "In 2020, researchers using UK Biobank found something strange: obesity appeared to be PROTECTIVE against COVID-19 death. This contradicted everything known about COVID risk factors. How could obesity protect against a disease where obesity is a major risk factor?",
            "The answer was a collider effect. The same factors that led to UK Biobank participation (health consciousness, education, access) also reduced COVID risk. Among UK Biobank participants, those who were obese but still healthy enough to participate were a selected, healthier group. Selection into the study created a spurious protective association."
          ],
          lesson: "Even the best datasets can produce wrong answers if you don't account for how people got into the study. Selection is a collider. When your study population is selected (and it always is, somehow), ask: could that selection distort the relationship I'm studying?"
        }
      },
      {
        type: 'tool',
        content: {
          type: 'dag-builder',
          title: "DAG Builder Tool",
          description: "Build a causal diagram to identify confounders, mediators, and colliders."
        }
      },
      {
        type: 'decision-tree',
        content: {
          id: 'dag-adjustment',
          title: "The Adjustment Decision",
          situation: "You're studying whether a new diabetes drug reduces cardiovascular events. You have data on: the drug, CV events, age, prior CV disease, and HbA1c (blood sugar control). HbA1c improves with the drug. What should you adjust for?",
          nodes: {
            start: {
              question: "Age is associated with both drug prescribing (older patients get more meds) and CV events. What type of variable is age?",
              branches: [
                { text: "Confounder ‚Äî adjust for it", nextNode: "age_correct" },
                { text: "Mediator ‚Äî don't adjust", nextNode: "age_wrong" },
                { text: "Collider ‚Äî adjusting would create bias", nextNode: "age_wrong" }
              ]
            },
            age_correct: {
              situation: "Correct! Age is a confounder (common cause). Now: HbA1c (blood sugar) improves with the drug and also affects CV events. What type of variable is HbA1c?",
              question: "Should you adjust for HbA1c?",
              branches: [
                { text: "Yes ‚Äî it's a confounder", nextNode: "hba1c_wrong" },
                { text: "No ‚Äî it's a mediator on the causal pathway", nextNode: "hba1c_correct" },
                { text: "It depends on the research question", nextNode: "hba1c_nuanced" }
              ]
            },
            age_wrong: {
              type: 'outcome',
              outcome: 'danger',
              title: "Not quite right",
              text: "Age is a confounder ‚Äî it causes both the exposure (older patients more likely to get drugs) and the outcome (older patients have more CV events). You should adjust for age to block this backdoor path.",
              lesson: "A confounder is a common CAUSE. Age causes treatment decisions and causes CV events. It's not on the causal pathway from drug ‚Üí CV events."
            },
            hba1c_wrong: {
              type: 'outcome',
              outcome: 'danger',
              title: "Careful!",
              text: "HbA1c is on the CAUSAL PATHWAY: Drug ‚Üí HbA1c ‚Üí CV events. If the drug works by improving blood sugar, adjusting for HbA1c blocks the very effect you're trying to measure!",
              lesson: "Never adjust for mediators. You'll estimate only the 'direct effect' not mediated through that pathway ‚Äî which may be zero even if the drug truly works."
            },
            hba1c_correct: {
              situation: "Excellent! Now the final question: Prior CV disease predicts both drug prescribing (doctors give the drug to high-risk patients) AND CV events. What is it?",
              question: "Should you adjust for prior CV disease?",
              branches: [
                { text: "Yes ‚Äî it's a confounder (confounding by indication)", nextNode: "final_success" },
                { text: "No ‚Äî it might be a collider", nextNode: "final_partial" }
              ]
            },
            hba1c_nuanced: {
              type: 'outcome',
              outcome: 'partial',
              title: "That's a sophisticated answer",
              text: "You're right that it depends! If you want the TOTAL effect of the drug, don't adjust for HbA1c (it's a mediator). If you want to know if the drug has effects BEYOND glucose control, you might adjust ‚Äî but that's a different question.",
              lesson: "The DAG should reflect your specific causal question. Different questions ‚Üí different adjustment sets."
            },
            final_success: {
              type: 'outcome',
              outcome: 'success',
              title: "Perfect DAG reasoning!",
              text: "You correctly identified: Age = confounder (adjust), HbA1c = mediator (don't adjust), Prior CV disease = confounder by indication (adjust). Your analysis will estimate the causal effect of the drug.",
              lesson: "This is called 'confounding by indication' ‚Äî the most common bias in drug studies. Sicker patients get treatment, so treatment appears harmful. You MUST adjust for baseline severity."
            },
            final_partial: {
              type: 'outcome',
              outcome: 'partial',
              title: "Almost!",
              text: "Prior CV disease IS a confounder here ‚Äî it causes both treatment decisions and outcomes. You should adjust for it. It's NOT a collider because CV events (the outcome) doesn't cause prior CV disease (temporally impossible).",
              lesson: "Colliders require two arrows pointing INTO the variable. Prior CV disease has arrows pointing OUT (to drug, to outcome). It's a confounder."
            }
          }
        }
      },
      {
        type: 'quiz',
        content: {
          question: "In a study of coffee and lung cancer, smoking is associated with both coffee drinking and lung cancer. After adjusting for smoking, the coffee-cancer association disappears. What happened?",
          options: [
            { id: 'a', text: "Smoking was a mediator ‚Äî coffee causes smoking which causes cancer", correct: false },
            { id: 'b', text: "Smoking was a confounder ‚Äî adjusting removed spurious association", correct: true },
            { id: 'c', text: "Smoking was a collider ‚Äî adjusting induced bias", correct: false },
            { id: 'd', text: "Coffee protects against cancer but smoking cancels the benefit", correct: false }
          ],
          explanation: "Smoking is a classic confounder: Coffee ‚Üê Smoking ‚Üí Cancer. Smokers drink more coffee AND get more cancer. The coffee-cancer association was spurious, created by the common cause (smoking). Adjusting for the confounder blocked the backdoor path and revealed no true effect."
        }
      }
    ]
  },
  // MODULE 4: THE BIAS (Selection, Information, Time-Related Biases)
  {
    id: 4,
    title: "The Bias",
    subtitle: "Selection & Information Bias",
    principle: 2,
    estimatedTime: "30 min",
    slides: [
      {
        type: 'principle-display',
        content: {
          principle: "Time flows one direction"
        }
      },
      {
        type: 'story-deep',
        content: {
          label: "THE IMMORTALITY ILLUSION: STATINS AND THE DEATHLESS TIME",
          source: "Am J Epidemiol 2003; Suissa | Drug Safety 2007 | 'Immortal Time Bias'",
          timeline: [
            { year: "2001-04", text: "Multiple observational studies find statins reduce cancer mortality by 30-50%. Biologically plausible: anti-inflammatory effects, cell cycle regulation.", type: "normal" },
            { year: "The Design", text: "Cohort study: Patients classified as 'statin users' if they EVER filled a statin prescription. Compared to never-users. Follow-up from diagnosis to death.", type: "normal" },
            { year: "The Flaw", text: "To be classified as 'statin user,' you must SURVIVE long enough to fill a prescription. Time before first prescription is 'immortal' ‚Äî by definition, you can't die during it.", type: "revelation" },
            { year: "The Math", text: "Immortal time is misclassified as 'exposed.' This artificially inflates survival in the exposed group. The 'benefit' is a mathematical artifact.", type: "crisis" },
            { year: "Correction", text: "When immortal time is properly handled (time-varying exposure), statin's cancer mortality benefit disappears: HR 0.99 (0.89-1.10)", type: "revelation" },
            { year: "Lesson", text: "You can't compare 'ever vs never' when exposure timing matters. Time must be classified correctly, or you create an illusion of immortality.", type: "revelation" }
          ],
          realData: {
            endpoint: "Cancer mortality",
            drug: "Statins (immortal time bias)",
            placebo: "No statins",
            rr: "HR 0.52 (biased) ‚Üí HR 0.99 (corrected)",
            ci: "Artifact ‚Üí null",
            nnh: "False hope for cancer patients"
          },
          hook: "THE HOOK: Immortal time bias is everywhere. Any study comparing 'ever vs never' users is at risk. The bias direction is ALWAYS toward benefit for the exposure. If your observational study shows a drug prevents cancer/death/etc, check for immortal time first."
        }
      },
      {
        type: 'principle',
        content: {
          text: "‚è∏Ô∏è KEY TAKEAWAY: Immortal time bias occurs when the definition of 'exposed' requires surviving to a certain point, but that survival time is misclassified as 'exposed' time. The bias ALWAYS makes the exposure look beneficial. Landmark analysis or time-varying covariates can fix it."
        }
      },
      {
        type: 'story-box',
        content: {
          icon: 'üíä',
          title: "The Immortal Time Bias in Statin Cancer Studies",
          source: "Am J Epidemiol 2003; Suissa S. | Drug Safety 2007",
          paragraphs: [
            "In the early 2000s, several observational studies reported exciting findings: statins appeared to reduce cancer risk by 20-30%. The biological mechanism seemed plausible‚Äîstatins have anti-inflammatory properties and might inhibit cancer cell growth.",
            "But epidemiologist Samy Suissa identified a critical flaw. These studies compared 'statin users' to 'non-users' from time zero‚Äîoften the date of diagnosis or cohort entry. The problem: some 'users' hadn't even started statins yet at time zero.",
            "The time between cohort entry and first statin prescription was 'immortal time'‚Äîby definition, patients couldn't die during this period (they had to survive to become statin users). This immortal time was misclassified as 'exposed' time, artificially inflating survival in the statin group. When properly analyzed with time-varying exposure, the cancer benefit disappeared completely."
          ],
          lesson: "Whenever you see an observational study showing a drug 'prevents' cancer or death, ask: How was exposure defined? Did patients need to survive to become 'exposed'? If the answer is yes, immortal time bias is likely inflating the benefit."
        }
      },
      {
        type: 'content',
        content: {
          title: "The Three Major Bias Families",
          sections: [
            {
              heading: "1. SELECTION BIAS",
              items: [
                "Who gets INTO the study? Who stays IN?",
                "Healthy user bias: HRT users were healthier to start",
                "Sick quitter bias: People quit smoking because they're ill, making quitters look worse",
                "Loss to follow-up: Sicker patients drop out, making survivors look better",
                "Berkson's bias: Hospital-based selection distorts associations"
              ]
            },
            {
              heading: "2. INFORMATION BIAS",
              items: [
                "How accurately is exposure/outcome measured?",
                "Recall bias: Cases remember exposures better than controls",
                "Interviewer bias: Interviewers probe harder when they know disease status",
                "Misclassification: Errors in exposure or outcome measurement",
                "Differential misclassification can bias in either direction"
              ]
            },
            {
              heading: "3. TIME-RELATED BIAS",
              items: [
                "Immortal time bias: Survival required to become 'exposed'",
                "Time-lag bias: Comparing prevalent vs incident users",
                "Depletion of susceptibles: Early deaths remove high-risk from 'current user' category",
                "Lead time bias: Screening advances diagnosis without extending life"
              ]
            }
          ]
        }
      },
      {
        type: 'method',
        content: {
          label: "THE METHOD: DETECTING IMMORTAL TIME BIAS",
          title: "Red Flags and Solutions",
          sections: [
            {
              heading: "Red Flags (Study Design):",
              text: "‚Ä¢ Exposure defined as 'ever vs never' with no time component\n‚Ä¢ Exposure requires multiple prescriptions/visits\n‚Ä¢ Time zero differs between groups\n‚Ä¢ Exposure definition is based on future events"
            },
            {
              heading: "Red Flags (Results):",
              text: "‚Ä¢ Unexpectedly large protective effect (HR < 0.70)\n‚Ä¢ Exposure 'protects' against multiple unrelated outcomes\n‚Ä¢ Biologically implausible benefit for plausible exposure\n‚Ä¢ Dose-response goes the 'wrong' direction"
            },
            {
              heading: "Solutions:",
              text: "1. LANDMARK ANALYSIS: Start follow-up at a fixed time point (e.g., 6 months post-diagnosis). Classify exposure based on that time.\n\n2. TIME-VARYING EXPOSURE: Change exposure status on the day it occurs. Before first statin = unexposed time. After = exposed time.\n\n3. CLONING METHODS: Create copies of patients, assign to exposure groups, censor appropriately."
            }
          ]
        }
      },
      {
        type: 'content',
        content: {
          title: "Selection Bias: The Healthy User and Sick Quitter",
          sections: [
            {
              heading: "Healthy User Bias:",
              items: [
                "People who choose treatment are systematically different",
                "HRT: Women who chose HRT were wealthier, more health-conscious",
                "Vaccines: Parents who vaccinate also do other healthy behaviors",
                "Supplements: Users have healthier lifestyles overall",
                "The treatment 'benefit' is actually the selection effect"
              ]
            },
            {
              heading: "Sick Quitter Bias:",
              items: [
                "People stop behaviors when they feel ill",
                "Alcohol: Former drinkers have higher mortality than current drinkers",
                "But former drinkers quit because they were sick",
                "Smoking: Recent quitters have higher cancer rates (cancer caused quitting)",
                "Creates the appearance of 'J-shaped' curves or protective effects"
              ]
            },
            {
              heading: "Detection and Correction:",
              items: [
                "Compare to 'never users,' not 'former users'",
                "Look at TIME of quitting relative to outcome",
                "Use active comparators (another drug) not non-users",
                "Consider intentions (prescriptions filled vs filled and taken)"
              ]
            }
          ]
        }
      },
      {
        type: 'story-box',
        content: {
          icon: 'üè•',
          title: "The Hospitalized Patient Paradox: Berkson's Bias",
          source: "Berkson J, Biometrics 1946 | Classic Selection Bias",
          paragraphs: [
            "In hospital-based studies, researchers noticed something strange: diabetes appeared to be PROTECTIVE against infections. Diabetic patients seemed less likely to have infectious diseases. This was paradoxical‚Äîdiabetes impairs immune function.",
            "The explanation was Berkson's bias, a form of selection bias. Hospitalized diabetics were there primarily for diabetes management, not infections. But hospitalized NON-diabetics were more likely to be there FOR infections (among other acute conditions).",
            "By studying only hospitalized patients, researchers created a spurious negative association. The same diabetes-infection relationship studied in the general population showed the expected POSITIVE association‚Äîdiabetes increases infection risk."
          ],
          lesson: "Studying only hospitalized (or otherwise selected) populations can create, eliminate, or reverse associations that exist in the general population. Always ask: how did patients get INTO this study, and could that selection process distort the exposure-outcome relationship?"
        }
      },
      {
        type: 'decision-tree',
        content: {
          id: 'bias-detection',
          title: "The Bias Detector",
          situation: "A study claims that metformin reduces cancer risk in diabetics (HR 0.63, 95% CI 0.58-0.68). The study compared metformin users to non-users. Patients were classified as metformin users if they filled ‚â•2 prescriptions. Follow-up started at diabetes diagnosis.",
          nodes: {
            start: {
              question: "What is the most likely bias in this study?",
              branches: [
                { text: "Confounding by indication ‚Äî metformin given to healthier patients", nextNode: "confounding" },
                { text: "Immortal time bias ‚Äî must survive to fill 2 prescriptions", nextNode: "immortal_correct" },
                { text: "Healthy user bias ‚Äî metformin users are health-conscious", nextNode: "healthy_user" },
                { text: "No bias ‚Äî the confidence interval is narrow", nextNode: "no_bias_wrong" }
              ]
            },
            immortal_correct: {
              situation: "Correct! To fill 2 prescriptions, patients must survive at least the time between them. This survival time is misclassified as 'exposed' when it should be 'unexposed.'",
              question: "How would you fix this study?",
              branches: [
                { text: "Use landmark analysis ‚Äî start follow-up after a fixed period", nextNode: "fix_correct" },
                { text: "Adjust for comorbidities", nextNode: "fix_wrong" },
                { text: "Exclude patients who died early", nextNode: "fix_wrong2" }
              ]
            },
            confounding: {
              type: 'outcome',
              outcome: 'partial',
              title: "Possible, but not the main issue",
              text: "Confounding by indication is a concern (metformin given to 'healthier' diabetics). But the study design explicitly creates IMMORTAL TIME ‚Äî requiring 2 prescriptions means survival is required to be classified as exposed. This is the dominant bias.",
              lesson: "When a study requires multiple events (prescriptions, visits, tests) to define exposure, immortal time bias is almost always present."
            },
            healthy_user: {
              type: 'outcome',
              outcome: 'partial',
              title: "Related, but not the mechanism",
              text: "Healthy user bias is a form of confounding ‚Äî metformin users may be more health-conscious. But the study design creates a STRONGER bias: immortal time. Even if users and non-users were identical at baseline, requiring 2 prescriptions creates artificial immortality.",
              lesson: "Immortal time bias is NOT confounding ‚Äî it's a structural bias from misclassifying time. It exists even without any difference between groups."
            },
            no_bias_wrong: {
              type: 'outcome',
              outcome: 'danger',
              title: "Narrow CI doesn't mean no bias!",
              text: "A narrow confidence interval means the estimate is precise ‚Äî not that it's unbiased. This study has a HUGE systematic error. The 'true' effect could be null (HR 1.0) despite the tight CI around 0.63.",
              lesson: "Precision ‚â† Accuracy. Bias is systematic error. Sample size and precision don't fix bias ‚Äî they just make you more precisely wrong."
            },
            fix_correct: {
              type: 'outcome',
              outcome: 'success',
              title: "Excellent solution!",
              text: "Landmark analysis would set follow-up to start at, say, 6 months post-diagnosis. Everyone who survives to 6 months is included. Exposure status is defined at that point. No immortal time can be misclassified.",
              lesson: "Landmark analysis is the simplest fix for immortal time bias. The 'landmark' must be clinically meaningful and applied equally to all patients."
            },
            fix_wrong: {
              type: 'outcome',
              outcome: 'danger',
              title: "Adjustment doesn't fix immortal time",
              text: "Immortal time bias is NOT confounding ‚Äî you can't adjust it away. No matter how many comorbidities you control for, the structural problem remains: time before first prescription is misclassified.",
              lesson: "Immortal time bias requires DESIGN fixes (landmark, time-varying exposure), not statistical adjustment."
            },
            fix_wrong2: {
              type: 'outcome',
              outcome: 'danger',
              title: "This makes it worse!",
              text: "Excluding early deaths removes the very patients who demonstrate the bias! You'd keep only survivors, making the immortal time problem even more extreme. This is survival bias on top of immortal time bias.",
              lesson: "Never 'fix' bias by removing data. Fix it by correctly classifying time from the start."
            }
          }
        }
      },
      {
        type: 'quiz',
        content: {
          question: "A study finds that patients who survive 5+ years after cancer diagnosis and then start meditation have 60% lower mortality than non-meditators. What is the most critical flaw?",
          options: [
            { id: 'a', text: "Confounding ‚Äî meditators are healthier overall", correct: false },
            { id: 'b', text: "Immortal time bias ‚Äî must survive 5 years to become a meditator", correct: true },
            { id: 'c', text: "Recall bias ‚Äî survivors remember meditation better", correct: false },
            { id: 'd', text: "Selection bias ‚Äî only motivated patients meditate", correct: false }
          ],
          explanation: "The study defines 'meditators' as those who survive 5+ years AND THEN start meditation. All 5 years of survival are 'immortal' ‚Äî by definition, you can't die during time required to become exposed. This immortal time is then misclassified as 'exposed' time, artificially inflating survival in meditators."
        }
      },
      {
        type: 'story-deep',
        content: {
          label: "THE MEMORY TRAP: RECALL BIAS AND THE PHANTOM EXPOSURES",
          source: "Case-control studies of birth defects | Multiple examples | Information bias",
          timeline: [
            { year: "Classic Setup", text: "Mother of baby with birth defect is asked: 'Did you take any medications during pregnancy?' She searches her memory desperately for anything that might explain her child's condition.", type: "normal" },
            { year: "The Comparison", text: "Mother of healthy baby is asked same question. She shrugs: 'Maybe some Tylenol? I don't really remember.' No motivation to dig through memory.", type: "normal" },
            { year: "The Bias", text: "Case mothers REMEMBER more exposures than control mothers ‚Äî not because they HAD more, but because they SEARCHED harder. This is differential recall.", type: "crisis" },
            { year: "Real Example", text: "Case-control studies found associations between many medications and birth defects. When prescription records (objective data) were used instead of recall, most associations DISAPPEARED.", type: "revelation" },
            { year: "Bendectin Disaster", text: "Morning sickness drug Bendectin was withdrawn due to lawsuit pressure from case-control recall studies. Later research showed it was SAFE. Pregnant women lost access to effective treatment due to recall bias.", type: "crisis" },
            { year: "Lesson", text: "When outcomes prompt memory searches, recall is biased. Use OBJECTIVE exposure data (records, biomarkers) when possible. When using recall, make interviewers BLIND to case/control status.", type: "revelation" }
          ],
          realData: {
            endpoint: "Various birth defects",
            drug: "Multiple medications (recall-based)",
            placebo: "No medication (recall-based)",
            rr: "OR 2-4x higher in recall studies vs objective records",
            ci: "Recall-based associations often spurious",
            nnh: "Bendectin withdrawn despite being safe"
          },
          hook: "THE HOOK: Recall bias is insidious because it feels like valid data. Mothers genuinely believe they're reporting accurately ‚Äî but grief and guilt drive memory searches that control mothers don't perform. The cure? Objective data sources, or blinded interviewers."
        }
      },
      {
        type: 'decision-tree',
        content: {
          id: 'recall-bias-detection',
          title: "Is This Recall Bias?",
          situation: "You're reviewing case-control studies. Identify whether recall bias is a major threat.",
          nodes: {
            start: {
              question: "STUDY A: Cases with lung cancer asked about smoking history vs controls without cancer. Both groups asked same questions by same interviewers. Is recall bias a concern?",
              branches: [
                { text: "Yes ‚Äî lung cancer patients remember smoking differently", nextNode: "lung_cancer_wrong" },
                { text: "Minimal ‚Äî smoking is a salient, memorable behavior", nextNode: "lung_cancer_correct" }
              ]
            },
            lung_cancer_correct: {
              situation: "Correct! Smoking is memorable and verifiable. Recall bias is less problematic for MAJOR SALIENT exposures. STUDY B: Cases with childhood leukemia vs controls. Parents asked about household pesticide use 5 years ago.",
              question: "Is recall bias a concern?",
              branches: [
                { text: "Major concern ‚Äî parents of sick children search memory harder", nextNode: "leukemia_correct" },
                { text: "Minor concern ‚Äî pesticide use is memorable", nextNode: "leukemia_wrong" }
              ]
            },
            lung_cancer_wrong: {
              type: 'outcome',
              outcome: 'partial',
              title: "Some concern, but limited",
              text: "Recall bias is most problematic for SUBTLE, MINOR exposures that require memory searches. Smoking is salient ‚Äî people know if they smoked. It's verifiable via biomarkers. The bigger concern for lung cancer studies is confounding (smokers have other risk behaviors).",
              lesson: "Recall bias is exposure-specific. Major behaviors (smoking, alcohol) are less affected than minor ones (dietary supplements, brief exposures)."
            },
            leukemia_correct: {
              situation: "Exactly! Household pesticide use 5 years ago is vague and searchable. STUDY C: Cases with myocardial infarction. Exposure data extracted from pharmacy prescription records BEFORE the MI occurred.",
              question: "Is recall bias a concern?",
              branches: [
                { text: "Yes ‚Äî patients still might misreport", nextNode: "mi_wrong" },
                { text: "No ‚Äî data was recorded BEFORE outcome, can't be influenced", nextNode: "mi_correct" }
              ]
            },
            leukemia_wrong: {
              type: 'outcome',
              outcome: 'danger',
              title: "High recall bias risk!",
              text: "Pesticide use 5 years ago is exactly the type of exposure prone to recall bias: (1) vague definition, (2) long ago, (3) guilt-inducing for parents of sick children. Parents of leukemia cases will search memory for ANY chemical exposure. Controls won't.",
              lesson: "Red flags for recall bias: vague exposures, long recall periods, emotionally-charged outcomes (especially children), differential motivation to remember."
            },
            mi_correct: {
              type: 'outcome',
              outcome: 'success',
              title: "No recall bias possible!",
              text: "When exposure data is recorded BEFORE the outcome occurs (prospective ascertainment), recall bias is impossible. The data can't change based on outcome status. This is why cohort studies and studies using medical records are less susceptible to recall bias.",
              lesson: "The cure for recall bias: prospective data collection, medical/pharmacy records, biomarkers ‚Äî anything recorded before the outcome is known."
            },
            mi_wrong: {
              type: 'outcome',
              outcome: 'danger',
              title: "Not with objective records!",
              text: "Pharmacy records were filled BEFORE the MI. The patient can't go back and change what prescriptions they filled. This is objective, prospectively-recorded data immune to recall bias. This is exactly why researchers use electronic health records.",
              lesson: "Objective records > memory. Prospective > retrospective. When you have records, use them instead of asking patients to remember."
            }
          }
        }
      },
      {
        type: 'principle',
        content: {
          text: "‚ö†Ô∏è THE WARNING: Selection bias, information bias, and time-related bias all make associations appear where none exist (or disappear when real). They are NOT fixed by larger sample sizes. They are NOT fixed by narrow confidence intervals. They are ONLY fixed by proper study design. A precise biased estimate is just precise bias."
        }
      },
      {
        type: 'principle',
        content: {
          text: "üéØ PROGRESS CHECK: You've mastered the bias zoo. Immortal time (survival to exposure), healthy user (who chooses treatment), sick quitter (who stops), recall bias (differential memory), Berkson's (hospital selection). Now you'll learn ROBINS-I ‚Äî the systematic framework to assess all these biases together."
        }
      }
    ]
  },
  // MODULE 5: THE ASSESSMENT (ROBINS-I)
  {
    id: 5,
    title: "The Assessment",
    subtitle: "ROBINS-I for Bias",
    principle: 4,
    estimatedTime: "25 min",
    slides: [
      {
        type: 'principle-display',
        content: {
          principle: "Measurement shapes reality"
        }
      },
      {
        type: 'story-deep',
        content: {
          label: "THE PANDEMIC TRAP: HYDROXYCHLOROQUINE AND OBSERVATIONAL CHAOS",
          source: "Lancet 2020 (retracted) | Multiple observational studies | COVID-19 pandemic",
          timeline: [
            { year: "Mar 2020", text: "French study (Gautret): HCQ + azithromycin shows viral clearance. 'Cure found!' Small, non-randomized, methodologically flawed.", type: "normal" },
            { year: "Apr 2020", text: "Observational studies flood preprint servers. Some show benefit (confounding by indication, immortal time). Some show harm (sicker patients got HCQ).", type: "crisis" },
            { year: "May 2020", text: "Lancet publishes observational study: HCQ increases mortality (HR 1.35). World pauses trials. Study later RETRACTED ‚Äî data fabricated.", type: "crisis" },
            { year: "Jun 2020", text: "WHO SOLIDARITY, RECOVERY trials (RCTs) show HCQ doesn't work. Observational studies had given contradictory answers for months.", type: "revelation" },
            { year: "The Problem", text: "Observational studies during crisis had severe confounding (sicker patients got HCQ), immortal time bias (survival required to receive drug), and indication bias.", type: "revelation" },
            { year: "The Lesson", text: "Systematic bias assessment (ROBINS-I) could have flagged the most unreliable studies BEFORE policy was made. Speed without quality costs lives.", type: "revelation" }
          ],
          realData: {
            endpoint: "COVID-19 mortality",
            drug: "Hydroxychloroquine observational",
            placebo: "No HCQ",
            rr: "Ranged from HR 0.50 to HR 2.60",
            ci: "Completely contradictory",
            nnh: "Months of confusion, RCTs delayed"
          },
          hook: "THE HOOK: The HCQ debacle showed what happens when observational studies are done without rigorous bias assessment. ROBINS-I provides a systematic framework to assess risk of bias in non-randomized studies ‚Äî before you trust their results."
        }
      },
      {
        type: 'principle',
        content: {
          text: "‚è∏Ô∏è KEY INSIGHT: ROBINS-I asks: 'What would this study look like as an RCT?' Then systematically checks where it deviates. It's not about whether observational studies are 'bad' ‚Äî it's about honestly assessing their limitations."
        }
      },
      {
        type: 'content',
        content: {
          title: "ROBINS-I: Risk of Bias In Non-randomized Studies of Interventions",
          sections: [
            {
              heading: "What Is ROBINS-I?",
              items: [
                "Developed by Cochrane for systematic reviews",
                "Structured assessment of 7 bias domains",
                "Anchored to a 'target trial' ‚Äî the ideal RCT you wish existed",
                "Produces domain-level and overall risk of bias judgments",
                "Required by many journals and guideline bodies"
              ]
            },
            {
              heading: "The Target Trial Concept:",
              items: [
                "What RCT WOULD you do if ethics and logistics allowed?",
                "Define: eligibility, interventions, outcomes, follow-up, analysis",
                "The observational study EMULATES this trial",
                "Bias = deviation from the target trial"
              ]
            }
          ]
        }
      },
      {
        type: 'method',
        content: {
          label: "THE METHOD: ROBINS-I DOMAINS",
          title: "Seven Sources of Bias",
          sections: [
            {
              heading: "Pre-Intervention Domains:",
              text: "1. CONFOUNDING: Were groups comparable at baseline?\n   - Unmeasured confounders? Time-varying confounding?\n   - Think: HRT users vs non-users\n\n2. SELECTION: Was selection into study related to intervention and outcome?\n   - Prevalent user bias? Hospital-based selection?\n   - Think: Selecting only survivors"
            },
            {
              heading: "At-Intervention Domain:",
              text: "3. CLASSIFICATION OF INTERVENTIONS: Was intervention status well-defined and ascertained?\n   - Immortal time bias? Misclassification of exposure?\n   - Think: 'Ever vs never' definitions"
            },
            {
              heading: "Post-Intervention Domains:",
              text: "4. DEVIATIONS: Were there deviations from intended interventions?\n   - Non-adherence? Co-interventions?\n   - Think: Patients stopping treatment\n\n5. MISSING DATA: Were outcomes measured for all participants?\n   - Differential loss to follow-up?\n   - Think: Sicker patients dropping out\n\n6. MEASUREMENT: Could outcome measurement be affected by intervention status?\n   - Blinding? Detection bias?\n   - Think: Knowing treatment affects diagnosis\n\n7. SELECTION OF RESULTS: Were results selected from multiple analyses?\n   - Outcome switching? Subgroup fishing?\n   - Think: Reporting only favorable analyses"
            }
          ]
        }
      },
      {
        type: 'content',
        content: {
          title: "ROBINS-I Judgment Levels",
          sections: [
            {
              heading: "Low Risk of Bias:",
              text: "The study is comparable to a well-performed RCT with regard to this domain. Confounders identified AND adjusted. No immortal time. Complete follow-up."
            },
            {
              heading: "Moderate Risk of Bias:",
              text: "Sound for a non-randomized study but cannot be considered comparable to an RCT. Some confounding likely remains. Minor concerns about methods."
            },
            {
              heading: "Serious Risk of Bias:",
              text: "The study has important problems. Substantial confounding likely. Design flaws (immortal time, selection). Results should be interpreted with major caution."
            },
            {
              heading: "Critical Risk of Bias:",
              text: "The study is too problematic to provide useful evidence. Fundamental flaws that cannot be addressed. Should generally not be included in synthesis."
            },
            {
              heading: "Overall Judgment:",
              text: "The overall risk of bias is the MOST SEVERE judgment across domains. One critical domain = critical overall. This is intentionally conservative."
            }
          ]
        }
      },
      {
        type: 'decision-tree',
        content: {
          id: 'robins-assessment',
          title: "ROBINS-I Assessment Practice",
          situation: "An observational study compares COVID-19 outcomes in patients who received remdesivir vs. standard care. Remdesivir was given based on physician judgment. The study adjusted for age, sex, and comorbidities. No data on disease severity at treatment initiation.",
          nodes: {
            start: {
              question: "For the CONFOUNDING domain, what is your judgment?",
              branches: [
                { text: "Low risk ‚Äî they adjusted for key confounders", nextNode: "confound_low" },
                { text: "Serious risk ‚Äî disease severity unmeasured", nextNode: "confound_correct" },
                { text: "Critical risk ‚Äî the study is fundamentally flawed", nextNode: "confound_critical" }
              ]
            },
            confound_correct: {
              situation: "Good judgment! Physicians gave remdesivir to sicker patients. Without adjusting for baseline severity, the study is biased AGAINST remdesivir (confounding by indication). Now assess CLASSIFICATION OF INTERVENTIONS:",
              question: "Patients were classified as 'remdesivir users' if they received at least one dose during hospitalization.",
              branches: [
                { text: "Low risk ‚Äî clear definition", nextNode: "class_low" },
                { text: "Serious risk ‚Äî immortal time bias possible", nextNode: "class_correct" }
              ]
            },
            confound_low: {
              type: 'outcome',
              outcome: 'danger',
              title: "Too optimistic!",
              text: "Adjusting for age, sex, and comorbidities doesn't capture the most important confounder: DISEASE SEVERITY at treatment initiation. Physicians gave remdesivir to sicker patients. This creates confounding by indication ‚Äî the treatment appears harmful because treated patients were sicker.",
              lesson: "Always ask: 'What determined who got treatment?' If it's disease severity and you can't measure that, confounding is serious."
            },
            confound_critical: {
              type: 'outcome',
              outcome: 'partial',
              title: "Possibly too harsh",
              text: "While confounding is serious, 'critical' is reserved for bias that cannot be corrected even in principle, or where the direction and magnitude make results completely uninformative. Some information about the comparison may still be extractable with caution.",
              lesson: "Critical risk of bias means the study should generally be excluded from synthesis. Reserve this for truly fatal flaws."
            },
            class_low: {
              type: 'outcome',
              outcome: 'danger',
              title: "Check for immortal time!",
              text: "To receive remdesivir during hospitalization, patients must SURVIVE until treatment. Time from admission to first dose is 'immortal' ‚Äî patients can't die during it. If this time is classified as 'treated' time, it creates immortal time bias favoring remdesivir.",
              lesson: "Any time-to-treatment or requirement to survive to receive treatment creates potential immortal time bias."
            },
            class_correct: {
              situation: "Correct! If time from admission to remdesivir is classified as 'exposed,' there's immortal time bias. Now, what is your OVERALL risk of bias judgment?",
              question: "Overall judgment:",
              branches: [
                { text: "Moderate ‚Äî there are concerns but the study is usable", nextNode: "overall_moderate" },
                { text: "Serious ‚Äî multiple domains have important problems", nextNode: "overall_correct" },
                { text: "Critical ‚Äî the study provides no useful evidence", nextNode: "overall_critical" }
              ]
            },
            overall_moderate: {
              type: 'outcome',
              outcome: 'partial',
              title: "Likely too generous",
              text: "With serious confounding AND serious classification bias (immortal time), the overall judgment should be at least SERIOUS. The overall is determined by the worst domain ‚Äî you can't average away serious concerns.",
              lesson: "Overall ROBINS-I judgment = worst single domain judgment. One serious domain = serious overall."
            },
            overall_correct: {
              type: 'outcome',
              outcome: 'success',
              title: "Appropriate judgment!",
              text: "With serious confounding (unmeasured severity) and serious classification bias (potential immortal time), the overall risk of bias is SERIOUS. The study results should be interpreted with major caution and may not be suitable for quantitative synthesis.",
              lesson: "ROBINS-I is intentionally conservative. Real-world observational drug studies often have serious risk of bias. Acknowledging this honestly is better than pretending otherwise."
            },
            overall_critical: {
              type: 'outcome',
              outcome: 'partial',
              title: "Possibly warranted, but justify carefully",
              text: "Critical risk requires at least one domain to be critical, or multiple serious domains that together make results uninformative. If you can articulate why no useful information is extractable, critical may be appropriate.",
              lesson: "Critical judgment means: 'This study should not inform clinical decisions.' Use sparingly but don't avoid it when truly warranted."
            }
          }
        }
      },
      {
        type: 'quiz',
        content: {
          question: "A study has 'low' risk for 6 ROBINS-I domains but 'serious' risk for confounding. What is the overall risk of bias?",
          options: [
            { id: 'a', text: "Low ‚Äî most domains are fine", correct: false },
            { id: 'b', text: "Moderate ‚Äî one serious domain warrants caution", correct: false },
            { id: 'c', text: "Serious ‚Äî overall is the worst single domain", correct: true },
            { id: 'd', text: "Cannot determine ‚Äî need to average the domains", correct: false }
          ],
          explanation: "In ROBINS-I, the overall risk of bias judgment equals the MOST SERIOUS judgment across all domains. This is not averaged ‚Äî one fatal flaw is still fatal. If confounding is serious, the study cannot be considered 'low' or 'moderate' risk overall, regardless of how well other domains are handled."
        }
      }
    ]
  },
  // MODULE 6: THE ADJUSTMENT (Propensity Scores)
  {
    id: 6,
    title: "The Adjustment",
    subtitle: "Propensity Scores",
    principle: 5,
    estimatedTime: "30 min",
    slides: [
      {
        type: 'principle-display',
        content: {
          principle: "Adjustment is not magic"
        }
      },
      {
        type: 'story-deep',
        content: {
          label: "THE BALANCE ILLUSION: PROPENSITY SCORES AND THE UNMEASURED",
          source: "King & Nielsen 2019 | Epidemiology debates | Propensity score wars",
          timeline: [
            { year: "1983", text: "Rosenbaum & Rubin introduce propensity scores: probability of treatment given covariates. Revolutionary for causal inference in observational data.", type: "normal" },
            { year: "2000s", text: "Propensity score matching becomes the 'gold standard' for observational studies. Papers multiply claiming 'RCT-like' balance.", type: "normal" },
            { year: "2010s", text: "Problems emerge: matching discards data, pruning can increase bias. IPTW and overlap weighting gain favor.", type: "crisis" },
            { year: "Key Issue", text: "Propensity scores balance MEASURED confounders only. If the key confounder is UNMEASURED, propensity scores give false confidence.", type: "revelation" },
            { year: "Example", text: "COX-2 inhibitors vs NSAIDs: propensity-matched studies showed safety. But unmeasured factors (channeling to lower-risk patients) weren't captured. RCTs revealed CV harm.", type: "crisis" },
            { year: "Lesson", text: "Propensity scores are a TOOL, not a cure. They balance what you measure. Unmeasured confounding remains ‚Äî sensitivity analysis is essential.", type: "revelation" }
          ],
          realData: {
            endpoint: "Cardiovascular events",
            drug: "COX-2 inhibitors (propensity-adjusted)",
            placebo: "Traditional NSAIDs",
            rr: "Observational: HR ~0.80 | RCT: HR 1.50+",
            ci: "Unmeasured channeling bias",
            nnh: "Vioxx withdrawn after 88,000+ cardiac events"
          },
          hook: "THE HOOK: Propensity scores made observational studies look 'balanced.' But balance on measured factors doesn't mean balance on ALL factors. The COX-2/Vioxx disaster showed that sophisticated statistics can't fix missing data."
        }
      },
      {
        type: 'principle',
        content: {
          text: "‚è∏Ô∏è KEY INSIGHT: Propensity scores control for confounding by MEASURED variables. They create a pseudo-population where treatment is unrelated to those variables. But UNMEASURED confounders remain ‚Äî and propensity scores can create false confidence by making studies look 'rigorous' when key confounders are missing."
        }
      },
      {
        type: 'content',
        content: {
          title: "What Is a Propensity Score?",
          sections: [
            {
              heading: "Definition:",
              items: [
                "Probability of receiving treatment given observed covariates",
                "PS = P(Treatment=1 | X‚ÇÅ, X‚ÇÇ, ..., X‚Çñ)",
                "Estimated using logistic regression (or machine learning)",
                "Summarizes many confounders into a single number"
              ]
            },
            {
              heading: "Why It Works (When It Works):",
              items: [
                "Balancing property: At each PS value, treatment is 'random' with respect to covariates",
                "Creates pseudo-randomization: mimics what an RCT would do",
                "Enables comparison of 'like with like'",
                "Reduces dimensionality: many confounders ‚Üí one score"
              ]
            },
            {
              heading: "The Limitation:",
              items: [
                "Only balances what's IN the model",
                "Unmeasured confounders remain unbalanced",
                "Can't balance what you don't know",
                "The 'strong ignorability' assumption is UNTESTABLE"
              ]
            }
          ]
        }
      },
      {
        type: 'method',
        content: {
          label: "THE METHOD: PROPENSITY SCORE APPROACHES",
          title: "Four Ways to Use Propensity Scores",
          sections: [
            {
              heading: "1. MATCHING",
              text: "Pair treated and untreated patients with similar PS values.\n+ Intuitive, transparent\n‚àí Discards unmatched patients\n‚àí Can increase bias if poorly done (King & Nielsen)"
            },
            {
              heading: "2. STRATIFICATION",
              text: "Divide population into strata (e.g., quintiles) by PS.\n+ Simple, uses all data\n‚àí Residual confounding within strata\n‚àí Fewer strata = more bias; more = sparse data"
            },
            {
              heading: "3. INVERSE PROBABILITY WEIGHTING (IPTW)",
              text: "Weight patients by inverse of their PS.\n+ Uses all data, estimates population effect\n‚àí Extreme weights cause instability\n‚àí Sensitive to model misspecification"
            },
            {
              heading: "4. COVARIATE ADJUSTMENT",
              text: "Include PS as covariate in outcome model.\n+ Simple to implement\n‚àí Less efficient than other methods\n‚àí Doesn't check balance directly"
            },
            {
              heading: "Modern Preference:",
              text: "IPTW with stabilized weights or overlap weights often preferred. Matching increasingly criticized. But ALL methods require good covariate selection and sensitivity analysis."
            }
          ]
        }
      },
      {
        type: 'content',
        content: {
          title: "Checking Balance: The Key Diagnostic",
          sections: [
            {
              heading: "Standardized Mean Difference (SMD):",
              items: [
                "SMD = (mean_treated - mean_control) / pooled_SD",
                "Before PS adjustment: expect large SMDs (confounding)",
                "After PS adjustment: SMDs should be <0.1 (balanced)",
                "If SMDs remain large, PS failed to balance"
              ]
            },
            {
              heading: "What to Check:",
              items: [
                "Balance on ALL measured confounders (not just PS)",
                "Balance on important interactions and non-linearities",
                "Overlap: both groups should have similar PS distributions",
                "If no overlap, effect is not estimable"
              ]
            },
            {
              heading: "Red Flags:",
              items: [
                "SMD >0.1 after adjustment = residual imbalance",
                "Non-overlapping PS distributions = positivity violation",
                "Extreme weights (>10 or <0.1) = instability",
                "Results sensitive to PS model specification = fragile"
              ]
            }
          ]
        }
      },
      {
        type: 'content',
        content: {
          title: "IPTW Deep Dive: Modern Weighting Methods",
          sections: [
            {
              heading: "Standard IPTW (Inverse Probability of Treatment Weighting)",
              items: [
                "Weight for treated: w = 1/PS",
                "Weight for untreated: w = 1/(1-PS)",
                "Creates pseudo-population where treatment is independent of covariates",
                "Estimates AVERAGE TREATMENT EFFECT (ATE) in full population",
                "Problem: extreme weights when PS near 0 or 1"
              ]
            },
            {
              heading: "Stabilized Weights (sw-IPTW)",
              items: [
                "Treated: sw = P(T=1)/PS",
                "Untreated: sw = P(T=0)/(1-PS)",
                "Numerator stabilizes by multiplying by marginal probability",
                "Reduces variance, preserves sample size interpretation",
                "Preferred over standard IPTW in modern practice"
              ]
            },
            {
              heading: "Overlap Weights (OW) ‚Äî Modern Favorite",
              items: [
                "Treated: w = 1-PS",
                "Untreated: w = PS",
                "Targets patients with clinical equipoise (PS near 0.5)",
                "Automatically handles extreme PS ‚Äî no trimming needed",
                "Estimates effect in population where treatment decision is uncertain",
                "Best balance properties; increasingly recommended"
              ]
            },
            {
              heading: "Weight Diagnostics:",
              items: [
                "Check weight distribution (mean, max, SD)",
                "Mean of weights should ‚âà 1 for stabilized",
                "Truncate at 99th percentile if extreme (but acknowledge sensitivity)",
                "Plot weighted SMDs ‚Äî all should be <0.1",
                "Effective sample size: ESS = (Œ£w)¬≤/Œ£w¬≤ ‚Äî watch for low ESS"
              ]
            },
            {
              heading: "When to Use Which:",
              text: "IPTW/stabilized: want population-average effect, have good overlap. Overlap weights: extreme PS values, want robust estimates, uncertain treatment decisions. Matching: want intuitive comparison, can afford data loss. Avoid matching if sample is small or effect heterogeneity matters."
            }
          ]
        }
      },
      {
        type: 'decision-tree',
        content: {
          id: 'propensity-decision',
          title: "The Propensity Score Decision",
          situation: "You're analyzing whether a new anticoagulant (vs warfarin) reduces stroke in atrial fibrillation. You have data on age, sex, comorbidities, and CHA‚ÇÇDS‚ÇÇ-VASc score. You DON'T have data on: renal function, patient frailty, or reason for drug choice.",
          nodes: {
            start: {
              question: "You plan to use propensity score matching. What is the first thing you should check?",
              branches: [
                { text: "Whether the propensity score model is statistically significant", nextNode: "sig_wrong" },
                { text: "Whether covariates are balanced after matching (SMDs <0.1)", nextNode: "balance_correct" },
                { text: "Whether the treatment effect is statistically significant", nextNode: "effect_wrong" }
              ]
            },
            balance_correct: {
              situation: "Correct! After matching, your SMDs are all <0.1. But you're worried about unmeasured confounding (renal function, frailty). What should you do?",
              question: "How do you address unmeasured confounding?",
              branches: [
                { text: "Add more measured variables to the PS model", nextNode: "more_vars" },
                { text: "Conduct sensitivity analysis for unmeasured confounding", nextNode: "sensitivity_correct" },
                { text: "Report the matched result as 'adjusted for confounding'", nextNode: "report_wrong" }
              ]
            },
            sig_wrong: {
              type: 'outcome',
              outcome: 'danger',
              title: "Wrong focus!",
              text: "Statistical significance of the PS model is irrelevant. You don't care if treatment is 'predictable' ‚Äî you care if covariates are BALANCED. A highly significant PS model can still fail to balance key confounders.",
              lesson: "Propensity score models are judged by balance achieved, not by p-values or c-statistics. Check SMDs, not model fit."
            },
            effect_wrong: {
              type: 'outcome',
              outcome: 'danger',
              title: "Wrong order!",
              text: "You should NEVER look at treatment effects before verifying balance. If covariates aren't balanced, the effect estimate is biased. Looking at effects first can tempt you to keep tweaking until you get the answer you want.",
              lesson: "Always check balance BEFORE examining treatment effects. Pre-specify your PS approach and balance criteria."
            },
            more_vars: {
              type: 'outcome',
              outcome: 'partial',
              title: "Helpful but insufficient",
              text: "Adding measured variables can help ‚Äî but you said renal function and frailty are UNMEASURED. You can't add what you don't have. You need sensitivity analysis to assess how much unmeasured confounding would be needed to change your conclusion.",
              lesson: "You can't adjust for what you don't measure. Sensitivity analysis quantifies the potential impact of what's missing."
            },
            sensitivity_correct: {
              situation: "Excellent! You run sensitivity analysis using the E-value. Your result is HR 0.75 (0.65-0.87). The E-value is 1.82. What does this mean?",
              question: "Interpretation:",
              branches: [
                { text: "An unmeasured confounder with RR ‚â•1.82 with both treatment and outcome could explain away the effect", nextNode: "evalue_correct" },
                { text: "The result is robust because 1.82 is a large number", nextNode: "evalue_partial" }
              ]
            },
            report_wrong: {
              type: 'outcome',
              outcome: 'danger',
              title: "Misleading claim!",
              text: "Reporting as 'adjusted for confounding' implies all confounding is addressed. But propensity scores ONLY balance measured variables. With unmeasured confounders (renal function, frailty, channeling), your estimate may still be severely biased.",
              lesson: "Always state: 'Adjusted for MEASURED confounders.' Acknowledge what's missing. Never claim full adjustment."
            },
            evalue_correct: {
              type: 'outcome',
              outcome: 'success',
              title: "Perfect interpretation!",
              text: "The E-value quantifies robustness: an unmeasured confounder would need RR ‚â•1.82 with BOTH exposure and outcome to fully explain your result. You should now ask: 'Is a confounder with RR 1.82 plausible?' For renal function affecting both anticoagulant choice and stroke ‚Äî quite possibly yes.",
              lesson: "E-values don't prove causation. They help you assess: 'How strong would hidden bias need to be?' Compare to known confounder strengths."
            },
            evalue_partial: {
              type: 'outcome',
              outcome: 'partial',
              title: "Needs context!",
              text: "Whether 1.82 is 'large' depends on the context. Smoking has RR ~20 for lung cancer, ~2-3 for heart disease. Renal function might have RR 1.5-2 for stroke. You need to compare to plausible confounder strengths, not to an arbitrary threshold.",
              lesson: "E-values require clinical judgment. 1.82 is not inherently robust or fragile ‚Äî it depends on what unmeasured confounders exist and how strong they might be."
            }
          }
        }
      },
      {
        type: 'quiz',
        content: {
          question: "After propensity score matching, you achieve perfect balance (all SMDs <0.1) on 15 measured covariates. You can now conclude:",
          options: [
            { id: 'a', text: "The treatment effect is unconfounded", correct: false },
            { id: 'b', text: "The treatment effect is unconfounded by the 15 measured covariates", correct: true },
            { id: 'c', text: "The study is equivalent to an RCT", correct: false },
            { id: 'd', text: "Unmeasured confounding has been addressed", correct: false }
          ],
          explanation: "Propensity scores only balance what's in the model. Perfect balance on 15 covariates means those 15 are no longer confounders ‚Äî but says nothing about unmeasured variables. The study is NOT equivalent to an RCT because randomization balances ALL confounders, measured and unmeasured."
        }
      },
      {
        type: 'content',
        content: {
          title: "Negative Control Outcomes: Testing Your Adjustment",
          sections: [
            {
              heading: "The Brilliant Idea:",
              items: [
                "Choose an outcome that your exposure CANNOT plausibly affect",
                "If your analysis shows an 'effect' on this negative control ‚Üí you have residual confounding",
                "Example: Statins shouldn't affect car accidents. If your statin study shows fewer car accidents in statin users ‚Üí confounding (healthier people take statins AND drive safely)"
              ]
            },
            {
              heading: "How It Works:",
              items: [
                "Same exposure, same adjustment, different outcome",
                "Negative control outcome should share confounders with primary outcome",
                "But exposure has no biological pathway to negative control",
                "Association with negative control = confounding signal"
              ]
            },
            {
              heading: "Real Example:",
              items: [
                "Study: Do ACE inhibitors reduce COVID mortality?",
                "Primary outcome: COVID death",
                "Negative control: Injuries/accidents",
                "If ACE inhibitors 'reduce' injuries too ‚Üí healthy user confounding",
                "Used in major COVID-19 pharmacoepidemiology studies"
              ]
            }
          ]
        }
      },
      {
        type: 'decision-tree',
        content: {
          id: 'negative-control-design',
          title: "Design a Negative Control Test",
          situation: "You're studying whether flu vaccination reduces cardiovascular events. You want to test for healthy vaccinee confounding using negative controls.",
          nodes: {
            start: {
              question: "Which outcome would be a good NEGATIVE CONTROL for flu vaccine ‚Üí cardiovascular events?",
              branches: [
                { text: "Pneumonia hospitalization", nextNode: "pneumonia_wrong" },
                { text: "Hip fracture", nextNode: "hip_correct" },
                { text: "Diabetes diagnosis", nextNode: "diabetes_wrong" }
              ]
            },
            pneumonia_wrong: {
              type: 'outcome',
              outcome: 'danger',
              title: "Not a good negative control!",
              text: "Flu vaccine MIGHT actually prevent pneumonia (flu can lead to secondary bacterial pneumonia). A negative control must be an outcome the exposure CANNOT plausibly affect. Pneumonia is biologically related to flu.",
              lesson: "Negative controls must have NO biological pathway from exposure. If there's any plausible mechanism, it's not a valid control."
            },
            hip_correct: {
              situation: "Excellent choice! Flu vaccine has no biological pathway to hip fractures. But hip fractures share confounders with cardiovascular events (age, frailty, health-seeking behavior). Now, you find that flu vaccination is associated with 20% fewer hip fractures (RR 0.80).",
              question: "What does this tell you about your cardiovascular finding?",
              branches: [
                { text: "Flu vaccine might actually prevent fractures too ‚Äî it's beneficial!", nextNode: "beneficial_wrong" },
                { text: "You have unmeasured confounding ‚Äî healthy vaccinees have better outcomes generally", nextNode: "confounding_correct" }
              ]
            },
            diabetes_wrong: {
              type: 'outcome',
              outcome: 'partial',
              title: "Possible but not ideal",
              text: "Diabetes diagnosis is chronic and might share confounders. But the timing is tricky ‚Äî you need NEW outcomes after vaccination. Chronic conditions are harder to time precisely. Hip fractures or accidents are better because they're acute events.",
              lesson: "Good negative controls are: (1) acute (clear timing), (2) share confounders with primary outcome, (3) have no biological link to exposure."
            },
            beneficial_wrong: {
              type: 'outcome',
              outcome: 'danger',
              title: "This is the confounding trap!",
              text: "There is NO biological mechanism by which flu vaccine prevents hip fractures. The 'benefit' is confounding: people who get vaccinated are healthier, more mobile, less frail, and less likely to fall. This SAME confounding affects your cardiovascular finding.",
              lesson: "When negative controls show 'effects,' your main analysis is confounded. The size of the negative control effect indicates the size of your bias."
            },
            confounding_correct: {
              type: 'outcome',
              outcome: 'success',
              title: "Exactly right!",
              text: "If flu vaccine 'prevents' hip fractures (RR 0.80), and there's no biological mechanism, then ~20% of your observed effects are due to healthy vaccinee confounding. Your cardiovascular RR of 0.70 might really be closer to 0.88 (RR/0.80). The negative control quantifies your bias.",
              lesson: "Negative controls are diagnostic. Use them to: (1) detect confounding, (2) estimate its magnitude, (3) potentially calibrate your main estimate. This is essential for credible observational research."
            }
          }
        }
      },
      {
        type: 'principle',
        content: {
          text: "‚ö†Ô∏è THE WARNING: Propensity scores are TOOLS, not magic wands. They balance what you measure. They create false confidence when you haven't measured the key confounders. Always ask: 'What would a negative control show?' If your exposure 'prevents' outcomes it biologically cannot affect, your adjustment has failed."
        }
      }
    ]
  },
  // MODULE 7: THE TARGET TRIAL (Target Trial Emulation)
  {
    id: 7,
    title: "The Target Trial",
    subtitle: "Emulating RCTs",
    principle: 1,
    estimatedTime: "25 min",
    slides: [
      {
        type: 'principle-display',
        content: {
          principle: "Association is not causation"
        }
      },
      {
        type: 'story-deep',
        content: {
          label: "THE CLARIFICATION: ASPIRIN AND CANCER ‚Äî WHEN FRAMING CHANGED EVERYTHING",
          source: "Hern√°n & Robins | Am J Epidemiol 2016 | Target trial framework",
          timeline: [
            { year: "1990s-2000s", text: "Observational studies inconsistent on aspirin and cancer. Some show protection, some don't. Different time windows, populations, definitions.", type: "normal" },
            { year: "The Problem", text: "Each study asked a slightly different question. 'Does aspirin prevent cancer?' is ambiguous. WHICH aspirin regimen? In WHOM? Started WHEN? Compared to WHAT?", type: "crisis" },
            { year: "Target Trial", text: "Specify the RCT you WISH you could do: eligibility (healthy adults 50-70), intervention (aspirin 75mg daily), comparator (no aspirin), outcomes (cancer incidence at 10 years), time zero.", type: "revelation" },
            { year: "Emulation", text: "Now analyze observational data AS IF it were this trial. Clone patients at time zero. Apply eligibility criteria. Track from the same starting point. Compare same outcomes.", type: "revelation" },
            { year: "Resolution", text: "When studies emulated the SAME target trial, results became consistent. The discrepancies were due to different (often implicit) research questions.", type: "revelation" },
            { year: "Lesson", text: "Before analyzing observational data, SPECIFY YOUR TARGET TRIAL. This makes assumptions explicit, prevents common biases, and allows comparison across studies.", type: "revelation" }
          ],
          realData: {
            endpoint: "Cancer incidence/mortality",
            drug: "Aspirin (various regimens)",
            placebo: "No aspirin (various comparators)",
            rr: "Ranged HR 0.70 to 1.20 depending on implicit trial",
            ci: "Clarified once target trial specified",
            nnh: "Decades of confusion from ambiguous questions"
          },
          hook: "THE HOOK: 'Does aspirin prevent cancer?' isn't a research question ‚Äî it's a family of questions. Target trial emulation forces you to be precise: WHICH intervention, in WHOM, compared to WHAT, measured HOW. Precision enables causal inference."
        }
      },
      {
        type: 'principle',
        content: {
          text: "‚è∏Ô∏è KEY INSIGHT: Every observational analysis implicitly emulates SOME randomized trial. The target trial framework makes this explicit. By specifying eligibility, interventions, outcomes, and time zero BEFORE analysis, you prevent biases like immortal time, prevalent user bias, and confounding by indication."
        }
      },
      {
        type: 'story-box',
        content: {
          icon: 'üéØ',
          title: "The Target Trial Emulation Revolution",
          source: "Hernan & Robins, Am J Epidemiol 2016 | Causal Inference Framework",
          paragraphs: [
            "In 2016, Miguel Hernan and James Robins formalized a methodological revolution: 'target trial emulation.' The idea was deceptively simple‚Äîdesign your observational analysis as if it were the RCT you wish you could do.",
            "They applied this to a contentious question: do statins prevent death in primary prevention? Traditional observational methods showed a 25% mortality reduction. But when analyzed using target trial emulation‚Äîproper time zero, new-user design, clear eligibility‚Äîthe benefit dropped to 15%.",
            "The 10-percentage-point difference wasn't noise‚Äîit was bias that traditional methods had missed. Immortal time, prevalent user bias, and unclear time zero had all inflated the apparent benefit. Target trial emulation didn't just give a different answer; it gave a more honest one."
          ],
          lesson: "Target trial emulation is reshaping observational research. By forcing explicit specification of eligibility, interventions, time zero, and outcomes BEFORE analysis, it prevents the biases that have historically made observational studies unreliable. It's not a statistical trick‚Äîit's a framework for honest causal thinking."
        }
      },
      {
        type: 'content',
        content: {
          title: "The Target Trial Framework",
          sections: [
            {
              heading: "Step 1: Specify the Protocol (7 Components):",
              items: [
                "1. ELIGIBILITY: Who would be enrolled?",
                "2. INTERVENTIONS: What treatments, at what doses?",
                "3. ASSIGNMENT: How would randomization work?",
                "4. TIME ZERO: When does follow-up start?",
                "5. OUTCOMES: What do you measure, and when?",
                "6. FOLLOW-UP: How long do you track patients?",
                "7. ANALYSIS: Intention-to-treat? Per-protocol?"
              ]
            },
            {
              heading: "Step 2: Emulate with Observational Data:",
              items: [
                "Apply eligibility criteria to your database",
                "Define time zero (same for all patients!)",
                "Classify exposure at time zero (not after)",
                "Use methods to handle confounding (PS, IPW)",
                "Analyze as you would the RCT"
              ]
            }
          ]
        }
      },
      {
        type: 'method',
        content: {
          label: "THE METHOD: AVOIDING BIAS THROUGH TARGET TRIAL",
          title: "How Specification Prevents Bias",
          sections: [
            {
              heading: "Prevents IMMORTAL TIME BIAS:",
              text: "By defining time zero, you can't misclassify survival time as exposure time. Everyone's clock starts at the same point (eligibility + treatment assignment), not when they happen to receive treatment."
            },
            {
              heading: "Prevents PREVALENT USER BIAS:",
              text: "Target trial specifies NEW users, just like an RCT. You don't mix people who just started (incident) with people on treatment for years (prevalent). The trial doesn't enroll prevalent users."
            },
            {
              heading: "Prevents CONFOUNDING BY INDICATION:",
              text: "Eligibility criteria define who could receive either treatment. Propensity scores or IPW handle remaining confounding. You're comparing 'like with like' at time zero."
            },
            {
              heading: "Ensures CLEAR OUTCOMES:",
              text: "Outcome assessment is defined a priori. You can't change the endpoint after seeing the data. The target trial protocol locks in your analysis plan."
            }
          ]
        }
      },
      {
        type: 'content',
        content: {
          title: "Time Zero: The Critical Concept",
          sections: [
            {
              heading: "What Is Time Zero?",
              items: [
                "The moment when the hypothetical trial would randomize",
                "MUST be the same for all patients in the analysis",
                "MUST be when exposure status is assigned",
                "Follow-up starts AT time zero, not before"
              ]
            },
            {
              heading: "Common Mistakes:",
              items: [
                "Using 'ever vs never' exposure (no time zero)",
                "Starting follow-up at diagnosis but assigning exposure later",
                "Mixing incident and prevalent users",
                "Different time zeros for different groups"
              ]
            },
            {
              heading: "Example: Statins After MI",
              items: [
                "Target trial: Randomize at hospital discharge",
                "Emulation: Time zero = discharge date",
                "Assign statin status AT DISCHARGE (not later prescriptions)",
                "Follow from discharge to outcome",
                "This prevents immortal time bias"
              ]
            }
          ]
        }
      },
      {
        type: 'decision-tree',
        content: {
          id: 'target-trial-design',
          title: "Design Your Target Trial",
          situation: "You want to study whether starting a Mediterranean diet after a heart attack reduces mortality compared to usual diet. You have electronic health records with dietary assessments at various time points.",
          nodes: {
            start: {
              question: "What should be your time zero?",
              branches: [
                { text: "Date of first Mediterranean diet assessment", nextNode: "diet_date_wrong" },
                { text: "Hospital discharge after MI", nextNode: "discharge_correct" },
                { text: "Date of MI diagnosis", nextNode: "mi_date_partial" }
              ]
            },
            discharge_correct: {
              situation: "Good choice! Discharge is when a dietary intervention could plausibly start. Now, how do you define 'Mediterranean diet' exposure?",
              question: "Exposure definition:",
              branches: [
                { text: "Any Mediterranean diet assessment scored 'high' during follow-up", nextNode: "any_high_wrong" },
                { text: "Mediterranean diet score at the first post-discharge assessment", nextNode: "first_assessment_correct" },
                { text: "Sustained high Mediterranean diet score for 6+ months", nextNode: "sustained_partial" }
              ]
            },
            diet_date_wrong: {
              type: 'outcome',
              outcome: 'danger',
              title: "This creates immortal time bias!",
              text: "Patients must SURVIVE until their first dietary assessment to be classified as 'Mediterranean diet.' The time between MI and assessment is immortal time. If misclassified, it artificially inflates survival in the diet group.",
              lesson: "Time zero must be when the intervention COULD start, not when it was measured. Dietary assessment dates vary ‚Äî this creates differential time zeros."
            },
            mi_date_partial: {
              type: 'outcome',
              outcome: 'partial',
              title: "Reasonable but challenging",
              text: "MI date is reasonable for time zero, but dietary intervention can't start until patient is stable (usually discharge). If you start at MI, you have a brief period of 'acute care' where dietary exposure is undefined.",
              lesson: "Time zero should be when the intervention is FEASIBLE. For post-MI lifestyle interventions, discharge is often more practical than the MI itself."
            },
            any_high_wrong: {
              type: 'outcome',
              outcome: 'danger',
              title: "This is immortal time bias again!",
              text: "Defining exposure by ANY assessment during follow-up means patients must survive to that assessment. Time before the 'high' score is immortal time. This is the same bias as the statin-cancer studies.",
              lesson: "Exposure must be assigned AT time zero, not based on future events. You can't 'become exposed' during follow-up in the target trial framework."
            },
            first_assessment_correct: {
              situation: "Excellent! Exposure assigned at the first assessment after time zero. Now, what about patients without a dietary assessment?",
              question: "How do you handle missing dietary data?",
              branches: [
                { text: "Exclude them ‚Äî they don't have the key variable", nextNode: "exclude_wrong" },
                { text: "Classify as 'usual diet' (comparator) and conduct sensitivity analysis", nextNode: "classify_correct" }
              ]
            },
            sustained_partial: {
              type: 'outcome',
              outcome: 'partial',
              title: "This is a different question",
              text: "'Sustained' exposure over 6 months is a valid question, but it's a DIFFERENT target trial: one studying adherent patients (per-protocol effect). The primary analysis should be intention-to-treat: initial assignment regardless of subsequent adherence.",
              lesson: "Target trial can be ITT or per-protocol. ITT compares initial strategies. Per-protocol compares sustained adherence. State which you're emulating."
            },
            exclude_wrong: {
              type: 'outcome',
              outcome: 'danger',
              title: "This creates selection bias!",
              text: "Excluding patients without dietary data means you're selecting a non-random subset. If sicker patients are less likely to complete dietary assessments, your comparison is now among healthier patients only ‚Äî selection bias.",
              lesson: "Missing data should be handled, not used for exclusion. The target trial wouldn't exclude patients who missed a questionnaire."
            },
            classify_correct: {
              type: 'outcome',
              outcome: 'success',
              title: "Thoughtful approach!",
              text: "Treating missing as 'usual diet' maintains the cohort. Sensitivity analyses can explore alternatives. This mimics what an RCT would do: patients who don't follow the diet protocol are still analyzed in their assigned group (ITT).",
              lesson: "Handle missing data with principled methods (multiple imputation, inverse probability weighting). Never exclude based on post-time-zero data availability."
            }
          }
        }
      },
      {
        type: 'quiz',
        content: {
          question: "A study compares 'metformin initiators' to 'sulfonylurea initiators' among patients with newly diagnosed diabetes. Time zero is defined as the date of first drug prescription. This study design:",
          options: [
            { id: 'a', text: "Has immortal time bias because patients must survive to get a prescription", correct: false },
            { id: 'b', text: "Appropriately emulates a target trial comparing these two treatments", correct: true },
            { id: 'c', text: "Has prevalent user bias because some patients are on long-term therapy", correct: false },
            { id: 'd', text: "Cannot estimate causal effects because it's observational", correct: false }
          ],
          explanation: "This is an ACTIVE COMPARATOR NEW USER (ACNU) design ‚Äî the gold standard for drug safety studies. Time zero is first prescription (new users). Both groups start at the same point. There's no immortal time because patients are classified at the moment of first prescription, and no prevalent user bias because only new users are included."
        }
      }
    ]
  },
  // MODULE 8: THE SYNTHESIS (Meta-analysis of Observational Studies)
  {
    id: 8,
    title: "The Synthesis",
    subtitle: "Pooling Observational Evidence",
    principle: 6,
    estimatedTime: "30 min",
    slides: [
      {
        type: 'principle-display',
        content: {
          principle: "The average can lie"
        }
      },
      {
        type: 'story-deep',
        content: {
          label: "THE POOLING PROBLEM: VITAMIN D AND MORTALITY ‚Äî WHEN META-ANALYSIS MAGNIFIED BIAS",
          source: "Multiple vitamin D meta-analyses | Autier 2014 | Mendelian randomization studies",
          timeline: [
            { year: "2007-2012", text: "Observational studies consistently show low vitamin D predicts higher mortality. Plausible biology. Meta-analyses of cohorts: pooled RR ~1.5-2.0 for low vs high vitamin D.", type: "normal" },
            { year: "The MA Problem", text: "Meta-analyzing observational studies pools BIAS, not just signal. If each study has healthy user bias, the pooled estimate is a precise estimate of the biased effect.", type: "crisis" },
            { year: "RCTs Arrive", text: "VITAL, ViDA, D-Health: large RCTs of vitamin D supplementation. Results: null effects on mortality, cardiovascular disease, cancer. RR ~1.00.", type: "revelation" },
            { year: "Mendelian Randomization", text: "MR studies (using genetic variants as instruments): no causal effect of vitamin D on mortality. The observational association was CONFOUNDED.", type: "revelation" },
            { year: "The Explanation", text: "Reverse causation: illness lowers vitamin D levels. Confounding: outdoor activity, exercise, healthy lifestyle all correlate with vitamin D AND longevity.", type: "revelation" },
            { year: "Lesson", text: "Meta-analysis of biased studies gives a precise biased answer. 'Garbage in, garbage out' at scale. Heterogeneity in bias, not just effect, matters.", type: "revelation" }
          ],
          realData: {
            endpoint: "All-cause mortality",
            drug: "Vitamin D (observational low vs high)",
            placebo: "RCT supplementation vs placebo",
            rr: "Observational: RR 1.57 | RCT: RR 0.97 (0.93-1.02)",
            ci: "Confounding created false association",
            nnh: "Billions spent on vitamin D supplements"
          },
          hook: "THE HOOK: Meta-analysis of 50 biased studies doesn't give you the truth ‚Äî it gives you a very precise biased estimate. Before pooling observational studies, assess each one's ROBINS-I risk of bias. Consider whether you're pooling signal or noise."
        }
      },
      {
        type: 'principle',
        content: {
          text: "‚è∏Ô∏è KEY INSIGHT: Heterogeneity in observational meta-analyses isn't just about effect size variation ‚Äî it's about BIAS variation. Different studies have different confounding structures, selection mechanisms, and measurement approaches. Pooling doesn't solve this; it obscures it."
        }
      },
      {
        type: 'content',
        content: {
          title: "When to Meta-Analyze Observational Studies",
          sections: [
            {
              heading: "Appropriate Situations:",
              items: [
                "RCTs are impossible (rare harms, long-term outcomes)",
                "Exposure cannot be randomized (smoking, environmental)",
                "Complementing RCT evidence (generalizability, subgroups)",
                "Studies use similar designs and address similar biases",
                "Question is about ASSOCIATION (not necessarily causation)"
              ]
            },
            {
              heading: "Problematic Situations:",
              items: [
                "Studies have incompatible confounding structures",
                "Major unmeasured confounders likely differ across studies",
                "Studies use different exposure/outcome definitions",
                "Pooling to achieve 'statistical significance'",
                "Ignoring within-study bias to focus on between-study variance"
              ]
            },
            {
              heading: "The Fundamental Question:",
              text: "Are you pooling STUDIES or pooling BIAS? If each study is confounded in the same direction, meta-analysis will give you a more precise confounded estimate, not the truth."
            }
          ]
        }
      },
      {
        type: 'method',
        content: {
          label: "THE METHOD: OBSERVATIONAL META-ANALYSIS",
          title: "Best Practices",
          sections: [
            {
              heading: "1. Use ROBINS-I for Each Study:",
              text: "Assess risk of bias domain-by-domain. Critical-risk studies should generally be excluded or analyzed separately. Serious-risk studies require sensitivity analysis."
            },
            {
              heading: "2. Don't Mix RCTs and Observational:",
              text: "Different bias structures make combining problematic. Present separately. If combined, weight by study design quality, not just variance."
            },
            {
              heading: "3. Explore Heterogeneity by Bias:",
              text: "Subgroup by ROBINS-I risk level. If low-risk studies give different answers than high-risk studies, that's informative: bias explains heterogeneity."
            },
            {
              heading: "4. Consider Adjusted vs Crude:",
              text: "Meta-analyze adjusted estimates (not crude). But different adjustment sets = different estimands. Document what each study adjusted for."
            },
            {
              heading: "5. Use GRADE for Observational:",
              text: "Start at 'Low' certainty (not 'High' like RCTs). Rate down for additional bias, inconsistency, imprecision, indirectness. Rate up only with caution."
            }
          ]
        }
      },
      {
        type: 'content',
        content: {
          title: "Heterogeneity: Different Sources in Observational Data",
          sections: [
            {
              heading: "Clinical Heterogeneity:",
              text: "Different populations, interventions, outcomes, timing ‚Äî same as in RCT meta-analyses."
            },
            {
              heading: "Methodological Heterogeneity:",
              text: "Different study designs (cohort vs case-control), different adjustment strategies, different exposure definitions. This is MORE important in observational MA."
            },
            {
              heading: "Bias Heterogeneity:",
              text: "Different confounding structures, different amounts of unmeasured confounding, different selection mechanisms. This is UNIQUE to observational MA."
            },
            {
              heading: "What High I¬≤ Means:",
              items: [
                "In RCT MA: treatment effects truly differ across populations",
                "In observational MA: could be effect heterogeneity OR bias heterogeneity",
                "You can't distinguish without examining the studies",
                "Meta-regression by study quality can help, but is often underpowered"
              ]
            }
          ]
        }
      },
      {
        type: 'decision-tree',
        content: {
          id: 'obs-ma-decision',
          title: "Should You Pool These Studies?",
          situation: "You're conducting a systematic review on coffee and cardiovascular disease. You found 15 cohort studies, 3 case-control studies, and 2 RCTs. ROBINS-I assessment: 5 cohorts at moderate risk, 8 at serious risk, 2 at critical risk. The case-controls are all serious risk. RCTs are low risk but underpowered.",
          nodes: {
            start: {
              question: "What is your approach to synthesis?",
              branches: [
                { text: "Pool all 20 studies to maximize power", nextNode: "pool_all_wrong" },
                { text: "Pool only low/moderate risk studies, exclude high risk", nextNode: "exclude_high" },
                { text: "Present stratified analyses by risk of bias level", nextNode: "stratified_correct" }
              ]
            },
            pool_all_wrong: {
              type: 'outcome',
              outcome: 'danger',
              title: "This magnifies bias!",
              text: "Pooling 20 studies when 10+ have serious/critical bias means your pooled estimate is dominated by biased data. You'll get a very precise estimate of... the average bias across studies.",
              lesson: "More studies ‚â† better meta-analysis. Quality matters more than quantity. Never pool critical-risk studies into the main analysis."
            },
            exclude_high: {
              situation: "Better! But you now have only 5 cohorts (moderate) and 2 RCTs (low) ‚Äî limited data. What do you do next?",
              question: "Synthesis approach:",
              branches: [
                { text: "Pool the 5 cohorts and 2 RCTs together", nextNode: "pool_mixed_wrong" },
                { text: "Present RCTs separately, cohorts separately, with sensitivity analysis", nextNode: "separate_correct" }
              ]
            },
            stratified_correct: {
              situation: "Excellent! You plan to show: (1) RCTs alone, (2) Low/moderate risk cohorts, (3) All studies. This is transparent.",
              question: "Your RCTs show RR 0.95 (0.60-1.50). Moderate-risk cohorts show RR 0.75 (0.70-0.80). High-risk studies show RR 0.65 (0.60-0.70). What do you conclude?",
              branches: [
                { text: "Coffee protects ‚Äî all estimates show benefit", nextNode: "conclude_benefit_wrong" },
                { text: "Lower quality studies show stronger effects ‚Äî suggests bias", nextNode: "conclude_bias_correct" }
              ]
            },
            pool_mixed_wrong: {
              type: 'outcome',
              outcome: 'partial',
              title: "Careful with mixing!",
              text: "RCTs and observational studies have fundamentally different bias structures. Pooling them gives a number, but it's not clear what that number estimates. Better to present separately and discuss concordance/discordance.",
              lesson: "If RCTs and observational studies agree, confidence increases. If they disagree, explore why (confounding? effect modification?). Don't hide disagreement by pooling."
            },
            separate_correct: {
              type: 'outcome',
              outcome: 'success',
              title: "Rigorous approach!",
              text: "Presenting RCTs and observational studies separately allows readers to see concordance/discordance. Sensitivity analyses show how results change with different assumptions. This is transparent and informative.",
              lesson: "The goal of meta-analysis is to summarize evidence, not manufacture a single number. Stratification by study quality is more honest than pooling everything."
            },
            conclude_benefit_wrong: {
              type: 'outcome',
              outcome: 'danger',
              title: "Watch for the pattern!",
              text: "The RCT (lowest bias) shows a null effect (0.95, CI crosses 1). As risk of bias increases, the apparent benefit increases (0.75 ‚Üí 0.65). This is a classic sign that CONFOUNDING, not coffee, explains the 'benefit.'",
              lesson: "When effect size increases with risk of bias, suspect bias, not causation. The RCT is your anchor ‚Äî observational estimates should be interpreted relative to it."
            },
            conclude_bias_correct: {
              type: 'outcome',
              outcome: 'success',
              title: "Astute interpretation!",
              text: "You've identified the 'risk of bias vs effect size' pattern: lower quality studies show larger effects. This is strong evidence of confounding (healthy user bias: coffee drinkers are healthier). The RCT's null result is likely closer to the truth.",
              lesson: "Stratifying by risk of bias is diagnostic. If high-quality and low-quality studies give different answers, trust the high-quality ones and investigate what biases the low-quality ones."
            }
          }
        }
      },
      {
        type: 'quiz',
        content: {
          question: "A meta-analysis of 30 observational studies shows a pooled OR of 0.72 (0.68-0.76) with I¬≤ = 5%. What can you conclude?",
          options: [
            { id: 'a', text: "The effect is real ‚Äî consistent across studies with high precision", correct: false },
            { id: 'b', text: "The studies are homogeneous, which increases confidence in the estimate", correct: false },
            { id: 'c', text: "Low I¬≤ means studies agree, but they might all be biased in the same direction", correct: true },
            { id: 'd', text: "This is strong evidence for a causal protective effect", correct: false }
          ],
          explanation: "Low I¬≤ means studies are consistent ‚Äî but they could be consistently BIASED. If all 30 studies have healthy user bias, they'll all show a protective effect, and I¬≤ will be low. Homogeneity is reassuring only if studies aren't all biased the same way. Without ROBINS-I assessment, you can't distinguish consistency of effect from consistency of bias."
        }
      },
      {
        type: 'story-deep',
        content: {
          label: "THE TIME ILLUSION: LEAD TIME BIAS ‚Äî WHEN SCREENING LOOKED MIRACULOUS",
          source: "Welch 2010 | Overdiagnosed | Neuroblastoma screening | PSA debates",
          timeline: [
            { year: "The Promise", text: "Cancer screening finds disease early. 'Early detection saves lives.' 5-year survival with screening: 95%. Without screening: 60%. Screening works... right?", type: "normal" },
            { year: "The Illusion", text: "A patient diagnosed at age 60 (no screening) dies at 65. 5-year survival = 0%. The SAME patient diagnosed at 55 (screening) dies at 65. 5-year survival = 100%. NOTHING CHANGED except diagnosis date.", type: "revelation" },
            { year: "Neuroblastoma", text: "Japan screened all infants for neuroblastoma (childhood cancer). Found 3x more cases. 5-year survival soared. BUT: Mortality was UNCHANGED. They found cancers that would have regressed on their own.", type: "crisis" },
            { year: "PSA Screening", text: "Prostate screening increases 5-year survival dramatically. But mortality benefit is tiny or zero in many trials. Many men get treatment for cancers that would never have killed them.", type: "crisis" },
            { year: "The Math", text: "Lead time = time between screen detection and when symptoms would appear. If lead time is 5 years, 5-year survival improves by 100% even with ZERO mortality benefit.", type: "revelation" },
            { year: "Lesson", text: "NEVER use survival statistics to evaluate screening. Only MORTALITY (deaths per population) tells the truth. Survival is contaminated by lead time and overdiagnosis.", type: "revelation" }
          ],
          realData: {
            endpoint: "5-year survival vs population mortality",
            drug: "Cancer screening programs",
            placebo: "No screening",
            rr: "Survival: dramatic improvement | Mortality: often minimal",
            ci: "Lead time creates illusion of benefit",
            nnh: "Millions overdiagnosed with 'cancers' that never would have caused harm"
          },
          hook: "THE HOOK: '5-year survival improved 50%' sounds like screening works. But it might just mean you moved the starting line. Survival measures time from DIAGNOSIS. If diagnosis is earlier but death is the same, survival 'improves' without anyone living longer. This is lead time bias ‚Äî and it has fooled millions."
        }
      },
      {
        type: 'decision-tree',
        content: {
          id: 'screening-evaluation',
          title: "Evaluate This Screening Claim",
          situation: "A new screening test for pancreatic cancer is promoted. Marketing materials show: '5-year survival is 25% with screening vs 5% without.' The test costs $500 and has a 3% false positive rate requiring invasive follow-up.",
          nodes: {
            start: {
              question: "What is your first concern about the '25% vs 5%' survival claim?",
              branches: [
                { text: "It's impressive ‚Äî 5x better survival!", nextNode: "impressed_wrong" },
                { text: "Survival doesn't prove mortality benefit ‚Äî could be lead time", nextNode: "lead_time_correct" },
                { text: "The study probably wasn't randomized", nextNode: "randomization_partial" }
              ]
            },
            impressed_wrong: {
              type: 'outcome',
              outcome: 'danger',
              title: "You've been fooled by lead time!",
              text: "Pancreatic cancer is almost universally fatal. If screening advances diagnosis by 1 year but patients still die at the same age, 1-year survival goes from ~20% to ~40% ‚Äî with ZERO lives saved. Survival statistics are meaningless for evaluating screening.",
              lesson: "NEVER accept survival as evidence for screening benefit. Demand mortality data from randomized trials."
            },
            lead_time_correct: {
              situation: "Excellent skepticism! You ask for mortality data. They provide: 'In a cohort study, screened patients had 30% lower pancreatic cancer mortality.'",
              question: "Is this convincing?",
              branches: [
                { text: "Yes ‚Äî mortality is the right endpoint", nextNode: "cohort_wrong" },
                { text: "No ‚Äî cohort studies of screening have healthy screener bias", nextNode: "healthy_screener_correct" }
              ]
            },
            randomization_partial: {
              type: 'outcome',
              outcome: 'partial',
              title: "Good instinct, but the specific bias matters",
              text: "Yes, the study is likely observational. But the SPECIFIC bias is lead time ‚Äî survival improves just by diagnosing earlier even if death date is unchanged. Randomization would help, but even then, you need MORTALITY, not survival, as the endpoint.",
              lesson: "For screening evaluation: (1) Must be mortality, not survival, (2) Must be randomized or very carefully designed to avoid healthy screener bias."
            },
            cohort_wrong: {
              type: 'outcome',
              outcome: 'danger',
              title: "Healthy screener bias!",
              text: "People who choose screening are systematically healthier. They exercise more, eat better, have better access to healthcare. They have lower mortality FROM EVERYTHING ‚Äî including pancreatic cancer ‚Äî even if screening doesn't work. This is HRT all over again.",
              lesson: "Healthy screener bias is healthy user bias applied to screening. Only RCTs can eliminate it. Observational mortality comparisons for screening are unreliable."
            },
            healthy_screener_correct: {
              situation: "Perfect! You demand RCT evidence. The company says: 'An RCT is ongoing but won't report for 10 years. In the meantime, shouldn't we offer screening?'",
              question: "Your response:",
              branches: [
                { text: "Yes ‚Äî some benefit is likely, and screening is harmless", nextNode: "harmless_wrong" },
                { text: "No ‚Äî unproven screening causes harm through false positives, overdiagnosis, and anxiety", nextNode: "wait_correct" }
              ]
            },
            harmless_wrong: {
              type: 'outcome',
              outcome: 'danger',
              title: "Screening is NOT harmless!",
              text: "3% false positive rate √ó millions screened = tens of thousands of invasive biopsies. Pancreas biopsies can cause pancreatitis, bleeding, death. Plus anxiety from false alarms. Plus overdiagnosis of indolent tumors treated unnecessarily. Screening without proven benefit is NET HARM.",
              lesson: "Screening has COSTS: false positives, overdiagnosis, anxiety, procedures. These are CERTAIN. Benefit is UNCERTAIN until RCT-proven. Uncertain benefit + certain harm = wait for evidence."
            },
            wait_correct: {
              type: 'outcome',
              outcome: 'success',
              title: "Evidence-based patience!",
              text: "You correctly identified: (1) survival claims mean nothing (lead time), (2) observational mortality claims have healthy screener bias, (3) screening has real harms. Until an RCT shows MORTALITY benefit outweighs harms, screening should not be implemented.",
              lesson: "Screening is INTERVENTION. It requires the same evidence standard as drugs: RCT showing benefits > harms. 'Early detection' sounds good but isn't automatically beneficial."
            }
          }
        }
      },
      {
        type: 'principle',
        content: {
          text: "‚ö†Ô∏è THE WARNING: Screening programs are among the most bias-prone topics in medicine. Lead time bias makes survival look better than reality. Length bias makes screening find slow-growing (less lethal) cancers. Healthy screener bias makes screened populations look healthier. Overdiagnosis turns healthy people into patients. DEMAND RCT mortality evidence before accepting screening claims."
        }
      },
      {
        type: 'principle',
        content: {
          text: "üéØ PROGRESS CHECK: You've learned to pool observational evidence carefully. You understand that meta-analysis can magnify bias as easily as signal. You can identify lead time bias in screening studies. You know when to trust pooled estimates and when to be skeptical. Next: pharmacovigilance ‚Äî detecting drug safety signals."
        }
      }
    ]
  },
  // MODULE 9: THE PHARMACOVIGILANCE (Signal Detection)
  {
    id: 9,
    title: "The Pharmacovigilance",
    subtitle: "Signal Detection",
    principle: 2,
    estimatedTime: "25 min",
    slides: [
      {
        type: 'principle-display',
        content: {
          principle: "Time flows one direction"
        }
      },
      {
        type: 'story-deep',
        content: {
          label: "THE SIGNAL IGNORED: VIOXX ‚Äî WHEN 88,000 HEARTS STOPPED",
          source: "NEJM 2005 | FDA | Merck internal documents | VIGOR, APPROVe trials",
          timeline: [
            { year: "1999", text: "Vioxx (rofecoxib) approved. COX-2 inhibitor for arthritis. Marketed as 'safer on stomach' than older NSAIDs. Billions in sales projected.", type: "normal" },
            { year: "2000", text: "VIGOR trial: 4x higher cardiovascular events vs naproxen. Merck interprets as 'naproxen is cardioprotective,' not 'Vioxx is cardiotoxic.' FDA concerned.", type: "crisis" },
            { year: "2001-04", text: "Observational studies show signal: cardiovascular events in Vioxx users. David Graham (FDA) estimates 88,000-140,000 excess cardiac events. Internal Merck data shows risk.", type: "crisis" },
            { year: "2004", text: "APPROVe trial (colon polyps): Stopped early for cardiovascular harm. RR 1.92 (95% CI 1.19-3.11). Merck withdraws Vioxx worldwide.", type: "revelation" },
            { year: "The Failure", text: "Spontaneous reports, observational signals, even internal data were dismissed. The hierarchy of evidence was used to IGNORE warning signs until RCTs confirmed harm.", type: "revelation" },
            { year: "Lesson", text: "Observational evidence for HARMS should not require the same threshold as evidence for BENEFITS. Signals matter. 88,000 deaths is the cost of waiting for 'perfect' evidence.", type: "revelation" }
          ],
          realData: {
            endpoint: "Myocardial infarction / sudden cardiac death",
            drug: "Rofecoxib (Vioxx)",
            placebo: "Naproxen / placebo",
            rr: "RR 1.92 (1.19-3.11) in APPROVe",
            ci: "Signal present for 4 years before withdrawal",
            nnh: "88,000-140,000 excess cardiac events estimated"
          },
          hook: "THE HOOK: Pharmacovigilance failed because signals were dismissed as 'only observational.' The evidence hierarchy that protects against false positives for benefits should not be used to dismiss warnings of harm. When lives are at stake, false negatives kill."
        }
      },
      {
        type: 'principle',
        content: {
          text: "‚è∏Ô∏è KEY INSIGHT: For HARMS, the evidence threshold should be LOWER than for benefits. Why? False positive (thinking something harmful is safe) has worse consequences than false negative (thinking something safe is harmful). Observational signals for harm deserve urgent attention, not dismissal."
        }
      },
      {
        type: 'content',
        content: {
          title: "Pharmacovigilance: The Science of Safety Signals",
          sections: [
            {
              heading: "Why Observational Data Is Essential for Safety:",
              items: [
                "RCTs are POWERED for benefits, not rare harms",
                "100-patient RCT: can detect 3% event rate, NOT 0.1% rate",
                "Rare harms need millions of patient-years of exposure",
                "Post-marketing surveillance is the only way to detect them",
                "Thalidomide, Vioxx, DES ‚Äî all detected observationally"
              ]
            },
            {
              heading: "Signal Detection Methods:",
              items: [
                "Spontaneous reporting (FAERS, Yellow Card) ‚Äî passive surveillance",
                "Disproportionality analysis ‚Äî observed vs expected reports",
                "Case series ‚Äî temporal clustering of events",
                "Cohort studies ‚Äî active surveillance in databases",
                "Self-controlled designs ‚Äî within-person comparisons"
              ]
            }
          ]
        }
      },
      {
        type: 'method',
        content: {
          label: "THE METHOD: EVALUATING SAFETY SIGNALS",
          title: "From Signal to Action",
          sections: [
            {
              heading: "Signal Detection (Is there something there?):",
              text: "‚Ä¢ Spontaneous reports: PRR, ROR, IC (information component)\n‚Ä¢ Database studies: compare exposed vs unexposed rates\n‚Ä¢ Case series: temporal pattern, dose-response\n‚Ä¢ Biological plausibility: is there a mechanism?"
            },
            {
              heading: "Signal Validation (Is it real?):",
              text: "‚Ä¢ Can the signal be replicated in another database?\n‚Ä¢ Is there confounding by indication?\n‚Ä¢ Is there detection/notoriety bias?\n‚Ä¢ Do independent methods give consistent results?"
            },
            {
              heading: "Signal Assessment (Is it clinically important?):",
              text: "‚Ä¢ Absolute risk: how many excess events per 1,000 users?\n‚Ä¢ Comparison to alternatives: are other drugs safer?\n‚Ä¢ Severity: death/disability vs transient symptoms?\n‚Ä¢ Population at risk: vulnerable subgroups?"
            },
            {
              heading: "Action:",
              text: "‚Ä¢ Communicate risk (label changes, dear doctor letters)\n‚Ä¢ Restrict use (contraindications, REMS)\n‚Ä¢ Withdraw (if risk outweighs all benefit)\n‚Ä¢ Request confirmatory studies (if uncertainty remains)"
            }
          ]
        }
      },
      {
        type: 'content',
        content: {
          title: "Self-Controlled Designs: Eliminating Between-Person Confounding",
          sections: [
            {
              heading: "The Idea:",
              items: [
                "Use each person as their own control",
                "Compare risk during 'exposed' periods to 'unexposed' periods",
                "All time-invariant confounders automatically controlled",
                "No healthy user bias from comparing different people"
              ]
            },
            {
              heading: "Case-Crossover Design:",
              items: [
                "Start with cases (people who had the event)",
                "Compare their exposure in the hazard period (just before event)",
                "To their exposure in control periods (earlier times)",
                "If exposure is higher in hazard periods ‚Üí association"
              ]
            },
            {
              heading: "Self-Controlled Case Series (SCCS):",
              items: [
                "Uses only people who had BOTH exposure and outcome",
                "Compares rate during exposed periods to unexposed periods",
                "Requires that exposure doesn't affect future outcome probability",
                "Used extensively for vaccine safety (MMR-autism debunked this way)"
              ]
            },
            {
              heading: "Limitations:",
              items: [
                "Can't control for TIME-VARYING confounders",
                "Assumes event doesn't change future exposure probability",
                "Needs intermittent exposure (not continuous use)",
                "Can be affected by exposure trends over time"
              ]
            }
          ]
        }
      },
      {
        type: 'decision-tree',
        content: {
          id: 'signal-assessment',
          title: "Evaluate This Safety Signal",
          situation: "A new antidepressant has been on the market for 2 years. Spontaneous reports to FAERS suggest a possible association with sudden cardiac death. The reporting rate is 3x higher than for other antidepressants. The drug has no known QT prolongation in trials. 500,000 patients have used it.",
          nodes: {
            start: {
              question: "First step: Is this signal reliable?",
              branches: [
                { text: "No ‚Äî spontaneous reports are unreliable, need RCT confirmation", nextNode: "dismiss_wrong" },
                { text: "Maybe ‚Äî check for reporting bias and confounding by indication", nextNode: "check_bias_correct" },
                { text: "Yes ‚Äî 3x higher is definitely a signal, withdraw the drug", nextNode: "overreact_wrong" }
              ]
            },
            check_bias_correct: {
              situation: "Good. You investigate. The drug is preferentially prescribed to older, sicker patients (confounding by indication). But the disproportionality persists after adjusting for age and comorbidity in database studies. Rate ratio: 2.1 (95% CI 1.4-3.2) vs comparator antidepressants.",
              question: "Next step:",
              branches: [
                { text: "Validate in an independent database using different methods", nextNode: "validate_correct" },
                { text: "Issue immediate drug withdrawal ‚Äî 2.1 RR is alarming", nextNode: "withdraw_early" },
                { text: "Dismiss ‚Äî database studies are observational, wait for RCT", nextNode: "dismiss_again_wrong" }
              ]
            },
            dismiss_wrong: {
              type: 'outcome',
              outcome: 'danger',
              title: "Dangerous dismissal!",
              text: "Spontaneous reports CAN be unreliable, but they're the front line of safety surveillance. A 3x higher reporting rate warrants investigation, not dismissal. Vioxx's cardiac signal was in spontaneous reports for years before action was taken.",
              lesson: "Signals warrant investigation. 'Unreliable' doesn't mean 'ignore.' It means 'investigate further with better methods.'"
            },
            overreact_wrong: {
              type: 'outcome',
              outcome: 'partial',
              title: "Premature action!",
              text: "Spontaneous reporting has many biases: notoriety bias (more reports after media coverage), channeling (drug given to sicker patients), stimulated reporting. A 3x disproportionality needs confirmation before withdrawing a drug that may help millions.",
              lesson: "Signals need validation before drastic action. But validation should be FAST ‚Äî not the 4 years it took for Vioxx."
            },
            validate_correct: {
              situation: "You replicate in a second database and find similar results: RR 1.9 (1.3-2.8). A self-controlled case series also shows elevated risk in exposed periods: IRR 2.5 (1.6-3.9). Now what?",
              question: "Decision time:",
              branches: [
                { text: "Strong evidence ‚Äî communicate risk and consider restrictions", nextNode: "action_correct" },
                { text: "Still observational ‚Äî request an RCT before acting", nextNode: "request_rct_wrong" }
              ]
            },
            withdraw_early: {
              type: 'outcome',
              outcome: 'partial',
              title: "Maybe appropriate, but validate first",
              text: "A rate ratio of 2.1 for sudden cardiac death is serious. But replication in independent data would strengthen confidence. If the signal is real, action is needed. But if it's artifactual, withdrawal harms patients who benefit from the drug.",
              lesson: "For serious harms, err toward action. But rapid validation (days to weeks, not years) can prevent both unnecessary withdrawals and delayed action."
            },
            dismiss_again_wrong: {
              type: 'outcome',
              outcome: 'danger',
              title: "This is the Vioxx failure!",
              text: "Waiting for RCT evidence of harm is a mistake. RCTs for rare harms would need enormous sample sizes. Database studies with consistent results across methods (cohort, SCCS) and populations provide strong evidence. 'Observational' doesn't mean 'ignore.'",
              lesson: "For harms, multiple consistent observational studies often provide stronger evidence than waiting for an (often impossible) RCT. Act on the best available evidence."
            },
            request_rct_wrong: {
              type: 'outcome',
              outcome: 'danger',
              title: "An RCT for sudden cardiac death?",
              text: "To detect a doubling of sudden cardiac death (baseline rate ~0.1%), you'd need 50,000+ patients followed for years. This is impractical. By the time an RCT completes, thousands more could die. Observational evidence is the BEST evidence we'll ever have for rare, serious harms.",
              lesson: "Evidence-based medicine isn't 'RCT-or-nothing.' It's 'use the best evidence available.' For rare harms, that means well-conducted observational studies."
            },
            action_correct: {
              type: 'outcome',
              outcome: 'success',
              title: "Appropriate response!",
              text: "With replicated observational evidence using multiple methods, action is warranted. Options: label warnings, contraindications for high-risk patients, REMS program, or (if alternatives exist and harm is severe) withdrawal. The exact action depends on benefit-harm balance.",
              lesson: "Signal ‚Üí Validation ‚Üí Assessment ‚Üí Action. The Vioxx disaster happened because action was delayed. Multiple consistent observational signals DEMAND response."
            }
          }
        }
      },
      {
        type: 'quiz',
        content: {
          question: "Why is the evidence threshold for drug HARMS generally lower than for drug BENEFITS?",
          options: [
            { id: 'a', text: "Harms are easier to measure than benefits", correct: false },
            { id: 'b', text: "The cost of a false negative (missing harm) exceeds the cost of a false positive (missing benefit)", correct: true },
            { id: 'c', text: "Observational studies are more reliable for harms than benefits", correct: false },
            { id: 'd', text: "RCTs cannot detect harms, only benefits", correct: false }
          ],
          explanation: "For benefits, a false positive (approving ineffective treatment) wastes resources. For harms, a false negative (missing a harmful effect) kills people. The asymmetry in consequences justifies asymmetric evidence thresholds. We should require LESS certainty to suspect harm than to believe benefit."
        }
      }
    ]
  },
  // MODULE 10: THE INTEGRATION (When to Trust Observational Evidence)
  {
    id: 10,
    title: "The Integration",
    subtitle: "When to Trust",
    principle: 6,
    estimatedTime: "35 min",
    slides: [
      {
        type: 'principle-display',
        content: {
          principle: "Replication builds confidence"
        }
      },
      {
        type: 'story-deep',
        content: {
          label: "THE CONVERGENCE: SMOKING AND LUNG CANCER ‚Äî WHEN OBSERVATION WAS ENOUGH",
          source: "Doll & Hill 1950-2004 | Bradford Hill Criteria | Never randomized",
          timeline: [
            { year: "1950", text: "Doll & Hill case-control study: smokers 9x more likely to have lung cancer. Tobacco industry demands RCT proof. (Unethical to randomize smoking)", type: "normal" },
            { year: "1954", text: "British Doctors cohort begins. Prospective design addresses reverse causation. Shows dose-response: more cigarettes ‚Üí more cancer.", type: "normal" },
            { year: "1964", text: "US Surgeon General declares smoking causes lung cancer. Based entirely on observational evidence. No RCT ever conducted.", type: "revelation" },
            { year: "2004", text: "50-year follow-up: smokers lose 10 years of life expectancy. Quitting at any age helps. Observational evidence now indisputable.", type: "revelation" },
            { year: "How We Knew", text: "Strength (RR = 10-30), consistency (every study), temporality (smoking preceded cancer), dose-response, biological plausibility, coherence, specificity, analogy, experiment (cessation reduces risk).", type: "revelation" },
            { year: "Lesson", text: "Bradford Hill criteria enabled causal inference from observational data when RCTs were impossible. Strong, consistent, biologically plausible associations CAN establish causation without randomization.", type: "revelation" }
          ],
          realData: {
            endpoint: "Lung cancer mortality",
            drug: "Heavy smoking (20+ cigarettes/day)",
            placebo: "Never smokers",
            rr: "RR 10-30 (study dependent)",
            ci: "Unmistakable association",
            nnh: "Millions of deaths attributable to smoking"
          },
          hook: "THE HOOK: We've never randomized smoking. Yet no one doubts smoking causes lung cancer. How did observational evidence alone convince the world? The Bradford Hill criteria ‚Äî a framework for causal inference when RCTs are impossible or unethical."
        }
      },
      {
        type: 'principle',
        content: {
          text: "‚è∏Ô∏è KEY INSIGHT: Observational evidence CAN establish causation when: (1) associations are STRONG, (2) results REPLICATE across studies/populations/methods, (3) temporality is clear, (4) dose-response exists, (5) biological mechanism is plausible, (6) findings are COHERENT with existing knowledge. No single criterion is required; it's the totality of evidence."
        }
      },
      {
        type: 'content',
        content: {
          title: "The Bradford Hill Criteria (Updated)",
          sections: [
            {
              heading: "1. Strength of Association:",
              text: "Larger effect sizes are less likely to be entirely due to confounding. RR = 10 is hard to explain by bias alone; RR = 1.2 might be entirely confounded."
            },
            {
              heading: "2. Consistency:",
              text: "Same finding across different populations, settings, methods, times. If it replicates everywhere, less likely to be artifact."
            },
            {
              heading: "3. Specificity:",
              text: "Exposure leads to specific outcome (not everything). But multi-causal diseases violate this ‚Äî smoking causes many diseases. Least important criterion."
            },
            {
              heading: "4. Temporality:",
              text: "Cause MUST precede effect. This is essential. Cohort studies establish temporality; cross-sectional cannot."
            },
            {
              heading: "5. Biological Gradient (Dose-Response):",
              text: "More exposure ‚Üí more outcome. Supports causation. But non-linear relationships can be causal too."
            },
            {
              heading: "6. Plausibility:",
              text: "Biological mechanism exists that could explain the relationship. But mechanism is not always known for true causes."
            },
            {
              heading: "7. Coherence:",
              text: "Association doesn't conflict with known biology, natural history, epidemiology. Should 'fit' existing knowledge."
            },
            {
              heading: "8. Experiment:",
              text: "Removing the exposure reduces the outcome (cessation studies). Or natural experiments show effect."
            },
            {
              heading: "9. Analogy:",
              text: "Similar exposures cause similar outcomes. If A causes X, then similar B might cause similar Y."
            }
          ]
        }
      },
      {
        type: 'method',
        content: {
          label: "THE METHOD: TRIANGULATION",
          title: "Modern Approach to Causal Inference",
          sections: [
            {
              heading: "What Is Triangulation?",
              text: "Using multiple study designs, each with DIFFERENT sources of bias, to see if they converge on the same answer. If biases differ but results agree, more likely causal."
            },
            {
              heading: "Example: Alcohol and Heart Disease",
              text: "‚Ä¢ Cohort studies: moderate drinking appears protective (confounded by healthy user?)\n‚Ä¢ Mendelian randomization: genetic variants for alcohol metabolism show NO protection\n‚Ä¢ Sibling comparisons: within-family, no protective effect\n\nTriangulation: cohort studies were confounded. Observational 'benefit' is not causal."
            },
            {
              heading: "Key Insight:",
              text: "Different methods have different biases:\n‚Ä¢ Cohort studies: confounding, selection\n‚Ä¢ Case-control: recall bias\n‚Ä¢ Mendelian randomization: pleiotropy, weak instruments\n‚Ä¢ Within-family: shared family environment\n\nIf ALL methods agree despite DIFFERENT biases, confidence in causality increases."
            }
          ]
        }
      },
      {
        type: 'content',
        content: {
          title: "When to Trust Observational Evidence",
          sections: [
            {
              heading: "HIGH Confidence When:",
              items: [
                "Large effect size (RR > 2-3) ‚Äî hard to explain by bias alone",
                "Consistent across multiple methods with different biases",
                "Clear temporality (prospective cohort, not cross-sectional)",
                "Dose-response present",
                "Biologically plausible mechanism known",
                "Low risk of bias by ROBINS-I criteria",
                "Mendelian randomization agrees with observational"
              ]
            },
            {
              heading: "LOW Confidence When:",
              items: [
                "Small effect size (RR 1.0-1.5) ‚Äî easily confounded",
                "Results vary by method (cohort vs case-control disagree)",
                "Cross-sectional design (reverse causation possible)",
                "No dose-response or paradoxical patterns",
                "Mechanism unknown or contradicts biology",
                "High risk of bias across studies",
                "Mendelian randomization contradicts observational"
              ]
            },
            {
              heading: "The 'Smoking Test':",
              text: "Could unmeasured confounding be as strong as smoking ‚Üí lung cancer (RR 10-30)? If your effect is RR 1.3, a confounder with RR 2 on both exposure and outcome could fully explain it. If your effect is RR 10, it's much harder to explain away."
            }
          ]
        }
      },
      {
        type: 'decision-tree',
        content: {
          id: 'trust-decision',
          title: "Should You Trust This Observational Finding?",
          situation: "You've read that red meat consumption is associated with colorectal cancer. Cohort studies show RR ~1.2 (1.1-1.4) for high vs low consumption. This is consistent across multiple cohorts. Biological plausibility exists (heme iron, heterocyclic amines). No RCT is possible (can't randomize diet for decades).",
          nodes: {
            start: {
              question: "First consideration: What do you think of RR = 1.2?",
              branches: [
                { text: "Moderate effect ‚Äî warrants public health attention", nextNode: "moderate_wrong" },
                { text: "Small effect ‚Äî could easily be explained by confounding", nextNode: "small_correct" },
                { text: "Negligible ‚Äî ignore it", nextNode: "ignore_wrong" }
              ]
            },
            small_correct: {
              situation: "Correct. RR 1.2 is small and could be confounded. But it's CONSISTENT across cohorts. Does that change things?",
              question: "Consistency across cohorts means:",
              branches: [
                { text: "It's probably causal ‚Äî too consistent to be chance", nextNode: "consistent_overinterpret" },
                { text: "Studies may share the same bias (healthy user, residual confounding)", nextNode: "shared_bias_correct" }
              ]
            },
            moderate_wrong: {
              type: 'outcome',
              outcome: 'partial',
              title: "Be more skeptical",
              text: "RR 1.2 is a SMALL effect in epidemiology. For comparison, smoking and lung cancer is RR 10-30. An effect size of 1.2 is within the range that unmeasured confounding could easily produce. It's not 'moderate' ‚Äî it's 'uncertain.'",
              lesson: "In observational epidemiology, be skeptical of RR < 2. Such effects could be entirely confounded."
            },
            ignore_wrong: {
              type: 'outcome',
              outcome: 'danger',
              title: "Don't dismiss entirely",
              text: "RR 1.2 at a population level still matters. If millions eat high red meat, even small excess risks produce substantial burden. The effect may be real but confounded; it's worth investigating with different methods.",
              lesson: "Small effects can have large public health impact. Don't dismiss, but be appropriately uncertain."
            },
            consistent_overinterpret: {
              type: 'outcome',
              outcome: 'partial',
              title: "Careful with consistency!",
              text: "Consistency is reassuring, but cohort studies share SIMILAR biases: all have healthy user effects, similar measurement error, similar confounding structures. Consistency within one method doesn't rule out systematic bias in that method.",
              lesson: "Consistency across METHODS (cohort, case-control, Mendelian randomization) is more reassuring than consistency within one method."
            },
            shared_bias_correct: {
              situation: "Right. What if Mendelian randomization (MR) studies were done, using genetic variants that affect red meat consumption? Suppose MR shows NO association with colorectal cancer.",
              question: "What do you conclude?",
              branches: [
                { text: "MR is definitive ‚Äî the cohort studies were confounded", nextNode: "mr_definitive_partial" },
                { text: "Triangulation: discordant results suggest confounding, but MR has limitations too", nextNode: "triangulation_correct" }
              ]
            },
            mr_definitive_partial: {
              type: 'outcome',
              outcome: 'partial',
              title: "MR isn't perfect either",
              text: "Mendelian randomization has limitations: genetic variants may affect multiple pathways (pleiotropy), instruments may be weak, genetic effects operate lifelong (not same as adult dietary change). Discordant MR suggests confounding in cohorts, but doesn't definitively prove null effect.",
              lesson: "No single method is definitive. Triangulation means weighing evidence from multiple approaches, each with different limitations."
            },
            triangulation_correct: {
              type: 'outcome',
              outcome: 'success',
              title: "Excellent triangulation!",
              text: "You've correctly identified: (1) small effect size ‚Üí possibly confounded; (2) consistency within method doesn't rule out shared bias; (3) discordant MR suggests confounding but isn't definitive. The appropriate conclusion is: 'Uncertain ‚Äî possible small effect, possibly confounded.'",
              lesson: "This is the current scientific consensus on red meat and colorectal cancer: probably some effect, but magnitude uncertain due to potential confounding. Public health messaging should reflect this uncertainty."
            }
          }
        }
      },
      {
        type: 'quiz',
        content: {
          question: "Which scenario provides the STRONGEST observational evidence for causation?",
          options: [
            { id: 'a', text: "20 cohort studies showing RR 1.3, all with similar confounding structures", correct: false },
            { id: 'b', text: "5 studies using different methods (cohort, case-control, MR, sibling) all showing RR ~3", correct: true },
            { id: 'c', text: "1 large cohort study with 1 million participants showing RR 1.5", correct: false },
            { id: 'd', text: "A meta-analysis of 50 studies showing pooled RR 1.2 with I¬≤ = 0%", correct: false }
          ],
          explanation: "Triangulation across different methods with different biases provides the strongest evidence. If cohort studies (confounding), case-control (recall bias), MR (pleiotropy), and sibling comparisons (genetic confounding) all converge on RR ~3, each method's biases are unlikely to produce the same false answer. Large N or many studies with the SAME bias doesn't help."
        }
      },
      {
        type: 'content',
        content: {
          title: "Mendelian Randomization: Nature's RCT",
          sections: [
            {
              heading: "The Brilliant Idea:",
              items: [
                "Genetic variants are assigned at conception (before any confounders)",
                "Like random assignment in an RCT",
                "Find a gene that affects exposure (e.g., alcohol metabolism)",
                "Compare outcomes in people with different gene variants",
                "Since genes are 'randomized,' confounding is eliminated"
              ]
            },
            {
              heading: "Example: Alcohol and Heart Disease",
              items: [
                "Observational: moderate drinkers have lower CVD than non-drinkers",
                "Confounding? Moderate drinkers may be healthier overall",
                "MR approach: Use ALDH2 gene (affects alcohol metabolism)",
                "People with 'slow metabolizer' variant drink less",
                "MR result: NO cardioprotection from moderate drinking",
                "The observational association was CONFOUNDED"
              ]
            },
            {
              heading: "Limitations (IMPORTANT):",
              items: [
                "PLEIOTROPY: Gene may affect outcome through other pathways",
                "WEAK INSTRUMENTS: Gene may explain tiny fraction of exposure",
                "POPULATION STRATIFICATION: Ancestry can confound",
                "DEVELOPMENTAL EFFECTS: Lifelong genetic effect ‚â† adult intervention",
                "MR is powerful but not infallible ‚Äî use for triangulation"
              ]
            }
          ]
        }
      },
      {
        type: 'decision-tree',
        content: {
          id: 'mr-interpretation',
          title: "Interpret This MR Study",
          situation: "Observational studies consistently show that higher vitamin D levels are associated with lower risk of multiple sclerosis (MS). RR = 0.60 (0.50-0.70) per 50 nmol/L higher vitamin D. An MR study uses genetic variants affecting vitamin D synthesis.",
          nodes: {
            start: {
              question: "The MR study finds: genetic predisposition to higher vitamin D is associated with lower MS risk (OR 0.70 per genetically-predicted 50 nmol/L). What does this suggest?",
              branches: [
                { text: "Vitamin D supplementation will prevent MS", nextNode: "supplement_wrong" },
                { text: "The observational association may be causal, not just confounded", nextNode: "causal_correct" },
                { text: "We should dismiss the observational studies", nextNode: "dismiss_wrong" }
              ]
            },
            supplement_wrong: {
              type: 'outcome',
              outcome: 'danger',
              title: "Too far!",
              text: "MR supports causality of vitamin D LEVELS, but: (1) Lifelong genetically-determined levels ‚â† adult supplementation; (2) The genetic effect operates from birth; (3) There may be critical windows in childhood. MR suggests vitamin D matters but doesn't prove SUPPLEMENTATION works.",
              lesson: "MR tests the causal effect of the EXPOSURE. It doesn't tell you if an INTERVENTION will work, especially if timing/dose/form differ."
            },
            causal_correct: {
              situation: "Correct interpretation! The MR supports causality. But before you're confident, what should you check?",
              question: "What's the key assumption to verify?",
              branches: [
                { text: "Sample size is adequate", nextNode: "sample_wrong" },
                { text: "The genetic variants don't affect MS through other pathways (pleiotropy)", nextNode: "pleiotropy_correct" }
              ]
            },
            dismiss_wrong: {
              type: 'outcome',
              outcome: 'partial',
              title: "Don't dismiss ‚Äî triangulate!",
              text: "MR SUPPORTING observational findings is good news! When methods with different biases agree (observational: confounding; MR: pleiotropy), confidence increases. Consistency between methods is the goal of triangulation.",
              lesson: "Agreement between observational and MR studies STRENGTHENS the case for causality. They have different biases, so if both agree, confounding in observational studies is less likely."
            },
            sample_wrong: {
              type: 'outcome',
              outcome: 'partial',
              title: "True, but not the key assumption",
              text: "Adequate sample size matters for precision, but the FUNDAMENTAL assumption of MR is that the genetic variants only affect the outcome THROUGH the exposure. If the vitamin D genes also affect immune function directly (pleiotropy), MR is biased.",
              lesson: "MR validity depends on: (1) Genes affect exposure, (2) Genes don't affect outcome except through exposure, (3) Genes aren't confounded (usually satisfied). Violation of #2 (pleiotropy) is the main threat."
            },
            pleiotropy_correct: {
              type: 'outcome',
              outcome: 'success',
              title: "Exactly right!",
              text: "Pleiotropy is the Achilles' heel of MR. If vitamin D genes also affect immune function, sun exposure behavior, or other pathways to MS, the MR estimate is biased. Methods exist to test/adjust for pleiotropy (MR-Egger, weighted median), but it remains a concern.",
              lesson: "When reading MR studies, always ask: 'Could these genes affect the outcome through OTHER pathways?' If yes, interpret cautiously. Use multiple genetic variants and sensitivity analyses."
            }
          }
        }
      },
      {
        type: 'story-deep',
        content: {
          label: "THE SUBGROUP TRAP: ACCORD ‚Äî WHEN THE AVERAGE HID THE HARM",
          source: "NEJM 2008; ACCORD Study Group | Intensive glycemic control | Effect modification",
          timeline: [
            { year: "Hypothesis", text: "Lower blood sugar should prevent diabetic complications. Target HbA1c <6% (intensive) vs <7.5% (standard). Makes biological sense.", type: "normal" },
            { year: "2008", text: "ACCORD stopped early for HARM. Intensive control increased MORTALITY: HR 1.22 (1.01-1.46). 257 deaths vs 203. The opposite of expected.", type: "crisis" },
            { year: "But Wait", text: "ADVANCE trial (similar design): NO mortality increase. VADT trial: NO mortality increase. Same intervention, different results. Why?", type: "crisis" },
            { year: "Subgroup Analysis", text: "In ACCORD, patients WITH prior cardiovascular disease had HIGHER mortality with intensive control. Patients WITHOUT CVD had LOWER mortality. The AVERAGE obscured opposite effects.", type: "revelation" },
            { year: "The Lesson", text: "Effect modification: the intervention helps some and hurts others. Averaging across subgroups gives a misleading 'null' or small effect. Personalized medicine requires understanding WHO benefits and WHO is harmed.", type: "revelation" },
            { year: "Clinical Impact", text: "Guidelines now recommend AGAINST aggressive glucose targets in older patients with CVD. But FOR intensive control in younger, healthier diabetics. One answer doesn't fit all.", type: "revelation" }
          ],
          realData: {
            endpoint: "All-cause mortality",
            drug: "Intensive glycemic control (HbA1c <6%)",
            placebo: "Standard control (HbA1c <7.5%)",
            rr: "Overall: HR 1.22 (1.01-1.46) | By CVD: OPPOSITE directions",
            ci: "Heterogeneity of treatment effect",
            nnh: "One-size-fits-all kills"
          },
          hook: "THE HOOK: ACCORD shows why 'average treatment effects' can be dangerous. The average across all patients was small harm. But this AVERAGE hid the fact that intensive control helped some and killed others. Observational studies can explore effect modification that RCTs miss."
        }
      },
      {
        type: 'decision-tree',
        content: {
          id: 'effect-modification',
          title: "Is This Effect Modification or Confounding?",
          situation: "In your observational study, you find that a statin reduces cardiovascular events overall (HR 0.80). But when you stratify by age: <65 years HR 0.60; ‚â•65 years HR 0.95.",
          nodes: {
            start: {
              question: "What is happening here?",
              branches: [
                { text: "Confounding by age ‚Äî need to adjust", nextNode: "confounding_wrong" },
                { text: "Effect modification ‚Äî statin works better in younger patients", nextNode: "modification_correct" },
                { text: "Statistical artifact ‚Äî subgroups are underpowered", nextNode: "artifact_partial" }
              ]
            },
            confounding_wrong: {
              type: 'outcome',
              outcome: 'danger',
              title: "This is NOT confounding!",
              text: "Confounding means age DISTORTS the exposure-outcome relationship (older patients more likely to get statins AND have CVD). Effect modification means the EFFECT OF STATINS DIFFERS by age. These are fundamentally different. You've already stratified by age ‚Äî this SHOWS the different effects.",
              lesson: "Confounding: the confounder creates spurious association. Effect modification: the effect is genuinely DIFFERENT in subgroups. Stratification reveals effect modification."
            },
            modification_correct: {
              situation: "Correct! The effect genuinely differs by age. Now: should you report the overall HR 0.80 or the stratified results?",
              question: "Best reporting:",
              branches: [
                { text: "Report only overall HR 0.80 ‚Äî stratified results are hypothesis-generating", nextNode: "overall_wrong" },
                { text: "Report both, emphasizing that effect differs by age and clinical implications", nextNode: "both_correct" }
              ]
            },
            artifact_partial: {
              type: 'outcome',
              outcome: 'partial',
              title: "Worth checking, but pattern suggests real modification",
              text: "Always check if subgroup differences could be chance. But HR 0.60 vs HR 0.95 is a large difference. Test for interaction (p for interaction). If significant, effect modification is likely real. Even if not significant, the clinical difference may matter.",
              lesson: "Test for statistical interaction. But don't dismiss clinically important differences just because p>0.05 ‚Äî subgroup analyses are often underpowered."
            },
            overall_wrong: {
              type: 'outcome',
              outcome: 'danger',
              title: "This is the ACCORD mistake!",
              text: "Reporting only the overall effect hides the fact that statins work VERY well in younger patients and barely work in older patients. A 65-year-old patient deciding about statins would get misleading information. Effect modification has CLINICAL IMPLICATIONS.",
              lesson: "When effect modification exists, the overall effect can be MISLEADING. Report stratified results and discuss who benefits most and who may not benefit."
            },
            both_correct: {
              type: 'outcome',
              outcome: 'success',
              title: "Transparent and clinically useful!",
              text: "Reporting both allows clinicians to make better decisions. A 50-year-old might be more motivated to take statins (HR 0.60). An 80-year-old might reasonably decline (HR 0.95, with potential side effects). Personalized medicine requires understanding heterogeneity.",
              lesson: "Effect modification is INFORMATION, not a nuisance. Exploring and reporting subgroup effects ‚Äî with appropriate caution about multiple testing ‚Äî improves clinical care."
            }
          }
        }
      },
      {
        type: 'content',
        content: {
          title: "Beyond PS: Instrumental Variables & Natural Experiments",
          sections: [
            {
              heading: "When PS Methods Fail:",
              text: "Propensity scores require the 'no unmeasured confounding' assumption. When key confounders are unmeasured, we need different approaches: instrumental variables (IV) and natural experiments."
            },
            {
              heading: "Instrumental Variable Intuition:",
              items: [
                "Find something that affects TREATMENT but not OUTCOME (except through treatment)",
                "This 'instrument' mimics randomization for a subset of patients",
                "Example: Distance to hospital affects treatment choice, not directly affecting outcome",
                "IV estimates are valid even with unmeasured confounding ‚Äî if instrument is valid"
              ]
            },
            {
              heading: "Common Instruments in Healthcare:",
              items: [
                "Geographic variation (physician preference, facility availability)",
                "Calendar time (guideline changes, drug approvals)",
                "Mendelian randomization (genetic variants as instruments)",
                "Regression discontinuity (treatment thresholds based on arbitrary cutoffs)"
              ]
            },
            {
              heading: "Limitations:",
              items: [
                "Instruments often have weak correlation with treatment (low power)",
                "Exclusion restriction is untestable (must argue, can't prove)",
                "Estimates may be local (compliers only, not full population)",
                "Finding valid instruments is HARD ‚Äî most proposed instruments fail scrutiny"
              ]
            },
            {
              heading: "Key Takeaway:",
              text: "IV methods are powerful when valid instruments exist. Mendelian randomization is IV with genetic instruments. But the assumptions are strong and often violated. Use IV as triangulation, not as the sole evidence source."
            }
          ]
        }
      },
      {
        type: 'principle',
        content: {
          text: "üéØ MASTERY CHECKPOINT: You've now learned the complete toolkit for observational evidence: bias identification, DAGs, study designs, ROBINS-I, propensity scores (matching, IPTW, overlap weights), target trial emulation, instrumental variables, Mendelian randomization, negative controls, Bradford Hill criteria, and triangulation. You can IDENTIFY when observational evidence is trustworthy and when it's not. This is the core competency of evidence-based medicine."
        }
      },
      {
        type: 'principle',
        content: {
          text: "‚ö†Ô∏è THE WARNING: Average effects can hide opposite effects in subgroups. 'No overall effect' might mean 'helps some, harms others.' Effect modification is not a statistical nuisance ‚Äî it's clinical reality. When you find it, REPORT it. When you don't find it, you may have missed it."
        }
      }
    ]
  },
  // MODULE 11: THE CAPSTONE (Putting It All Together)
  {
    id: 11,
    title: "The Capstone",
    subtitle: "Putting It Together",
    principle: null,
    estimatedTime: "45 min",
    slides: [
      {
        type: 'title',
        content: {
          title: "The Capstone",
          subtitle: "Analyzing an Observational Study",
          text: "Apply everything you've learned to critically evaluate a real observational study. You'll assess bias, design, and decide whether to trust the conclusions."
        }
      },
      {
        type: 'content',
        content: {
          title: "Capstone Exercise: Evaluate This Study",
          sections: [
            {
              heading: "The Study:",
              text: "A cohort study claims that a new blood pressure medication (Drug X) reduces stroke risk by 40% compared to older medications (RR 0.60, 95% CI 0.52-0.70). The study used a health insurance database with 50,000 patients followed for 3 years."
            },
            {
              heading: "Study Details:",
              items: [
                "Patients were classified as 'Drug X users' if they had ‚â•2 prescriptions",
                "Comparator was 'any other antihypertensive'",
                "Adjusted for age, sex, diabetes, and prior cardiovascular disease",
                "Follow-up started from first Drug X prescription",
                "Drug X was newer and more expensive, often used after other drugs failed"
              ]
            },
            {
              heading: "Your Task:",
              text: "Use the principles from this course to evaluate this study. Consider biases, confounding, study design, and whether the results should change clinical practice."
            }
          ]
        }
      },
      {
        type: 'decision-tree',
        content: {
          id: 'capstone-assessment',
          title: "Capstone: Full Evaluation",
          situation: "You're evaluating the Drug X study. Work through each bias systematically.",
          nodes: {
            start: {
              question: "STEP 1 - IMMORTAL TIME: Patients needed ‚â•2 prescriptions to be 'Drug X users.' Time from first to second prescription is...",
              branches: [
                { text: "Correctly classified as unexposed ‚Äî no problem", nextNode: "immortal_wrong" },
                { text: "Likely immortal time ‚Äî must survive to get 2 prescriptions", nextNode: "immortal_correct" }
              ]
            },
            immortal_correct: {
              situation: "Correct! Requiring 2 prescriptions creates immortal time. This biases TOWARD benefit for Drug X.",
              question: "STEP 2 - CONFOUNDING BY INDICATION: Drug X was 'used after other drugs failed.' This means Drug X users are...",
              branches: [
                { text: "Sicker patients with harder-to-control BP ‚Äî confounding AGAINST Drug X", nextNode: "indication_sicker_correct" },
                { text: "Healthier patients who can afford newer drugs ‚Äî confounding FOR Drug X", nextNode: "indication_healthier_partial" }
              ]
            },
            immortal_wrong: {
              type: 'outcome',
              outcome: 'danger',
              title: "This IS immortal time bias!",
              text: "If a patient dies after their first prescription but before their second, they're classified as 'non-Drug X user' ‚Äî but they DID use Drug X. Time between prescriptions is immortal and misclassified. This ALWAYS biases toward apparent benefit for the exposure requiring survival.",
              lesson: "Any exposure definition requiring multiple events (prescriptions, visits, tests) creates immortal time bias."
            },
            indication_sicker_correct: {
              situation: "Correct! Drug X given to sicker patients would bias AGAINST the drug. But the study shows benefit. If indication bias is AGAINST and the result shows benefit, what does that mean?",
              question: "STEP 3 - DIRECTION OF BIAS: With immortal time (FOR) and confounding by indication (AGAINST), the NET bias is...",
              branches: [
                { text: "They cancel out ‚Äî result is probably unbiased", nextNode: "cancel_wrong" },
                { text: "Unclear ‚Äî depends on which bias is larger", nextNode: "direction_correct" }
              ]
            },
            indication_healthier_partial: {
              type: 'outcome',
              outcome: 'partial',
              title: "Possible, but consider the full picture",
              text: "'Used after other drugs failed' usually means HARDER TO TREAT patients, not healthier ones. They've failed first-line therapy. This creates confounding by indication AGAINST Drug X. The study would UNDERESTIMATE any true benefit.",
              lesson: "Confounding by indication in drug studies usually makes new/expensive drugs look WORSE (given to sicker patients) ‚Äî unless healthy user bias dominates."
            },
            cancel_wrong: {
              type: 'outcome',
              outcome: 'danger',
              title: "Biases don't just 'cancel out'!",
              text: "You can't assume biases cancel. Immortal time bias is nearly always present when the design creates it. Confounding by indication depends on prescribing patterns. You need to estimate the MAGNITUDE of each bias, not assume they offset.",
              lesson: "Identifying bias direction is step 1. Estimating bias MAGNITUDE requires sensitivity analysis or design changes."
            },
            direction_correct: {
              situation: "Correct! Net bias is unclear. You need more information.",
              question: "STEP 4 - ROBINS-I ASSESSMENT: Given what you know, what is your overall risk of bias judgment?",
              branches: [
                { text: "Moderate ‚Äî some concerns but usable", nextNode: "robins_moderate_wrong" },
                { text: "Serious ‚Äî important problems that require caution", nextNode: "robins_serious_correct" },
                { text: "Critical ‚Äî too flawed to be useful", nextNode: "robins_critical_partial" }
              ]
            },
            robins_moderate_wrong: {
              type: 'outcome',
              outcome: 'danger',
              title: "Too generous!",
              text: "With BOTH immortal time bias AND unmeasured confounding (severity of hypertension, prior treatment failure), this study has SERIOUS methodological problems. 'Moderate' implies it's nearly as good as an RCT ‚Äî it's not.",
              lesson: "ROBINS-I is intentionally strict. Real-world drug studies rarely achieve 'low' or 'moderate' without careful design (new user, active comparator, etc.)."
            },
            robins_serious_correct: {
              situation: "Appropriate! The study has serious risk of bias. Final step:",
              question: "STEP 5 - CLINICAL DECISION: A colleague wants to switch their patients to Drug X based on this study. You advise...",
              branches: [
                { text: "Switch ‚Äî even with bias, 40% reduction is clinically meaningful", nextNode: "switch_wrong" },
                { text: "Don't switch ‚Äî wait for better evidence (RCT or better-designed observational)", nextNode: "wait_correct" }
              ]
            },
            robins_critical_partial: {
              type: 'outcome',
              outcome: 'partial',
              title: "Possible, but justify carefully",
              text: "'Critical' means the study provides essentially no useful information. With serious immortal time bias and confounding, results are questionable, but some information about the drug's real-world use is still present. 'Serious' with major caveats may be more appropriate.",
              lesson: "Reserve 'critical' for truly fatal flaws: fabricated data, fundamental design impossibilities, or complete uninformativeness."
            },
            switch_wrong: {
              type: 'outcome',
              outcome: 'danger',
              title: "This is exactly the HRT mistake!",
              text: "A 40% reduction in an observational study with serious bias could easily be ENTIRELY artifactual. Remember: HRT showed 40-50% reduction in cohorts, but the truth was HARM. Immortal time alone can create 20-40% apparent benefit. Don't change practice based on seriously biased observational data.",
              lesson: "Never equate 'statistically significant observational result' with 'true effect.' The HRT, vitamin D, and other reversals all started with seemingly compelling observational evidence."
            },
            wait_correct: {
              type: 'outcome',
              outcome: 'success',
              title: "Excellent clinical judgment!",
              text: "You've correctly identified that: (1) immortal time bias inflates benefit, (2) confounding direction is unclear, (3) ROBINS-I = serious risk, (4) a 40% reduction could be artifact. The appropriate response is to wait for better evidence while acknowledging uncertainty.",
              lesson: "This capstone synthesizes everything: bias identification, ROBINS-I assessment, and clinical decision-making under uncertainty. You've learned to see beyond the headline number."
            }
          }
        }
      },
      {
        type: 'decision-tree',
        content: {
          id: 'capstone-screening',
          title: "Capstone 2: The Screening Controversy",
          situation: "A new blood test claims to detect early Alzheimer's disease. Marketing: '5-year survival 80% with early detection vs 40% without.' Observational studies show patients diagnosed early 'live longer.' You're on a health policy committee deciding whether to recommend population screening.",
          nodes: {
            start: {
              question: "FIRST: What is your immediate concern about the '80% vs 40% survival' claim?",
              branches: [
                { text: "The numbers sound too good ‚Äî probably exaggerated", nextNode: "exaggerated_partial" },
                { text: "This is lead time bias ‚Äî survival improves just by diagnosing earlier", nextNode: "lead_time_correct" },
                { text: "Sample sizes must have been small", nextNode: "sample_wrong" }
              ]
            },
            lead_time_correct: {
              situation: "Exactly! You demand MORTALITY data. They provide: 'Observational cohort shows 25% lower dementia-related mortality in screened patients (HR 0.75, 95% CI 0.65-0.87).'",
              question: "Is this convincing evidence for population screening?",
              branches: [
                { text: "Yes ‚Äî mortality is the right outcome and HR is significant", nextNode: "mortality_wrong" },
                { text: "No ‚Äî observational screening studies have healthy screener bias", nextNode: "screener_bias_correct" }
              ]
            },
            exaggerated_partial: {
              type: 'outcome',
              outcome: 'partial',
              title: "Skepticism is good, but identify the SPECIFIC bias",
              text: "Your instinct is right, but the specific mechanism is LEAD TIME BIAS. If Alzheimer's is detected 3 years earlier by screening but patients still die at the same age, 5-year survival goes from 40% to 80% with ZERO mortality benefit. Survival statistics are systematically misleading for screening.",
              lesson: "Always name the specific bias. 'Sounds too good' isn't actionable. 'Lead time bias inflates survival' is."
            },
            sample_wrong: {
              type: 'outcome',
              outcome: 'danger',
              title: "Sample size isn't the issue here!",
              text: "Even with a million patients, survival statistics for screening are MEANINGLESS due to lead time bias. The study could be perfectly precise and still tell you nothing about whether screening saves lives. This is systematic bias, not random error.",
              lesson: "Precision (large N) doesn't fix bias. A very precise estimate of the wrong thing is still wrong."
            },
            mortality_wrong: {
              type: 'outcome',
              outcome: 'danger',
              title: "You forgot healthy screener bias!",
              text: "People who seek screening are systematically healthier: they exercise, eat well, have good healthcare access. They have lower mortality FROM EVERYTHING ‚Äî including dementia ‚Äî even if screening doesn't help. This is the same bias that fooled us with HRT, colonoscopy, and health checkups.",
              lesson: "Observational comparisons of screened vs unscreened populations are ALWAYS confounded by healthy screener bias. Only RCTs can eliminate it."
            },
            screener_bias_correct: {
              situation: "Perfect! You demand RCT evidence. They say: 'No RCT exists, but screening is harmless ‚Äî it's just a blood test. Why not offer it while we wait for RCT results?'",
              question: "Your response:",
              branches: [
                { text: "Reasonable ‚Äî a blood test has minimal harm", nextNode: "harmless_wrong" },
                { text: "Screening is NOT harmless ‚Äî there are downstream harms", nextNode: "harms_correct" }
              ]
            },
            harmless_wrong: {
              type: 'outcome',
              outcome: 'danger',
              title: "Screening cascade causes real harm!",
              text: "The blood test may be harmless, but what happens NEXT? False positives lead to: anxiety, depression, insurance discrimination, further invasive testing, treatments with side effects for disease that may never cause symptoms. For Alzheimer's with no disease-modifying treatment, early diagnosis may cause psychological harm without benefit.",
              lesson: "Screening harms: false positives ‚Üí anxiety + invasive follow-up; overdiagnosis ‚Üí treating indolent disease; psychological burden of 'patient' label. These are CERTAIN. Benefits are UNCERTAIN until RCT-proven."
            },
            harms_correct: {
              type: 'outcome',
              outcome: 'success',
              title: "Outstanding policy reasoning!",
              text: "You correctly identified: (1) survival claims = lead time bias; (2) mortality observational data = healthy screener bias; (3) screening has real downstream harms. Your recommendation: NO population screening until RCT demonstrates that mortality benefits outweigh harms of false positives, overdiagnosis, and psychological burden.",
              lesson: "This capstone integrates: lead time bias, healthy screener confounding, harm-benefit balance, and evidence standards. You've learned to think critically about screening claims."
            }
          }
        }
      },
      {
        type: 'decision-tree',
        content: {
          id: 'capstone-safety-signal',
          title: "Capstone 3: The Safety Signal",
          situation: "A widely-used diabetes drug has been on the market for 8 years. Spontaneous reports suggest possible bladder cancer association. Observational studies show conflicting results: some OR 1.3, some OR 1.0. An industry-funded cohort shows no association. Patient advocacy groups demand withdrawal.",
          nodes: {
            start: {
              question: "FIRST STEP: How do you evaluate the conflicting observational evidence?",
              branches: [
                { text: "Trust the industry cohort ‚Äî it's the largest and most rigorous", nextNode: "industry_wrong" },
                { text: "Assess each study's risk of bias systematically using ROBINS-I", nextNode: "robins_correct" },
                { text: "Average all the studies ‚Äî the truth is probably in the middle", nextNode: "average_wrong" }
              ]
            },
            industry_wrong: {
              type: 'outcome',
              outcome: 'danger',
              title: "Funding bias is real!",
              text: "Industry-funded studies of their own drugs consistently show more favorable results than independent studies. This isn't necessarily fraud ‚Äî it's design choices: shorter follow-up (bladder cancer takes years), healthier populations, favorable comparators. Evaluate the METHODS, not the sponsor.",
              lesson: "Assess risk of bias, not prestige. Large doesn't mean unbiased. Consider: follow-up duration, comparator choice, outcome ascertainment, time-related biases."
            },
            robins_correct: {
              situation: "Good approach! ROBINS-I reveals: Studies showing OR 1.3 have longer follow-up (5+ years). Studies showing null have shorter follow-up (2-3 years). Bladder cancer has long latency. What do you conclude?",
              question: "Your interpretation:",
              branches: [
                { text: "The null studies are probably right ‚Äî more studies show no effect", nextNode: "null_wrong" },
                { text: "Longer follow-up is methodologically correct for latent outcomes ‚Äî the signal may be real", nextNode: "latency_correct" }
              ]
            },
            average_wrong: {
              type: 'outcome',
              outcome: 'danger',
              title: "Don't average biased with unbiased!",
              text: "If some studies have design flaws (short follow-up for a latent outcome), averaging them with better studies dilutes the signal. You don't want the 'average' of good and bad evidence ‚Äî you want to understand WHY they differ and trust the methodologically sound ones.",
              lesson: "Meta-analysis is not averaging. It's synthesis with quality weighting. Understand heterogeneity sources before pooling."
            },
            null_wrong: {
              type: 'outcome',
              outcome: 'danger',
              title: "Count of studies doesn't matter ‚Äî quality does!",
              text: "Three studies with 2-year follow-up can't detect a cancer that takes 5+ years to develop. They're methodologically incapable of finding the signal even if it exists. The two studies with adequate follow-up both show elevated risk. For latent outcomes, insufficient follow-up = unable to detect, not 'no effect.'",
              lesson: "For safety signals with latent outcomes: (1) Longer follow-up is REQUIRED; (2) Short-term null studies are uninformative; (3) Trust methodologically adequate studies, not study counts."
            },
            latency_correct: {
              situation: "Correct! Now: The drug helps millions with diabetes. Bladder cancer is rare. Even if OR=1.3 is real, absolute risk is small. How do you weigh benefits vs harms?",
              question: "Your recommendation:",
              branches: [
                { text: "Withdraw the drug ‚Äî any cancer signal is unacceptable", nextNode: "withdraw_extreme" },
                { text: "Continue with enhanced monitoring, patient/prescriber education, and ongoing studies", nextNode: "monitor_correct" }
              ]
            },
            withdraw_extreme: {
              type: 'outcome',
              outcome: 'partial',
              title: "Consider the benefit-harm balance!",
              text: "Diabetes causes heart attacks, strokes, amputations, blindness. If this drug provides substantial benefit and the cancer risk is small (NNH > 1000), withdrawal might cause NET HARM ‚Äî more deaths from uncontrolled diabetes than prevented cancers. Regulatory decisions must weigh absolute risks.",
              lesson: "Drug safety isn't binary. Weigh: (1) magnitude of benefit, (2) magnitude of harm, (3) availability of alternatives, (4) population affected. Small relative risks in rare outcomes may be acceptable if benefits are large."
            },
            monitor_correct: {
              type: 'outcome',
              outcome: 'success',
              title: "Balanced regulatory thinking!",
              text: "Your recommendation acknowledges: (1) Signal is plausible given latency-appropriate evidence; (2) Absolute risk is small; (3) Benefits are substantial; (4) Uncertainty remains. Enhanced monitoring allows continued benefit while gathering more data. Consider contraindication in patients with prior bladder cancer or other high-risk features.",
              lesson: "This capstone integrates: signal evaluation, bias assessment, benefit-harm balance, and proportionate response. Real pharmacovigilance is nuanced, not reflexive withdrawal or dismissal."
            }
          }
        }
      },
      {
        type: 'content',
        content: {
          title: "üéì Course Complete: What You've Learned",
          sections: [
            {
              heading: "You can now:",
              items: [
                "‚úì Distinguish confounding, selection bias, and information bias",
                "‚úì Draw and interpret DAGs (Directed Acyclic Graphs)",
                "‚úì Identify immortal time bias and other time-related biases",
                "‚úì Recognize lead time bias in screening studies",
                "‚úì Conduct ROBINS-I risk of bias assessments",
                "‚úì Understand propensity scores and their limitations",
                "‚úì Use negative controls to detect unmeasured confounding",
                "‚úì Apply the target trial framework",
                "‚úì Interpret Mendelian randomization studies",
                "‚úì Evaluate when to meta-analyze observational studies",
                "‚úì Use Bradford Hill criteria and triangulation for causal inference",
                "‚úì Interpret pharmacovigilance signals appropriately",
                "‚úì Understand effect modification and heterogeneity"
              ]
            },
            {
              heading: "The Seven Principles:",
              items: [
                "1. Association is not causation ‚Äî confounding deceives",
                "2. Time flows one direction ‚Äî temporality matters",
                "3. You see what you look for ‚Äî selection bias hides",
                "4. Measurement shapes reality ‚Äî information bias distorts",
                "5. Adjustment is not magic ‚Äî residual confounding remains",
                "6. The average can lie ‚Äî heterogeneity matters",
                "7. Replication builds confidence ‚Äî one study is never enough"
              ]
            }
          ]
        }
      },
      {
        type: 'content',
        content: {
          title: "Final Reflection",
          sections: [
            {
              heading: "Remember:",
              text: "Observational evidence is not inferior to RCT evidence ‚Äî it's DIFFERENT. When RCTs are impossible, unethical, or insufficient, observational data is the best evidence we have. But it requires careful interpretation."
            },
            {
              heading: "The Thalidomide-HRT Paradox:",
              items: [
                "Thalidomide: Observational evidence SAVED lives (detected harm RCTs missed)",
                "HRT: Observational evidence COST lives (confounding created false benefit)",
                "The difference wasn't observation vs randomization ‚Äî it was careful vs careless analysis"
              ]
            },
            {
              heading: "Your Responsibility:",
              text: "As someone who now understands observational evidence, you can identify when it's trustworthy, when it's misleading, and when to demand better data. Use this knowledge to help patients, not to dismiss all observational research reflexively."
            },
            {
              heading: "The Straight Path:",
              text: "Between blind trust in observational findings and automatic dismissal lies critical appraisal. You've learned to walk that path. Use it wisely."
            }
          ]
        }
      },
      {
        type: 'quiz',
        content: {
          question: "You've completed the course! Based on everything you've learned, which statement best captures the role of observational evidence in medicine?",
          options: [
            { id: 'a', text: "Observational evidence should never be used for clinical decisions ‚Äî only RCTs count", correct: false },
            { id: 'b', text: "Observational evidence is as reliable as RCT evidence when sample sizes are large enough", correct: false },
            { id: 'c', text: "Observational evidence is essential but requires careful assessment of bias, confounding, and replication before trust", correct: true },
            { id: 'd', text: "Observational evidence is only useful for generating hypotheses, never for confirming them", correct: false }
          ],
          explanation: "Observational evidence is essential for rare harms, long-term outcomes, and questions that can't be randomized. But it requires rigorous bias assessment (ROBINS-I), understanding of confounding structures (DAGs), and triangulation across methods. The goal isn't to dismiss observational data ‚Äî it's to know when it's trustworthy."
        }
      }
    ]
  }
];

// Render Functions
function renderModuleNav() {
  const nav = document.getElementById('module-nav');
  nav.innerHTML = modules.map((m, i) => `
    <button class="module-item ${i === currentModule ? 'active' : ''} ${gameState.modulesCompleted.includes(i) ? 'completed' : ''}"
            onclick="goToModule(${i})"
            aria-current="${i === currentModule ? 'true' : 'false'}">
      <div class="module-number">${gameState.modulesCompleted.includes(i) ? '‚úì' : i}</div>
      <div class="module-info">
        <div class="module-title">${m.title}</div>
        <div class="module-subtitle">${m.subtitle}${m.estimatedTime ? ` ¬∑ <span class="time-estimate">${m.estimatedTime}</span>` : ''}</div>
      </div>
    </button>
  `).join('');

  // Update total course time in header
  const totalMinutes = modules.reduce((sum, m) => {
    const mins = m.estimatedTime ? parseInt(m.estimatedTime) : 0;
    return sum + mins;
  }, 0);
  const hours = Math.floor(totalMinutes / 60);
  const mins = totalMinutes % 60;
  const timeDisplay = document.getElementById('total-time');
  if (timeDisplay) timeDisplay.textContent = `${hours}h ${mins}m total`;
}

// Badge checking and awarding
function checkBadges() {
  const newBadges = [];

  // Story Scholar - read all stories (complete modules with stories)
  if (gameState.modulesCompleted.length >= 10 && !gameState.earnedBadges.includes('story-scholar')) {
    newBadges.push('story-scholar');
  }

  // Decision Ace - complete significant decision trees
  const treesCompleted = Object.keys(gameState.decisionTrees).filter(k =>
    gameState.decisionTrees[k].history && gameState.decisionTrees[k].history.length > 0
  ).length;
  if (treesCompleted >= 15 && !gameState.earnedBadges.includes('decision-ace')) {
    newBadges.push('decision-ace');
  }

  // Methods Master - complete all modules
  if (gameState.modulesCompleted.length === 12 && !gameState.earnedBadges.includes('methods-master')) {
    newBadges.push('methods-master');
  }

  // Award new badges
  newBadges.forEach(badge => {
    gameState.earnedBadges.push(badge);
    showBadgeNotification(badge);
  });

  if (newBadges.length > 0) saveProgress();
}

function showBadgeNotification(badgeId) {
  const badge = BADGES[badgeId];
  if (!badge) return;

  const notification = document.createElement('div');
  notification.className = 'badge-notification';
  notification.innerHTML = `
    <div class="badge-icon" style="background: ${badge.color}">${badge.icon}</div>
    <div class="badge-info">
      <div class="badge-earned">Badge Earned!</div>
      <div class="badge-name">${badge.name}</div>
    </div>
  `;
  document.body.appendChild(notification);

  setTimeout(() => notification.classList.add('show'), 100);
  setTimeout(() => {
    notification.classList.remove('show');
    setTimeout(() => notification.remove(), 500);
  }, 3000);
}

function renderSlide() {
  const container = document.getElementById('slide-container');
  const module = modules[currentModule];
  const slide = module.slides[currentSlide];

  let html = '';

  switch(slide.type) {
    case 'title':
      html = `
        <div class="slide-title">
          <h1>${slide.content.title}</h1>
          <div class="subtitle">${slide.content.subtitle}</div>
          <p class="description">${slide.content.text}</p>
        </div>
      `;
      break;

    case 'principle-display':
      html = `
        <div class="principle-box">
          <div class="number">${module.principle !== null ? module.principle + 1 : ''}</div>
          <div class="text">"${slide.content.principle}"</div>
        </div>
      `;
      break;

    case 'principle':
      html = `
        <div class="principle-box" style="background: linear-gradient(135deg, rgba(212,175,55,0.15), rgba(30,39,97,0.1)); padding: 2rem;">
          <div class="text" style="font-size: 1.2rem; line-height: 1.6; white-space: pre-line;">${slide.content.text}</div>
        </div>
      `;
      break;

    case 'story-deep':
      html = renderStoryDeep(slide.content);
      break;

    case 'story-box':
      html = renderStoryBox(slide.content);
      break;

    case 'content':
      html = renderContent(slide.content);
      break;

    case 'method':
      html = renderMethod(slide.content);
      break;

    case 'tool':
      html = renderTool(slide.content);
      break;

    case 'decision-tree':
      html = renderDecisionTree(slide.content);
      break;

    case 'quiz':
      html = renderQuiz(slide.content);
      break;

    default:
      html = `<p>Unknown slide type: ${slide.type}</p>`;
  }

  container.innerHTML = html;
  updateProgress();
  updateNavButtons();

  // Announce slide change for screen readers
  const announcer = document.getElementById('slide-announce');
  if (announcer) {
    const module = modules[currentModule];
    announcer.textContent = `Slide ${currentSlide + 1} of ${module.slides.length}, Module: ${module.title}`;
  }
}

function renderStoryDeep(content) {
  return `
    <div class="story-deep">
      <div class="story-label">${content.label}</div>
      <div class="story-source">${content.source}</div>

      <div class="timeline">
        ${content.timeline.map(event => `
          <div class="timeline-event ${event.type}">
            <div class="timeline-year">${event.year}</div>
            <div class="timeline-text">${event.text}</div>
          </div>
        `).join('')}
      </div>

      <div class="real-data-card">
        <h4>The Data That Matters</h4>
        <div class="data-grid">
          <div class="data-item">
            <div class="data-value">${content.realData.endpoint}</div>
            <div class="data-label">Endpoint</div>
          </div>
          <div class="data-item">
            <div class="data-value">${content.realData.drug}</div>
            <div class="data-label">Exposed</div>
          </div>
          <div class="data-item">
            <div class="data-value">${content.realData.placebo}</div>
            <div class="data-label">Unexposed</div>
          </div>
          <div class="data-item">
            <div class="data-value">${content.realData.rr}</div>
            <div class="data-label">Effect</div>
          </div>
        </div>
      </div>

      <div class="story-hook">${content.hook}</div>
    </div>
  `;
}

function renderStoryBox(content) {
  return `
    <div class="story-box">
      <div class="story-box-header">
        <span class="story-box-icon">${content.icon || 'üìñ'}</span>
        <span class="story-box-title">${content.title}</span>
      </div>
      ${content.source ? `<div class="story-box-source">${content.source}</div>` : ''}
      <div class="story-box-content">
        ${content.paragraphs.map(p => `<p>${p}</p>`).join('')}
      </div>
      <div class="story-box-lesson">
        <div class="story-box-lesson-label">The Lesson</div>
        <div class="story-box-lesson-text">${content.lesson}</div>
      </div>
    </div>
  `;
}

function renderContent(content) {
  return `
    <div class="content-box">
      <h3>${content.title}</h3>
      ${content.sections.map(section => `
        <div class="content-section">
          <h4>${section.heading}</h4>
          ${section.text ? `<p>${section.text}</p>` : ''}
          ${section.items ? `<ul>${section.items.map(item => `<li>${item}</li>`).join('')}</ul>` : ''}
        </div>
      `).join('')}
    </div>
  `;
}

function renderMethod(content) {
  return `
    <div class="method-box">
      <div class="method-label">${content.label}</div>
      <h3>${content.title}</h3>
      ${content.sections.map(section => `
        <div class="content-section">
          <h4>${section.heading}</h4>
          <p style="white-space: pre-line;">${section.text}</p>
        </div>
      `).join('')}
    </div>
  `;
}

function renderTool(content) {
  if (content.id === 'dag-builder') {
    return renderDAGBuilder(content);
  }
  return `
    <div class="tool-container">
      <h3>${content.title}</h3>
      <p class="tool-description">${content.description}</p>
      <p style="color: var(--light-text); font-style: italic;">Tool implementation coming soon...</p>
    </div>
  `;
}

function renderDAGBuilder(content) {
  return `
    <div class="tool-container">
      <h3>${content.title}</h3>
      <p class="tool-description">${content.description}</p>

      <div class="tool-inputs" style="grid-template-columns: 1fr 1fr;">
        <div class="input-group">
          <label>Exposure</label>
          <input type="text" id="dag-exposure" placeholder="e.g., HRT use" value="HRT use">
        </div>
        <div class="input-group">
          <label>Outcome</label>
          <input type="text" id="dag-outcome" placeholder="e.g., CHD" value="CHD">
        </div>
      </div>

      <div class="input-group">
        <label>Potential Confounders (one per line)</label>
        <textarea id="dag-confounders" rows="4" placeholder="e.g.,&#10;Socioeconomic status&#10;Exercise&#10;Education">Socioeconomic status
Exercise habits
Healthcare access
Education level</textarea>
      </div>

      <button class="tool-btn" onclick="generateDAG()">Generate DAG</button>

      <div class="tool-output" id="dag-output" style="display: none;">
        <div id="dag-plot" class="plot-area"></div>
        <div id="dag-interpretation"></div>
      </div>
    </div>
  `;
}

function escapeHTML(s) {
  const d = document.createElement('div');
  d.textContent = s;
  return d.innerHTML;
}

function generateDAG() {
  const exposureRaw = document.getElementById('dag-exposure').value || 'Exposure';
  const outcomeRaw = document.getElementById('dag-outcome').value || 'Outcome';
  const confoundersText = document.getElementById('dag-confounders').value;
  const confoundersRaw = confoundersText.split('\n').filter(c => c.trim());
  const exposure = escapeHTML(exposureRaw);
  const outcome = escapeHTML(outcomeRaw);
  const confounders = confoundersRaw.map(c => escapeHTML(c));

  const output = document.getElementById('dag-output');
  output.style.display = 'block';

  // Create nodes
  const nodes = [
    { id: 'exposure', label: exposure, x: 0, y: 0.5 },
    { id: 'outcome', label: outcome, x: 1, y: 0.5 }
  ];

  confounders.forEach((c, i) => {
    nodes.push({
      id: `conf${i}`,
      label: c.trim(),
      x: 0.5,
      y: 0.1 + (i * 0.2)
    });
  });

  // Create edges
  const edges = [];
  confounders.forEach((c, i) => {
    edges.push({ from: `conf${i}`, to: 'exposure' });
    edges.push({ from: `conf${i}`, to: 'outcome' });
  });
  edges.push({ from: 'exposure', to: 'outcome', style: 'dashed' });

  // Create Plotly visualization
  const nodeX = nodes.map(n => n.x);
  const nodeY = nodes.map(n => n.y);
  const nodeLabels = nodes.map(n => n.label);

  // Create edge traces
  const edgeTraces = edges.map(e => {
    const fromNode = nodes.find(n => n.id === e.from);
    const toNode = nodes.find(n => n.id === e.to);
    return {
      x: [fromNode.x, toNode.x],
      y: [fromNode.y, toNode.y],
      mode: 'lines',
      line: {
        color: e.style === 'dashed' ? '#D4AF37' : '#1e2761',
        width: 2,
        dash: e.style === 'dashed' ? 'dash' : 'solid'
      },
      hoverinfo: 'none'
    };
  });

  const nodeTrace = {
    x: nodeX,
    y: nodeY,
    mode: 'markers+text',
    marker: {
      size: 40,
      color: nodes.map(n => n.id === 'exposure' ? '#2D8B8B' : n.id === 'outcome' ? '#BF2D2D' : '#D4AF37')
    },
    text: nodeLabels,
    textposition: 'bottom center',
    hoverinfo: 'text'
  };

  const layout = {
    showlegend: false,
    xaxis: { showgrid: false, zeroline: false, showticklabels: false, range: [-0.2, 1.2] },
    yaxis: { showgrid: false, zeroline: false, showticklabels: false, range: [-0.1, 1.1] },
    margin: { t: 20, b: 40, l: 20, r: 20 },
    height: 350,
    paper_bgcolor: 'rgba(0,0,0,0)',
    plot_bgcolor: 'rgba(0,0,0,0)'
  };

  Plotly.newPlot('dag-plot', [...edgeTraces, nodeTrace], layout, { displayModeBar: false });

  // Interpretation
  document.getElementById('dag-interpretation').innerHTML = `
    <h4 style="color: var(--teal); margin-top: 1rem;">Interpretation</h4>
    <p><strong>Backdoor paths identified:</strong> ${confounders.length} potential confounders create backdoor paths from ${exposure} to ${outcome}.</p>
    <p><strong>To estimate the causal effect of ${exposure} on ${outcome}:</strong></p>
    <ul style="margin-left: 1rem;">
      <li>You must adjust for: ${confounders.join(', ') || 'No confounders identified'}</li>
      <li>The dashed arrow represents the causal effect of interest</li>
      <li>Solid arrows represent confounding paths that must be blocked</li>
    </ul>
    <p style="color: var(--red); margin-top: 0.5rem;"><strong>Warning:</strong> Unmeasured confounders may still exist!</p>
  `;

  addPoints(50);
  if (!gameState.toolsUsed.includes('dag-builder')) {
    gameState.toolsUsed.push('dag-builder');
  }
  saveProgress();
}

function renderDecisionTree(content) {
  const treeId = content.id;
  const treeState = gameState.decisionTrees[treeId] || { currentNode: 'start', history: [] };

  let node;
  if (content.nodes[treeState.currentNode]) {
    node = content.nodes[treeState.currentNode];
  } else {
    node = content.nodes.start;
    treeState.currentNode = 'start';
  }

  let html = `
    <div class="decision-tree">
      <h3>${content.title}</h3>
      <div class="decision-scenario">${content.situation}</div>
  `;

  // Show history
  if (treeState.history.length > 0) {
    html += `
      <div class="decision-history">
        ${treeState.history.map((h, i) => `<span class="history-step">${i + 1}. ${h}</span>`).join('')}
      </div>
      <button class="undo-btn" onclick="undoDecision('${treeId}')">‚Üê Undo Last Choice</button>
    `;
  }

  // Current situation
  if (node.situation) {
    html += `<div class="decision-situation">${node.situation}</div>`;
  }

  // Check if it's an ending
  if (node.type === 'outcome' || node.isEnding) {
    html += `
      <div class="decision-outcome ${node.consequence || node.outcome}">
        <h4>${node.title || 'Outcome'}</h4>
        <p>${node.text || ''}</p>
        <div class="decision-lesson">${node.lesson || ''}</div>
      </div>
      <button class="tool-btn" style="margin-top: 1rem;" onclick="resetDecisionTree('${treeId}')">Try Again</button>
    `;
  } else {
    // Show question and branches
    html += `<div class="decision-question">${node.question}</div>`;
    html += `<div class="decision-branches">`;
    node.branches.forEach(branch => {
      html += `
        <button class="decision-branch" onclick="makeDecision('${treeId}', '${branch.nextNode}', '${branch.text.substring(0, 30).replace(/\\/g, '\\\\').replace(/'/g, "\\'")}...')">
          ${branch.text}
        </button>
      `;
    });
    html += `</div>`;
  }

  html += `</div>`;
  return html;
}

function makeDecision(treeId, nextNode, choiceText) {
  if (!gameState.decisionTrees[treeId]) {
    gameState.decisionTrees[treeId] = { currentNode: 'start', history: [] };
  }
  gameState.decisionTrees[treeId].history.push({ nextNode: nextNode, choiceText: choiceText });
  gameState.decisionTrees[treeId].currentNode = nextNode;
  addPoints(10);
  saveProgress();
  renderSlide();
}

function undoDecision(treeId) {
  const tree = gameState.decisionTrees[treeId];
  if (tree && tree.history.length > 0) {
    tree.history.pop();
    // Replay from start using stored nextNode values
    tree.currentNode = 'start';
    for (const entry of tree.history) {
      // Support both old string format and new object format
      const node = typeof entry === 'object' ? entry.nextNode : null;
      if (node) tree.currentNode = node;
    }
    saveProgress();
    renderSlide();
  }
}

function resetDecisionTree(treeId) {
  gameState.decisionTrees[treeId] = { currentNode: 'start', history: [] };
  saveProgress();
  renderSlide();
}

function renderQuiz(content) {
  const quizId = `quiz_${currentModule}_${currentSlide}`;

  return `
    <div class="quiz-container" role="group" aria-labelledby="quiz-question">
      <div class="quiz-question" id="quiz-question">${content.question}</div>
      <div class="quiz-options" role="radiogroup">
        ${content.options.map((opt, i) => `
          <button class="quiz-option"
                  role="radio"
                  aria-checked="false"
                  data-correct="${opt.correct}"
                  data-option-id="${opt.id}"
                  onclick="selectQuizOption(this, '${quizId}', ${opt.correct})">
            ${opt.text}
          </button>
        `).join('')}
      </div>
      <div class="quiz-feedback" id="feedback-${quizId}" role="alert" aria-live="polite">
        <p>${content.explanation}</p>
      </div>
    </div>
  `;
}

const _answeredQuizzes = new Set();

function selectQuizOption(element, quizId, isCorrect) {
  // Prevent re-answering after first answer
  if (_answeredQuizzes.has(quizId)) return;

  const container = element.closest('.quiz-container');
  const options = container.querySelectorAll('.quiz-option');
  const feedback = document.getElementById(`feedback-${quizId}`);

  // Clear previous selections
  options.forEach(opt => {
    opt.classList.remove('selected', 'correct', 'incorrect');
    opt.setAttribute('aria-checked', 'false');
  });

  // Mark selection
  element.classList.add('selected');
  element.setAttribute('aria-checked', 'true');

  // Show result
  if (isCorrect) {
    element.classList.add('correct');
    feedback.classList.add('show', 'correct');
    feedback.classList.remove('incorrect');
    addPoints(30);
  } else {
    element.classList.add('incorrect');
    feedback.classList.add('show', 'incorrect');
    feedback.classList.remove('correct');
    // Show correct answer
    options.forEach(opt => {
      if (opt.dataset.correct === 'true') {
        opt.classList.add('correct');
      }
    });
  }

  // Lock quiz after answering
  _answeredQuizzes.add(quizId);
  options.forEach(opt => {
    opt.style.pointerEvents = 'none';
    opt.setAttribute('aria-disabled', 'true');
  });

  saveProgress();
}

// Navigation
function nextSlide() {
  const module = modules[currentModule];
  if (currentSlide < module.slides.length - 1) {
    currentSlide++;
  } else if (currentModule < modules.length - 1) {
    if (!gameState.modulesCompleted.includes(currentModule)) {
      gameState.modulesCompleted.push(currentModule);
      addPoints(100);
      checkBadges();
    }
    currentModule++;
    currentSlide = 0;
  }
  saveProgress();
  renderSlide();
  renderModuleNav();
  window.scrollTo(0, 0);
}

function prevSlide() {
  if (currentSlide > 0) {
    currentSlide--;
  } else if (currentModule > 0) {
    currentModule--;
    currentSlide = modules[currentModule].slides.length - 1;
  }
  saveProgress();
  renderSlide();
  renderModuleNav();
  window.scrollTo(0, 0);
}

function goToModule(moduleIndex) {
  currentModule = moduleIndex;
  currentSlide = 0;
  saveProgress();
  renderSlide();
  renderModuleNav();
  closeSidebar();
  window.scrollTo(0, 0);
}

function updateNavButtons() {
  const prevBtn = document.getElementById('prev-btn');
  const nextBtn = document.getElementById('next-btn');

  prevBtn.disabled = currentModule === 0 && currentSlide === 0;

  const isLastSlide = currentModule === modules.length - 1 &&
                      currentSlide === modules[currentModule].slides.length - 1;
  nextBtn.textContent = isLastSlide ? 'Complete Course' : 'Next ‚Üí';
}

function updateProgress() {
  let totalSlides = 0;
  let completedSlides = 0;

  modules.forEach((m, i) => {
    totalSlides += m.slides.length;
    if (i < currentModule) {
      completedSlides += m.slides.length;
    } else if (i === currentModule) {
      completedSlides += currentSlide;
    }
  });

  const percent = Math.round((completedSlides / totalSlides) * 100);
  document.getElementById('progress-fill').style.width = `${percent}%`;
  document.getElementById('progress-text').textContent = `${percent}% Complete`;
}

// Points System
function addPoints(points) {
  gameState.points += points;
  document.getElementById('points-display').textContent = gameState.points;
}

// Persistence
function saveProgress() {
  try {
    localStorage.setItem(STORAGE_KEY, JSON.stringify({
      currentModule,
      currentSlide,
      gameState
    }));
  } catch (e) {
    console.log('Could not save progress:', e);
  }
}

function loadProgress() {
  try {
    const saved = localStorage.getItem(STORAGE_KEY);
    if (saved) {
      const data = JSON.parse(saved);
      if (data.gameState) {
        gameState = {
          points: data.gameState.points || 0,
          earnedBadges: data.gameState.earnedBadges || [],
          toolsUsed: data.gameState.toolsUsed || [],
          modulesCompleted: data.gameState.modulesCompleted || [],
          scenariosCompleted: data.gameState.scenariosCompleted || {},
          decisionTrees: data.gameState.decisionTrees || {}
        };
      }
      if (typeof data.currentModule === 'number' && data.currentModule >= 0 && data.currentModule < modules.length) {
        currentModule = data.currentModule;
      }
      if (typeof data.currentSlide === 'number' && data.currentSlide >= 0) {
        currentSlide = Math.min(data.currentSlide, modules[currentModule].slides.length - 1);
      }
    }
  } catch (e) {
    console.log('Could not load progress:', e);
  }
}

// Mobile Menu
function toggleSidebar() {
  const sidebar = document.querySelector('.sidebar');
  const overlay = document.querySelector('.sidebar-overlay');
  const hamburger = document.querySelector('.hamburger');

  sidebar.classList.toggle('open');
  overlay.classList.toggle('show');
  hamburger.setAttribute('aria-expanded', sidebar.classList.contains('open'));
}

function closeSidebar() {
  const sidebar = document.querySelector('.sidebar');
  const overlay = document.querySelector('.sidebar-overlay');
  const hamburger = document.querySelector('.hamburger');

  sidebar.classList.remove('open');
  overlay.classList.remove('show');
  hamburger.setAttribute('aria-expanded', 'false');
}

// Modal utilities: close by ID, Escape key handler
function closeModalOverlay(id) {
  const el = document.getElementById(id);
  if (el) el.remove();
}

function _attachModalEscapeHandler(overlayId) {
  function handler(e) {
    if (e.key === 'Escape') {
      closeModalOverlay(overlayId);
      document.removeEventListener('keydown', handler);
    }
  }
  document.addEventListener('keydown', handler);
}

// Badges Modal
function openBadges() {
  const earnedCount = gameState.earnedBadges.length;
  const totalCount = Object.keys(BADGES).length;

  const html = `
    <div id="badges-modal-overlay" role="dialog" aria-modal="true" aria-label="Badges" style="position: fixed; inset: 0; background: rgba(0,0,0,0.5); z-index: 2000; display: flex; align-items: center; justify-content: center; padding: 1rem;">
      <div style="background: white; border-radius: 12px; max-width: 700px; max-height: 80vh; overflow-y: auto; padding: 2rem;">
        <div style="display: flex; justify-content: space-between; align-items: center; margin-bottom: 1rem;">
          <h2 style="font-family: 'Cormorant Garamond', serif; color: var(--navy);">üèÜ Badges (${earnedCount}/${totalCount})</h2>
          <button id="badges-modal-close" onclick="closeModalOverlay('badges-modal-overlay')" style="background: none; border: none; font-size: 1.5rem; cursor: pointer;" aria-label="Close badges">&times;</button>
        </div>
        <div class="badge-grid">
          ${Object.entries(BADGES).map(([id, badge]) => {
            const earned = gameState.earnedBadges.includes(id);
            return `
              <div class="badge-card ${earned ? 'earned' : 'locked'}">
                <div class="badge-icon" style="background: ${badge.color}">${badge.icon}</div>
                <div class="badge-name">${badge.name}</div>
                <div class="badge-requirement">${earned ? '‚úì Earned!' : badge.requirement}</div>
              </div>
            `;
          }).join('')}
        </div>
      </div>
    </div>
  `;

  document.body.insertAdjacentHTML('beforeend', html);
  const closeBtn = document.getElementById('badges-modal-close');
  if (closeBtn) closeBtn.focus();
  _attachModalEscapeHandler('badges-modal-overlay');
}

// Glossary
function openGlossary() {
  const terms = [
    { term: "Confounding", def: "A variable that is associated with both the exposure and outcome, distorting the apparent relationship between them." },
    { term: "Selection Bias", def: "Systematic error arising from the way participants are selected or retained in a study." },
    { term: "Information Bias", def: "Systematic error in measurement or classification of exposure or outcome." },
    { term: "DAG", def: "Directed Acyclic Graph - a visual representation of causal relationships between variables." },
    { term: "Cohort Study", def: "Observational study following a group over time to see who develops an outcome." },
    { term: "Case-Control Study", def: "Study comparing people with an outcome (cases) to those without (controls) to identify exposures." },
    { term: "Odds Ratio", def: "Ratio of odds of exposure in cases vs controls; approximates RR when outcome is rare." },
    { term: "Risk Ratio", def: "Ratio of risk in exposed vs unexposed; measures strength of association." },
    { term: "Healthy User Bias", def: "Confounding where people who seek treatment are systematically healthier." },
    { term: "Immortal Time Bias", def: "Bias from misclassifying person-time when exposure status changes over time." },
    { term: "ROBINS-I", def: "Risk of Bias In Non-randomized Studies - Interventions tool for assessing bias." },
    { term: "Propensity Score", def: "Probability of receiving treatment given observed covariates; used for adjustment." },
    { term: "Target Trial", def: "Hypothetical RCT that observational analysis attempts to emulate." },
    { term: "Residual Confounding", def: "Confounding that remains after adjustment due to unmeasured or imperfectly measured confounders." },
    { term: "Effect Modification", def: "When the effect of exposure on outcome differs across levels of another variable." },
    { term: "IPTW", def: "Inverse Probability of Treatment Weighting - weights subjects by inverse of propensity score to balance confounders." },
    { term: "Overlap Weights", def: "Modern PS weighting targeting patients with clinical equipoise; weights by 1-PS for treated, PS for untreated." },
    { term: "Instrumental Variable", def: "A variable affecting treatment but not outcome except through treatment; enables causal inference despite unmeasured confounding." },
    { term: "Mendelian Randomization", def: "Using genetic variants as instrumental variables; leverages random inheritance to mimic randomization." },
    { term: "Bradford Hill Criteria", def: "Nine criteria for assessing causation from observational data: strength, consistency, specificity, temporality, biological gradient, plausibility, coherence, experiment, analogy." },
    { term: "Triangulation", def: "Comparing evidence across multiple methods with different biases; concordance increases confidence in causal claims." },
    { term: "Negative Control", def: "An exposure-outcome pair with no expected causal relationship; association suggests unmeasured confounding." },
    { term: "Lead Time Bias", def: "Apparent survival improvement from earlier diagnosis without true mortality benefit; common in screening evaluation." },
    { term: "E-value", def: "Minimum strength of unmeasured confounding needed to explain away an observed association." },
    { term: "New User Design", def: "Including only patients starting treatment (not prevalent users) to avoid survivor bias and capture early effects." }
  ];

  const html = `
    <div id="glossary-modal-overlay" role="dialog" aria-modal="true" aria-label="Glossary" style="position: fixed; inset: 0; background: rgba(0,0,0,0.5); z-index: 2000; display: flex; align-items: center; justify-content: center; padding: 1rem;">
      <div style="background: white; border-radius: 12px; max-width: 600px; max-height: 80vh; overflow-y: auto; padding: 2rem;">
        <div style="display: flex; justify-content: space-between; align-items: center; margin-bottom: 1rem;">
          <h2 style="font-family: 'Cormorant Garamond', serif; color: var(--navy);">Glossary</h2>
          <button id="glossary-modal-close" onclick="closeModalOverlay('glossary-modal-overlay')" style="background: none; border: none; font-size: 1.5rem; cursor: pointer;" aria-label="Close glossary">&times;</button>
        </div>
        ${terms.map(t => `
          <div style="margin-bottom: 1rem; padding-bottom: 1rem; border-bottom: 1px solid rgba(0,0,0,0.1);">
            <strong style="color: var(--teal);">${t.term}</strong>
            <p style="margin-top: 0.25rem; color: var(--navy);">${t.def}</p>
          </div>
        `).join('')}
      </div>
    </div>
  `;

  document.body.insertAdjacentHTML('beforeend', html);
  const closeBtn = document.getElementById('glossary-modal-close');
  if (closeBtn) closeBtn.focus();
  _attachModalEscapeHandler('glossary-modal-overlay');
}

function openToolLibrary() {
  alert('Tool Library coming soon! Tools covered in this course:\n\n‚Ä¢ DAG Builder\n‚Ä¢ Confounding Visualizer\n‚Ä¢ ROBINS-I Assessment\n‚Ä¢ Propensity Score Calculator\n‚Ä¢ Target Trial Designer');
}

// Initialize
document.addEventListener('DOMContentLoaded', () => {
  loadProgress();
  renderModuleNav();
  renderSlide();
  document.getElementById('points-display').textContent = gameState.points;

  // Mobile menu handlers
  document.querySelector('.hamburger').addEventListener('click', toggleSidebar);
  document.querySelector('.sidebar-overlay').addEventListener('click', closeSidebar);

  // Keyboard navigation
  document.addEventListener('keydown', (e) => {
    if (e.key === 'ArrowRight' && !e.target.matches('input, textarea, button, select, [role="button"]')) {
      nextSlide();
    } else if (e.key === 'ArrowLeft' && !e.target.matches('input, textarea, button, select, [role="button"]')) {
      prevSlide();
    }
  });
});
</script>
</body>
</html>
