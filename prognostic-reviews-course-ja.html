<!DOCTYPE html>

<html lang="en">
<head>
<meta charset="utf-8"/>
<meta content="width=device-width, initial-scale=1.0" name="viewport"/>
<title>Prognostic Reviews: Predicting Patient Futures</title>
<link href="https://fonts.googleapis.com" rel="preconnect"/>
<link crossorigin="" href="https://fonts.gstatic.com" rel="preconnect"/>
<link href="https://fonts.googleapis.com/css2?family=Cormorant+Garamond:wght@400;600;700&amp;family=Source+Sans+Pro:wght@400;600&amp;display=swap" rel="stylesheet"/>
<style>
:root {
  --navy: #1E2761;
  --deep-navy: #141B3D;
  --gold: #D4AF37;
  --cream: #FAF8F5;
  --red: #BF2D2D;
  --teal: #2D8B8B;
  --light-text: #718096;
  --green: #2D8B5F;
  --purple: #6B46C1;
}

* {
  margin: 0;
  padding: 0;
  box-sizing: border-box;
}

body {
  font-family: 'Source Sans Pro', sans-serif;
  background: var(--cream);
  color: var(--navy);
  min-height: 100vh;
  display: flex;
}

.skip-link {
  position: absolute;
  top: -40px;
  left: 0;
  background: var(--gold);
  color: var(--navy);
  padding: 8px 16px;
  z-index: 1000;
  font-weight: 600;
  text-decoration: none;
  border-radius: 0 0 8px 0;
}

.skip-link:focus {
  top: 0;
}

.hamburger {
  display: none;
  position: fixed;
  top: 1rem;
  left: 1rem;
  z-index: 1001;
  background: var(--navy);
  border: none;
  border-radius: 8px;
  padding: 12px;
  cursor: pointer;
  flex-direction: column;
  gap: 4px;
}

.hamburger span {
  display: block;
  width: 24px;
  height: 3px;
  background: var(--gold);
  border-radius: 2px;
  transition: transform 0.3s;
}

.sidebar-overlay {
  display: none;
  position: fixed;
  inset: 0;
  background: rgba(0,0,0,0.5);
  z-index: 999;
}

.sidebar {
  width: 280px;
  background: var(--navy);
  padding: 2rem 1rem;
  display: flex;
  flex-direction: column;
  position: fixed;
  height: 100vh;
  overflow-y: auto;
  z-index: 1000;
}

.logo {
  font-family: 'Cormorant Garamond', serif;
  font-size: 1.3rem;
  color: var(--gold);
  margin-bottom: 0.5rem;
  text-align: center;
}

.tagline {
  font-size: 0.75rem;
  color: rgba(255,255,255,0.6);
  text-align: center;
  margin-bottom: 2rem;
  font-style: italic;
}

.nav-section {
  margin-bottom: 1.5rem;
}

.nav-label {
  font-size: 0.7rem;
  text-transform: uppercase;
  letter-spacing: 1px;
  color: rgba(255,255,255,0.4);
  margin-bottom: 0.75rem;
  padding-left: 0.5rem;
}

.module-item {
  display: flex;
  align-items: center;
  padding: 0.75rem;
  border-radius: 8px;
  cursor: pointer;
  transition: all 0.2s;
  margin-bottom: 0.25rem;
  border: none;
  background: transparent;
  width: 100%;
  text-align: left;
  font-family: inherit;
  font-size: inherit;
}

.module-item:hover {
  background: rgba(255,255,255,0.1);
}

.module-item.active {
  background: rgba(212, 175, 55, 0.2);
  border-left: 3px solid var(--gold);
}

.module-item.completed .module-number {
  background: var(--green);
}

.module-number {
  width: 28px;
  height: 28px;
  border-radius: 50%;
  background: rgba(255,255,255,0.2);
  display: flex;
  align-items: center;
  justify-content: center;
  font-size: 0.8rem;
  color: white;
  margin-right: 0.75rem;
  flex-shrink: 0;
}

.module-info {
  flex: 1;
  min-width: 0;
}

.module-title {
  font-size: 0.9rem;
  color: white;
  white-space: nowrap;
  overflow: hidden;
  text-overflow: ellipsis;
}

.module-subtitle {
  font-size: 0.7rem;
  color: rgba(255,255,255,0.5);
}

.time-estimate {
  color: var(--teal);
  font-weight: 600;
  font-size: 0.65rem;
}

.main-content {
  flex: 1;
  margin-left: 280px;
  display: flex;
  flex-direction: column;
  min-height: 100vh;
}

.top-bar {
  display: flex;
  justify-content: space-between;
  align-items: center;
  padding: 1rem 2rem;
  background: white;
  border-bottom: 1px solid rgba(0,0,0,0.1);
  flex-wrap: wrap;
  gap: 1rem;
}

.progress-section {
  display: flex;
  align-items: center;
  gap: 1rem;
}

.progress-bar {
  width: 200px;
  height: 8px;
  background: rgba(0,0,0,0.1);
  border-radius: 4px;
  overflow: hidden;
}

.progress-fill {
  height: 100%;
  background: linear-gradient(90deg, var(--gold), var(--purple));
  border-radius: 4px;
  transition: width 0.3s;
}

.progress-text {
  font-size: 0.85rem;
  color: var(--light-text);
}

.course-time {
  font-size: 0.8rem;
  color: var(--light-text);
  padding: 0.25rem 0.75rem;
  background: rgba(107, 70, 193, 0.1);
  border-radius: 12px;
}

.points-display {
  display: flex;
  align-items: center;
  gap: 0.5rem;
  background: linear-gradient(135deg, var(--navy), #2a3a7d);
  color: var(--gold);
  padding: 0.5rem 1rem;
  border-radius: 20px;
  font-weight: 600;
}

.top-actions {
  display: flex;
  gap: 0.5rem;
}

.action-btn {
  padding: 0.5rem 1rem;
  border: 1px solid var(--navy);
  background: transparent;
  border-radius: 6px;
  cursor: pointer;
  font-size: 0.85rem;
  transition: all 0.2s;
}

.action-btn:hover {
  background: var(--navy);
  color: white;
}

.slide-container {
  flex: 1;
  padding: 2rem;
  max-width: 900px;
  margin: 0 auto;
  width: 100%;
}

.slide-title {
  text-align: center;
  padding: 4rem 2rem;
}

.slide-title h1 {
  font-family: 'Cormorant Garamond', serif;
  font-size: 3rem;
  color: var(--navy);
  margin-bottom: 1rem;
}

.slide-title .subtitle {
  font-size: 1.5rem;
  color: var(--purple);
  margin-bottom: 1rem;
}

.slide-title .description {
  font-size: 1.1rem;
  color: var(--light-text);
  max-width: 600px;
  margin: 0 auto;
}

.principle-box {
  background: linear-gradient(135deg, var(--navy), #2a3a7d);
  border-radius: 16px;
  padding: 3rem;
  text-align: center;
  margin: 2rem 0;
}

.principle-box .number {
  font-size: 4rem;
  color: var(--gold);
  font-family: 'Cormorant Garamond', serif;
  line-height: 1;
}

.principle-box .text {
  font-size: 1.8rem;
  color: white;
  font-family: 'Cormorant Garamond', serif;
  margin-top: 1rem;
  font-style: italic;
}

.story-deep {
  background: linear-gradient(135deg, rgba(107,70,193,0.08), rgba(30,39,97,0.12));
  border-left: 4px solid var(--purple);
  border-radius: 0 16px 16px 0;
  padding: 1.5rem;
  margin: 1.5rem 0;
}

.story-label {
  font-size: 0.75rem;
  text-transform: uppercase;
  letter-spacing: 2px;
  color: var(--purple);
  margin-bottom: 0.5rem;
  font-weight: 600;
}

.story-source {
  font-size: 0.8rem;
  color: var(--light-text);
  margin-bottom: 1rem;
  font-style: italic;
}

.timeline {
  position: relative;
  padding-left: 2rem;
  margin: 1.5rem 0;
}

.timeline::before {
  content: '';
  position: absolute;
  left: 0.5rem;
  top: 0;
  bottom: 0;
  width: 2px;
  background: linear-gradient(to bottom, var(--gold), var(--purple), var(--green));
}

.timeline-event {
  position: relative;
  margin-bottom: 1rem;
  padding-left: 1rem;
}

.timeline-event::before {
  content: '';
  position: absolute;
  left: -1.5rem;
  top: 0.5rem;
  width: 10px;
  height: 10px;
  border-radius: 50%;
  background: var(--gold);
}

.timeline-event.crisis::before {
  background: var(--red);
}

.timeline-event.revelation::before {
  background: var(--green);
}

.timeline-year {
  font-weight: 600;
  color: var(--purple);
  font-size: 0.9rem;
}

.timeline-text {
  color: var(--navy);
  font-size: 0.95rem;
  margin-top: 0.25rem;
}

.real-data-box {
  background: rgba(45, 139, 139, 0.1);
  border-radius: 12px;
  padding: 1rem;
  margin-top: 1rem;
}

.real-data-box h4 {
  color: var(--teal);
  font-size: 0.85rem;
  margin-bottom: 0.75rem;
  text-transform: uppercase;
  letter-spacing: 1px;
}

.data-grid {
  display: grid;
  grid-template-columns: repeat(3, 1fr);
  gap: 0.75rem;
}

.data-item {
  text-align: center;
}

.data-label {
  font-size: 0.7rem;
  color: var(--light-text);
  text-transform: uppercase;
}

.data-value {
  font-size: 1rem;
  font-weight: 600;
  color: var(--navy);
}

.hook-text {
  background: linear-gradient(135deg, rgba(212,175,55,0.15), rgba(30,39,97,0.1));
  padding: 1rem;
  border-radius: 8px;
  margin-top: 1rem;
  font-style: italic;
  color: var(--navy);
}

.lesson-gold {
  color: var(--gold);
  font-weight: 600;
  font-style: normal;
  display: block;
  margin-top: 0.5rem;
  padding: 0.75rem;
  background: rgba(30,39,97,0.05);
  border-left: 3px solid var(--gold);
  border-radius: 0 8px 8px 0;
}

.content-box {
  background: white;
  border-radius: 16px;
  padding: 2rem;
  margin: 1.5rem 0;
  box-shadow: 0 2px 8px rgba(0,0,0,0.05);
}

.content-box h2 {
  font-family: 'Cormorant Garamond', serif;
  font-size: 1.8rem;
  color: var(--navy);
  margin-bottom: 1.5rem;
}

.content-section {
  margin-bottom: 1.5rem;
}

.content-section:last-child {
  margin-bottom: 0;
}

.content-section h3 {
  color: var(--purple);
  font-size: 1.1rem;
  margin-bottom: 0.75rem;
}

.content-section ul {
  list-style: none;
  padding-left: 0;
}

.content-section li {
  padding: 0.5rem 0;
  padding-left: 1.5rem;
  position: relative;
  border-bottom: 1px solid rgba(0,0,0,0.05);
}

.content-section li:last-child {
  border-bottom: none;
}

.content-section li::before {
  content: 'â†’';
  position: absolute;
  left: 0;
  color: var(--gold);
}

.content-section p {
  color: var(--navy);
  line-height: 1.6;
}

.method-box {
  background: linear-gradient(135deg, rgba(45,139,139,0.08), rgba(30,39,97,0.05));
  border-radius: 16px;
  padding: 2rem;
  margin: 1.5rem 0;
}

.method-label {
  font-size: 0.7rem;
  text-transform: uppercase;
  letter-spacing: 2px;
  color: var(--teal);
  margin-bottom: 0.5rem;
}

.method-box h2 {
  font-family: 'Cormorant Garamond', serif;
  font-size: 1.6rem;
  color: var(--navy);
  margin-bottom: 1.5rem;
}

.method-section {
  margin-bottom: 1.25rem;
  padding-bottom: 1.25rem;
  border-bottom: 1px solid rgba(0,0,0,0.1);
}

.method-section:last-child {
  border-bottom: none;
  margin-bottom: 0;
  padding-bottom: 0;
}

.method-section h3 {
  color: var(--teal);
  font-size: 1rem;
  margin-bottom: 0.5rem;
}

.method-section p {
  color: var(--navy);
  line-height: 1.6;
  white-space: pre-line;
}

.decision-tree {
  background: white;
  border-radius: 16px;
  padding: 2rem;
  margin: 1.5rem 0;
  box-shadow: 0 4px 16px rgba(0,0,0,0.08);
}

.decision-tree h2 {
  font-family: 'Cormorant Garamond', serif;
  font-size: 1.6rem;
  color: var(--navy);
  margin-bottom: 0.5rem;
}

.decision-situation {
  background: rgba(107,70,193,0.1);
  padding: 1rem;
  border-radius: 8px;
  margin-bottom: 1.5rem;
  font-size: 0.95rem;
  color: var(--navy);
}

.decision-question {
  font-weight: 600;
  color: var(--purple);
  margin-bottom: 1rem;
  font-size: 1.1rem;
}

.decision-branches {
  display: flex;
  flex-direction: column;
  gap: 0.75rem;
}

.decision-branch {
  padding: 1rem;
  background: rgba(0,0,0,0.03);
  border: 2px solid transparent;
  border-radius: 8px;
  cursor: pointer;
  transition: all 0.2s;
  text-align: left;
  font-family: inherit;
  font-size: 0.95rem;
}

.decision-branch:hover {
  border-color: var(--purple);
  background: rgba(107,70,193,0.05);
}

.decision-outcome {
  padding: 1.5rem;
  border-radius: 12px;
  margin-top: 1rem;
}

.decision-outcome.success {
  background: linear-gradient(135deg, rgba(45,139,95,0.15), rgba(45,139,95,0.05));
  border-left: 4px solid var(--green);
}

.decision-outcome.danger {
  background: linear-gradient(135deg, rgba(191,45,45,0.15), rgba(191,45,45,0.05));
  border-left: 4px solid var(--red);
}

.decision-outcome.partial {
  background: linear-gradient(135deg, rgba(212,175,55,0.15), rgba(212,175,55,0.05));
  border-left: 4px solid var(--gold);
}

.outcome-title {
  font-weight: 600;
  font-size: 1.1rem;
  margin-bottom: 0.5rem;
}

.success .outcome-title { color: var(--green); }
.danger .outcome-title { color: var(--red); }
.partial .outcome-title { color: var(--gold); }

.outcome-text {
  color: var(--navy);
  margin-bottom: 1rem;
  line-height: 1.6;
}

.outcome-lesson {
  font-style: italic;
  color: var(--light-text);
  padding-top: 0.75rem;
  border-top: 1px solid rgba(0,0,0,0.1);
}

.tree-controls {
  display: flex;
  gap: 0.5rem;
  margin-top: 1rem;
}

.tree-btn {
  padding: 0.5rem 1rem;
  border: 1px solid var(--navy);
  background: transparent;
  border-radius: 6px;
  cursor: pointer;
  font-size: 0.85rem;
  transition: all 0.2s;
}

.tree-btn:hover {
  background: var(--navy);
  color: white;
}

.quiz-container {
  background: white;
  border-radius: 16px;
  padding: 2rem;
  margin: 1.5rem 0;
  box-shadow: 0 4px 16px rgba(0,0,0,0.08);
}

.quiz-question {
  font-size: 1.1rem;
  color: var(--navy);
  margin-bottom: 1.5rem;
  font-weight: 500;
}

.quiz-options {
  display: flex;
  flex-direction: column;
  gap: 0.75rem;
}

.quiz-option {
  padding: 1rem;
  background: rgba(0,0,0,0.03);
  border: 2px solid transparent;
  border-radius: 8px;
  cursor: pointer;
  transition: all 0.2s;
  text-align: left;
  font-family: inherit;
  font-size: 0.95rem;
}

.quiz-option:hover {
  border-color: var(--purple);
}

.quiz-option.selected {
  border-color: var(--navy);
  background: rgba(30,39,97,0.05);
}

.quiz-option.correct {
  border-color: var(--green);
  background: rgba(45,139,95,0.1);
}

.quiz-option.incorrect {
  border-color: var(--red);
  background: rgba(191,45,45,0.1);
}

.quiz-feedback {
  margin-top: 1rem;
  padding: 1rem;
  border-radius: 8px;
  display: none;
}

.quiz-feedback.show {
  display: block;
}

.quiz-feedback.correct {
  background: rgba(45,139,95,0.1);
  border-left: 4px solid var(--green);
}

.quiz-feedback.incorrect {
  background: rgba(191,45,45,0.1);
  border-left: 4px solid var(--red);
}

.nav-buttons {
  display: flex;
  justify-content: space-between;
  padding: 1rem 2rem;
  background: white;
  border-top: 1px solid rgba(0,0,0,0.1);
}

.nav-btn {
  display: flex;
  align-items: center;
  gap: 0.5rem;
  padding: 0.75rem 1.5rem;
  border: none;
  border-radius: 8px;
  cursor: pointer;
  font-size: 1rem;
  font-weight: 600;
  transition: all 0.2s;
}

.nav-btn.prev {
  background: rgba(0,0,0,0.05);
  color: var(--navy);
}

.nav-btn.prev:hover {
  background: rgba(0,0,0,0.1);
}

.nav-btn.next {
  background: linear-gradient(135deg, var(--purple), #8B5CF6);
  color: white;
}

.nav-btn.next:hover {
  transform: translateX(4px);
}

.nav-btn:disabled {
  opacity: 0.5;
  cursor: not-allowed;
}

.badge-notification {
  position: fixed;
  bottom: 2rem;
  right: 2rem;
  background: linear-gradient(135deg, var(--navy), #2a3a7d);
  border-radius: 16px;
  padding: 1rem 1.5rem;
  display: flex;
  align-items: center;
  gap: 1rem;
  box-shadow: 0 8px 32px rgba(0,0,0,0.3);
  z-index: 3000;
  transform: translateY(100px);
  opacity: 0;
  transition: all 0.5s cubic-bezier(0.34, 1.56, 0.64, 1);
}

.badge-notification.show {
  transform: translateY(0);
  opacity: 1;
}

.badge-icon {
  width: 48px;
  height: 48px;
  border-radius: 50%;
  display: flex;
  align-items: center;
  justify-content: center;
  font-size: 1.5rem;
  box-shadow: 0 4px 12px rgba(0,0,0,0.2);
}

.badge-info {
  color: white;
}

.badge-earned {
  font-size: 0.7rem;
  text-transform: uppercase;
  letter-spacing: 1px;
  color: var(--gold);
  margin-bottom: 0.25rem;
}

.badge-name {
  font-family: 'Cormorant Garamond', serif;
  font-size: 1.2rem;
  font-weight: 600;
}

.badge-grid {
  display: grid;
  grid-template-columns: repeat(auto-fill, minmax(140px, 1fr));
  gap: 1rem;
  margin-top: 1rem;
}

.badge-card {
  background: white;
  border-radius: 12px;
  padding: 1rem;
  text-align: center;
  border: 2px solid transparent;
  transition: all 0.3s;
}

.badge-card.earned {
  border-color: var(--gold);
  box-shadow: 0 4px 12px rgba(212, 175, 55, 0.2);
}

.badge-card.locked {
  opacity: 0.5;
  filter: grayscale(1);
}

.formula-box {
  background: rgba(30, 39, 97, 0.08);
  border-radius: 8px;
  padding: 1rem;
  margin: 1rem 0;
  font-family: 'Courier New', monospace;
  text-align: center;
  color: var(--navy);
  font-size: 1.1rem;
}

.performance-metric {
  display: flex;
  align-items: center;
  gap: 1rem;
  padding: 1rem;
  background: rgba(107, 70, 193, 0.08);
  border-radius: 8px;
  margin: 0.75rem 0;
}

.metric-value {
  font-size: 2rem;
  font-weight: 700;
  color: var(--purple);
  min-width: 80px;
  text-align: center;
}

.metric-info h4 {
  color: var(--navy);
  margin-bottom: 0.25rem;
}

.metric-info p {
  font-size: 0.85rem;
  color: var(--light-text);
}

@media (max-width: 768px) {
  .hamburger {
    display: flex;
  }

  .sidebar {
    transform: translateX(-100%);
    transition: transform 0.3s;
  }

  .sidebar.open {
    transform: translateX(0);
  }

  .sidebar-overlay.show {
    display: block;
  }

  .main-content {
    margin-left: 0;
  }

  .slide-title h1 {
    font-size: 2rem;
  }

  .data-grid {
    grid-template-columns: 1fr 1fr;
  }

  .top-bar {
    padding: 1rem;
  }

  .progress-bar {
    width: 120px;
  }
}

@media (max-width: 480px) {
  .sidebar {
    width: 100%;
  }

  .slide-container {
    padding: 1rem;
  }

  .story-deep, .method-box, .content-box {
    padding: 1rem;
  }

  .data-grid {
    grid-template-columns: 1fr 1fr;
  }

  .top-actions {
    width: 100%;
    justify-content: center;
  }
}

    /* Focus-visible styles for keyboard navigation */
    :focus-visible {
      outline: 2px solid var(--gold, #D4AF37);
      outline-offset: 2px;
    }

    :focus:not(:focus-visible) {
      outline: none;
    }

    button:focus-visible,
    a:focus-visible,
    [role="button"]:focus-visible,
    input:focus-visible,
    select:focus-visible,
    textarea:focus-visible {
      outline: 2px solid var(--gold, #D4AF37);
      outline-offset: 2px;
      box-shadow: 0 0 0 4px rgba(212, 175, 55, 0.3);
    }

    /* Screen Reader Only */
    .sr-only {
      position: absolute;
      width: 1px;
      height: 1px;
      padding: 0;
      margin: -1px;
      overflow: hidden;
      clip: rect(0, 0, 0, 0);
      white-space: nowrap;
      border: 0;
    }

    @media (prefers-reduced-motion: reduce) {
      *, *::before, *::after {
        animation-duration: 0.01ms !important;
        animation-iteration-count: 1 !important;
        transition-duration: 0.01ms !important;
        scroll-behavior: auto !important;
      }
    }
  </style>
</head>
<body>
<a class="skip-link" href="#main-content">Skip to main content</a>
<button aria-expanded="false" aria-label="Toggle navigation menu" class="hamburger">
<span></span>
<span></span>
<span></span>
</button>
<div class="sidebar-overlay"></div>
<nav aria-label="ã‚³ãƒ¼ã‚¹ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«" class="sidebar" role="navigation">
<a href="index.html" onmouseout="this.style.color='rgba(212,175,55,0.7)'" onmouseover="this.style.color='#D4AF37'" style="display:block;font-size:0.7rem;color:rgba(212,175,55,0.7);text-decoration:none;margin-bottom:0.5rem;padding:0.5rem 1rem 0;">â† Course Library</a>
<div class="logo">Prognostic Reviews</div>
<div class="tagline">Predicting Patient Futures</div>
<div class="nav-section">
<div class="nav-label">Modules</div>
<div id="module-nav"></div>
</div>
</nav>
<main class="main-content" id="main-content">
<div class="top-bar">
<div class="progress-section">
<div class="progress-bar">
<div class="progress-fill" id="progress-fill" style="width: 0%"></div>
</div>
<span class="progress-text" id="progress-text">0% Complete</span>
</div>
<div class="course-time">
<span id="total-time">5h 40m total</span>
</div>
<div class="points-display">
<span id="points-display">0</span> XP
      </div>
<div class="top-actions">
<button class="action-btn" onclick="openBadges()">ğŸ† Badges</button>
<button class="action-btn" onclick="openGlossary()">Glossary</button>
</div>
</div>
<div class="slide-container" id="slide-container"></div>
<div aria-live="polite" class="sr-only" id="slide-announce"></div>
<div class="nav-buttons">
<button class="nav-btn prev" id="prev-btn" onclick="prevSlide()">
<span>â†</span> Previous
      </button>
<button class="nav-btn next" id="next-btn" onclick="nextSlide()">
        Next <span>â†’</span>
</button>
</div>
</main>
<script>
const STORAGE_KEY = 'prognostic-reviews-course-progress';

let currentModule = 0;
let currentSlide = 0;
let gameState = {
  points: 0,
  earnedBadges: [],
  modulesCompleted: [],
  decisionTrees: {}
};

// Badge Definitions
const BADGES = {
  'model-builder': { name: 'Model Builder', icon: 'ğŸ”§', color: '#6B46C1', requirement: 'å®Œå…¨ãªãƒ¢ãƒ‡ãƒ«é–‹ç™ºãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«' },
  'validation-expert': { name: 'Validation Expert', icon: 'âœ…', color: '#2D8B5F', requirement: 'å®Œå…¨ãªæ¤œè¨¼ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«' },
  'calibration-master': { name: 'Calibration Master', icon: 'ğŸ“Š', color: '#2D8B8B', requirement: 'å®Œå…¨ãªã‚­ãƒ£ãƒªãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³æ¼”ç¿’' },
  'tripod-scholar': { name: 'TRIPOD Scholar', icon: 'ğŸ“', color: '#D4AF37', requirement: 'å®Œå…¨ãªãƒ¬ãƒãƒ¼ãƒˆãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«' },
  'decision-analyst': { name: 'Decision Analyst', icon: 'ğŸ“ˆ', color: '#BF2D2D', requirement: 'å®Œå…¨ãªæ±ºå®šæ›²ç·šãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«' },
  'story-collector': { name: 'Story Collector', icon: 'ğŸ“š', color: '#1e2761', requirement: 'ã™ã¹ã¦ã®ã‚±ãƒ¼ã‚¹ã‚’èª­ã‚€ç ”ç©¶' },
  'tree-navigator': { name: 'Tree Navigator', icon: 'ğŸŒ³', color: '#2D8B5F', requirement: '15 ã®æ±ºå®šã‚’å®Œäº†æœ¨' },
  'prognosis-master': { name: 'Prognosis Master', icon: 'ğŸ“', color: '#6B46C1', requirement: 'ã‚³ãƒ¼ã‚¹å…¨ä½“ã‚’å®Œäº†ã™ã‚‹' },
  'penalization-pro': { name: 'Penalization Pro', icon: 'ğŸ¯', color: '#8B5CF6', requirement: 'Master LASSO/Ridge content' },
  'communicator': { name: 'Patient Communicator', icon: 'ğŸ’¬', color: '#EC4899', requirement: 'Learn uncertainty communication' },
  'skeptic': { name: 'AI Skeptic', icon: 'ğŸ¤–', color: '#F59E0B', requirement: 'å®Œå…¨ãª ML å¯¾å›å¸°ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«' },
  'implementer': { name: 'Implementation Expert', icon: 'ğŸ¥', color: '#10B981', requirement: 'å®Œå…¨ãªå®Ÿè£…ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«' }
};

const modules = [
  {
    id: 0,
    title: "The Opening",
    subtitle: "Why Prognosis Matters",
    principle: null,
    estimatedTime: "15 min",
    slides: [
      {
        type: 'title',
        content: {
          title: "Prognostic Reviews",
          subtitle: "Predicting Patient Futures",
          text: "å‘½ã‚’æ•‘ã£ãŸã‚¹ã‚³ã‚¢ã®ã‚¹ãƒˆãƒ¼ãƒªãƒ¼ã¨ã€ã‚ã¾ã‚Šã«ã‚‚å¤šãã‚’ç´„æŸã—ãŸã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚’é€šã˜ã¦ã€äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«ã®è©•ä¾¡ã¨æ§‹ç¯‰ã‚’å­¦ã³ã¾ã™ã€‚"
        }
      },
      {
        type: 'story-deep',
        content: {
          label: "è²¡å›£: ãƒ•ãƒ¬ãƒ¼ãƒŸãƒ³ã‚°ãƒãƒ  â€” åŒ»å¸«ã®ã¨ãå°†æ¥ã‚’è¦‹ã‚‹ã“ã¨ã‚’å­¦ã³ã¾ã—ãŸ",
          source: "Framingham Heart Study 1948-present | Wilson 1998 | Circulation",
          timeline: [
            { year: "1948", text: "Framingham Heart Study begins in Massachusetts. 5,209 adults enrolled. No one knows what causes heart disease. Cholesterol is just a chemical.", type: "normal" },
            { year: "1961", text: "First major finding: high cholesterol, high blood pressure, and smoking predict heart attacks. The concept of 'risk factors' is born.", type: "revelation" },
            { year: "1976", text: "Framingham Risk Score developed: age, sex, cholesterol, BP, smoking, diabetes combined into one number. Doctors can now QUANTIFY a patient's 10-year risk.", type: "revelation" },
            { year: "1998", text: "Updated Framingham Risk Score published. C-statistic 0.76-0.79. Widely adopted. Millions of statin decisions based on this score.", type: "normal" },
            { year: "2000s", text: "External validation shows Framingham overestimates risk in some populations (UK, Europe, Asia). Recalibration needed. One model doesn't fit all.", type: "crisis" },
            { year: "Legacy", text: "Framingham proved prognosis is POSSIBLE and USEFUL. But it also showed: models must be validated, calibration matters, and context is everything.", type: "revelation" }
          ],
          realData: {
            endpoint: "10-year cardiovascular disease risk",
            model: "Framingham Risk Score",
            discrimination: "C-statistic 0.76-0.79",
            impact: "Guides statin therapy for millions worldwide"
          },
          hook: "THE HOOK: Before Framingham, doctors guessed who would have heart attacks. After Framingham, they could calculate it. This course teaches you to evaluate such calculations â€” to know when a prognostic model helps patients and when it's just mathematical theater."
        }
      },
      {
        type: 'principle',
        content: {
          text: "â¸ï¸ KEY INSIGHT: Prognostic models translate uncertainty into numbers. A patient asking 'What are my chances?' deserves more than 'It depends.' But those numbers must be ACCURATE (calibration), DISCRIMINATING (separate high from low risk), and USEFUL (change decisions). A model can fail any of these â€” and often does."
        }
      },
      {
        type: 'content',
        content: {
          title: "What Is Prognostic Research?",
          sections: [
            {
              heading: "Prognosis vs Other Research Types:",
              items: [
                "DIAGNOSTIC: Who HAS the disease NOW? (presence/absence)",
                "ETIOLOGIC: What CAUSES the disease? (causation)",
                "THERAPEUTIC: What TREATS the disease? (intervention effects)",
                "PROGNOSTIC: What WILL HAPPEN to the patient? (future outcomes)"
              ]
            },
            {
              heading: "Why Prognosis Matters:",
              items: [
                "Treatment decisions: Should this patient get aggressive therapy?",
                "Patient counseling: What should I expect?",
                "Resource allocation: Who needs intensive monitoring?",
                "Trial design: Enriching populations for higher event rates",
                "Quality measurement: Risk-adjusted outcomes"
              ]
            },
            {
              heading: "The Fundamental Question:",
              text: "æ‚£è€…ã«ã¤ã„ã¦ç¾åœ¨ã‚ã‹ã£ã¦ã„ã‚‹ã“ã¨ã‚’è€ƒæ…®ã™ã‚‹ã¨ã€å®šç¾©ã•ã‚ŒãŸæœŸé–“å†…ã«ç‰¹å®šã®çµæœãŒèµ·ã“ã‚‹ç¢ºç‡ã¯ã©ã‚Œãã‚‰ã„ã§ã™ã‹?"
            }
          ]
        }
      },
      {
        type: 'content',
        content: {
          title: "The Seven Principles of Prognostic Modeling",
          sections: [
            {
              heading: "Your Guide Through This Course:",
              items: [
                "1. \\\"äºˆæ¸¬ã¯å› æœé–¢ä¿‚ã§ã¯ã‚ã‚Šã¾ã›ã‚“\\\" â€” äºˆæ¸¬ã¯åŸå› ã§ã‚ã‚‹å¿…è¦ã¯ã‚ã‚Šã¾ã›ã‚“",
                "2. \"A model is only as good as its validation\" â€” Development means nothing without testing",
                "3. \"Discrimination is not enough\" â€” A model must also be calibrated",
                "4. \"More predictors is not better\" â€” Overfitting destroys generalizability",
                "5ã€‚ \\\"æ¯é›†å›£ãŒäºˆæ¸¬ã‚’å®šç¾©ã—ã¾ã™\\\" â€” ãƒ¢ãƒ‡ãƒ«ã¯è‡ªç”±ã«ç§»å‹•ã—ã¾ã›ã‚“",
                "6. \"Clinical utility trumps statistics\" â€” Good numbers don't guarantee good decisions",
                "7. \"Transparency enables trust\" â€” TRIPOD and reporting standards matter"
              ]
            }
          ]
        }
      },
      {
        type: 'decision-tree',
        content: {
          id: 'prognosis-vs-diagnosis',
          title: "Prognosis or Diagnosis?",
          situation: "Classify each clinical question as prognostic, diagnostic, etiologic, or therapeutic.",
          nodes: {
            start: {
              question: "è³ªå• 1: ã€Œèƒ¸ç—›ã®ã‚ã‚‹ã“ã®æ‚£è€…ã¯è‚ºå¡æ “ç—‡ã‚’æ‚£ã£ã¦ã„ã¾ã™ã‹?ã€",
              branches: [
                { text: "Prognostic â€” predicting future outcome", nextNode: "q1_wrong" },
                { text: "Diagnostic â€” determining current disease state", nextNode: "q1_correct" }
              ]
            },
            q1_wrong: {
              type: 'outcome',
              outcome: 'danger',
              title: "This is diagnostic!",
              text: "The question is about what the patient HAS right now (PE or not), not what will happen in the future. Diagnosis = current state. Prognosis = future outcome.",
              lesson: "è¨ºæ–­è³ªå•: æ‚£è€…ã¯ç—‡çŠ¶ X ã‚’æŒã£ã¦ã„ã¾ã™ã‹?äºˆå¾Œã«é–¢ã™ã‚‹è³ªå•: æ‚£è€…ã«ä½•ãŒèµ·ã“ã‚‹ã§ã—ã‚‡ã†ã‹?"
            },
            q1_correct: {
              situation: "æ­£è§£!è³ªå•ã¯ç¾åœ¨ã®ç—…çŠ¶ã«é–¢ã™ã‚‹ã‚‚ã®ã§ã‚ã‚Šã€å°†æ¥ã®è»¢å¸°ã«ã¤ã„ã¦ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚",
              question: "è³ªå• 2: ã€Œã“ã® ICU æ‚£è€…ãŒé€€é™¢ã¾ã§ç”Ÿå­˜ã™ã‚‹å¯èƒ½æ€§ã¯ã©ã‚Œãã‚‰ã„ã§ã™ã‹?ã€",
              branches: [
                { text: "Prognostic â€” predicting future survival", nextNode: "q2_correct" },
                { text: "Diagnostic â€” assessing current severity", nextNode: "q2_wrong" }
              ]
            },
            q2_wrong: {
              type: 'outcome',
              outcome: 'partial',
              title: "çµ‚äº†ã§ã™ãŒã€ã“ã‚Œã¯äºˆå¾Œã§ã™",
              text: "é‡ç—‡åº¦è©•ä¾¡ã¯äºˆæ¸¬ã«å½¹ç«‹ã¤å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ãŒã€è³ªå•ã¯å°†æ¥ã®è»¢å¸°ã«é–¢ã™ã‚‹ã‚‚ã®ã§ã™ã€‚ ï¼ˆé€€é™¢ã¾ã§ã®ç”Ÿå­˜ï¼‰ã€‚æ™‚é–“è»¸ã«ã‚ˆã‚Šã€äºˆæ¸¬ãŒå¯èƒ½ã«ãªã‚Šã¾ã™ã€‚",
              lesson: "è³ªå•ãŒå°†æ¥ã®æ™‚ç‚¹ (ç”Ÿå­˜ã™ã‚‹ã‹ã€ç™ºç—‡ã™ã‚‹ã‹ã€å†ç™ºã™ã‚‹ã‹) ã«é–¢ä¿‚ã™ã‚‹å ´åˆã€ãã‚Œã¯äºˆå¾Œã§ã™ã€‚"
            },
            q2_correct: {
              situation: "Correct! Survival to discharge is a future outcome â€” classic prognosis.",
              question: "QUESTION 3: 'Does smoking cause lung cancer?'",
              branches: [
                { text: "Prognostic â€” smoking predicts cancer", nextNode: "q3_prog_wrong" },
                { text: "ç—…å›  â€” å› æœé–¢ä¿‚ã«ã¤ã„ã¦å°‹ã­ã¾ã™", nextNode: "q3_correct" }
              ]
            },
            q3_prog_wrong: {
              type: 'outcome',
              outcome: 'partial',
              title: "å–«ç…™ã¯äºˆæ¸¬çš„ã§ã™ãŒã€ãã‚Œã¯äºˆæ¸¬ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚è³ªå•",
              text: "å–«ç…™ã¯è‚ºãŒã‚“ã‚’äºˆæ¸¬ã—ã¦ãŠã‚Šã€äºˆå¾Œãƒ¢ãƒ‡ãƒ«ã«å«ã¾ã‚Œã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚ã—ã‹ã—å•é¡Œã¯ã€å–«ç…™ãŒç™Œã®åŸå› ã¨ãªã‚‹ã‹ã©ã†ã‹ã‚’å•ã†ã‚‚ã®ã§ã‚ã‚Šã€ãã‚Œã¯ç—…å› çš„ãªã‚‚ã®ã§ã‚ã‚‹ã€‚äºˆå¾Œã§ã¯ã€å› æœé–¢ä¿‚ã«é–¢ä¿‚ãªãäºˆæ¸¬å› å­ãŒä½¿ç”¨ã•ã‚Œã¾ã™ã€‚",
              lesson: "Prognostic models can include non-causal predictors. Etiologic research specifically asks about CAUSATION."
            },
            q3_correct: {
              type: 'outcome',
              outcome: 'success',
              title: "Exactly right!",
              text: "å•é¡Œã¯å› æœé–¢ä¿‚ã«é–¢ã™ã‚‹ã‚‚ã®ã§ã™ã€‚å–«ç…™ã¯ç™Œã®åŸå› ã«ãªã‚Šã¾ã™ã‹?ã“ã‚Œã«ã¯ã€å› æœæ¨è«–æ‰‹æ³• (äº¤çµ¡åˆ¶å¾¡ã€æ™‚é–“æ€§ãªã©) ãŒå¿…è¦ã§ã™ã€‚äºˆå¾Œãƒ¢ãƒ‡ãƒ«ã¯ã€å› æœé–¢ä¿‚ã‚’è¨¼æ˜ã™ã‚‹ã“ã¨ãªãå–«ç…™ã‚’äºˆæ¸¬å› å­ã¨ã—ã¦ä½¿ç”¨ã§ãã¾ã™ã€‚",
              lesson: "Prediction â‰  Causation. A prognostic model can include age, sex, biomarkers â€” none 'cause' the outcome, but all predict it."
            }
          }
        }
      },
      {
        type: 'principle',
        content: {
          text: "âš ï¸ THE WARNING: As you learn prognostic methods, remember: every model is wrong, but some are useful. Framingham changed medicine. But poorly validated models have also caused harm â€” allocating resources wrongly, giving false reassurance, or creating false alarm. The question isn't whether a model exists, but whether it WORKS and HELPS."
        }
      }
    ]
  },
  {
    id: 1,
    title: "The Factors",
    subtitle: "äºˆå¾Œå› å­ç ”ç©¶",
    principle: 0,
    estimatedTime: "25 min",
    slides: [
      {
        type: 'principle-display',
        content: {
          principle: "äºˆæ¸¬ã¯å› æœé–¢ä¿‚ã§ã¯ã‚ã‚Šã¾ã›ã‚“"
        }
      },
      {
        type: 'story-deep',
        content: {
          label: "THE BIOMARKER TRAP: TROPONIN â€” WHEN A PREDICTOR BECAME A TARGET",
          source: "Multiple troponin trials | JAMA, NEJM | High-sensitivity assays",
          timeline: [
            { year: "1990s", text: "Cardiac troponin identified as marker of myocardial damage. Elevated troponin strongly predicts death in ACS patients. OR for death: 3-5x.", type: "normal" },
            { year: "2000s", text: "Troponin becomes standard for ACS diagnosis AND prognosis. Higher levels = worse outcomes. Dose-response relationship clear.", type: "normal" },
            { year: "The Idea", text: "'If high troponin predicts bad outcomes, we should treat patients with high troponin more aggressively.' Trials test intensive therapy in troponin-positive patients.", type: "normal" },
            { year: "The Results", text: "FRISC-II, TACTICS-TIMI 18: Invasive strategy helps troponin-positive patients. Success? Or just treating sicker patients?", type: "revelation" },
            { year: "The Trap", text: "ãƒˆãƒ­ãƒãƒ‹ãƒ³ã¯çµæœã‚’äºˆæ¸¬ã—ã¾ã™ãŒã€çµæœã‚’å¼•ãèµ·ã“ã™ã‚‚ã®ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚ãƒˆãƒ­ãƒãƒ‹ãƒ³ï¼ˆæ•°å€¤ï¼‰ã‚’ä¸‹ã’ã¦ã‚‚çµæœã¯æ”¹å–„ã—ã¾ã›ã‚“ã€‚ãƒˆãƒ­ãƒãƒ‹ãƒ³ã¯æå‚·ã®ãƒãƒ¼ã‚«ãƒ¼ã§ã‚ã‚Šã€æ²»ç™‚ç›®æ¨™ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚", type: "crisis" },
            { year: "Lesson", text: "äºˆå¾Œå› å­ã¯ã€ã©ã®æ‚£è€…ã‚’é›†ä¸­çš„ã«æ²»ç™‚ã™ã‚‹ã‹ã‚’ã‚¬ã‚¤ãƒ‰ã§ãã¾ã™ã€‚ã—ã‹ã—ã€è¦å› ã‚’æ²»ç™‚ã™ã‚‹ï¼ˆæ•°å€¤ã‚’ä¸‹ã’ã‚‹ï¼‰ã“ã¨ã¯ã€ãã®è¦å› ãŒåŸå› ã§ã‚ã‚Šã€ã‹ã¤ä¿®æ­£å¯èƒ½ã§ãªã„é™ã‚Šå½¹ã«ç«‹ã¡ã¾ã›ã‚“ã€‚", type: "revelation" }
          ],
          realData: {
            endpoint: "Mortality, reinfarction",
            factor: "Troponin elevation",
            effect: "æœ‰å®³ãªè»¢å¸°ã®å ´åˆã¯ 3 ï½ 5",
            lesson: "Predicts outcome; not a treatment target"
          },
          hook: "THE HOOK: Troponin is a superb prognostic factor. But trying to 'lower troponin' makes no sense â€” it's smoke, not fire. The first principle of prognostic factors: PREDICTION does not equal CAUSATION. A factor can be a perfect predictor and a useless treatment target."
        }
      },
      {
        type: 'principle',
        content: {
          text: "â¸ï¸ ä¸»ãªæ´å¯Ÿ: äºˆå¾Œå› å­ã¯ã€å°†æ¥ã®è»¢å¸°ã«é–¢é€£ã™ã‚‹å¤‰æ•°ã§ã™ã€‚ãã‚Œã‚‰ã¯å› æœé–¢ä¿‚ã§ã‚ã‚‹å¿…è¦ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚å¹´é½¢ã¯æ­»äº¡ç‡ã‚’äºˆæ¸¬ã—ã¾ã™ãŒã€å¹´é½¢ã‚’å¤‰ãˆã‚‹ã“ã¨ã¯ã§ãã¾ã›ã‚“ã€‚è…«ç˜ãƒãƒ¼ã‚«ãƒ¼ã¯å†ç™ºã‚’äºˆæ¸¬ã—ã¾ã™ãŒã€ãƒãƒ¼ã‚«ãƒ¼ã‚’ä¸‹ã’ã¦ã‚‚ãŒã‚“ã¯æ²»ç™’ã—ã¾ã›ã‚“ã€‚äºˆå¾Œå› å­ã¨æ²»ç™‚ç›®æ¨™ã‚’åŒºåˆ¥ã—ã¾ã™ã€‚"
        }
      },
      {
        type: 'content',
        content: {
          title: "äºˆå¾Œå› å­ç ”ç©¶ã¨ã¯ä½•ã§ã™ã‹?",
          sections: [
            {
              heading: "Definition:",
              items: [
                "å› å­ãŒè‡¨åºŠè»¢å¸°ã«é–¢é€£ã—ã¦ã„ã‚‹ã‹ã©ã†ã‹ã‚’èª¿ã¹ã‚‹ç ”ç©¶",
                "Usually in patients with a specific condition (inception cohort)",
                "Factor measured at baseline; outcome measured later",
                "Adjust for other known prognostic factors to assess INDEPENDENT contribution"
              ]
            },
            {
              heading: "Types of Prognostic Factors:",
              items: [
                "DEMOGRAPHIC: Age, sex, race/ethnicity",
                "CLINICAL: Disease stage, comorbidities, functional status",
                "BIOMARKERS: Lab values, imaging findings, genetic markers",
                "PATIENT-REPORTED: Quality of life, symptoms, preferences"
              ]
            },
            {
              heading: "Key Distinction:",
              text: "äºˆå¾Œå› å­ â‰  ãƒªã‚¹ã‚¯å› å­ã€‚å±é™ºå› å­ã¯å¥åº·ãªé›†å›£ï¼ˆèª°ãŒç—…æ°—ã‚’ç™ºç—‡ã™ã‚‹ã‹ï¼‰ã‚’å¯¾è±¡ã«ç ”ç©¶ã•ã‚Œã¾ã™ã€‚äºˆå¾Œå› å­ã¯ç–¾æ‚£ã®ã‚ã‚‹æ‚£è€…ã§ç ”ç©¶ã•ã‚Œã¾ã™ (æ‚£è€…ã«ä½•ãŒèµ·ã“ã‚‹ã‹?)ã€‚"
            }
          ]
        }
      },
      {
        type: 'method',
        content: {
          label: "æ–¹æ³•: äºˆå¾Œå› å­ã®ç ”ç©¶è¨­è¨ˆ",
          title: "äºˆå¾Œå› å­ã®ç ”ç©¶æ–¹æ³•",
          sections: [
            {
              heading: "1. Define the Population (Inception Cohort):",
              text: "â€¢ Start point: Diagnosis, treatment initiation, or clinical event\nâ€¢ All patients should be at SIMILAR point in disease course\nâ€¢ Avoid prevalent cohorts (survivors already selected)"
            },
            {
              heading: "2. Measure the Factor at Baseline:",
              text: "â€¢ Before outcome can occur\nâ€¢ Standardized measurement\nâ€¢ Handle missing data transparently"
            },
            {
              heading: "3. Define the Outcome:",
              text: "â€¢ Clinically meaningful (death, recurrence, functional status)\nâ€¢ Fixed time horizon (5-year survival, 30-day readmission)\nâ€¢ Objective measurement or adjudication"
            },
            {
              heading: "4. Adjust for Confounders:",
              text: "â€¢ ãã®ä»–ã®ç¢ºç«‹ã•ã‚ŒãŸäºˆå¾Œå› å­â€¢ é–¢é€£æ€§ã‚’èª¬æ˜ã§ãã‚‹å¤‰æ•°â€¢ DAG ã‚’ä½¿ç”¨ã—ã¦ç‰¹å®šã™ã‚‹èª¿æ•´ã‚»ãƒƒãƒˆ"
            },
            {
              heading: "5. Report Effect Sizes with Uncertainty:",
              text: "â€¢ Hazard ratios, odds ratios, or risk ratios with 95% CIs\nâ€¢ Continuous factors: per-unit change or meaningful increments\nâ€¢ Avoid arbitrary dichotomization"
            }
          ]
        }
      },
      {
        type: 'story-deep',
        content: {
          label: "THE FALSE PROMISE: PSA VELOCITY â€” WHEN A PROGNOSTIC FACTOR WASN'T",
          source: "Vickers et al. JNCI 2011 | PSA velocity meta-analysis | Prostate cancer",
          timeline: [
            { year: "1990s", text: "PSA velocity (rate of PSA rise) proposed as prostate cancer predictor. Faster rise = more aggressive cancer. Made biological sense.", type: "normal" },
            { year: "2000s", text: "è¦³å¯Ÿç ”ç©¶ã§ã¯ã€PSA é€Ÿåº¦ãŒæ­»äº¡ç‡ã‚’äºˆæ¸¬ã™ã‚‹ã“ã¨ãŒç¤ºã•ã‚Œã¦ã„ã¾ã™ã€‚ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³ã§ã¯ã€ç”Ÿæ¤œã®æ±ºå®šã«é€Ÿåº¦ãŒçµ„ã¿è¾¼ã¾ã‚Œã¦ã„ã¾ã™ã€‚ã‚¯ãƒªãƒ‹ã‚«ãƒ«ãƒ‘ã‚¹å…¨ä½“ãŒãã‚Œã‚’ä¸­å¿ƒã«æ§‹ç¯‰ã•ã‚Œã¾ã™ã€‚", type: "normal" },
            { year: "2007", text: "Systematic review by Vickers: When ADJUSTING FOR BASELINE PSA, velocity adds NO prognostic information. Velocity was confounded by baseline level.", type: "crisis" },
            { year: "The Math", text: "High velocity often means high PSA. High PSA predicts outcomes. Velocity appeared predictive only because it correlated with level. Classic confounding.", type: "revelation" },
            { year: "Aftermath", text: "Guidelines revised. Velocity de-emphasized. Years of clinical practice based on a 'prognostic factor' that wasn't independently prognostic.", type: "crisis" },
            { year: "Lesson", text: "ã“ã®è¦ç´ ã¯ã€ç§ãŸã¡ãŒã™ã§ã«çŸ¥ã£ã¦ã„ã‚‹ä»¥ä¸Šã®æƒ…å ±ã‚’è¿½åŠ ã—ã¾ã™ã‹? å¸¸ã«å°‹ã­ã¦ãã ã•ã„ã€‚ç‹¬ç«‹ã—ãŸäºˆå¾Œå€¤ã«ã¯ã€ç¢ºç«‹ã•ã‚ŒãŸå› å­ã®èª¿æ•´ãŒå¿…è¦ã§ã™ã€‚", type: "revelation" }
          ],
          realData: {
            endpoint: "Prostate cancer mortality",
            factor: "PSA velocity (unadjusted)",
            effect: "é«˜å€¤å¯¾ä½å€¤ã§ HR ~2.0",
            adjusted: "HR ~1.0 when adjusted for baseline PSA"
          },
          hook: "THE HOOK: PSA velocity was used for years before anyone checked if it added information beyond baseline PSA. It didn't. The lesson: A factor that CORRELATES with the outcome isn't necessarily an INDEPENDENT prognostic factor. Always adjust for what you already know."
        }
      },
      {
        type: 'decision-tree',
        content: {
          id: 'prognostic-factor-assessment',
          title: "ã“ã®å› å­ã¯æœ¬å½“ã«äºˆå¾Œçš„ã§ã™ã‹?",
          situation: "A study claims that serum ferritin predicts mortality in heart failure patients. HR 2.1 (95% CI 1.5-2.9) for high vs low ferritin. The study adjusted for age and sex only. Known prognostic factors in heart failure include: ejection fraction, BNP, renal function, NYHA class.",
          nodes: {
            start: {
              question: "ã“ã®ç ”ç©¶ã«ã¤ã„ã¦ã®æœ€åˆã®æ‡¸å¿µã¯ä½•ã§ã™ã‹?",
              branches: [
                { text: "2.1 ã® HR ã¯å¤§ãã™ãã¦äºˆæ¸¬ã§ãã¾ã›ã‚“ä¿¡ã˜ã‚‰ã‚Œã‚‹", nextNode: "hr_concern" },
                { text: "å¹´é½¢ã¨æ€§åˆ¥ã ã‘ã®èª¿æ•´ã§ã¯ä¸ååˆ†", nextNode: "adjustment_correct" },
                { text: "Ferritin isn't biologically plausible", nextNode: "biology_concern" }
              ]
            },
            hr_concern: {
              type: 'outcome',
              outcome: 'partial',
              title: "HR 2.1 isn't inherently implausible",
              text: "åŠ¹æœé‡ 2.0 ã¯ã€å¼·åŠ›ãªäºˆå¾Œå› å­ (ãƒˆãƒ­ãƒãƒ‹ãƒ³ã€BNP) ã§ã¯ä¸€èˆ¬çš„ã§ã™ã€‚å•é¡Œã¯åŠ¹æœã®å¤§ãã•ã§ã¯ãªãã€é©åˆ‡ã«èª¿æ•´ã—ãŸå¾Œã«åŠ¹æœãŒæŒç¶šã™ã‚‹ã‹ã©ã†ã‹ã§ã™ã€‚ HR 2.0 ãŒèª¿æ•´ã•ã‚Œã¦ã„ãªã„ä¿‚æ•°ã¯ã€HR 1.0 ãŒèª¿æ•´ã•ã‚Œã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚",
              lesson: "Judge prognostic factors by their adjusted effects, not by whether raw effects 'seem' too big."
            },
            adjustment_correct: {
              situation: "ãã®é€šã‚Šã§ã™ã€‚ EFã€BNPã€è…æ©Ÿèƒ½ã€NYHA ã‚¯ãƒ©ã‚¹ã‚’èª¿æ•´ã—ãªã„ã¨ã€ãƒ•ã‚§ãƒªãƒãƒ³ãŒç‹¬ç«‹ã—ã¦äºˆå¾Œã‚’ç¤ºã™ã®ã‹ã€ãã‚Œã¨ã‚‚ã“ã‚Œã‚‰ã®ç¢ºç«‹ã•ã‚ŒãŸå› å­ã¨å˜ã«ç›¸é–¢ã™ã‚‹ã®ã‹ã¯ã‚ã‹ã‚Šã¾ã›ã‚“ã€‚",
              question: "æ–°ã—ã„åˆ†æã§ã¯ã€ã™ã¹ã¦ã®ä¸»è¦ãªå› å­ãŒèª¿æ•´ã•ã‚Œã¾ã™ã€‚ãƒ•ã‚§ãƒªãƒãƒ³HRã¯2.1ã‹ã‚‰1.3(0.95-1.7)ã«ä½ä¸‹ã—ã¾ã™ã€‚ã‚ãªãŸã¯ã©ã†çµè«–ã¥ã‘ã¾ã™ã‹?",
              branches: [
                { text: "Ferritin is still prognostic â€” HR > 1.0", nextNode: "still_prognostic_wrong" },
                { text: "Ferritin adds minimal independent information â€” CI includes 1.0", nextNode: "minimal_info_correct" },
                { text: "ç ”ç©¶ã¯é–“é•ã£ã¦ã„ãŸ â€” ãƒ•ã‚§ãƒªãƒãƒ³ã¯å½¹ã«ç«‹ãŸãªã‹ã£ãŸ", nextNode: "useless_too_strong" }
              ]
            },
            biology_concern: {
              type: 'outcome',
              outcome: 'partial',
              title: "Biology matters, but don't require it",
              text: "Biological plausibility strengthens causal claims. But prognostic factors don't need to be causal! Age predicts mortality without 'causing' it. Ferritin could be a marker of inflammation, iron status, or comorbidity â€” any of which might explain prediction.",
              lesson: "äºˆå¾Œ: ã‚‚ã£ã¨ã‚‚ã‚‰ã—ã•ã¯è‰¯ã„ã§ã™ãŒã€å¿…é ˆã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚ç—…å› ã«ã¤ã„ã¦: ã‚‚ã£ã¨ã‚‚ã‚‰ã—ã•ãŒé‡è¦ã§ã™ã€‚"
            },
            still_prognostic_wrong: {
              type: 'outcome',
              outcome: 'danger',
              title: "ä¿¡é ¼åŒºé–“ã‚’è¦‹ã¦ãã ã•ã„!",
              text: "HR 1.3ã€95% CI 0.95-1.7 ã«ã¯ 1.0 ãŒå«ã¾ã‚Œã¾ã™ã€‚ã“ã‚Œã¯ã€ã„ã‹ãªã‚‹é–¢é€£æ€§ã‚‚æ’é™¤ã§ããªã„ã“ã¨ã‚’æ„å‘³ã—ã¾ã™ã€‚ç‚¹æ¨å®šå€¤ã¯èª¿æ•´å¾Œ (2.1 ã‹ã‚‰ 1.3) ã« 60% ä½ä¸‹ã—ã€ã»ã¨ã‚“ã©ã®ã€ŒåŠ¹æœã€ãŒæ··ä¹±ã—ã¦ã„ãŸã“ã¨ã‚’ç¤ºå”†ã—ã¦ã„ã¾ã™ã€‚",
              lesson: "Always report and interpret confidence intervals. A point estimate means nothing without uncertainty."
            },
            minimal_info_correct: {
              type: 'outcome',
              outcome: 'success',
              title: "Correct interpretation!",
              text: "60% ã®æ¸›è¡° (2.1 â†’ 1.3) ã¯ã€ãƒ•ã‚§ãƒªãƒãƒ³ãŒä»–ã®è¦å›  (ãŠãã‚‰ãè…æ©Ÿèƒ½ã¨ç‚ç—‡) ã®å¤‰å‹•ã‚’ä¸»ã«æ‰ãˆã¦ã„ãŸã“ã¨ã‚’ç¤ºå”†ã—ã¦ã„ã¾ã™ã€‚ CI ã«ã¯ 1.0 ãŒå«ã¾ã‚Œã‚‹ã‚ˆã†ã«ãªã‚Šã¾ã—ãŸã€‚ãƒ•ã‚§ãƒªãƒãƒ³ã¯ãŠãã‚‰ãã€å¿ƒä¸å…¨ã«ãŠã‘ã‚‹ç‹¬ç«‹ã—ãŸäºˆå¾Œæƒ…å ±ã‚’ã»ã¨ã‚“ã©è¿½åŠ ã—ã¾ã›ã‚“ã€‚",
              lesson: "This pattern (strong unadjusted, weak adjusted) is extremely common. Always demand properly adjusted analyses before accepting a 'new prognostic factor.'"
            },
            useless_too_strong: {
              type: 'outcome',
              outcome: 'partial',
              title: "Too strong a conclusion",
              text: "The adjusted HR is 1.3 â€” not 1.0. Ferritin MIGHT have modest independent prognostic value; we're just uncertain. It's not 'useless' â€” it's 'not proven useful beyond existing factors.' A larger study might clarify.",
              lesson: "è¨¼æ‹ ã®ä¸åœ¨â‰ ä¸åœ¨ã®è¨¼æ‹ ã€‚ã—ã‹ã—ã€ç‹¬ç«‹ã—ãŸäºˆå¾Œå€¤ãŒç¢ºç«‹ã•ã‚Œã‚‹ã¾ã§ã¯ã€å› å­ã‚’è‡¨åºŠçš„ã«ä½¿ç”¨ã™ã¹ãã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚"
            }
          }
        }
      },
      {
        type: 'quiz',
        content: {
          question: "A biomarker strongly predicts mortality (HR 4.0, p<0.001) but is NOT on the causal pathway to death. This biomarker could still be useful for:",
          options: [
            { id: 'a', text: "ãƒã‚¤ã‚ªãƒãƒ¼ã‚«ãƒ¼ã‚’ä½ä¸‹ã•ã›ã‚‹æ²»ç™‚æ³•ã®é–‹ç™º", correct: false },
            { id: 'b', text: "Risk stratification to guide treatment intensity", correct: true },
            { id: 'c', text: "ãƒã‚¤ã‚ªãƒãƒ¼ã‚«ãƒ¼ãŒæ­»äº¡ã‚’å¼•ãèµ·ã“ã™ã“ã¨ã‚’è¨¼æ˜ã™ã‚‹", correct: false },
            { id: 'd', text: "Replacing other prognostic factors in clinical assessment", correct: false }
          ],
          explanation: "éå› æœçš„äºˆæ¸¬å› å­ã¯æ²»ç™‚å¯¾è±¡ã¨ã—ã¦ã¯å½¹ã«ç«‹ã¡ã¾ã›ã‚“ï¼ˆä½ä¸‹ã—ã¦ã‚‚å½¹ã«ç«‹ã¡ã¾ã›ã‚“ï¼‰ãŒã€ãƒªã‚¹ã‚¯å±¤åˆ¥åŒ–ã«ã¯å½¹ç«‹ã¡ã¾ã™ã€‚ãƒã‚¤ã‚ªãƒãƒ¼ã‚«ãƒ¼ã«ã‚ˆã£ã¦é«˜ãƒªã‚¹ã‚¯ã®æ‚£è€…ãŒç‰¹å®šã•ã‚ŒãŸå ´åˆã€è‡¨åºŠåŒ»ã¯ã€ãƒã‚¤ã‚ªãƒãƒ¼ã‚«ãƒ¼è‡ªä½“ãŒæ²»ç™‚æ¨™çš„ã§ãªã„å ´åˆã§ã‚‚ã€ãã‚Œã‚‰ã®æ‚£è€…ã‚’ã‚ˆã‚Šç©æ¥µçš„ã«æ²»ç™‚ã§ãã¾ã™ã€‚"
        }
      },
      {
        type: 'story-deep',
        content: {
          label: "REAL-WORLD CASE: THE PSA SCREENING CONTROVERSY â€” EXCELLENT DISCRIMINATION, TERRIBLE UTILITY",
          source: "US Preventive Services Task Force | ERSPC Trial | Prostate cancer screening debates",
          timeline: [
            { year: "1986", text: "å‰ç«‹è…ºç‰¹ç•°æŠ—åŸ (PSA) ã¯ã€å‰ç«‹è…ºãŒã‚“ã®ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°ç”¨ã¨ã—ã¦ FDA ã«æ‰¿èªã•ã‚Œã¦ã„ã¾ã™ã€‚ã™ãã«å¥åº·ãªç”·æ€§ã®ã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ã«æ¡ç”¨ã•ã‚Œã¾ã—ãŸã€‚è«–ç†: PSA ã®ä¸Šæ˜‡ã¯å‰ç«‹è…ºãŒã‚“ã‚’äºˆæ¸¬ã—ã¾ã™ã€‚", type: "normal" },
            { year: "1990s", text: "PSA screening becomes routine. Millions of men tested annually. Prostate cancer diagnoses skyrocket. 'Early detection saves lives' becomes dogma.", type: "normal" },
            { year: "The Problem", text: "PSA is elevated in prostate cancer â€” but also in benign prostatic hyperplasia, prostatitis, even vigorous cycling. PSA discriminates cancer from no-cancer... imperfectly.", type: "crisis" },
            { year: "Overdiagnosis", text: "Many detected cancers would NEVER have caused symptoms or death. These indolent tumors were treated anyway: surgery, radiation, hormones. Men suffered incontinence, impotence, anxiety â€” for cancers that didn't need treatment.", type: "crisis" },
            { year: "2012", text: "USPSTF ã¯å®šæœŸçš„ãª PSA ã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ã‚’æ¨å¥¨ã—ã¾ã›ã‚“ã€‚å®³ï¼ˆéå‰°è¨ºæ–­ã€éå‰°æ²»ç™‚ï¼‰ãŒåˆ©ç›Šã‚’ä¸Šå›ã‚Šã¾ã—ãŸã€‚å„ªã‚ŒãŸè­˜åˆ¥åŠ›ã‚’æŒã¤äºˆå¾Œå› å­ã§ã™ãŒã€å®Ÿè³ªçš„ãªè‡¨åºŠçš„å®³ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚", type: "revelation" },
            { year: "Lesson", text: "PSA correctly identifies men with prostate cancer. But not all prostate cancers are equal. Detecting harmless cancers and treating them aggressively causes MORE harm than missing them. <span class='lesson-gold'>THE LESSON: A prognostic factor can have excellent discrimination yet terrible clinical utility. The question isn't just 'does it predict?' but 'does acting on the prediction help patients?'</span>", type: "revelation" }
          ],
          realData: {
            endpoint: "Prostate cancer detection",
            factor: "PSA (prostate-specific antigen)",
            discrimination: "ãŒã‚“æ¤œå‡ºã® C çµ±è¨ˆå€¤ ~0.70",
            problem: "Overdiagnosis and overtreatment of indolent cancers"
          },
          hook: "THE HOOK: PSA is the canonical example of a good prognostic factor that causes harm in practice. It PREDICTS prostate cancer. The prediction is ACCURATE. But acting on that prediction â€” biopsying, treating, worrying â€” often hurts men more than the cancer would have. Clinical utility requires more than accurate prediction."
        }
      },
      {
        type: 'principle',
        content: {
          text: "ğŸ¯ PROGRESS CHECK: You now understand prognostic factor studies. Key lessons: (1) Factors must be independently predictive after adjustment; (2) Prediction â‰  causation; (3) Unadjusted associations are often confounded; (4) Non-causal predictors can still guide treatment decisions by identifying high-risk patients."
        }
      }
    ]
  },
  {
    id: 2,
    title: "The Models",
    subtitle: "Prediction Model Development",
    principle: 1,
    estimatedTime: "40 min",
    slides: [
      {
        type: 'principle-display',
        content: {
          principle: "A model is only as good as its validation"
        }
      },
      {
        type: 'story-deep',
        content: {
          label: "éå‰°é©åˆ: ãƒ‡ãƒ¥ãƒ¼ã‚¯ã®ãŒã‚“ã‚²ãƒãƒŸã‚¯ã‚¹ â€” å®Œç’§ãªäºˆæ¸¬ãŒå®Œå…¨ã«é–“é•ã£ã¦ã„ãŸã¨ã",
          source: "Baggerly & Coombes 2009 | Nature Medicine | Duke scandal",
          timeline: [
            { year: "2006", text: "Duke researchers publish genomic signatures that 'perfectly' predict chemotherapy response. Lancet, Nature Medicine. C-statistics near 1.0. Clinical trials launched.", type: "normal" },
            { year: "2007-08", text: "Biostatisticians Baggerly & Coombes try to reproduce results. Find errors: mislabeled samples, wrong gene names, data inconsistencies. Report concerns.", type: "crisis" },
            { year: "2009", text: "ãƒ‡ãƒ¥ãƒ¼ã‚¯ã¯æ‡¸å¿µã‚’å¦å®šã—ã¾ã™ã€‚æ²»é¨“ã¯å¼•ãç¶šãæ‚£è€…ã®ç™»éŒ²ã‚’è¡Œã£ã¦ã„ã‚‹ã€‚ ã€ŒçµæœãŒã™ã¹ã¦ã‚’ç‰©èªã£ã¦ã„ã¾ã™ã€‚ã€å†…éƒ¨èª¿æŸ»ã§ã¯å•é¡Œã¯è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚", type: "crisis" },
            { year: "2010", text: "NCI pauses trials. External audit confirms systematic errors. Lead researcher Potti found to have fabricated credentials. Trials terminated. Patients harmed.", type: "crisis" },
            { year: "Root Cause", text: "Models were overfit: trained and 'validated' on same data with errors. 'Perfect' discrimination was data artifacts, not real signal. No independent validation.", type: "revelation" },
            { year: "Lesson", text: "High apparent performance is a RED FLAG without external validation. Development data can memorize noise. Overfitting looks like success â€” until real-world deployment.", type: "revelation" }
          ],
          realData: {
            endpoint: "Chemotherapy response",
            claimed: "C-statistic ~0.90-1.0",
            actual: "ãƒã‚¤ã‚ºã¨ãƒ‡ãƒ¼ã‚¿ã®ã‚¨ãƒ©ãƒ¼",
            harm: "Patients enrolled in trials based on fabricated models"
          },
          hook: "THE HOOK: The Duke researchers had 'perfect' predictions. C-statistics near 1.0. Publications in top journals. Clinical trials. The only problem? The models were completely wrong. Overfitting and data errors masqueraded as breakthrough science. This is why validation isn't optional â€” it's the only thing that matters."
        }
      },
      {
        type: 'principle',
        content: {
          text: "â¸ï¸ KEY INSIGHT: Development performance is meaningless. A model can achieve C = 0.99 on development data by memorizing noise. Only EXTERNAL validation â€” testing on completely new data â€” reveals true performance. If someone shows you only development metrics, you know nothing about whether the model works."
        }
      },
      {
        type: 'content',
        content: {
          title: "äºˆå¾Œãƒ¢ãƒ‡ãƒ«ã® PICOT",
          sections: [
            {
              heading: "P â€” Population:",
              text: "ã“ã®ãƒ¢ãƒ‡ãƒ«ã¯èª°ã®ãŸã‚ã®ã‚‚ã®ã§ã™ã‹?åŒ…å«/é™¤å¤–åŸºæº–ã‚’å®šç¾©ã—ã¾ã™ã€‚ã“ã®ãƒ¢ãƒ‡ãƒ«ã¯åŒæ§˜ã®æ‚£è€…ã«ã®ã¿é©ç”¨ã•ã‚Œã¾ã™ã€‚ ICU æ‚£è€…ç”¨ã®ãƒ¢ãƒ‡ãƒ«ã¯å¤–æ¥æ‚£è€…ã«ã¯é©ç”¨ã•ã‚Œã¾ã›ã‚“ã€‚"
            },
            {
              heading: "I â€” Index (Predictors):",
              text: "ãƒ¢ãƒ‡ãƒ«ã«ã¯ã©ã®ã‚ˆã†ãªæƒ…å ±ãŒå…¥åŠ›ã•ã‚Œã¾ã™ã‹?äººå£çµ±è¨ˆã€ç ”ç©¶å®¤ã€ç”»åƒå‡¦ç†ã€ã‚²ãƒãƒŸã‚¯ã‚¹?äºˆæ¸¬æ™‚ã«ã¯ã™ã¹ã¦ã®äºˆæ¸¬å­ãŒåˆ©ç”¨å¯èƒ½ã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚"
            },
            {
              heading: "C â€” Comparator (Alternative Models):",
              text: "What are we comparing to? Existing models? Clinical judgment? No model? New models should IMPROVE on existing options."
            },
            {
              heading: "O â€” Outcome:",
              text: "ä½•ã‚’äºˆæ¸¬ã—ã¦ã„ã‚‹ã®ã§ã—ã‚‡ã†ã‹?æ­»ï¼Ÿå†å…¥é™¢ï¼Ÿç—…æ°—ã®é€²è¡Œï¼Ÿè‡¨åºŠçš„ã«æ„å‘³ãŒã‚ã‚Šã€å®¢è¦³çš„ã«æ¸¬å®šå¯èƒ½ã§ã€æ‚£è€…/è‡¨åºŠåŒ»ã«ã¨ã£ã¦é‡è¦ã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚"
            },
            {
              heading: "T â€” Time Horizon:",
              text: "ã„ã¤äºˆæ¸¬ã—ã¾ã™ã‹? 30æ—¥ä»¥å†…ã®æ­»äº¡ç‡ï¼Ÿ 5å¹´ç”Ÿå­˜? 10å¹´ãƒªã‚¹ã‚¯ã¯ã‚ã‚‹ï¼Ÿæ™‚é–“è»¸ã¯ã€äºˆæ¸¬å› å­ã€ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã€è‡¨åºŠçš„æœ‰ç”¨æ€§ãªã©ã€ã™ã¹ã¦ã‚’å¤‰ãˆã¾ã™ã€‚"
            }
          ]
        }
      },
      {
        type: 'method',
        content: {
          label: "æ–¹æ³•: ãƒ¢ãƒ‡ãƒ«é–‹ç™ºã®æ‰‹é †",
          title: "Building a Prognostic Model",
          sections: [
            {
              heading: "1. Assemble the Cohort:",
              text: "â€¢ æ˜ç¢ºãªé–‹å§‹ç‚¹ã‚’æŒã¤é–‹å§‹ã‚³ãƒ›ãƒ¼ãƒˆ â€¢ é©åˆ‡ãªã‚µãƒ³ãƒ—ãƒ«ã‚µã‚¤ã‚ºï¼ˆäºˆæ¸¬å› å­ã”ã¨ã« 10 ã‚¤ãƒ™ãƒ³ãƒˆä»¥ä¸Šã€ã§ãã‚Œã° 20 ã‚¤ãƒ™ãƒ³ãƒˆä»¥ä¸Šï¼‰ â€¢ æ™‚é–“è»¸ã‚’é€šã˜ãŸå®Œå…¨ãªè¿½è·¡èª¿æŸ» â€¢ å¯¾è±¡é›†å›£ã®ä»£è¡¨"
            },
            {
              heading: "2. Select Predictors:",
              text: "â€¢ ãƒ‡ãƒ¼ã‚¿é§†å‹•å‹ã®é¸æŠã§ã¯ãªãã€ä»¥å‰ã®è¨¼æ‹ ã«åŸºã¥ã â€¢ äºˆæ¸¬æ™‚ã«åˆ©ç”¨å¯èƒ½ï¼ˆå°†æ¥ã®æƒ…å ±ã¯ãªã„ï¼‰ â€¢ ä¿¡é ¼æ€§ã¨ä¸€è²«æ€§ã®ã‚ã‚‹æ¸¬å®š â€¢ äº‹å‰ã«æ¬ æãƒ‡ãƒ¼ã‚¿ã‚’å‡¦ç†ãƒ¢ãƒ‡ãƒªãƒ³ã‚°"
            },
            {
              heading: "3. Choose the Model Type:",
              text: "â€¢ Logistic regression: Binary outcomes at fixed time\nâ€¢ Cox regression: Time-to-event data\nâ€¢ Machine learning: Flexible but prone to overfitting\nâ€¢ Simpler models often generalize better"
            },
            {
              heading: "4. Fit the Model:",
              text: "â€¢ ãƒ¢ãƒ‡ãƒªãƒ³ã‚°æˆ¦ç•¥ã‚’äº‹å‰ã«æŒ‡å®šã™ã‚‹ â€¢ äºˆæ¸¬å­ãŒå¤šã„å ´åˆã¯ãƒšãƒŠãƒ«ãƒ†ã‚£è¨­å®š (LASSOã€ãƒªãƒƒã‚¸) ã‚’ä½¿ç”¨ã™ã‚‹ â€¢ ä»®å®šã‚’ãƒã‚§ãƒƒã‚¯ã™ã‚‹ (ç·šå½¢æ€§ã€æ¯”ä¾‹ãƒã‚¶ãƒ¼ãƒ‰) â€¢ ãƒ–ãƒ¼ãƒˆã‚¹ãƒˆãƒ©ãƒƒãƒ—ã¾ãŸã¯äº¤å·®æ¤œè¨¼ã«ã‚ˆã‚‹å†…éƒ¨æ¤œè¨¼"
            },
            {
              heading: "5. Apply Shrinkage:",
              text: "â€¢ æ¨å®šã•ã‚ŒãŸä¿‚æ•°ã¯æ¥½è¦³çš„ (ã‚ªãƒ¼ãƒãƒ¼ãƒ•ã‚£ãƒƒãƒˆ) â€¢ åç¸®ç‡ã‚’è¨ˆç®—ã™ã‚‹ (å‡ä¸€ã¾ãŸã¯ãƒšãƒŠãƒ«ãƒ†ã‚£ã‚ã‚Š) â€¢ ã™ã¹ã¦ã®ä¿‚æ•°ã«é©ç”¨ã€Œæœ€çµ‚ã€ãƒ¢ãƒ‡ãƒ«ã®å‰ â€¢ ã“ã‚Œã«ã‚ˆã‚Šã€éå­¦ç¿’ãŒæ¸›å°‘ã—ã¾ã™"
            }
          ]
        }
      },
      {
        type: 'content',
        content: {
          title: "Sample Size: The Events Per Variable Rule",
          sections: [
            {
              heading: "The Problem:",
              text: "äºˆæ¸¬å­ã¨æ¯”è¼ƒã—ã¦çµæœã‚¤ãƒ™ãƒ³ãƒˆãŒå°‘ãªã™ãã‚‹ã¨ã€ãƒ¢ãƒ‡ãƒ«ã¯å£Šæ»…çš„ã«éå­¦ç¿’ã—ã¾ã™ã€‚ã“ã‚Œã‚‰ã¯ä¿¡å·ã§ã¯ãªããƒã‚¤ã‚ºã«é©åˆã—ã¾ã™ã€‚"
            },
            {
              heading: "Traditional Rule: EPV â‰¥ 10",
              items: [
                "At least 10 events per predictor variable",
                "10 å€‹ã®äºˆæ¸¬å­ã®å ´åˆã€100 å€‹ä»¥ä¸Šã®ã‚¤ãƒ™ãƒ³ãƒˆãŒå¿…è¦",
                "Minimum for stable coefficient estimates",
                "Many experts now recommend EPV â‰¥ 20"
              ]
            },
            {
              heading: "Example Calculation:",
              text: "You want to develop a model with 12 predictors for 30-day mortality. Mortality rate is 5%. For EPV=10: need 120 events. At 5% rate: need 120/0.05 = 2,400 patients. For EPV=20: need 4,800 patients."
            },
            {
              heading: "When EPV Is Low:",
              items: [
                "Use penalization (LASSO, ridge regression)",
                "Reduce number of predictors (combine, eliminate)",
                "Consider simpler models",
                "Be very skeptical of apparent performance"
              ]
            }
          ]
        }
      },
      {
        type: 'method',
        content: {
          label: "è©³ç´°: ãƒšãƒŠãƒªã‚¼ãƒ¼ã‚·ãƒ§ãƒ³æ–¹æ³•",
          title: "LASSO, Ridge, and Elastic Net Explained",
          sections: [
            {
              heading: "The Problem Penalization Solves:",
              text: "æ¨™æº–å›å¸°ã«ã‚ˆã‚Šã€ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚° ãƒ‡ãƒ¼ã‚¿ã«æœ€ã‚‚ã‚ˆãé©åˆã™ã‚‹ä¿‚æ•°ãŒè¦‹ã¤ã‹ã‚Šã¾ã™ã€‚ã—ã‹ã—ã€ã€Œæœ€é©ãªé©åˆã€ã¯å¤šãã®å ´åˆã€ã€Œéé©åˆãƒã‚¤ã‚ºã€ã‚’æ„å‘³ã—ã¾ã™ã€‚ãƒšãƒŠãƒ«ãƒ†ã‚£ã‚’é©ç”¨ã™ã‚‹ã¨ã€ä¿‚æ•°ãŒå¤§ãã„å ´åˆã« COST ãŒè¿½åŠ ã•ã‚Œã€ãƒ¢ãƒ‡ãƒ«ãŒã‚ˆã‚Šå˜ç´”ãªè§£ã‚’è¦‹ã¤ã‘ã‚‹ã“ã¨ãŒå¼·åˆ¶ã•ã‚Œã¾ã™ã€‚"
            },
            {
              heading: "Ridge Regression (L2 Penalty):",
              text: "â€¢ Adds penalty = Î» Ã— Î£(Î²Â²) â€” sum of squared coefficients\nâ€¢ SHRINKS all coefficients toward zero (but never exactly zero)\nâ€¢ Good when many predictors contribute small effects\nâ€¢ Handles correlated predictors well\nâ€¢ Î» controls shrinkage strength: higher Î» = more shrinkage"
            },
            {
              heading: "LASSO (L1 Penalty):",
              text: "â€¢ Adds penalty = Î» Ã— Î£|Î²| â€” sum of absolute coefficients\nâ€¢ SHRINKS coefficients AND sets some exactly to zero\nâ€¢ Performs variable SELECTION (sparse models)\nâ€¢ Better when few predictors are truly important\nâ€¢ Can be unstable with correlated predictors"
            },
            {
              heading: "Elastic Net (L1 + L2):",
              text: "â€¢ ä¸¡æ–¹ã®ãƒšãƒŠãƒ«ãƒ†ã‚£ã‚’çµ„ã¿åˆã‚ã›ã¾ã™: Î»â‚Î£|Î²| + Î»â‚‚Î£(Î²Â²) â€¢ ä¸¡æ–¹ã®åˆ©ç‚¹ã‚’å¾—ã‚‹: é¸æŠã¨ã‚°ãƒ«ãƒ¼ãƒ—åŒ–ã•ã‚ŒãŸç¸®å° â€¢ å¤šãã®å ´åˆã€æœ€è‰¯ã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆé¸æŠ â€¢ 2 ã¤ã®èª¿æ•´ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ¼ (ç›¸äº’æ¤œè¨¼ã‚’ä½¿ç”¨)"
            },
            {
              heading: "Choosing Lambda (Î»):",
              text: "â€¢ Use cross-validation to find optimal Î»\nâ€¢ Î».min: minimizes prediction error\nâ€¢ Î».1se: largest Î» within 1 SE of minimum (more parsimonious)\nâ€¢ Clinical prediction often uses Î».1se for simplicity"
            },
            {
              heading: "Critical Limitation:",
              text: "Penalization REDUCES overfitting but doesn't ELIMINATE it. With EPV < 5, even LASSO cannot rescue a model. Penalization is not a substitute for adequate sample size â€” it's a tool for when you have borderline-adequate data."
            }
          ]
        }
      },
      {
        type: 'decision-tree',
        content: {
          id: 'penalization-choice',
          title: "ã©ã®ãƒšãƒŠãƒ«ãƒ†ã‚£ãƒ¡ã‚½ãƒƒãƒ‰?",
          situation: "200 ã®ã‚¤ãƒ™ãƒ³ãƒˆã¨ 30 ã®å€™è£œäºˆæ¸¬å­ (EPV â‰ˆ 7) ãŒã‚ã‚Šã¾ã™ã€‚æœ¬å½“ã«é‡è¦ãªäºˆæ¸¬å¤‰æ•°ã¯ 5 ï½ 8 å€‹ã ã‘ã ã¨æ€ã‚ã‚Œã¾ã™ãŒã€ã©ã‚ŒãŒã©ã‚Œã‹ã¯ã‚ã‹ã‚Šã¾ã›ã‚“ã€‚ä¸€éƒ¨ã®äºˆæ¸¬å­ã¯ç›¸é–¢ã—ã¦ã„ã¾ã™ (åç¸®æœŸè¡€åœ§ã¨æ‹¡å¼µæœŸè¡€åœ§ãªã©)ã€‚",
          nodes: {
            start: {
              question: "é‡è¦ãªäºˆæ¸¬å­ã¯ã»ã¨ã‚“ã©ãªã„ã¨æ€ã‚ã‚Œã‚‹ãŒã€ç›¸é–¢å¤‰æ•°ãŒã‚ã‚‹å ´åˆã€ã©ã®æ–¹æ³•ã‚’ä½¿ç”¨ã—ã¾ã™ã‹?",
              branches: [
                { text: "LASSO â€” I want variable selection", nextNode: "lasso_choice" },
                { text: "Ridge â€” handles correlated predictors better", nextNode: "ridge_choice" },
                { text: "Elastic Net â€” gets benefits of both", nextNode: "elastic_correct" }
              ]
            },
            lasso_choice: {
              type: 'outcome',
              outcome: 'partial',
              title: "LASSO has a weakness here",
              text: "LASSO ã¯å¸Œæœ›ã™ã‚‹é¸æŠã‚’å®Ÿè¡Œã—ã¾ã™ã€‚ã—ã‹ã—ã€ç›¸é–¢äºˆæ¸¬å­ (BP å¤‰æ•°) ã‚’ä½¿ç”¨ã™ã‚‹ã¨ã€LASSO ã¯ä»»æ„ã« 1 ã¤ã‚’é¸æŠã—ã€ã‚‚ã† 1 ã¤ã‚’ã‚¼ãƒ­ã«ã—ã¾ã™ã€‚ã“ã‚Œã¯ä¸å®‰å®šã«ãªã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚å°ã•ãªãƒ‡ãƒ¼ã‚¿ã®å¤‰æ›´ã«ã‚ˆã‚Šã€ã©ã®å¤‰æ•°ãŒä¿æŒã•ã‚Œã‚‹ã‹ãŒåè»¢ã—ã¾ã™ã€‚ Elastic net ã¯ã“ã‚Œã‚’ã‚ˆã‚Šé©åˆ‡ã«å‡¦ç†ã—ã¾ã™ã€‚",
              lesson: "LASSO ã¯ã¾ã°ã‚‰ãªé¸æŠã«ã¯æœ€é©ã§ã™ãŒã€ç›¸é–¢äºˆæ¸¬å­ã«ã¯è‹¦åŠ´ã—ã¾ã™ã€‚äºˆæ¸¬å­ãŒç›¸é–¢ã—ã¦ã„ã‚‹å ´åˆã¯ã€ã‚¨ãƒ©ã‚¹ãƒ†ã‚£ãƒƒã‚¯ ãƒãƒƒãƒˆã‚’è€ƒæ…®ã—ã¦ãã ã•ã„ã€‚"
            },
            ridge_choice: {
              type: 'outcome',
              outcome: 'partial',
              title: "Ridge won't give you selection",
              text: "Ridge ã¯ã€ç›¸é–¢ã®ã‚ã‚‹äºˆæ¸¬å­ã‚’é©åˆ‡ã«å‡¦ç†ã—ã€éå¸¸ã«å®‰å®šã—ã¦ã„ã¾ã™ã€‚ãŸã ã—ã€30 å€‹ã®äºˆæ¸¬å­ã¯ã™ã¹ã¦ä¿æŒã•ã‚Œã¾ã™ (ç¸®å°ã™ã‚‹ã ã‘ã§ã™)ã€‚ 5 ï½ 8 ã¤ã ã‘ãŒé‡è¦ã ã¨è€ƒãˆã‚‹ã¨ã€ä¸å¿…è¦ã«è¤‡é›‘ãªãƒ¢ãƒ‡ãƒ«ãŒä½œæˆã•ã‚Œã¦ã—ã¾ã„ã¾ã™ã€‚è‡¨åºŠç”¨é€”ã§ã¯ã€å˜ç´”ã§ã‚ã‚‹ã»ã©è‰¯ã„ã“ã¨ãŒã‚ˆãã‚ã‚Šã¾ã™ã€‚",
              lesson: "Ridge ã¯å®‰å®šã—ã¦ã„ã¾ã™ãŒã€å˜ç´”åŒ–ã•ã‚Œã¾ã›ã‚“ã€‚ç¯€ç´„ãƒ¢ãƒ‡ãƒ«ãŒå¿…è¦ãªå ´åˆã¯ã€L1 (LASSO) ã¾ãŸã¯ã‚¨ãƒ©ã‚¹ãƒ†ã‚£ãƒƒã‚¯ ãƒãƒƒãƒˆãŒå¿…è¦ã§ã™ã€‚"
            },
            elastic_correct: {
              type: 'outcome',
              outcome: 'success',
              title: "ã“ã®ã‚·ãƒŠãƒªã‚ªã«æœ€é©ãªé¸æŠã§ã™!",
              text: "ã‚¨ãƒ©ã‚¹ãƒ†ã‚£ãƒƒã‚¯ ãƒãƒƒãƒˆã¯ã€LASSO ã®é¸æŠã¨ç›¸é–¢äºˆæ¸¬å­ã®ãƒªãƒƒã‚¸ã®å®‰å®šæ€§ã‚’çµ„ã¿åˆã‚ã›ã¾ã™ã€‚ BP ç›¸é–¢ã‚’é©åˆ‡ã«å‡¦ç†ã—ãªãŒã‚‰ã€5 ï½ 10 å€‹ã®äºˆæ¸¬å­ã‚’é¸æŠã™ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚ç›¸äº’æ¤œè¨¼ã‚’ä½¿ç”¨ã—ã¦ã€Î»â‚ ã¨ Î»2 (ã¾ãŸã¯æ··åˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ Î±) ã®ä¸¡æ–¹ã‚’èª¿æ•´ã—ã¾ã™ã€‚",
              lesson: "ç–‘ã‚ã—ã„å ´åˆã¯ã€ã‚¨ãƒ©ã‚¹ãƒ†ã‚£ãƒƒã‚¯ ãƒãƒƒãƒˆãŒæœ€ã‚‚å®‰å…¨ãªé¸æŠã¨ãªã‚‹ã“ã¨ãŒã‚ˆãã‚ã‚Šã¾ã™ã€‚ã“ã‚Œã¯ã€ç–ä¿¡å·æ§‹é€ ã¨å¯†ä¿¡å·æ§‹é€ ã®ä¸¡æ–¹ã«é©å¿œã—ã¾ã™ã€‚"
            }
          }
        }
      },
      {
        type: 'decision-tree',
        content: {
          id: 'sample-size-decision',
          title: "ã“ã®ãƒ¢ãƒ‡ãƒ«ã¯é©åˆ‡ã«å‹•ä½œã—ã¦ã„ã¾ã™ã‹?",
          situation: "è«–æ–‡ã§ã¯ã€æ–°ã—ã„çµæœãŒç™ºè¡¨ã•ã‚Œã¦ã„ã¾ã™ã€‚æ–°å‹ã‚³ãƒ­ãƒŠã‚¦ã‚¤ãƒ«ã‚¹æ„ŸæŸ“ç—‡æ‚£è€…ã®æ­»äº¡äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«ã€‚æ‚£è€…æ•°ã¯500åã€ã†ã¡75åãŒæ­»äº¡ï¼ˆæ­»äº¡ç‡15ï¼…ï¼‰ã€‚å½¼ã‚‰ã¯ 25 å€‹ã®äºˆæ¸¬å¤‰æ•°ã®å€™è£œã‚’ãƒ†ã‚¹ãƒˆã—ã€æœ€çµ‚ãƒ¢ãƒ‡ãƒ«ã¨ã—ã¦ 8 å€‹ã‚’é¸æŠã—ã¾ã—ãŸã€‚ãƒ–ãƒ¼ãƒˆã‚¹ãƒˆãƒ©ãƒƒãƒ—ã«ã‚ˆã‚‹å†…éƒ¨æ¤œè¨¼ã§ã¯ã€C çµ±è¨ˆé‡ 0.82 ãŒç¤ºã•ã‚Œã¦ã„ã¾ã™ã€‚",
          nodes: {
            start: {
              question: "æœ€åˆã®æ‡¸å¿µã¯ä½•ã§ã™ã‹?",
              branches: [
                { text: "EPV is low: 75 events / 8 predictors = 9.4", nextNode: "epv_correct" },
                { text: "C çµ±è¨ˆé‡ 0.82 ã¯ãã‚Œã»ã©å°è±¡çš„ã§ã¯ã‚ã‚Šã¾ã›ã‚“", nextNode: "cstat_issue" },
                { text: "They tested 25 predictors but only used 8", nextNode: "selection_correct" }
              ]
            },
            epv_correct: {
              situation: "Correct â€” EPV is below 10. But there's an even bigger problem...",
              question: "è‘—è€…ã¯ 8 ã¤ã‚’é¸æŠã™ã‚‹å‰ã« 25 å€‹ã®äºˆæ¸¬å¤‰æ•°ã®å€™è£œã‚’ãƒ†ã‚¹ãƒˆã—ã¾ã—ãŸã€‚ã“ã‚Œã¯ãªãœã§ã™ã‹?å•é¡ŒãŒã‚ã‚Šã¾ã™ã‹?",
              branches: [
                { text: "They wasted statistical power on non-significant predictors", nextNode: "power_wrong" },
                { text: "The effective EPV is 75/25 = 3, not 75/8", nextNode: "effective_epv_correct" }
              ]
            },
            cstat_issue: {
              type: 'outcome',
              outcome: 'partial',
              title: "C çµ±è¨ˆã¯å•é¡Œã‚ã‚Šã¾ã›ã‚“ãŒã€ãã‚Œã¯å•é¡Œã§ã¯ã‚ã‚Šã¾ã›ã‚“",
              text: "C = 0.82 would be good if it holds in external validation. The problem is that with low EPV and data-driven selection, this C-statistic is almost certainly OPTIMISTIC. The true external performance is probably much lower.",
              lesson: "å ±å‘Šã•ã‚ŒãŸãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æŒ‡æ¨™ã§ã¯ãªãã€ã‚µãƒ³ãƒ—ãƒ« ã‚µã‚¤ã‚ºã¨æ‰‹æ³•ã«ã‚ˆã£ã¦ãƒ¢ãƒ‡ãƒ«é–‹ç™ºã‚’åˆ¤æ–­ã—ã¦ãã ã•ã„ã€‚"
            },
            power_wrong: {
              type: 'outcome',
              outcome: 'partial',
              title: "ã€Œé›»åŠ›ã®ç„¡é§„é£ã„ã€ã«ã¤ã„ã¦ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚",
              text: "å•é¡Œã¯ãƒ‘ãƒ¯ãƒ¼ã§ã¯ãªãã€éå‰°é©åˆã§ã™ã€‚ 75 ã®ã‚¤ãƒ™ãƒ³ãƒˆã«ã¤ã„ã¦ 25 ã®äºˆæ¸¬å¤‰æ•°ã‚’ãƒ†ã‚¹ãƒˆã™ã‚‹ã¨ã€ä¸€éƒ¨ã¯å¶ç„¶ã«äºˆæ¸¬ã§ãã‚‹ã‚ˆã†ã«è¦‹ãˆã¾ã™ã€‚ ã€Œæœ‰æ„ãªã€äºˆæ¸¬å¤‰æ•°ã‚’é¸æŠã™ã‚‹ã¨ã€ã“ã‚Œã‚‰ã®å¶ç„¶ã®ç™ºè¦‹ãŒæ´»ç”¨ã•ã‚Œã¾ã™ã€‚ãƒ¢ãƒ‡ãƒ«ã¯éƒ¨åˆ†çš„ã«ãƒã‚¤ã‚ºã«åŸºã¥ã„ã¦æ§‹ç¯‰ã•ã‚Œã¦ã„ã¾ã™ã€‚",
              lesson: "Data-driven predictor selection (testing many, keeping 'significant' ones) is a major source of overfitting."
            },
            selection_correct: {
              situation: "Good catch! They tested 25 predictors with only 75 events. The effective EPV is 75/25 = 3.",
              question: "What should they have done instead?",
              branches: [
                { text: "Pre-specify 5-6 predictors based on prior evidence", nextNode: "prespecify_correct" },
                { text: "Use LASSO to select predictors automatically", nextNode: "lasso_partial" },
                { text: "Collect more data before testing any predictors", nextNode: "more_data_partial" }
              ]
            },
            effective_epv_correct: {
              type: 'outcome',
              outcome: 'success',
              title: "Exactly right!",
              text: "The effective degrees of freedom used is ALL 25 predictors that were tested, not just the 8 that were kept. EPV = 75/25 = 3, which is catastrophically low. The model is almost certainly overfit, regardless of what the bootstrap validation shows.",
              lesson: "EPV ã¯ã€æœ€çµ‚ãƒ¢ãƒ‡ãƒ«å†…ã®äºˆæ¸¬å­ã ã‘ã§ãªãã€ãƒ†ã‚¹ãƒˆã•ã‚ŒãŸã™ã¹ã¦ã®äºˆæ¸¬å­ã«åŸºã¥ã„ã¦è¨ˆç®—ã•ã‚Œã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚ãƒ‡ãƒ¼ã‚¿é§†å‹•å‹ã®é¸æŠã§ã¯ã€è‡ªç”±åº¦ãŒã€Œä¿å­˜ã€ã•ã‚Œã¾ã›ã‚“ã€‚"
            },
            prespecify_correct: {
              type: 'outcome',
              outcome: 'success',
              title: "Best practice!",
              text: "Pre-specifying a small number of predictors based on prior clinical knowledge (not this dataset) would give EPV = 75/6 â‰ˆ 12.5. Combined with shrinkage, this might produce a generalizable model. Data-driven selection should be avoided when EPV is limited.",
              lesson: "ãƒ‡ãƒ¼ã‚¿é§†å‹•å‹ã®é¸æŠã§ã¯ãªãã€è‡¨åºŠçŸ¥è­˜ã«åŸºã¥ãäº‹å‰ä»•æ§˜ãŒã€å …ç‰¢ãªãƒ¢ãƒ‡ãƒ«é–‹ç™ºã®åŸºç¤ã§ã™ã€‚"
            },
            lasso_partial: {
              type: 'outcome',
              outcome: 'partial',
              title: "LASSO helps, but doesn't fully solve the problem",
              text: "LASSO ã¯ã€ãƒšãƒŠãƒ«ãƒ†ã‚£ãŒé©ç”¨ã•ã‚Œã‚‹ãŸã‚ã€æ®µéšçš„é¸æŠã‚ˆã‚Šã‚‚å„ªã‚Œã¦ã„ã¾ã™ã€‚ã—ã‹ã—ã€75 ã®ã‚¤ãƒ™ãƒ³ãƒˆã¨ 25 ã®å€™è£œãŒã‚ã‚‹ãŸã‚ã€LASSO ã§ã‚‚ãƒã‚¤ã‚ºå¤‰æ•°ãŒã„ãã¤ã‹æ®‹ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚ãã‚Œã§ã‚‚ååˆ†ãªã‚µãƒ³ãƒ—ãƒ« ã‚µã‚¤ã‚ºãŒå¿…è¦ã§ã™ã€‚",
              lesson: "Penalization reduces overfitting but doesn't eliminate it. When EPV is very low, no statistical technique can compensate."
            },
            more_data_partial: {
              type: 'outcome',
              outcome: 'partial',
              title: "Ideal but not always possible",
              text: "More data is always better. But in an emerging pandemic, you may need to build models with what's available. The solution: use prior knowledge to select a small number of predictors, accept that initial models are preliminary, and plan for validation and updating.",
              lesson: "When data is limited, simplicity is essential. Complex models require large datasets."
            }
          }
        }
      },
      {
        type: 'quiz',
        content: {
          question: "A model shows C-statistic of 0.90 in development but 0.65 in external validation. The most likely explanation is:",
          options: [
            { id: 'a', text: "å¤–éƒ¨æ¤œè¨¼æ¯é›†å›£ãŒç•°ãªã£ã¦ã„ãŸ (ã‚±ãƒ¼ã‚¹æ··åˆ)", correct: false },
            { id: 'b', text: "é–‹ç™ºã‚³ãƒ›ãƒ¼ãƒˆã§ã®éå­¦ç¿’", correct: true },
            { id: 'c', text: "å¤–éƒ¨ãƒ‡ãƒ¼ã‚¿ã®æ¸¬å®šã‚¨ãƒ©ãƒ¼", correct: false },
            { id: 'd', text: "ãƒ¢ãƒ‡ãƒ«ã¯å®Ÿéš›ã«ã¯ååˆ†ã«èª¿æ•´ã•ã‚Œã¦ã„ã‚‹", correct: false }
          ],
          explanation: "A drop from 0.90 to 0.65 is dramatic (Î” = 0.25). While case-mix differences can reduce discrimination, this magnitude of drop strongly suggests overfitting. The development C-statistic was inflated by fitting noise. The external validation reveals the true (much lower) performance."
        }
      },
      {
        type: 'principle',
        content: {
          text: "âš ï¸ THE WARNING: The Duke scandal happened because prestigious researchers, top journals, and major institutions all accepted 'perfect' model performance without independent validation. Overfitting doesn't look like failure â€” it looks like remarkable success. High development performance should trigger SKEPTICISM, not celebration."
        }
      }
    ]
  },
  {
    id: 3,
    title: "The Performance",
    subtitle: "Discrimination & Calibration",
    principle: 2,
    estimatedTime: "45 min",
    slides: [
      {
        type: 'principle-display',
        content: {
          principle: "å·®åˆ¥ã ã‘ã§ã¯ä¸ååˆ†"
        }
      },
      {
        type: 'story-deep',
        content: {
          label: "THE CALIBRATION CRISIS: FRAMINGHAM IN EUROPE â€” WHEN A GOOD MODEL GAVE BAD NUMBERS",
          source: "Brindle 2003 | Heart | SCORE investigators | European populations",
          timeline: [
            { year: "1998", text: "Framingham Risk Score published. Excellent discrimination (C ~0.77). Becomes global standard for CVD risk assessment.", type: "normal" },
            { year: "2000s", text: "European countries adopt Framingham. Cardiologists calculate 10-year risks. Treatment decisions based on thresholds (e.g., >20% = high risk).", type: "normal" },
            { year: "2003", text: "Brindle et al. validate Framingham in UK population. DISCRIMINATION preserved (C similar). But CALIBRATION failed: Framingham predicted 47% more events than observed.", type: "crisis" },
            { year: "The Problem", text: "Framingham developed in US (higher CVD rates). Applied to UK (lower rates). The MODEL ranked patients correctly (discrimination) but gave WRONG PROBABILITIES (calibration).", type: "crisis" },
            { year: "Consequence", text: "Patients told '25% risk' when true risk was ~17%. Millions prescribed statins based on inflated numbers. Cost, side effects, psychological harm.", type: "crisis" },
            { year: "Solution", text: "ã‚¹ã‚³ã‚¢ã€QRISK ã¯ãƒ¨ãƒ¼ãƒ­ãƒƒãƒ‘ã®äººå£å‘ã‘ã«é–‹ç™ºã•ã‚Œã¾ã—ãŸã€‚å±€æ‰€çš„ãªç™ºç”Ÿç‡ã¸ã®å†èª¿æ•´ã€‚ãƒ¢ãƒ‡ãƒ«ã¯æ¯é›†å›£ã«é©åˆã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚", type: "revelation" }
          ],
          realData: {
            endpoint: "10-year CVD events",
            discrimination: "C-statistic similar (0.75-0.77)",
            calibration: "Predicted 47% more events than observed",
            ratio: "Predicted/Observed = 1.47"
          },
          hook: "THE HOOK: Framingham DISCRIMINATED perfectly in Europe â€” it correctly ranked who was higher vs lower risk. But it gave WRONG NUMBERS. A patient with 10% true risk was told 15%. This is the calibration problem: discrimination tells you WHO is at higher risk; calibration tells you WHAT that risk actually is."
        }
      },
      {
        type: 'principle',
        content: {
          text: "â¸ï¸ ä¸»ãªæ´å¯Ÿ: ãƒ¢ãƒ‡ãƒ«ã«ã¯ 2 ã¤ã®ã‚¸ãƒ§ãƒ–ãŒã‚ã‚Šã¾ã™ã€‚è­˜åˆ¥: é«˜ãƒªã‚¹ã‚¯ã®æ‚£è€…ã¨ä½ãƒªã‚¹ã‚¯ã®æ‚£è€…ã‚’åŒºåˆ¥ã—ã¾ã™ (ãƒ©ãƒ³ã‚¯ä»˜ã‘)ã€‚æ ¡æ­£: æ­£ç¢ºãªç¢ºç‡æ¨å®šå€¤ (æ•°å€¤) ã‚’æä¾›ã—ã¾ã™ã€‚ãƒ¢ãƒ‡ãƒ«ã¯ã€ä¸€æ–¹ã§ã¯æˆåŠŸã—ã¦ã‚‚ã€ä»–æ–¹ã§ã¯å¤±æ•—ã™ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚ã©ã¡ã‚‰ã‚‚è‡¨åºŠä¸Šã®æ±ºå®šã«å¿…è¦ã§ã™ã€‚"
        }
      },
      {
        type: 'story-deep',
        content: {
          label: "REAL-WORLD CASE: THE FRAMINGHAM RISK SCORE DECAY â€” WHEN TIME ERODES ACCURACY",
          source: "Framingham Heart Study | Ridker 2016 | Population-level temporal drift",
          timeline: [
            { year: "1998", text: "ãƒ•ãƒ©ãƒŸãƒ³ã‚¬ãƒ  ãƒªã‚¹ã‚¯ ã‚¹ã‚³ã‚¢ã¯ã€ç¾ä»£ã‚¢ãƒ¡ãƒªã‚«äººé›†å›£ã®å¿ƒè‡“ç—…ã‚’äºˆæ¸¬ã™ã‚‹ãŸã‚ã«å„ªã‚ŒãŸç²¾åº¦ã§å…¬é–‹ã•ã‚Œã¦ã„ã¾ã™ã€‚ C çµ±è¨ˆã¯ç´„ 0.76 ï½ 0.79ã€‚", type: "normal" },
            { year: "2000s", text: "ã‚¹ã‚³ã‚¢ãŒã‚´ãƒ¼ãƒ«ãƒ‰ ã‚¹ã‚¿ãƒ³ãƒ€ãƒ¼ãƒ‰ã«ãªã‚Šã¾ã™ã€‚ä½•ç™¾ä¸‡ã‚‚ã®ã‚¹ã‚¿ãƒãƒ³å‡¦æ–¹ã¯ã€ãƒ•ãƒ©ãƒŸãƒ³ã‚¬ãƒ ã®äºˆæ¸¬ã«åŸºã¥ã„ã¦ã„ã¾ã™ã€‚è‡¨åºŠã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³ã§ã¯ãã®é–¾å€¤ãŒå®šã‚ã‚‰ã‚Œã¦ã„ã¾ã™ã€‚", type: "normal" },
            { year: "2010s", text: "Researchers notice systematic overestimation. The model predicts more heart attacks than actually occur. Something has changed.", type: "crisis" },
            { year: "The Cause", text: "ãƒ¢ãƒ‡ãƒ«ãŒå‡çµã•ã‚ŒãŸã¾ã¾ã§ã‚ã‚‹é–“ã«ã€é›†å›£ã¯é€²åŒ–ã—ã¾ã—ãŸã€‚ã‚¹ã‚¿ãƒãƒ³ã®ä½¿ç”¨ãŒåºƒã¾ã‚Šã¾ã—ãŸã€‚å–«ç…™ç‡ã¯æ¿€æ¸›ã—ãŸã€‚è¡€åœ§ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ«ãŒæ”¹å–„ã•ã‚Œã¾ã—ãŸã€‚ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ ãƒªã‚¹ã‚¯ãŒä½ä¸‹ã—ã¾ã—ãŸã€‚", type: "revelation" },
            { year: "2016", text: "Studies confirm Framingham systematically overestimates risk in modern populations. A model calibrated to 1998 Americans no longer fits 2016 Americans.", type: "crisis" },
            { year: "Lesson", text: "Prediction models are not timeless. As treatments improve, behaviors change, and populations evolve, even excellent models drift out of calibration. Regular recalibration is essential. <span class='lesson-gold'>THE LESSON: Models need maintenance. A prediction frozen in time will eventually mislead as the world around it changes.</span>", type: "revelation" }
          ],
          realData: {
            endpoint: "10-year cardiovascular disease risk",
            model: "Framingham Risk Score (1998 coefficients)",
            problem: "Systematic overestimation by 2010s",
            cause: "Population-level changes in baseline risk factors"
          },
          hook: "THE HOOK: The Framingham Risk Score didn't suddenly become a bad model. It was always a snapshot of 1998 America. But populations don't stand still. When statins, smoking cessation, and better blood pressure control changed baseline risk, the model's predictions drifted from reality. This is TEMPORAL CALIBRATION DRIFT â€” and it affects every long-lived prediction model."
        }
      },
      {
        type: 'content',
        content: {
          title: "è­˜åˆ¥: C çµ±è¨ˆ (AUC)",
          sections: [
            {
              heading: "What It Measures:",
              text: "è»¢å¸°ã‚ã‚Šã§ãƒ©ãƒ³ãƒ€ãƒ ã«é¸æŠã•ã‚ŒãŸæ‚£è€…ã®äºˆæ¸¬ãƒªã‚¹ã‚¯ãŒã€è»¢å¸°ãªã—ã§ãƒ©ãƒ³ãƒ€ãƒ ã«é¸æŠã•ã‚ŒãŸæ‚£è€…ã‚ˆã‚Šã‚‚é«˜ã„ç¢ºç‡ã€‚"
            },
            {
              heading: "Interpretation:",
              items: [
                "C = 0.50: No discrimination (coin flip)",
                "C = 0.60-0.70: Poor to modest discrimination",
                "C = 0.70-0.80: Acceptable discrimination",
                "C = 0.80-0.90: Excellent discrimination",
                "C > 0.90: Outstanding (or suspicious â€” check for overfitting)"
              ]
            },
            {
              heading: "Limitations:",
              items: [
                "äºˆæ¸¬ãƒªã‚¹ã‚¯ãŒæ­£ã—ã„ã‹ã©ã†ã‹ã¯ã‚ã‹ã‚Šã¾ã›ã‚“ã€‚æ­£ã—ã„",
                "Can be high even with terrible calibration",
                "Hard to improve in well-developed clinical areas",
                "Depends on case-mix (heterogeneity of population)"
              ]
            }
          ]
        }
      },
      {
        type: 'content',
        content: {
          title: "ã‚­ãƒ£ãƒªãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³: æ•°å€¤ã¯æ­£ã—ã„ã§ã™ã‹?",
          sections: [
            {
              heading: "What It Measures:",
              text: "Agreement between predicted probabilities and observed event rates. Among patients predicted 20% risk, do 20% actually have events?"
            },
            {
              heading: "Calibration-in-the-Large:",
              text: "Overall: Does the model predict the right NUMBER of events? If 100 events are predicted but 60 occur, the model overestimates (P/O = 1.67)."
            },
            {
              heading: "Calibration Slope:",
              items: [
                "Regress observed outcomes on predicted probabilities",
                "Ideal slope = 1.0 (perfect agreement)",
                "Slope < 1.0: Predictions too extreme (overfitting)",
                "Slope > 1.0: Predictions too conservative"
              ]
            },
            {
              heading: "Calibration Plot:",
              items: [
                "X-axis: Predicted probability (deciles or smooth)",
                "Y-axis: Observed event rate",
                "Perfect calibration: Points on 45-degree line",
                "ãƒ¢ãƒ‡ãƒ«æ¤œè¨¼ã«ä¸å¯æ¬ ãªã‚°ãƒ©ãƒ•ã‚£ãƒƒã‚¯"
              ]
            }
          ]
        }
      },
      {
        type: 'method',
        content: {
          label: "æ–¹æ³•: ã‚­ãƒ£ãƒªãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãƒ—ãƒ­ãƒƒãƒˆã®èª­ã¿å–ã‚Š",
          title: "Patterns and What They Mean",
          sections: [
            {
              heading: "Perfect Calibration:",
              text: "ã™ã¹ã¦ã®ç‚¹ãŒå¯¾è§’ç·šä¸Šã«ã‚ã‚Šã¾ã™ã€‚äºˆæ¸¬ 10% â†’ è¦³æ¸¬å€¤ 10%ã€‚äºˆæ¸¬ 50% â†’ è¦³æ¸¬ 50%ã€‚ã“ã‚ŒãŒç›®æ¨™ã§ã™ã€‚"
            },
            {
              heading: "Overestimation (Above Diagonal):",
              text: "Predicted risks too HIGH. Model says 30% but observed is 20%. Framingham in Europe. Leads to overtreatment."
            },
            {
              heading: "Underestimation (Below Diagonal):",
              text: "Predicted risks too LOW. Model says 10% but observed is 15%. Leads to undertreatment. Patients falsely reassured."
            },
            {
              heading: "Poor Calibration Slope:",
              text: "Predictions too SPREAD OUT (slope < 1) or too NARROW (slope > 1). Low-risk too low, high-risk too high = overfitting."
            },
            {
              heading: "Recalibration:",
              text: "If discrimination is good but calibration poor, RECALIBRATE: update intercept (baseline risk) and/or slope (coefficient shrinkage) to fit local population."
            }
          ]
        }
      },
      {
        type: 'decision-tree',
        content: {
          id: 'discrimination-calibration',
          title: "Discrimination vs Calibration",
          situation: "You're evaluating two ICU mortality models for your hospital.\n\nModel A: C-statistic 0.85, but predicts 40% mortality when your observed rate is 25%.\nModel B: C-statistic 0.72, but calibration is excellent (predicted/observed = 1.02).",
          nodes: {
            start: {
              question: "æ‚£è€…ã¨ã®ã‚³ãƒŸãƒ¥ãƒ‹ã‚±ãƒ¼ã‚·ãƒ§ãƒ³ (ãƒªã‚¹ã‚¯ã‚’æ‚£è€…ã«ä¼ãˆã‚‹) ã«ã¯ã©ã®ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã‹?",
              branches: [
                { text: "Model A â€” better discrimination", nextNode: "model_a_comm" },
                { text: "Model B â€” better calibration", nextNode: "model_b_comm_correct" }
              ]
            },
            model_a_comm: {
              type: 'outcome',
              outcome: 'danger',
              title: "Patients would get wrong numbers!",
              text: "ãƒ¢ãƒ‡ãƒ« A ã¯ã€å®Ÿéš›ã«ã¯ 25% ã§ã‚ã‚‹ãƒªã‚¹ã‚¯ã‚’æ‚£è€…ã« 40% ã¨ä¼ãˆã¾ã™ã€‚ã“ã‚Œã¯ä¸å¿…è¦ãªè‹¦ç—›ã‚’å¼•ãèµ·ã“ã—ã€ç©æ¥µçš„ãªæ²»ç™‚ã®æ±ºå®šã«å½±éŸ¿ã‚’ä¸ãˆã€å®¶æ—ã‚’èª¤è§£ã•ã›ã¾ã™ã€‚ã‚³ãƒŸãƒ¥ãƒ‹ã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã«ã¯ã‚­ãƒ£ãƒªãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãŒä¸å¯æ¬ ã§ã™ã€‚æ­£ã—ã„æ•°å€¤ãŒå¿…è¦ã§ã™ã€‚",
              lesson: "Patient communication requires calibrated probabilities. Telling someone '40% chance of death' when it's really 25% is harmful misinformation."
            },
            model_b_comm_correct: {
              situation: "Correct! For telling patients their risk, calibration matters most.",
              question: "Now: which model should you use to TRIAGE patients (decide who gets ICU vs step-down)?",
              branches: [
                { text: "Model A â€” better discrimination for ranking patients", nextNode: "model_a_triage_correct" },
                { text: "Model B â€” still need correct numbers", nextNode: "model_b_triage" }
              ]
            },
            model_a_triage_correct: {
              type: 'outcome',
              outcome: 'success',
              title: "Correct â€” for ranking, discrimination matters!",
              text: "Triage is about ranking: who is higher risk? Model A (C=0.85) better separates sick from less-sick patients. You don't need the exact probability to rank. Model A's miscalibration doesn't affect who gets ranked higher vs lower.",
              lesson: "ã‚¿ã‚¹ã‚¯ãŒæŒ‡æ¨™ã‚’æ±ºå®šã—ã¾ã™: ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã«ã¯è­˜åˆ¥ãŒå¿…è¦ã§ã™ã€‚ç¢ºç‡ã¯èª¿æ•´ãŒå¿…è¦ã§ã™ã€‚ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’è‡¨åºŠä¸Šã®è³ªå•ã«ä¸€è‡´ã•ã›ã¾ã™ã€‚"
            },
            model_b_triage: {
              type: 'outcome',
              outcome: 'partial',
              title: "Calibration is less critical for ranking",
              text: "For triage, you're RANKING patients, not quoting probabilities. Model A separates high-risk from low-risk better (C=0.85 vs 0.72). Even though Model A's numbers are off, its RANKINGS are better. Use A for triage, B for communication.",
              lesson: "ç•°ãªã‚‹è‡¨åºŠã‚¿ã‚¹ã‚¯ã«ã¯ã€ç•°ãªã‚‹ãƒ¢ãƒ‡ãƒ« ãƒ—ãƒ­ãƒ‘ãƒ†ã‚£ãŒå¿…è¦ã§ã™ã€‚å¤šãã®ãƒ¢ãƒ‡ãƒ«ã¯è¤‡æ•°ã®ç›®çš„ã«ä½¿ç”¨ã•ã‚Œã¾ã™ã€‚ãã‚Œãã‚Œã®ä½¿ç”¨ã«ä½•ãŒå¿…è¦ã‹ã‚’ç†è§£ã—ã¦ãã ã•ã„ã€‚"
            }
          }
        }
      },
      {
        type: 'decision-tree',
        content: {
          id: 'calibration-plot-reading',
          title: "Reading Calibration Plots",
          situation: "æ¤œè¨¼ç ”ç©¶ã‚’ãƒ¬ãƒ“ãƒ¥ãƒ¼ã—ã¦ã„ã¾ã™ã€‚ã‚­ãƒ£ãƒªãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ ãƒ—ãƒ­ãƒƒãƒˆã¯ä»¥ä¸‹ã‚’ç¤ºã—ã¾ã™ã€‚ â€¢ ååˆ†ä½ 1 (äºˆæ¸¬ 5%): å®Ÿæ¸¬ 8% â€¢ ååˆ†ä½ 5 (äºˆæ¸¬ 25%): å®Ÿæ¸¬ 24% â€¢ ååˆ†ä½ 10 (äºˆæ¸¬ 60%): å®Ÿæ¸¬ 45% ç‚¹ã¯ã€ä½ãƒªã‚¹ã‚¯ã§ã¯å¯¾è§’ç·šã®ä¸‹ã§å§‹ã¾ã‚Šã€é«˜ãƒªã‚¹ã‚¯ã§ã¯å¯¾è§’ç·šã®ä¸Šã§äº¤å·®ã™ã‚‹æ›²ç·šã‚’å½¢æˆã—ã¾ã™ã€‚",
          nodes: {
            start: {
              question: "What pattern does this calibration plot show?",
              branches: [
                { text: "Overestimation â€” predictions too high overall", nextNode: "over_wrong" },
                { text: "Poor slope â€” predictions too extreme", nextNode: "slope_correct" },
                { text: "Good calibration â€” points are close to diagonal", nextNode: "good_wrong" }
              ]
            },
            over_wrong: {
              type: 'outcome',
              outcome: 'partial',
              title: "Look at the pattern more carefully",
              text: "At LOW predicted risk (5%), observed was HIGHER (8%) â€” that's underestimation. At HIGH predicted risk (60%), observed was LOWER (45%) â€” that's overestimation. The model isn't consistently over- or under-estimating; it's making predictions that are too EXTREME.",
              lesson: "ã‚­ãƒ£ãƒªãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã®å•é¡Œã«ã¯ã•ã¾ã–ã¾ãªãƒ‘ã‚¿ãƒ¼ãƒ³ãŒã‚ã‚Šã¾ã™ã€‚å‡ä¸€ãªéå¤§/éå°è©•ä¾¡ã¯ã€å‚¾ãã®å•é¡Œã¨ã¯ç•°ãªã‚Šã¾ã™ã€‚"
            },
            slope_correct: {
              situation: "Correct! Low predictions too low, high predictions too high = slope < 1 (overfitting). Now:",
              question: "ã‚­ãƒ£ãƒªãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å‚¾ãã¯ 0.65 ã¨ã—ã¦è¨ˆç®—ã•ã‚Œã¾ã™ã€‚ãƒ¢ãƒ‡ãƒ«ã‚’ã©ã®ã‚ˆã†ã«å†èª¿æ•´ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã‹?",
              branches: [
                { text: "Multiply all predicted probabilities by 0.65", nextNode: "multiply_wrong" },
                { text: "äºˆæ¸¬ã‚’å¹³å‡å€¤ã«å‘ã‘ã¦ç¸®å°ã—ã¾ã™ (å‚¾ãèª¿æ•´ã‚’ä½¿ç”¨ã—ã¦å†æ¨å®šã—ã¾ã™)ã€‚", nextNode: "shrink_correct" }
              ]
            },
            good_wrong: {
              type: 'outcome',
              outcome: 'danger',
              title: "ã“ã‚Œã‚‰ã®é€¸è„±ã¯è‡¨åºŠçš„ã«é‡å¤§ã§ã™!",
              text: "äºˆæ¸¬å€¤ã¯ 5% ã§ã€å®Ÿæ¸¬å€¤ã¯ 8% ã§ã€äºˆæ¸¬å€¤ã‚ˆã‚Š 60% é«˜ããªã‚Šã¾ã™ã€‚äºˆæ¸¬å€¤ãŒ 60% ã®å ´åˆã€è¦³æ¸¬å€¤ã¯ 45% ã§ã‚ã‚Šã€ã“ã‚Œã¯ 25% ä½ã„ã§ã™ã€‚è‡¨åºŠä¸Šã®æ±ºå®šã«ãŠã„ã¦ã€å®Ÿéš›ã«ã¯ 45% ã§ã‚ã‚‹ã«ã‚‚ã‹ã‹ã‚ã‚‰ãšã€æ‚£è€…ã«ã€Œæ­»äº¡ãƒªã‚¹ã‚¯ã¯ 60%ã€ã¨ä¼ãˆã‚‹ã“ã¨ã¯ã€é‡å¤§ãªå®³ã‚’ã‚‚ãŸã‚‰ã—ã¾ã™ã€‚ã“ã‚Œã‚‰ã¯å°ã•ãªåå·®ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚",
              lesson: "çµ¶å¯¾çš„ã«ã¯ã€Œå°ã•ã„ã€ã‚ˆã†ã«è¦‹ãˆã‚‹ã‚­ãƒ£ãƒªãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³åå·®ã‚‚ã€ç›¸å¯¾çš„ã«ã¯å¤§ããã€è‡¨åºŠçš„ã«é‡è¦ã§ã‚ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚"
            },
            multiply_wrong: {
              type: 'outcome',
              outcome: 'danger',
              title: "That would make things worse!",
              text: "ã™ã¹ã¦ã®äºˆæ¸¬ã‚’ 0.65 ã§ä¹—ç®—ã™ã‚‹ã¨ã€ã™ã¹ã¦ã®äºˆæ¸¬ãŒä½ããªã‚Šã¾ã™ã€‚ã—ã‹ã—ã€ä½ã„äºˆæ¸¬ã¯ã™ã§ã«ä½ã™ãã¾ã™ã€‚äºˆæ¸¬ã‚’å¹³å‡å€¤ã«å‘ã‹ã£ã¦ç¸®å°ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚é«˜ã„äºˆæ¸¬ã¯ä¸‹ã’ã€ä½ã„äºˆæ¸¬ã¯ä¸Šã’ã¾ã™ã€‚ã“ã‚Œã«ã¯ã€å‹¾é…åˆ¶ç´„ã‚’ä½¿ç”¨ã—ã¦å†æ¨å®šã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚",
              lesson: "å‹¾é…ã®å†èª¿æ•´ â‰  å˜ç´”ãªä¹—ç®—ã€‚ã‚¼ãƒ­ã«å‘ã‹ã£ã¦ã§ã¯ãªãã€å¹³å‡ã«å‘ã‹ã£ã¦ç¸®å°ã—ã¾ã™ã€‚"
            },
            shrink_correct: {
              type: 'outcome',
              outcome: 'success',
              title: "Correct recalibration approach!",
              text: "With slope 0.65, you need to shrink predictions toward the mean outcome rate. Mathematically: calibrated_logit = intercept + 0.65 Ã— (original_logit). This pulls extreme predictions toward the center. Low-risk predictions increase; high-risk predictions decrease.",
              lesson: "å‚¾ãã®å†èª¿æ•´ã«ã‚ˆã‚Šã€äºˆæ¸¬ãŒå¹³å‡ã«å‘ã‹ã£ã¦ç¸®å°ã—ã¾ã™ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€ãƒ¢ãƒ‡ãƒ«ãŒä¸¡æ¥µç«¯ã§è‡ªä¿¡ã‚’æŒã¡ã™ããŸéå‰°é©åˆãƒ‘ã‚¿ãƒ¼ãƒ³ãŒä¿®æ­£ã•ã‚Œã¾ã™ã€‚"
            }
          }
        }
      },
      {
        type: 'content',
        content: {
          title: "Communicating Uncertainty to Patients",
          sections: [
            {
              heading: "Why This Matters:",
              text: "Prognostic models ultimately serve patients. A perfectly calibrated model is useless if clinicians can't communicate its outputs clearly. Miscommunication causes as much harm as miscalibration."
            },
            {
              heading: "Phrases That Help:",
              items: [
                "\"Based on patients similar to you...\" (acknowledges model basis)",
                "\"This estimate has uncertainty â€” it could be somewhat higher or lower\" (conveys CI)",
                "\\ã€Œã“ã‚Œã¯ç¢ºç‡ã§ã‚ã‚Šã€ç¢ºå®Ÿæ€§ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚ä¸€éƒ¨ã®æ‚£è€…ã¯äºˆæƒ³ã‚’æ‰“ã¡ç ´ã‚Šã¾ã™\\\" (æ±ºå®šè«–ã‚’å›é¿ã—ã¾ã™)",
                "\\\"ã“ã‚Œã¯ã€å°†æ¥ã‚’æ­£ç¢ºã«äºˆæ¸¬ã™ã‚‹ã®ã§ã¯ãªãã€ä¸€ç·’ã«æ±ºå®šã™ã‚‹ã®ã«å½¹ç«‹ã¡ã¾ã™\\\" (å…±æœ‰æ„æ€æ±ºå®š)",
                "\\ã€Œã‚ãªãŸã®ã‚ˆã†ãªæ‚£è€…ãŒ 100 äººè¿½è·¡ã•ã‚ŒãŸã‚‰...\\ã€ (å‘¨æ³¢æ•°ãƒ•ãƒ¬ãƒ¼ãƒŸãƒ³ã‚°)"
              ]
            },
            {
              heading: "Phrases to Avoid:",
              items: [
                "\"You have a 73% chance of...\" (false precision)",
                "\"The computer says...\" (abdicates responsibility)",
                "\\ã€Œã‚ãªãŸã¯ç”Ÿãæ®‹ã‚‹/ç”Ÿãæ®‹ã‚Œãªã„\\ã€ (æ±ºå®šè«–çš„è¨€èª)",
                "\\ã€Œæ•°å­—ã¯æ°—ã«ã—ãªã„ã§ãã ã•ã„ã€ (å¦å®šçš„)",
                "\"This is just a rough estimate\" (undermines useful information)"
              ]
            },
            {
              heading: "Handling Uncertainty:",
              text: "When the model says 30% (95% CI: 20-45%), you might say: 'Based on similar patients, the risk is probably between 1 in 5 and 1 in 2, with our best estimate around 1 in 3. This helps us think about whether aggressive treatment is right for you.'"
            },
            {
              heading: "When Models Conflict with Gestalt:",
              text: "If clinical intuition strongly disagrees with the model, acknowledge it: 'The calculator suggests X, but based on factors it doesn't capture, I think Y is more likely. Let's discuss both perspectives.'"
            }
          ]
        }
      },
      {
        type: 'content',
        content: {
          title: "Competing Risks: The Hidden Complexity",
          sections: [
            {
              heading: "The Problem:",
              text: "æ¨™æº–çš„ãªç”Ÿå­˜åˆ†æã§ã¯ã€æ‚£è€…ãŒã‚¤ãƒ™ãƒ³ãƒˆã‚’èµ·ã“ã—ãŸã‹ã€æ‰“ã¡åˆ‡ã‚‰ã‚ŒãŸ(è¿½è·¡ä¸èƒ½ã«ãªã£ãŸ)ã‹ã®ã„ãšã‚Œã‹ã‚’æƒ³å®šã—ã¦ã„ã¾ã™ã€‚ã—ã‹ã—ã€ã‚¤ãƒ™ãƒ³ãƒˆãŒç™ºç”Ÿã™ã‚‹å‰ã«å½¼ã‚‰ãŒæ­»äº¡ã—ãŸå ´åˆã¯ã©ã†ãªã‚‹ã§ã—ã‚‡ã†ã‹?æ­»ã¯é–¢å¿ƒã®ã‚ã‚‹çµæœã¨ã€Œç«¶åˆã€ã—ã¾ã™ã€‚"
            },
            {
              heading: "Example:",
              text: "You're predicting hip fracture in elderly patients. A patient dies of heart disease at month 6. They didn't have a hip fracture â€” but they also can't have one in the future. Standard Kaplan-Meier treats them as censored, which OVERESTIMATES fracture risk in survivors."
            },
            {
              heading: "When It Matters:",
              items: [
                "Elderly populations (high competing mortality)",
                "Cancer patients (death competes with recurrence)",
                "Long time horizons (more time for competing events)",
                "Non-fatal outcomes in sick populations"
              ]
            },
            {
              heading: "Solutions:",
              items: [
                "Cause-specific hazards: Model each event separately (traditional)",
                "Subdistribution hazards (Fine-Gray): Accounts for competing risks directly",
                "Multi-state models: Explicitly model transitions between states",
                "Report cumulative incidence, not 1-KM (acknowledges competing risks)"
              ]
            },
            {
              heading: "For Reviewers:",
              text: "When reading prognostic studies in elderly/sick populations with non-fatal outcomes, ask: 'How did they handle competing risks?' If the answer is 'standard Cox/KM,' the predictions may be biased upward."
            }
          ]
        }
      },
      {
        type: 'quiz',
        content: {
          question: "ãƒ¢ãƒ‡ãƒ«ã® C çµ±è¨ˆå€¤ã¯ 0.75ã€ã‚­ãƒ£ãƒªãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å‹¾é…ã¯ 0.6 ã§ã™ã€‚ã“ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã¯ä½•ã‚’ç¤ºå”†ã—ã¦ã„ã¾ã™ã‹?",
          options: [
            { id: 'a', text: "Good discrimination but predictions are too extreme (overfitting)", correct: true },
            { id: 'b', text: "Poor discrimination and poor calibration overall", correct: false },
            { id: 'c', text: "ãƒ¢ãƒ‡ãƒ«ã¯å…¨å“¡ã®ãƒªã‚¹ã‚¯ã‚’éå°è©•ä¾¡ã—ã¦ã„ã¾ã™", correct: false },
            { id: 'd', text: "The model needs more predictors", correct: false }
          ],
          explanation: "C = 0.75 indicates acceptable discrimination. Calibration slope of 0.6 (< 1.0) means predictions are too spread out: high-risk predictions are too high, low-risk predictions are too low. This is the classic pattern of overfitting â€” the model fits noise in development data, producing extreme predictions that don't generalize."
        }
      },
      {
        type: 'principle',
        content: {
          text: "ğŸ¯ PROGRESS CHECK: You now understand model performance dimensions AND how to communicate them. Discrimination (C-statistic) = ranking ability. Calibration = probability accuracy. Patient communication requires translating numbers into meaningful, honest conversations. Competing risks matter in elderly/sick populations with non-fatal outcomes."
        }
      }
    ]
  }
,
  {
    id: 4,
    title: "The Validation",
    subtitle: "Internal & External Testing",
    principle: 3,
    estimatedTime: "40 min",
    slides: [
      {
        type: 'principle-display',
        content: {
          principle: "äºˆæ¸¬å¤‰æ•°ãŒå¤šã„ã»ã©è‰¯ã„ã¨ã„ã†ã‚ã‘ã§ã¯ã‚ã‚Šã¾ã›ã‚“"
        }
      },
      {
        type: 'story-deep',
        content: {
          label: "THE EPIC FAILURE: SEPSIS AI â€” WHEN SILICON VALLEY MET REALITY",
          source: "Wong et al. JAMA Intern Med 2021 | Epic Sepsis Model | External validation",
          timeline: [
            { year: "2017", text: "Epic Systems develops machine learning model for sepsis prediction. Deployed in hundreds of hospitals. Marketing claims strong performance.", type: "normal" },
            { year: "2019", text: "Epic model in widespread clinical use. Alerts firing. Clinicians responding. Assumed to be saving lives.", type: "normal" },
            { year: "2021", text: "Wong et al. publish external validation at Michigan Medicine. C-statistic: 0.63 (poor). PPV at common threshold: 12%. Only 7% of sepsis cases detected.", type: "crisis" },
            { year: "The Gap", text: "Epic's internal 'validation' C = 0.76-0.83. Independent external: C = 0.63. The model performed FAR WORSE in real-world deployment than internal testing suggested.", type: "crisis" },
            { year: "Root Cause", text: "å†…éƒ¨æ¤œè¨¼ã§ã¯åŒã˜ãƒ‡ãƒ¼ã‚¿ ã‚½ãƒ¼ã‚¹ã¨åŒæ§˜ã®æ¯é›†å›£ãŒä½¿ç”¨ã•ã‚Œã¾ã—ãŸã€‚å°å…¥å‰ã«çœŸã®å¤–éƒ¨æ¤œè¨¼ã¯è¡Œã‚ã‚Œã¾ã›ã‚“ã€‚ãƒ™ãƒ³ãƒ€ãƒ¼ã®ä¸»å¼µã«åŸºã¥ã„ã¦å°å…¥ã•ã‚ŒãŸã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã€‚", type: "revelation" },
            { year: "Lesson", text: "æ©Ÿæ¢°å­¦ç¿’ã¯é­”æ³•ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚ç‹¬è‡ªã®ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã¯ã€è‡¨åºŠå°å…¥å‰ã«ç‹¬ç«‹ã—ãŸå¤–éƒ¨æ¤œè¨¼ãŒå¿…è¦ã§ã™ã€‚ãƒ™ãƒ³ãƒ€ãƒ¼ã®æŒ‡æ¨™ã¯è¨¼æ‹ ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚", type: "revelation" }
          ],
          realData: {
            endpoint: "Sepsis onset within 6 hours",
            internal: "C-statistic 0.76-0.83 (Epic's claim)",
            external: "C-statistic 0.63 (independent validation)",
            ppv: "12% at alert threshold"
          },
          hook: "THE HOOK: A proprietary algorithm was deployed in hundreds of hospitals based on vendor-provided metrics. Independent validation revealed it barely worked. Patients received thousands of false alerts while 93% of actual sepsis cases were missed. This is why external validation by INDEPENDENT researchers is essential."
        }
      },
      {
        type: 'principle',
        content: {
          text: "â¸ï¸ KEY INSIGHT: Validation has levels. INTERNAL validation (same data) catches obvious overfitting. EXTERNAL validation (new data, new setting) tests generalizability. INDEPENDENT validation (different researchers) catches selective reporting and hidden biases. All three matter."
        }
      },
      {
        type: 'content',
        content: {
          title: "Types of Validation",
          sections: [
            {
              heading: "Internal Validation (Same Data):",
              items: [
                "Bootstrap: Resample with replacement, train and test many times",
                "Cross-validation: Divide data into folds, train on k-1, test on 1, rotate",
                "Split-sample: Train on 70%, test on 30% (weak, wastes data)",
                "Purpose: Estimate optimism from overfitting. MINIMUM requirement."
              ]
            },
            {
              heading: "External Validation (New Data):",
              items: [
                "TEMPORAL: Different time period, same setting",
                "GEOGRAPHIC: Different location, same time period",
                "DOMAIN: Different patient population or clinical context",
                "Purpose: Test generalizability. Required before clinical use."
              ]
            },
            {
              heading: "Independent Validation:",
              items: [
                "Different research team conducts the validation",
                "Eliminates selective reporting, hidden specification searches",
                "ç¾å®Ÿä¸–ç•Œã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’çœŸã«ãƒ†ã‚¹ãƒˆã™ã‚‹å”¯ä¸€ã®æ¤œè¨¼",
                "Should be required for any high-stakes model deployment"
              ]
            }
          ]
        }
      },
      {
        type: 'story-deep',
        content: {
          label: "REAL-WORLD CASE: THE APACHE SCORE MISADVENTURE â€” WHEN GEOGRAPHY FOOLED EVERYONE",
          source: "APACHE II validation studies | UK Intensive Care Society | Geographic transportability",
          timeline: [
            { year: "1985", text: "APACHE II is developed in US academic medical centers to predict ICU mortality. Based on 5,815 admissions across 13 hospitals. Excellent discrimination.", type: "normal" },
            { year: "Late 1980s", text: "APACHE II becomes the standard for ICU risk adjustment. Hospitals compare their outcomes to APACHE-predicted mortality. 'Better than expected' = quality marker.", type: "normal" },
            { year: "UK Adoption", text: "British hospitals adopt APACHE II for quality benchmarking. The model predicts mortality; actual deaths are compared. Nearly every UK hospital appears to outperform expectations.", type: "crisis" },
            { year: "The Problem", text: "APACHE II ã¯ã€ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³æ­»äº¡ç‡ãŒé«˜ã„ 1980 å¹´ä»£ã®ã‚¢ãƒ¡ãƒªã‚«ã® ICU ã«åˆã‚ã›ã¦èª¿æ•´ã•ã‚Œã¦ã„ã¾ã™ã€‚è‹±å›½ã® ICU ã¯ç•°ãªã‚‹ç—‡ä¾‹æ§‹æˆã€æ—©æœŸã®å…¥é™¢åŸºæº–ã€ã‚ˆã‚Šè‰¯ã„è»¢å¸°ã‚’æŒã£ã¦ã„ã¾ã—ãŸã€‚ãƒ¢ãƒ‡ãƒ«ã®åˆ†æ¯ãŒé–“é•ã£ã¦ã„ã¾ã—ãŸã€‚", type: "revelation" },
            { year: "False Reassurance", text: "Hospitals celebrated 'beating' APACHE predictions. But they were being compared to an irrelevant baseline. Poor performers looked adequate; adequate performers looked excellent.", type: "crisis" },
            { year: "Lesson", text: "Geographic external validation isn't just about discrimination â€” it's about CALIBRATION TO LOCAL CONTEXT. A model developed in one healthcare system may systematically mispredict in another. <span class='lesson-gold'>THE LESSON: When a model makes every hospital look good, ask whether the model fits your population â€” or whether you're being fooled by geographic miscalibration.</span>", type: "revelation" }
          ],
          realData: {
            endpoint: "ICU mortality",
            model: "APACHE II (US-developed)",
            problem: "Systematic overestimation in UK",
            consequence: "False reassurance about hospital quality"
          },
          hook: "THE HOOK: APACHE II was a valid model in the wrong context. Its discrimination worked fine â€” it still ranked patients correctly by risk. But its CALIBRATION was anchored to American ICU mortality rates. When UK hospitals used it as a benchmark, they were measuring themselves against the wrong yardstick. Geographic validation without recalibration is a recipe for false confidence."
        }
      },
      {
        type: 'method',
        content: {
          label: "æ–¹æ³•: æ¤œè¨¼ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼",
          title: "å³å¯†ãªæ¤œè¨¼ã®æ‰‹é †",
          sections: [
            {
              heading: "1. Obtain Completely Independent Data:",
              text: "â€¢ ç•°ãªã‚‹æ™‚é–“ã€å ´æ‰€ã€æ©Ÿé–¢ â€¢ é–‹ç™ºãƒ‡ãƒ¼ã‚¿ã¨ã®é‡è¤‡ãªã— â€¢ ä½¿ç”¨ç›®çš„ã®æ¯é›†å›£ã‚’åæ˜  â€¢ ä¿¡é ¼æ€§ã®é«˜ã„æ¨å®šã‚’è¡Œã†ã®ã«ååˆ†ãªã‚¤ãƒ™ãƒ³ãƒˆ (100 ã‚¤ãƒ™ãƒ³ãƒˆä»¥ä¸Š)ç†æƒ³çš„)"
            },
            {
              heading: "2. Apply Model EXACTLY as Developed:",
              text: "â€¢ åŒã˜äºˆæ¸¬å­ã®å®šç¾© â€¢ åŒã˜å¤‰æ•°ã®å‡¦ç† (æ¬ æãƒ‡ãƒ¼ã‚¿ã€ã‚«ãƒƒãƒˆã‚ªãƒ•) â€¢ å†ãƒ•ã‚£ãƒƒãƒ†ã‚£ãƒ³ã‚°ã‚„å¤‰æ›´ã¯ä¸è¦ â€¢ ãƒ¢ãƒ‡ãƒ«ã¯ã€Œã™ãã«ã€æ©Ÿèƒ½ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™"
            },
            {
              heading: "3. Assess Discrimination:",
              text: "â€¢ Calculate C-statistic with 95% CI\nâ€¢ Compare to development performance\nâ€¢ Drop of >0.05 suggests poor generalizability"
            },
            {
              heading: "4. Assess Calibration:",
              text: "â€¢ Calibration plot (essential)\nâ€¢ Calibration-in-the-large (P/O ratio)\nâ€¢ Calibration slope\nâ€¢ Hosmer-Lemeshow test (limited value)"
            },
            {
              heading: "5. Consider Updating If Needed:",
              text: "â€¢ If discrimination OK but calibration poor â†’ recalibrate\nâ€¢ If discrimination poor â†’ model may need redevelopment\nâ€¢ Update intercept for new baseline rates\nâ€¢ Update slope if predictions too extreme"
            }
          ]
        }
      },
      {
        type: 'method',
        content: {
          label: "DEEP DIVE: MODEL UPDATING & RECALIBRATION",
          title: "When and How to Update Existing Models",
          sections: [
            {
              heading: "Why Update Rather Than Rebuild?",
              text: "æ–°ã—ã„ãƒ¢ãƒ‡ãƒ«ã®æ§‹ç¯‰ã«ã¯ã€å¤§è¦æ¨¡ãªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¨åºƒç¯„ãªæ¤œè¨¼ãŒå¿…è¦ã§ã™ã€‚æ—¢å­˜ã®ãƒ¢ãƒ‡ãƒ«ã¯é©åˆ‡ã«è­˜åˆ¥ã•ã‚Œã¦ã„ã‚‹ãŒã‚­ãƒ£ãƒªãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’èª¤ã£ã¦ã„ã‚‹å ´åˆã€UPDATING ã¯ã‚­ãƒ£ãƒªãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’ä¿®æ­£ã—ãªãŒã‚‰ã€æ¤œè¨¼ã•ã‚ŒãŸæ§‹é€ ã‚’ä¿æŒã—ã¾ã™ã€‚å¤šãã®å ´åˆã€ã“ã‚Œã¯æœ€åˆã‹ã‚‰é–‹å§‹ã™ã‚‹ã‚ˆã‚Šã‚‚å®‰å…¨ã§ã™ã€‚"
            },
            {
              heading: "Level 1: Intercept-Only Recalibration",
              text: "â€¢ Simplest update: adjust baseline risk only\nâ€¢ Use when: Model systematically over/under-estimates by a constant factor\nâ€¢ Method: Re-estimate intercept using local event rate\nâ€¢ Formula: new_intercept = log(local_odds) - mean(linear_predictor)\nâ€¢ Preserves all coefficients; only shifts predictions up/down"
            },
            {
              heading: "Level 2: Slope + Intercept Recalibration",
              text: "â€¢ Adjusts both baseline and spread of predictions\nâ€¢ Use when: Calibration slope â‰  1 (overfitting pattern)\nâ€¢ Method: Regress outcomes on linear predictor; use resulting intercept and slope\nâ€¢ Shrinks extreme predictions toward mean\nâ€¢ Often needed when applying models to new populations"
            },
            {
              heading: "Level 3: Model Revision (Re-estimation)",
              text: "â€¢ Re-estimate some or all coefficients\nâ€¢ Use when: Predictor effects differ substantially in new population\nâ€¢ Method: Start with original coefficients as priors; update with local data\nâ€¢ Bayesian approaches can combine original and new evidence\nâ€¢ Requires larger local dataset than simple recalibration"
            },
            {
              heading: "Level 4: Model Extension",
              text: "â€¢ æ—¢å­˜ã®ãƒ¢ãƒ‡ãƒ«ã«æ–°ã—ã„äºˆæ¸¬å­ã‚’è¿½åŠ ã™ã‚‹ â€¢ ä½¿ç”¨ã™ã‚‹å ´åˆ: æ–°ã—ã„ãƒã‚¤ã‚ªãƒãƒ¼ã‚«ãƒ¼ã¾ãŸã¯ãƒªã‚¹ã‚¯å› å­ãŒåˆ©ç”¨å¯èƒ½ã§ã‚ã‚‹ â€¢ æ–¹æ³•: å…ƒã®æ§‹é€ ã‚’ç¶­æŒã—ãªãŒã‚‰æ–°ã—ã„é …ã‚’è¿½åŠ ã™ã‚‹ â€¢ æ‹¡å¼µãƒ¢ãƒ‡ãƒ«ã‚’å¤–éƒ¨ã§æ¤œè¨¼ã™ã‚‹å¿…è¦ãŒã‚ã‚‹ â€¢ ãƒªã‚¹ã‚¯: æ–°ã—ã„äºˆæ¸¬å­ã¯ã‚·ã‚°ãƒŠãƒ«ã§ã¯ãªããƒã‚¤ã‚ºã‚’è¿½åŠ ã™ã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹"
            },
            {
              heading: "Decision Framework:",
              text: "Discrimination OK + Calibration-in-large off â†’ Level 1\nDiscrimination OK + Slope off â†’ Level 2\nDiscrimination reduced + Some predictors off â†’ Level 3\nNew predictors available â†’ Consider Level 4\nDiscrimination poor across predictors â†’ Rebuild from scratch"
            }
          ]
        }
      },
      {
        type: 'decision-tree',
        content: {
          id: 'model-updating-decision',
          title: "æ›´æ–°ã™ã‚‹å¿…è¦ãŒã‚ã‚‹ã‹å†æ§‹ç¯‰ã—ã¾ã™ã‹?",
          situation: "Framingham Risk Score is validated at your Asian hospital. Results:\nâ€¢ C-statistic: 0.78 (vs 0.79 in original) â€” discrimination preserved\nâ€¢ Predicted/Observed events: 1.85 â€” model predicts 85% more events than occur\nâ€¢ Calibration slope: 0.95 â€” close to 1.0\n\nThe model systematically overestimates, but rankings are correct.",
          nodes: {
            start: {
              question: "What type of update is most appropriate?",
              branches: [
                { text: "Rebuild a new model for Asian populations", nextNode: "rebuild_wrong" },
                { text: "Level 1: Intercept-only recalibration", nextNode: "level1_correct" },
                { text: "Level 2: Slope + intercept recalibration", nextNode: "level2_partial" }
              ]
            },
            rebuild_wrong: {
              type: 'outcome',
              outcome: 'danger',
              title: "ã“ã®å•é¡Œã«ã¯ã‚„ã‚Šã™ãã§ã™!",
              text: "Discrimination is excellent (0.78) â€” the model ranks patients correctly. The slope is 0.95 â€” predictions aren't too extreme. The only problem is SYSTEMATIC overestimation (P/O = 1.85). This is exactly what intercept recalibration fixes. Rebuilding wastes the validated structure.",
              lesson: "å†èª¿æ•´ã§ãã‚‹ã‚‚ã®ã¯å†æ§‹ç¯‰ã—ãªã„ã§ãã ã•ã„ã€‚è­˜åˆ¥ã¨å‚¾ããŒè‰¯å¥½ã§ã‚ã‚Œã°ã€åˆ‡ç‰‡èª¿æ•´ã§ååˆ†ã§ã™ã€‚"
            },
            level1_correct: {
              type: 'outcome',
              outcome: 'success',
              title: "Perfect choice!",
              text: "C-statistic preserved + slope ~1.0 + systematic over-prediction = Level 1 (intercept-only) recalibration. Simply adjust the baseline risk to reflect lower CVD rates in your Asian population. All the hard work (validated predictors, coefficients) is preserved.",
              lesson: "ã‚¤ãƒ³ã‚¿ãƒ¼ã‚»ãƒ—ãƒˆã®å†èª¿æ•´ã¯å¼·åŠ›ã‹ã¤ç°¡å˜ã§ã™ã€‚ãƒ¢ãƒ‡ãƒ«ãŒç³»çµ±çš„ã«éå¤§è©•ä¾¡ã¾ãŸã¯éå°è©•ä¾¡ã—ã¦ã„ã‚‹å ´åˆã«æœ€åˆã«è©¦è¡Œã™ã‚‹ã®ãŒã“ã‚Œã§ã™ã€‚"
            },
            level2_partial: {
              type: 'outcome',
              outcome: 'partial',
              title: "Would work, but more than needed",
              text: "ãƒ¬ãƒ™ãƒ« 2 ã§ã¯ã€åˆ‡ç‰‡ã¨å‚¾ãã®ä¸¡æ–¹ãŒèª¿æ•´ã•ã‚Œã¾ã™ã€‚ã—ã‹ã—ã€å‚¾ãã¯ã™ã§ã« 0.95 (æœ¬è³ªçš„ã«ã¯ 1.0) ã§ã™ã€‚äºˆæ¸¬ã¯ãã‚Œã»ã©æ¥µç«¯ã§ã¯ãªãã€ä½“ç³»çš„ã«é«˜ã„ã ã‘ã§ã™ã€‚ãƒ¬ãƒ™ãƒ« 1 ã¯ã‚ˆã‚Šç°¡å˜ã§ååˆ†ã§ã™ã€‚å‚¾ããŒ 1.0 ã‹ã‚‰å¤§å¹…ã«é€¸è„±ã™ã‚‹å ´åˆã¯ã€ãƒ¬ãƒ™ãƒ« 2 ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚",
              lesson: "æ›´æ–°ãƒ¬ãƒ™ãƒ«ã‚’å•é¡Œã«åˆã‚ã›ã¦ãã ã•ã„ã€‚ã‚·ãƒ³ãƒ—ãƒ«ãªæ›´æ–°ã¯ã‚ˆã‚Šå …ç‰¢ã§ã€å¿…è¦ãªãƒ‡ãƒ¼ã‚¿ãŒå°‘ãªããªã‚Šã¾ã™ã€‚"
            }
          }
        }
      },
      {
        type: 'decision-tree',
        content: {
          id: 'validation-type',
          title: "ã“ã‚Œã¯ã©ã®ã‚ˆã†ãªç¨®é¡ã®æ¤œè¨¼ã§ã™ã‹?",
          situation: "Classify each validation scenario by type and adequacy.",
          nodes: {
            start: {
              question: "A COVID mortality model developed in Wuhan (2020) is tested on data from Wuhan (2021). This is:",
              branches: [
                { text: "Internal validation â€” same location", nextNode: "internal_wrong" },
                { text: "Temporal external validation", nextNode: "temporal_correct" }
              ]
            },
            internal_wrong: {
              type: 'outcome',
              outcome: 'danger',
              title: "No â€” different time = external",
              text: "åŒã˜ç—…é™¢ã§ã‚ã£ã¦ã‚‚ã€2021 å¹´ã®ãƒ‡ãƒ¼ã‚¿ã¯ 2020 å¹´ã®é–‹ç™ºã‚³ãƒ›ãƒ¼ãƒˆã«ã¨ã£ã¦å¤–éƒ¨ã®ã‚‚ã®ã§ã™ã€‚ã“ã‚Œã¯ TEMPORAL å¤–éƒ¨æ¤œè¨¼ã§ã™ã€‚æ‚£è€…é›†å›£ã€æ²»ç™‚ãƒ—ãƒ­ãƒˆã‚³ãƒ«ã€ã‚¦ã‚¤ãƒ«ã‚¹ã®ãƒãƒªã‚¢ãƒ³ãƒˆã¯ç•°ãªã‚‹å ´åˆãŒã‚ã‚Šã¾ã™ã€‚",
              lesson: "å¤–éƒ¨æ¤œè¨¼ã«ã¯ã€ãƒ¢ãƒ‡ãƒ«é–‹ç™ºã«ä½¿ç”¨ã•ã‚Œã¦ã„ãªã„ãƒ‡ãƒ¼ã‚¿ãŒå¿…è¦ã§ã™ã€‚æ™‚é–“ã®åˆ†é›¢ã«ã‚ˆã£ã¦å¤–éƒ¨åŒ–ã•ã‚Œã¾ã™ã€‚"
            },
            temporal_correct: {
              situation: "Correct! Different time period = temporal external validation.",
              question: "åŒã˜ãƒ¢ãƒ‡ãƒ«ãŒ 2021 å¹´ã«ã‚¸ãƒ§ãƒ³ã‚º ãƒ›ãƒ—ã‚­ãƒ³ã‚¹å¤§å­¦ã§ãƒ†ã‚¹ãƒˆã•ã‚Œã¦ã„ã¾ã™ã€‚C çµ±è¨ˆã¯ 0.82 ã‹ã‚‰ 0.74 ã«ä½ä¸‹ã—ã¾ã™ã€‚ã©ã®ã‚ˆã†ã«è§£é‡ˆã•ã‚Œã¾ã™ã‹?",
              branches: [
                { text: "The model failed â€” drop is too large", nextNode: "drop_harsh" },
                { text: "Acceptable performance â€” C 0.74 is still adequate", nextNode: "acceptable_correct" },
                { text: "Need to check calibration before judging", nextNode: "calibration_best" }
              ]
            },
            drop_harsh: {
              type: 'outcome',
              outcome: 'partial',
              title: "A drop of 0.08 is concerning but not catastrophic",
              text: "C ãŒ 0.82 ã‹ã‚‰ 0.74 ã«ä½ä¸‹ã™ã‚‹ã“ã¨ã¯ã€ä½•ã‚‰ã‹ã®éå‰°é©åˆã¾ãŸã¯æ¯é›†å›£ã®é•ã„ã‚’ç¤ºå”†ã—ã¦ã„ã¾ã™ã€‚ã—ã‹ã—ã€0.74 ã¯ä¾ç„¶ã¨ã—ã¦åˆç†çš„ãªè­˜åˆ¥ã‚’æä¾›ã—ã¾ã™ã€‚é‡è¦ãªç–‘å•ã¯ã€0.74 ã¯è‡¨åºŠçš„ã«æœ‰ç”¨ã‹?ã¨ã„ã†ã“ã¨ã§ã™ã€‚ã‚­ãƒ£ãƒªãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã¯ã©ã†ã§ã™ã‹?",
              lesson: "å¤–éƒ¨æ¤œè¨¼ã§ã¯ã€C çµ±è¨ˆã®ã‚ã‚‹ç¨‹åº¦ã®ä½ä¸‹ãŒäºˆæƒ³ã•ã‚Œã¾ã™ã€‚ä½ä¸‹ã ã‘ã§ã¯ãªãã€çµ¶å¯¾çš„ãªãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã§åˆ¤æ–­ã—ã¦ãã ã•ã„ã€‚"
            },
            acceptable_correct: {
              type: 'outcome',
              outcome: 'partial',
              title: "C = 0.74 can be useful, but check calibration",
              text: "Discrimination of 0.74 is often adequate for clinical use. But you don't know if the model works until you check CALIBRATION. A model with C=0.74 but predicted/observed=2.0 would be dangerous.",
              lesson: "Never judge a model by C-statistic alone. Calibration failures can make discriminating models clinically harmful."
            },
            calibration_best: {
              type: 'outcome',
              outcome: 'success',
              title: "Excellent answer!",
              text: "C çµ±è¨ˆã ã‘ã§ã¯ä¸ååˆ†ã§ã‚ã‚‹ã“ã¨ã‚’æ­£ã—ãèªè­˜ã—ã¾ã—ãŸã€‚ã‚­ãƒ£ãƒªãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãŒç¶­æŒã•ã‚Œã¦ã„ã‚Œã°ã€0.82 ã‹ã‚‰ 0.74 ã¸ã®ä½ä¸‹ã¯è¨±å®¹ã§ãã¾ã™ã€‚ãƒ¢ãƒ‡ãƒ«ãŒæ­»äº¡ç‡ã‚’ 30% ã¨äºˆæ¸¬ã—ã¦ã„ã‚‹ã®ã«ã€ã‚¸ãƒ§ãƒ³ã‚ºãƒ»ãƒ›ãƒ—ã‚­ãƒ³ã‚¹å¤§å­¦ã§ã¯ 15% ã¨è¦‹ã¦ã„ã‚‹å ´åˆã€è¨±å®¹ã§ãã‚‹å·®åˆ¥ã«ã‚‚ã‹ã‹ã‚ã‚‰ãšã€ãƒ¢ãƒ‡ãƒ«ã¯æœ‰å®³ã§ã™ã€‚",
              lesson: "Always assess BOTH discrimination AND calibration in external validation. Many models discriminate adequately but miscalibrate badly."
            }
          }
        }
      },
      {
        type: 'quiz',
        content: {
          question: "A research team develops a model and tests it on a random 30% holdout of their original dataset. This is:",
          options: [
            { id: 'a', text: "å¤–éƒ¨æ¤œè¨¼ (ãƒ‡ãƒ¼ã‚¿ã¯é–‹ç™ºã«ä½¿ç”¨ã•ã‚Œã¦ã„ã¾ã›ã‚“)", correct: false },
            { id: 'b', text: "Internal validation (same source, doesn't test generalizability)", correct: true },
            { id: 'c', text: "Independent validation (separate test)", correct: false },
            { id: 'd', text: "æ¤œè¨¼ãªã— (ãƒ›ãƒ¼ãƒ«ãƒ‰ã‚¢ã‚¦ãƒˆ ãƒ‡ãƒ¼ã‚¿ã§ã¯æ¤œè¨¼ã§ãã¾ã›ã‚“)", correct: false }
          ],
          explanation: "Split-sample validation is a form of INTERNAL validation. The holdout data comes from the same time, place, and population as the development data. It does NOT test generalizability to new settings. This is the weakest form of validation â€” better than nothing, but far from sufficient for clinical deployment."
        }
      },
      {
        type: 'principle',
        content: {
          text: "âš ï¸è­¦å‘Š: Epic Sepsis ã®å¤§å¤±æ•—ã¯ã€ãƒ™ãƒ³ãƒ€ãƒ¼ãŒå†…éƒ¨æŒ‡æ¨™ã«åŸºã¥ã„ã¦ãƒ¢ãƒ‡ãƒ«ã‚’è²©å£²ã™ã‚‹ã“ã¨ã‚’ç¤ºã—ã¦ã„ã¾ã™ã€‚ç—…é™¢ã¯ç‹¬ç«‹ã—ãŸæ¤œæŸ»ã‚’è¡Œã‚ãšã«ãã‚Œã‚‰ã‚’å°å…¥ã—ã¾ã™ã€‚æ‚£è€…ã¯ã€Œæœºä¸Šã§ã¯æ©Ÿèƒ½ã™ã‚‹ã€ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚’é©ç”¨ã•ã‚Œã‚‹ã“ã¨ã«ãªã‚‹ãŒã€å®Ÿéš›ã«ã¯å¤±æ•—ã™ã‚‹ã“ã¨ã«ãªã‚‹ã€‚å¸¸ã«ç‹¬ç«‹ã—ãŸå¤–éƒ¨æ¤œè¨¼ã‚’è¦æ±‚ã—ã¾ã™ã€‚"
        }
      }
    ]
  },
  {
    id: 5,
    title: "The Scores",
    subtitle: "Clinical Prediction Rules",
    principle: 4,
    estimatedTime: "25 min",
    slides: [
      {
        type: 'principle-display',
        content: {
          principle: "æ¯é›†å›£ãŒäºˆæ¸¬ã‚’å®šç¾©ã—ã¾ã™"
        }
      },
      {
        type: 'story-deep',
        content: {
          label: "æˆåŠŸäº‹ä¾‹: ã‚¦ã‚§ãƒ«ã‚ºã®åŸºæº– â€” ã‚·ãƒ³ãƒ—ãƒ«ã•ãŒæ´»ã‹ã•ã‚Œã‚‹å ´åˆ",
          source: "Wells et al. 1998-2006 | Ann Intern Med | Thrombosis",
          timeline: [
            { year: "1995", text: "Philip Wells develops simple scoring system for DVT probability. Clinical signs + risk factors = points. No fancy math, no computers required.", type: "normal" },
            { year: "1997", text: "Wells DVT score validated: Low probability patients have <5% DVT prevalence. Can safely avoid imaging with negative D-dimer.", type: "revelation" },
            { year: "2000", text: "Wells PE score developed for pulmonary embolism. Similar simplicity: 7 items, integer points, three risk categories.", type: "normal" },
            { year: "2006", text: "ã‚¦ã‚§ãƒ«ã‚ºã® PE ã‚¹ã‚³ã‚¢ã¯åºƒç¯„å›²ã«æ¤œè¨¼ã•ã‚Œã¦ã„ã¾ã™ã€‚ PERCã€D-ãƒ€ã‚¤ãƒãƒ¼ã€ãŠã‚ˆã³ CTPA ãƒ—ãƒ­ãƒˆã‚³ãƒ«ã¨çµ„ã¿åˆã‚ã›ã¾ã™ã€‚ä½•ç™¾ä¸‡ã‚‚ã®æ•‘æ€¥å¤–æ¥ã®æ‚£è€…ãŒãƒªã‚¹ã‚¯éšå±¤åŒ–ã•ã‚Œã¦ã„ã¾ã™ã€‚", type: "revelation" },
            { year: "Impact", text: "Reduced unnecessary CT scans. Reduced radiation exposure. Faster diagnoses. Lives saved by rapid identification of high-risk patients.", type: "revelation" },
            { year: "Why It Worked", text: "ã‚·ãƒ³ãƒ—ãƒ« (è¨˜æ†¶å¯èƒ½)ã€æ¤œè¨¼æ¸ˆã¿ (å¤–éƒ¨ã€ç¹°ã‚Šè¿”ã—)ã€çµ±åˆ (è¨ºæ–­çµŒè·¯ã¨)ã€è‡¨åºŠçš„ã«æœ‰ç”¨ (æ„æ€æ±ºå®šã®å¤‰æ›´)ã€‚", type: "revelation" }
          ],
          realData: {
            endpoint: "DVT/PE presence",
            model: "Wells Score (DVT and PE versions)",
            discrimination: "C-statistic 0.70-0.75",
            impact: "Standard of care in emergency medicine worldwide"
          },
          hook: "THE HOOK: Wells criteria have modest C-statistics (0.70-0.75) â€” not impressive by AI standards. But they're memorizable, interpretable, validated, and integrated into care pathways. They've saved more lives than any black-box algorithm. Sometimes simple wins."
        }
      },
      {
        type: 'content',
        content: {
          title: "Famous Clinical Prediction Rules",
          sections: [
            {
              heading: "Cardiovascular:",
              items: [
                "Framingham/ASCVD: 10-year CVD risk â†’ statin decisions",
                "CHAâ‚‚DSâ‚‚-VASc: Stroke risk in AF â†’ anticoagulation",
                "HEART Score: Chest pain risk stratification â†’ discharge vs admit",
                "TIMI Risk Score: ACS prognosis â†’ treatment intensity"
              ]
            },
            {
              heading: "Emergency Medicine:",
              items: [
                "Wells DVT/PE: Thromboembolism probability â†’ testing strategy",
                "PERC: Rule out PE without testing",
                "Canadian C-Spine/CT Head: Imaging decisions after trauma",
                "Ottawa Ankle/Knee: X-ray necessity for injuries"
              ]
            },
            {
              heading: "Critical Care:",
              items: [
                "APACHE II/III/IV: ICU mortality prediction",
                "SOFA: Sequential organ failure assessment",
                "qSOFA: Quick sepsis screening (controversial)",
                "CURB-65: Pneumonia mortality â†’ admit vs discharge"
              ]
            },
            {
              heading: "What Makes Them Work:",
              items: [
                "Simple enough to use at bedside without calculator",
                "Validated extensively across populations",
                "è‡¨åºŠãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã¨ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³ã«çµ±åˆ",
                "Clear decision thresholds with actionable implications"
              ]
            }
          ]
        }
      },
      {
        type: 'story-deep',
        content: {
          label: "THE CONTROVERSY: qSOFA â€” WHEN A SCORE DIVIDED MEDICINE",
          source: "Seymour et al. JAMA 2016 | Singer et al. JAMA 2016 | Sepsis-3",
          timeline: [
            { year: "2016", text: "Sepsis-3 consensus redefines sepsis. Introduces qSOFA: 3 simple criteria (RRâ‰¥22, SBPâ‰¤100, altered mental status). 2+ points = 'think sepsis'.", type: "normal" },
            { year: "The Promise", text: "qSOFA is beautifully simple. No lab tests. Bedside assessment. Could identify sepsis risk anywhere, anytime. International uptake rapid.", type: "normal" },
            { year: "External Validation", text: "ç ”ç©¶ãŒæ®ºåˆ°ã€‚çµæœã¯ã¾ã¡ã¾ã¡ã€‚ qSOFA ã¯ç‰¹ç•°æ€§ (é™½æ€§ã®å ´åˆã€äºˆå¾Œä¸è‰¯) ã¯ã‚ã‚Šã¾ã™ãŒã€æ„Ÿåº¦ã¯åŠ£ã‚Šã¾ã™ (å¤šãã®æ•—è¡€ç—‡ç—‡ä¾‹ã‚’è¦‹é€ƒã—ã¾ã™)ã€‚ C ~0.65-0.70.", type: "crisis" },
            { year: "The Debate", text: "Is qSOFA for SCREENING (must be sensitive) or PROGNOSIS (can be specific)? Guidelines unclear. Emergency physicians frustrated: patients die with qSOFA=1.", type: "crisis" },
            { year: "Current Status", text: "qSOFA ã¯äºˆå¾Œã«æœ‰ç”¨ã§ã™ãŒ (é™½æ€§ã§ã‚ã‚Œã°æ­»äº¡ç‡ã‚’äºˆæ¸¬ã—ã¾ã™)ã€ã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ã«ã¯æœ‰ç”¨ã§ã¯ã‚ã‚Šã¾ã›ã‚“ (é™°æ€§ã§ã‚ã‚Œã°æ•—è¡€ç—‡ã‚’é™¤å¤–ã—ã¾ã›ã‚“)ã€‚ã•ã¾ã–ã¾ãªç›®çš„ã«å¿œã˜ãŸã•ã¾ã–ã¾ãªãƒ„ãƒ¼ãƒ«ã€‚", type: "revelation" },
            { year: "Lesson", text: "A score's PURPOSE determines its required properties. Screening tools need sensitivity. Prognostic tools can trade sensitivity for specificity. Mismatched purpose = clinical failure.", type: "revelation" }
          ],
          realData: {
            endpoint: "ICU mortality, prolonged stay",
            model: "qSOFA (RRâ‰¥22, SBPâ‰¤100, AMS)",
            discrimination: "C-statistic 0.65-0.70",
            sensitivity: "æ•—è¡€ç—‡è¨ºæ–­ã«ã¯ 45 ï½ 60%"
          },
          hook: "THE HOOK: qSOFA is a great PROGNOSTIC tool â€” qSOFAâ‰¥2 means poor prognosis. But it was marketed as a SCREENING tool, where it fails (misses half of sepsis). The lesson: Know your score's purpose. A prognostic score isn't a screening score."
        }
      },
      {
        type: 'decision-tree',
        content: {
          id: 'score-selection',
          title: "é©åˆ‡ãªã‚¹ã‚³ã‚¢ã®é¸æŠ",
          situation: "You're in the emergency department with a patient presenting with shortness of breath. You suspect PE. Multiple scores exist: Wells PE, Geneva, PERC, YEARS. How do you decide?",
          nodes: {
            start: {
              question: "What should guide your choice of score?",
              branches: [
                { text: "C çµ±è¨ˆãŒæœ€ã‚‚é«˜ã„ã‚¹ã‚³ã‚¢ã‚’ä½¿ç”¨", nextNode: "cstat_wrong" },
                { text: "æ¯é›†å›£å†…ã§æ¤œè¨¼ã•ã‚Œã€çµ„ç¹”ã«çµ±åˆã•ã‚ŒãŸã‚¹ã‚³ã‚¢ã‚’ä½¿ç”¨ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼", nextNode: "workflow_correct" },
                { text: "Use all scores and average them", nextNode: "average_wrong" }
              ]
            },
            cstat_wrong: {
              type: 'outcome',
              outcome: 'partial',
              title: "C-statistic isn't everything",
              text: "These scores have similar C-statistics (0.70-0.75). The differences are in: what populations they're validated for, how they integrate with testing (D-dimer, CTPA), and whether your institution has pathways built around them. Implementation matters more than small statistical differences.",
              lesson: "Among validated scores, choose based on local validation, workflow integration, and clinical pathway support."
            },
            workflow_correct: {
              situation: "Excellent! Your institution uses Wells + D-dimer protocol. Now: a patient has Wells score of 2 ('PE unlikely'). D-dimer is elevated. What next?",
              question: "Your action:",
              branches: [
                { text: "PE is unlikely based on Wells â€” reassure and discharge", nextNode: "discharge_wrong" },
                { text: "Elevated D-dimer overrides Wells â€” get CTPA", nextNode: "ctpa_correct" }
              ]
            },
            average_wrong: {
              type: 'outcome',
              outcome: 'danger',
              title: "ã“ã‚Œã¯æ··ä¹±ã‚’å¼•ãèµ·ã“ã—ã¾ã™!",
              text: "Scores aren't designed to be averaged. They have different thresholds, different action points, and different integration with testing. PERC rules out without testing; Wells guides D-dimer interpretation. Using multiple scores without understanding their roles leads to inconsistent care.",
              lesson: "å„ã‚¹ã‚³ã‚¢ã®ç›®çš„ã¨çµŒè·¯ã‚’ç†è§£ã—ã¦ãã ã•ã„ã€‚çµŒè·¯ã”ã¨ã« 1 ã¤ã®ã‚¹ã‚³ã‚¢ã‚’é¸æŠã—ã€ä¸€è²«ã—ã¦ä½¿ç”¨ã—ã¾ã™ã€‚"
            },
            discharge_wrong: {
              type: 'outcome',
              outcome: 'danger',
              title: "Dangerous decision!",
              text: "'PE unlikely' (Wells â‰¤4) means D-dimer can rule out PE. But if D-dimer is ELEVATED in a 'PE unlikely' patient, they need imaging. The pathway is: Wells â†’ D-dimer â†’ CTPA if D-dimer positive. You can't stop at Wells when D-dimer is abnormal.",
              lesson: "è‡¨åºŠäºˆæ¸¬ãƒ«ãƒ¼ãƒ«ã¯é€šå¸¸ã€ç‹¬ç«‹ã—ãŸæ±ºå®šã§ã¯ãªãã€PATHWAY ã®ä¸€éƒ¨ã§ã™ã€‚å®Œå…¨ãªã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã«å¾“ã£ã¦ãã ã•ã„ã€‚"
            },
            ctpa_correct: {
              type: 'outcome',
              outcome: 'success',
              title: "Correct clinical pathway!",
              text: "Wells 'PE unlikely' + negative D-dimer = rule out PE. Wells 'PE unlikely' + positive D-dimer = CTPA needed. The score stratifies who needs D-dimer, but the final decision combines score + D-dimer result.",
              lesson: "è‡¨åºŠäºˆæ¸¬ãƒ«ãƒ¼ãƒ«ã¯ã€çµŒè·¯å†…ã®è¨ºæ–­ãƒ†ã‚¹ãƒˆã¨çµ„ã¿åˆã‚ã•ã‚Œã‚‹ã“ã¨ãŒã‚ˆãã‚ã‚Šã¾ã™ã€‚ã‚¹ã‚³ã‚¢ã ã‘ã§ã¯æ±ºå®šã¯ã§ãã¾ã›ã‚“ã€‚"
            }
          }
        }
      },
      {
        type: 'quiz',
        content: {
          question: "CHAâ‚‚DSâ‚‚-VASc has a C-statistic of only 0.60-0.65 for predicting stroke in atrial fibrillation. Despite this modest discrimination, it's useful because:",
          options: [
            { id: 'a', text: "It perfectly calibrated in all populations", correct: false },
            { id: 'b', text: "It identifies a low-risk group (score 0-1) who can avoid anticoagulation", correct: true },
            { id: 'c', text: "ã“ã‚ŒãŒã“ã®ç›®çš„ã§åˆ©ç”¨ã§ãã‚‹å”¯ä¸€ã®ã‚¹ã‚³ã‚¢ã§ã™", correct: false },
            { id: 'd', text: "C çµ±è¨ˆãŒæ­£ã—ãæ¸¬å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚", correct: false }
          ],
          explanation: "CHAâ‚‚DSâ‚‚-VASc ã®è‡¨åºŠçš„æœ‰ç”¨æ€§ã¯ã€å…¨ä½“çš„ãªé«˜ã„è­˜åˆ¥ã«ã‚ˆã‚‹ã‚‚ã®ã§ã¯ãªãã€ä½ãƒªã‚¹ã‚¯ ã‚°ãƒ«ãƒ¼ãƒ—ã®ç‰¹å®šã«ã‚ˆã‚‹ã‚‚ã®ã§ã™ã€‚ã‚¹ã‚³ã‚¢ 0 (å¥³æ€§ã®å ´åˆã¯ 1) ã®æ‚£è€…ã¯è„³å’ä¸­ãƒªã‚¹ã‚¯ãŒååˆ†ã«ä½ã„ãŸã‚ã€æŠ—å‡å›ºç™‚æ³•ãŒæ­£å½“åŒ–ã•ã‚Œãªã„å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚ã‚¹ã‚³ã‚¢ã®ä¾¡å€¤ã¯äºˆæ¸¬ã§ã¯ãªãåˆ¤æ–­ã«ã‚ã‚Šã¾ã™ã€‚"
        }
      },
      {
        type: 'story-deep',
        content: {
          label: "å®Ÿéš›ã®äº‹ä¾‹: ONCOTYPE DX ã®æˆåŠŸäº‹ä¾‹ â€” æ¤œè¨¼ã‚’é€šã˜ã¦ä¿¡é ¼ã‚’ç²å¾—",
          source: "Paik et al. NEJM 2004 | TAILORx Trial 2018 | Breast cancer prognostics",
          timeline: [
            { year: "2004", text: "Oncotype DX is introduced: a 21-gene assay that generates a Recurrence Score (0-100) for early-stage, hormone receptor-positive breast cancer. Claims to predict chemotherapy benefit.", type: "normal" },
            { year: "Skepticism", text: "æ‰¹è©•å®¶ã¯è¨¼æ‹ ã‚’æ±‚ã‚ã¦ã„ã¾ã™ã€‚ã‚ã‚‹ç ”ç©¶ã§å¾—ã‚‰ã‚ŒãŸéºä¼å­ã‚·ã‚°ãƒãƒãƒ£ã¯ã€ä»–ã®ç ”ç©¶ã§ã¯æ©Ÿèƒ½ã—ãªã„å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚å‡ºç‰ˆãƒã‚¤ã‚¢ã‚¹ã€éå‰°é©åˆã€è‡¨åºŠæ¤œè¨¼ã®æ¬ å¦‚ â€” ã™ã¹ã¦ã®ä¸€èˆ¬çš„ãªæ‡¸å¿µäº‹é …ã§ã™ã€‚", type: "crisis" },
            { year: "2006-2015", text: "æ¤œè¨¼ç ”ç©¶ã¯è“„ç©ã•ã‚Œã¾ã™ã€‚ã‚¹ã‚³ã‚¢ã¯ã€ä»¥å‰ã®è‡¨åºŠè©¦é¨“ (NSABP B-14ã€B-20ã€ATAC) ã‹ã‚‰ã®ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ã•ã‚ŒãŸã‚µãƒ³ãƒ—ãƒ«ã§ãƒ†ã‚¹ãƒˆã•ã‚Œã¾ã™ã€‚ã‚³ãƒ›ãƒ¼ãƒˆå…¨ä½“ã§ä¸€è²«ã—ãŸçµæœã€‚å·®åˆ¥ã¯ç¶­æŒã•ã‚Œã¾ã™ã€‚", type: "normal" },
            { year: "2018", text: "TAILORx trial results published: 10,273 women with intermediate Recurrence Scores randomized to chemotherapy vs no chemotherapy. Low scores (0-25) could safely skip chemo. Prospective validation achieved.", type: "revelation" },
            { year: "Impact", text: "Thousands of women spared unnecessary chemotherapy each year. Reduced toxicity, preserved quality of life, saved costs. A prognostic model that EARNED its place in guidelines.", type: "revelation" },
            { year: "Lesson", text: "Oncotype DX succeeded because it was validated relentlessly: retrospective cohorts, prospective trials, multiple populations. Skeptics were answered with data, not marketing. <span class='lesson-gold'>THE LESSON: Trust in prognostic models is earned through validation. Oncotype DX shows what patient-centered, evidence-based model development looks like.</span>", type: "revelation" }
          ],
          realData: {
            endpoint: "10-year distant recurrence risk",
            model: "Oncotype DX 21-gene Recurrence Score",
            discrimination: "Validated across multiple independent cohorts",
            impact: "Changed standard of care; spares thousands from unnecessary chemotherapy"
          },
          hook: "THE HOOK: When Oncotype DX was introduced, it was just another gene signature claiming to predict cancer outcomes. What made it different? Fifteen years of validation. Independent cohorts. Randomized trial evidence. A commercial test that submitted itself to the rigors of science and emerged with guidelines recommending its use. This is how prognostic models should prove themselves."
        }
      },
      {
        type: 'principle',
        content: {
          text: "ğŸ¯ PROGRESS CHECK: You've learned about clinical prediction rules. Key lessons: (1) Simplicity enables adoption; (2) Scores work in pathways, not isolation; (3) Purpose (screening vs prognosis) determines required properties; (4) Moderate C-statistics can still be clinically useful if they identify actionable subgroups."
        }
      }
    ]
  },
  {
    id: 6,
    title: "The Reporting",
    subtitle: "TRIPOD Guidelines",
    principle: 5,
    estimatedTime: "20 min",
    slides: [
      {
        type: 'principle-display',
        content: {
          principle: "Clinical utility trumps statistics"
        }
      },
      {
        type: 'story-deep',
        content: {
          label: "THE HIDDEN PROBLEM: COVID MODELS â€” WHEN URGENCY TRUMPED RIGOR",
          source: "Wynants et al. BMJ 2020 (living review) | COVID prediction models",
          timeline: [
            { year: "Mar 2020", text: "Pandemic begins. Researchers worldwide rush to build COVID prognostic models. Hundreds appear on preprint servers within weeks.", type: "normal" },
            { year: "Wynants Review", text: "ä½“ç³»çš„ãƒ¬ãƒ“ãƒ¥ãƒ¼ã«ã‚ˆã‚Šã€2020 å¹´ 7 æœˆã¾ã§ã« 232 ã® æ–°å‹ã‚³ãƒ­ãƒŠã‚¦ã‚¤ãƒ«ã‚¹äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«ãŒç‰¹å®šã•ã‚Œã¾ã—ãŸã€‚PROBAST (ãƒã‚¤ã‚¢ã‚¹ã®ãƒªã‚¹ã‚¯ ãƒ„ãƒ¼ãƒ«) ã‚’ä½¿ç”¨ã—ãŸè©•ä¾¡: 99% ã§ãƒã‚¤ã‚¢ã‚¹ã®ãƒªã‚¹ã‚¯ãŒé«˜ã‹ã£ãŸã€‚", type: "crisis" },
            { year: "Common Problems", text: "Small samples, data-driven variable selection, no external validation, high risk of overfitting, poorly reported methods, non-reproducible.", type: "crisis" },
            { year: "Reporting Failures", text: "Most papers didn't report: predictor definitions, missing data handling, calibration plots, sample size calculations, or model equations. Impossible to reproduce or implement.", type: "crisis" },
            { year: "Consequence", text: "è‡¨åºŠåŒ»ã¯ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã§ãã¾ã›ã‚“ã§ã—ãŸ â€” æ–¹æ³•ãŒä¸æ˜ç­ã§ã€å®Ÿè£…æ–¹æ³•ãŒãªãã€å¿…æ­»ã«ãªã£ã¦ã‚‚åˆ©ç”¨ã§ãã‚‹æ¤œè¨¼æ¸ˆã¿ã®ãƒ„ãƒ¼ãƒ«ãŒã‚ã‚Šã¾ã›ã‚“å¿…è¦ã§ã™ã€‚", type: "crisis" },
            { year: "Lesson", text: "TRIPOD ãƒ¬ãƒãƒ¼ãƒˆ ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³ã¯å­˜åœ¨ã—ã¾ã—ãŸãŒã€æ€¥ã„ã§ç„¡è¦–ã•ã‚Œã¾ã—ãŸã€‚é€æ˜æ€§ã®ã‚ã‚‹ãƒ¬ãƒãƒ¼ãƒˆã¯å®˜åƒšçš„ãªã‚ªãƒ¼ãƒãƒ¼ãƒ˜ãƒƒãƒ‰ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚è‡¨åºŠåˆ©ç”¨ã«ã¯ä¸å¯æ¬ ã§ã™ã€‚", type: "revelation" }
          ],
          realData: {
            endpoint: "COVID-19 diagnosis, prognosis, mortality",
            models: "232 models reviewed",
            bias: "229/232 (99%) high risk of bias",
            issue: "Unusable due to poor reporting and methodology"
          },
          hook: "ã‚¶ãƒ»ãƒ•ãƒƒã‚¯: 2020 å¹´ã«ã¯ 232 ã® COVID äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«ãŒé–‹ç™ºã•ã‚Œã¾ã—ãŸã€‚99% ã¯åè¦‹ã¨ä¸ååˆ†ãªãƒ¬ãƒãƒ¼ãƒˆã®ãŸã‚ä½¿ç”¨ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚ãƒ‘ãƒ³ãƒ‡ãƒŸãƒƒã‚¯ã«ã¯äºˆçŸ¥ãƒ„ãƒ¼ãƒ«ãŒåˆ‡å®Ÿã«å¿…è¦ã§ã—ãŸãŒã€ç§ãŸã¡ã¯ä¿¡å·ã§ã¯ãªããƒã‚¤ã‚ºã‚’ç”Ÿã¿å‡ºã—ã¾ã—ãŸã€‚ã“ã‚ŒãŒ TRIPOD ãŒå­˜åœ¨ã™ã‚‹ç†ç”±ã§ã™ã€‚"
        }
      },
      {
        type: 'content',
        content: {
          title: "TRIPOD: Transparent Reporting of Prediction Models",
          sections: [
            {
              heading: "What Is TRIPOD?",
              items: [
                "äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«ç ”ç©¶ã®å ±å‘Šã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³ (2015)",
                "22-item checklist for transparent reporting",
                "é–‹ç™ºã€æ¤œè¨¼ã€ãŠã‚ˆã³çµ„ã¿åˆã‚ã›ãŸç ”ç©¶ã‚’ã‚«ãƒãƒ¼",
                "Required by many journals for publication",
                "TRIPOD-AI extension for machine learning models"
              ]
            },
            {
              heading: "Key Reporting Elements:",
              items: [
                "TITLE: Identify as development, validation, or both; name the outcome",
                "PARTICIPANTS: Eligibility criteria, settings, dates, flow diagram",
                "PREDICTORS: Definitions, assessment methods, blinding",
                "OUTCOME: Definition, assessment, timing, blinding",
                "SAMPLE SIZE: Number of participants and events, EPV",
                "MISSING DATA: How much, how handled",
                "MODEL: Full specification (coefficients, baseline risk)",
                "PERFORMANCE: Discrimination AND calibration measures"
              ]
            }
          ]
        }
      },
      {
        type: 'method',
        content: {
          label: "ãƒ¡ã‚½ãƒƒãƒ‰: TRIPOD ã®è¦ç‚¹",
          title: "What Readers Need to Implement Your Model",
          sections: [
            {
              heading: "Model Specification (Essential!):",
              text: "â€¢ å®šç¾©ä»˜ãã®ã™ã¹ã¦ã®äºˆæ¸¬å­ â€¢ å›å¸°ä¿‚æ•°ã¾ãŸã¯ã‚¹ã‚³ã‚¢ã®é‡ã¿ â€¢ ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã®ãƒªã‚¹ã‚¯ã¾ãŸã¯åˆ‡ç‰‡ â€¢ äºˆæ¸¬ç¢ºç‡ã®è¨ˆç®—æ‰‹é † â€¢ ã“ã‚ŒãŒãªã‘ã‚Œã°ãƒ¢ãƒ‡ãƒ«ã¯ä½¿ç”¨ã§ãã¾ã›ã‚“"
            },
            {
              heading: "Performance Measures:",
              text: "â€¢ 95% CI ã® C çµ±è¨ˆé‡ â€¢ ã‚­ãƒ£ãƒªãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ ãƒ—ãƒ­ãƒƒãƒˆ (SHOW IT) â€¢ å¤§è¦æ¨¡ãªã‚­ãƒ£ãƒªãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã¨å‚¾ã â€¢ é–¢é€£ã™ã‚‹ã—ãã„å€¤ã§ã®æ„Ÿåº¦/ç‰¹ç•°åº¦ â€¢ è‡¨åºŠçš„æœ‰ç”¨æ€§ã®ãŸã‚ã®æ±ºå®šæ›²ç·šåˆ†æ"
            },
            {
              heading: "Flow Diagram:",
              text: "â€¢ æ–¹æ³•å¤šãã®æ‚£è€…ãŒã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ã•ã‚Œã€å¯¾è±¡ã¨ãªã‚Šã€åˆ†æã•ã‚ŒãŸ â€¢ å„ã‚¹ãƒ†ãƒƒãƒ—ã§ã®é™¤å¤–ã®ç†ç”± â€¢ ãƒ‡ãƒ¼ã‚¿ãŒæ¬ è½ã—ã¦ã„ã‚‹æ•°å€¤ â€¢ èª­è€…ãŒé¸æŠãƒã‚¤ã‚¢ã‚¹ã‚’è©•ä¾¡ã§ãã‚‹"
            },
            {
              heading: "Missing Data:",
              text: "â€¢ å¤‰æ•°ã”ã¨ã®æ¬ è½ã®å‰²åˆ â€¢ æ¬ è½ãƒ‡ãƒ¼ã‚¿ã®å‡¦ç†æ–¹æ³• â€¢ å®Œå…¨ãªã‚±ãƒ¼ã‚¹ã¨è£œå®Œ â€¢ è£œå®ŒãŒä½¿ç”¨ã•ã‚ŒãŸå ´åˆã®æ„Ÿåº¦åˆ†æ"
            }
          ]
        }
      },
      {
        type: 'decision-tree',
        content: {
          id: 'tripod-assessment',
          title: "ã“ã®è«–æ–‡ã¯ä¸‰è„šã§ã™æº–æ‹ ã—ã¦ã„ã¾ã™ã‹?",
          situation: "ã‚ãªãŸã¯ã€æ–°ã—ã„æ­»äº¡ç‡äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«ã«é–¢ã™ã‚‹è«–æ–‡ã‚’èª­ã‚“ã§ã„ã¾ã™ã€‚ä¸»è¦ãª TRIPOD è¦ç´ ã‚’ç¢ºèªã—ã¾ã™ã€‚",
          nodes: {
            start: {
              question: "ãƒ¡ã‚½ãƒƒãƒ‰ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã§ã¯ 15 å€‹ã®äºˆæ¸¬å¤‰æ•°ã®å€™è£œã«ã¤ã„ã¦èª¬æ˜ã—ã¦ã„ã¾ã™ãŒã€æœ€çµ‚ãƒ¢ãƒ‡ãƒ«ã«ã©ã‚Œã ã‘ã®äºˆæ¸¬å¤‰æ•°ãŒå«ã¾ã‚Œã¦ã„ã‚‹ã‹ã«ã¤ã„ã¦ã¯è¨˜è¼‰ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ã“ã®ãƒ¢ãƒ‡ãƒ«ã‚’å®Ÿè£…ã§ãã¾ã™ã‹?",
              branches: [
                { text: "ã¯ã„ â€” æ–¹æ³•è«–ã¯æ˜ç¢ºã§ã™", nextNode: "yes_wrong" },
                { text: "No â€” I don't know which predictors are included", nextNode: "no_correct" }
              ]
            },
            yes_wrong: {
              type: 'outcome',
              outcome: 'danger',
              title: "å®šç¾©ã§ããªã„ã‚‚ã®ã¯å®Ÿè£…ã§ãã¾ã›ã‚“!",
              text: "Without knowing which predictors are in the final model and their coefficients, you CANNOT calculate predicted probabilities. The paper is incomplete. This is a TRIPOD violation: model specification must be complete.",
              lesson: "TRIPOD requires full model specification: all predictors, all coefficients, intercept/baseline. Without this, the paper is useless for clinical application."
            },
            no_correct: {
              situation: "Correct. You find the supplement with coefficients. Now: the paper reports C = 0.81 but shows no calibration plot.",
              question: "ã“ã‚Œã¯é©åˆ‡ãªãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ ãƒ¬ãƒãƒ¼ãƒˆã§ã™ã‹?",
              branches: [
                { text: "Yes â€” C-statistic tells us discrimination", nextNode: "cstat_only_wrong" },
                { text: "No â€” calibration plot is essential", nextNode: "calibration_needed_correct" }
              ]
            },
            cstat_only_wrong: {
              type: 'outcome',
              outcome: 'danger',
              title: "ç”»åƒã®åŠåˆ†ãŒæ¬ è½ã—ã¦ã„ã¾ã™!",
              text: "C-statistic tells you DISCRIMINATION only. Without a calibration plot, you don't know if predicted probabilities are accurate. A model can have C=0.81 but overestimate risk by 50%. You need BOTH metrics.",
              lesson: "TRIPOD ã¯æ˜ç¤ºçš„ã«å¿…è¦ã§ã™æ ¡æ­£è©•ä¾¡ã€‚ C çµ±è¨ˆã®ã¿ã‚’å ±å‘Šã™ã‚‹è«–æ–‡ã¯ä¸å®Œå…¨ã§ã™ã€‚ã‚­ãƒ£ãƒªãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ ãƒ—ãƒ­ãƒƒãƒˆã‚’è¦æ±‚ã—ã¾ã™ã€‚"
            },
            calibration_needed_correct: {
              situation: "ã„ã„ã§ã™ã­!è£œè¶³çš„ãªæ ¡æ­£ãƒ‡ãƒ¼ã‚¿ãŒå¿…è¦ã§ã™ã€‚æœ€å¾Œã«: ã“ã®è«–æ–‡ã§ã¯ã€ãƒ–ãƒ¼ãƒˆã‚¹ãƒˆãƒ©ãƒƒãƒ—ã«ã‚ˆã‚‹å†…éƒ¨æ¤œè¨¼ã¯å ±å‘Šã•ã‚Œã¦ã„ã¾ã™ãŒã€å¤–éƒ¨æ¤œè¨¼ã¯å ±å‘Šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚",
              question: "ã“ã®ãƒ¢ãƒ‡ãƒ«ã¯è‡¨åºŠä½¿ç”¨ã®æº–å‚™ãŒã§ãã¦ã„ã¾ã™ã‹?",
              branches: [
                { text: "Yes â€” bootstrap validation is rigorous", nextNode: "internal_only" },
                { text: "No â€” external validation required before clinical use", nextNode: "external_needed_correct" }
              ]
            },
            internal_only: {
              type: 'outcome',
              outcome: 'partial',
              title: "Bootstrap is necessary but not sufficient",
              text: "ãƒ–ãƒ¼ãƒˆã‚¹ãƒˆãƒ©ãƒƒãƒ—ã¯é–‹ç™ºãƒ‡ãƒ¼ã‚¿å†…ã§æ¥½è¦³çš„ã«èª¿æ•´ã—ã¾ã™ã€‚ãŸã ã—ã€æ–°ã—ã„è¨­å®šã«å¯¾ã™ã‚‹æ±ç”¨æ€§ã¯ãƒ†ã‚¹ãƒˆã•ã‚Œã¾ã›ã‚“ã€‚ãƒ¢ãƒ‡ãƒ«ã¯ãƒ–ãƒ¼ãƒˆã‚¹ãƒˆãƒ©ãƒƒãƒ—æ¤œè¨¼ã«åˆæ ¼ã—ã¦ã‚‚ã€ä»–ã®å ´æ‰€ã«ãƒ‡ãƒ—ãƒ­ã‚¤ã™ã‚‹ã¨å¤±æ•—ã™ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚è‡¨åºŠä½¿ç”¨å‰ã«å¤–éƒ¨æ¤œè¨¼ãŒå¿…è¦ã§ã™ã€‚",
              lesson: "Development + internal validation = MINIMUM for publication. External validation = MINIMUM for clinical implementation."
            },
            external_needed_correct: {
              type: 'outcome',
              outcome: 'success',
              title: "Correct judgment!",
              text: "ã“ã®æ–‡æ›¸ã§ã¯ã€å†…éƒ¨æ¤œè¨¼ã‚’ä¼´ã†é–‹ç™ºç ”ç©¶ã‚’æä¾›ã—ã¾ã™ã€‚å…¬é–‹å¯èƒ½ã§ã™ãŒã€è‡¨åºŠå±•é–‹ã®æº–å‚™ãŒã§ãã¦ã„ã¾ã›ã‚“ã€‚è‘—è€…ã¯å¤–éƒ¨æ¤œè¨¼ã®å¿…è¦æ€§ã‚’æ˜ç¢ºã«è¿°ã¹ã‚‹ã¹ãã§ã‚ã‚Šã€ãƒ¢ãƒ‡ãƒ«ã‚’è‡¨åºŠçš„ã«ä½¿ç”¨ã™ã‚‹å‰ã«ãã‚Œã‚’å¾…ã¤ã¹ãã§ã™ã€‚",
              lesson: "Be explicit about what a study provides. Development without external validation = hypothesis. External validation = evidence for deployment."
            }
          }
        }
      },
      {
        type: 'quiz',
        content: {
          question: "A prediction model paper shows excellent discrimination (C=0.87) and perfect calibration in development data. But it doesn't provide the model equation (coefficients). This paper is:",
          options: [
            { id: 'a', text: "å®Œå…¨ â€” ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãŒé‡è¦ãªæƒ…å ±", correct: false },
            { id: 'b', text: "Incomplete â€” readers cannot implement or validate the model", correct: true },
            { id: 'c', text: "Acceptable â€” coefficients can be requested from authors", correct: false },
            { id: 'd', text: "è‡¨åºŠå±•é–‹ã«ã¯ååˆ†", correct: false }
          ],
          explanation: "ä¿‚æ•°ãŒãªã‘ã‚Œã°ã€ãƒ¢ãƒ‡ãƒ«ã¯å®Ÿè£…ã€æ¤œè¨¼ã€ã¾ãŸã¯ä½¿ç”¨ã§ãã¾ã›ã‚“ã€‚ ã€Œè‘—è€…ã«é€£çµ¡ã™ã‚‹ã€ã¯å—ã‘å…¥ã‚Œã‚‰ã‚Œã¾ã›ã‚“ã€‚å¤šãã¯å¿œç­”ã›ãšã€è‡¨åºŠå®Ÿè£…ã«ã¯å³æ™‚ã‚¢ã‚¯ã‚»ã‚¹ãŒå¿…è¦ã§ã™ã€‚ TRIPOD ã«ã¯å®Œå…¨ãªãƒ¢ãƒ‡ãƒ«ä»•æ§˜ãŒå¿…è¦ã§ã™ã€‚ã“ã®è«–æ–‡ã¯åŸºæœ¬çš„ã«ä¸å®Œå…¨ã§ã™ã€‚"
        }
      },
      {
        type: 'principle',
        content: {
          text: "âš ï¸ THE WARNING: 99% of COVID prediction models were unusable. Not because prognosis was impossible â€” because reporting was inadequate. TRIPOD exists to ensure that prediction models can be implemented, validated, and used. Ignoring reporting standards wastes research and harms patients."
        }
      }
    ]
  },
  {
    id: 7,
    title: "The Utility",
    subtitle: "Decision Curves & Net Benefit",
    principle: 6,
    estimatedTime: "30 min",
    slides: [
      {
        type: 'principle-display',
        content: {
          principle: "Transparency enables trust"
        }
      },
      {
        type: 'story-deep',
        content: {
          label: "THE MISSING PIECE: WHEN GOOD MODELS DIDN'T HELP PATIENTS",
          source: "Vickers & Elkin 2006 | Medical Decision Making | Decision curve analysis",
          timeline: [
            { year: "Classic Era", text: "Prognostic models evaluated by C-statistic and calibration. 'Good' models (C>0.75, calibrated) assumed to be clinically useful. No direct measurement of utility.", type: "normal" },
            { year: "The Problem", text: "Many models with good statistics didn't change decisions or outcomes. Example: A model that classifies everyone as high-risk has C=0.50 but perfect 'sensitivity.' Statistics can be gamed.", type: "crisis" },
            { year: "2006", text: "Vickers & Elkin ã¯æ±ºå®šæ›²ç·šåˆ†æ (DCA) ã‚’å°å…¥ã—ã¦ã„ã¾ã™ã€‚ NET BENEFIT ã‚’ç›´æ¥æ¸¬å®šã—ã¾ã™: ãƒ¢ãƒ‡ãƒ«ã®ä½¿ç”¨ã«ã‚ˆã‚Šã€å®³ã‚’å—ã‘ã‚‹ã‚ˆã‚Šã‚‚åŠ©ã‹ã‚‹æ‚£è€…ã®æ–¹ãŒå¤šã„ã§ã™ã‹?", type: "revelation" },
            { year: "Key Insight", text: "Clinical utility depends on TREATMENT THRESHOLD â€” how bad is it to miss a case vs unnecessarily treat? Different thresholds, different utility assessments.", type: "revelation" },
            { year: "Adoption", text: "DCA ã¯ç¾åœ¨ã€å¤šãã®ã‚¸ãƒ£ãƒ¼ãƒŠãƒ«ã§å¿…è¦ã¨ã•ã‚Œã¦ã„ã¾ã™ã€‚ FDA ã¯ã€è¨ºæ–­æ©Ÿå™¨ã®æ‰¿èªã®ãŸã‚ã®æ±ºå®šæ›²ç·šã‚’æ¤œè¨ã—ã¦ã„ã¾ã™ã€‚ ã€Œè‰¯å¥½ãªçµ±è¨ˆã€ã‹ã‚‰ã€Œè‡¨åºŠçš„ä¾¡å€¤ã€ã¸ç§»è¡Œã—ã¾ã™ã€‚", type: "revelation" },
            { year: "Lesson", text: "Discrimination and calibration are necessary but not sufficient. The ultimate question: Does using this model lead to better decisions than not using it?", type: "revelation" }
          ],
          realData: {
            endpoint: "Decision-making improvement",
            method: "Net benefit calculation",
            comparison: "Model vs treat-all vs treat-none",
            impact: "Now standard in major journals"
          },
          hook: "THE HOOK: A model can have C=0.85 and perfect calibration but provide ZERO clinical benefit if it doesn't change appropriate decisions. Decision curves answer: 'Does this model help patients compared to simpler strategies?' This is the question that actually matters."
        }
      },
      {
        type: 'content',
        content: {
          title: "What Is Net Benefit?",
          sections: [
            {
              heading: "The Core Concept:",
              text: "ç´”åˆ©ç›Šã¯ã€çœŸã®é™½æ€§è€…ï¼ˆæ²»ç™‚å¯¾è±¡ã¨ã—ã¦æ­£ã—ãç‰¹å®šã•ã‚ŒãŸæ‚£è€…ï¼‰ã¨å½é™½æ€§è€…ï¼ˆä¸å¿…è¦ãªæ²»ç™‚ã‚’å—ã‘ãŸæ‚£è€…ï¼‰ã‚’é‡ã¿ä»˜ã‘ã—ã€ä¸å¿…è¦ãªæ²»ç™‚ã®å®³ã‚’è€ƒæ…®ã—ã¦èª¿æ•´ã—ã¾ã™ã€‚"
            },
            {
              heading: "The Formula:",
              text: "Net Benefit = (True Positives / N) - (False Positives / N) Ã— (threshold / (1 - threshold))"
            },
            {
              heading: "Treatment Threshold:",
              items: [
                "ã“ã®ç¢ºç‡ã‚’ä¸Šå›ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚æ²»ç™‚",
                "Reflects tradeoff: harm of missing case vs harm of unnecessary treatment",
                "Low threshold (5%): treat-all may be reasonable",
                "High threshold (30%): only treat clear high-risk patients"
              ]
            },
            {
              heading: "Comparators:",
              items: [
                "TREAT ALL: Give treatment to everyone (net benefit = outcome rate - FP penalty)",
                "TREAT NONE: Give treatment to no one (net benefit = 0)",
                "MODEL: Use model to select patients (should beat both alternatives)"
              ]
            }
          ]
        }
      },
      {
        type: 'method',
        content: {
          label: "æ–¹æ³•: æ±ºå®šæ›²ç·šã®èª­ã¿å–ã‚Š",
          title: "How to Interpret Decision Curve Analysis",
          sections: [
            {
              heading: "X-Axis: Threshold Probability",
              text: "The treatment threshold â€” probability above which you'd treat. Low thresholds (left) = aggressive treatment. High thresholds (right) = conservative treatment."
            },
            {
              heading: "Y-Axis: Net Benefit",
              text: "é«˜ã„ã»ã©è‰¯ã„ã€‚ ã€ŒçœŸé™½æ€§ã‹ã‚‰é‡ã¿ä»˜ã‘ã•ã‚ŒãŸå½é™½æ€§ã‚’å¼•ã„ãŸå€¤ã€ã‚’è¡¨ã—ã¾ã™ã€‚ã—ãã„å€¤ã§ã®ç´”åˆ©ç›ŠãŒæœ€ã‚‚é«˜ã„ãƒ¢ãƒ‡ãƒ«ãŒæœ€é©ã§ã™ã€‚"
            },
            {
              heading: "Key Curves:",
              text: "â€¢ TREAT ALL: Usually a downward slope (more FPs as threshold rises)\nâ€¢ TREAT NONE: Flat line at 0\nâ€¢ MODEL: Should be ABOVE both treat-all and treat-none in useful threshold range"
            },
            {
              heading: "Interpretation:",
              items: [
                "Model above treat-all AND treat-none = useful",
                "Model matches treat-all = model adds nothing",
                "Model below treat-none = model causes harm",
                "Focus on CLINICALLY RELEVANT threshold range"
              ]
            }
          ]
        }
      },
      {
        type: 'decision-tree',
        content: {
          id: 'decision-curve-interpretation',
          title: "Reading a Decision Curve",
          situation: "A decision curve shows a model for predicting 30-day readmission. At threshold 0.10: Model net benefit = 0.05, Treat-all = 0.04, Treat-none = 0. At threshold 0.30: Model net benefit = 0.02, Treat-all = -0.05, Treat-none = 0.",
          nodes: {
            start: {
              question: "At threshold 0.10 (intervene if risk >10%), is the model useful?",
              branches: [
                { text: "Yes â€” model has highest net benefit (0.05 > 0.04 > 0)", nextNode: "threshold10_correct" },
                { text: "Barely â€” model only slightly better than treat-all", nextNode: "threshold10_partial" }
              ]
            },
            threshold10_correct: {
              situation: "Correct â€” at 10% threshold, the model provides slightly more net benefit than treating everyone. Now consider threshold 0.30:",
              question: "At threshold 0.30 (intervene only if risk >30%), what's the best strategy?",
              branches: [
                { text: "Model â€” net benefit 0.02 is positive", nextNode: "model30_correct" },
                { text: "Treat-none â€” model benefit is tiny", nextNode: "treatnone_partial" }
              ]
            },
            threshold10_partial: {
              type: 'outcome',
              outcome: 'partial',
              title: "ãƒãƒ¼ã‚¸ãƒ³ã¯è‡¨åºŠçš„ã«é‡è¦ã§ã™",
              text: "Net benefit 0.05 vs 0.04 is indeed small. But over thousands of patients, even small improvements accumulate. The key question: Is the difference CLINICALLY meaningful and worth the implementation effort?",
              lesson: "Small net benefit improvements can still be worthwhile at scale. But weigh against implementation costs."
            },
            model30_correct: {
              type: 'outcome',
              outcome: 'success',
              title: "Correct reading!",
              text: "At threshold 0.30: Model (0.02) > Treat-none (0) > Treat-all (-0.05). The model provides positive net benefit when we're conservative about intervention. Importantly, treat-all is now HARMFUL (negative net benefit) â€” intervening on everyone at high threshold wastes resources on false positives.",
              lesson: "Decision curves show WHEN a model is useful. This model helps at both thresholds but especially at higher thresholds where treat-all fails."
            },
            treatnone_partial: {
              type: 'outcome',
              outcome: 'partial',
              title: "The model is still better than nothing",
              text: "ç´”åˆ©ç›Š 0.02 ã¯å°ã•ã„ã§ã™ãŒã€ãƒ—ãƒ©ã‚¹ã§ã™ã€‚æ²»ç™‚ãªã—ã®ãƒ¡ãƒªãƒƒãƒˆã¯ 0 ã§ã™ã€‚ä»‹å…¥ãŒè¨±å®¹å¯èƒ½ãªã‚³ã‚¹ãƒˆã§æœ‰æ„ç¾©ãªåˆ©ç›Šã‚’ã‚‚ãŸã‚‰ã™å ´åˆã€ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã™ã‚‹ä¾¡å€¤ã¯ä¾ç„¶ã¨ã—ã¦ã‚ã‚Šã¾ã™ã€‚ ã€Œã‚ãšã‹ãªåˆ©ç›Šã€ã§ã‚‚åˆ©ç›Šã¯å¤‰ã‚ã‚Šã¾ã›ã‚“ã€‚",
              lesson: "Don't dismiss small positive net benefits. But do consider: Is the benefit large enough to justify implementation?"
            }
          }
        }
      },
      {
        type: 'quiz',
        content: {
          question: "A model's decision curve shows it has LOWER net benefit than 'treat all' at thresholds below 15%, but HIGHER net benefit above 15%. This model:",
          options: [
            { id: 'a', text: "Is useless â€” it doesn't beat treat-all at low thresholds", correct: false },
            { id: 'b', text: "Is useful for conservative decision-makers (threshold >15%) but not aggressive ones", correct: true },
            { id: 'c', text: "Has poor discrimination", correct: false },
            { id: 'd', text: "Is poorly calibrated", correct: false }
          ],
          explanation: "Different thresholds reflect different clinical philosophies. If your threshold is >15% (conservative), use the model. If your threshold is <15% (aggressive), just treat everyone â€” the model doesn't help. Clinical utility is THRESHOLD-SPECIFIC."
        }
      },
      {
        type: 'principle',
        content: {
          text: "ğŸ¯ PROGRESS CHECK: You've learned that clinical utility matters more than statistical performance. Decision curve analysis directly measures whether a model improves decisions. A model with modest C-statistic but positive net benefit is more valuable than a 'perfect' model that doesn't change appropriate care."
        }
      }
    ]
  },
  {
    id: 8,
    title: "The Bias",
    subtitle: "PROBAST Assessment",
    principle: 1,
    estimatedTime: "25 min",
    slides: [
      {
        type: 'principle-display',
        content: {
          principle: "A model is only as good as its validation"
        }
      },
      {
        type: 'story-deep',
        content: {
          label: "THE AI MIRAGE: CHEST X-RAY MODELS â€” WHEN SHORTCUTS FOOLED EVERYONE",
          source: "Zech et al. PLOS Med 2018 | DeGrave et al. Nat Mach Intell 2021 | COVID CXR",
          timeline: [
            { year: "2017-18", text: "Deep learning models achieve 'radiologist-level' performance detecting pneumonia on chest X-rays. C-statistics >0.90. Major publications.", type: "normal" },
            { year: "2018", text: "Zech et al.ã‚·ãƒ§ãƒ¼ãƒ¢ãƒ‡ãƒ«ã¯ç—…é™¢ã®ãƒãƒ¼ã‚«ãƒ¼ï¼ˆç—…æ°—ã§ã¯ãªãï¼‰ã‚’å­¦ã³ã¾ã™ã€‚åˆ¥ã®ç—…é™¢ã®ç”»åƒã§ãƒ†ã‚¹ãƒˆã™ã‚‹ã¨ã€ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã¯ C ï½ 0.60 ã«ä½ä¸‹ã—ã¾ã™ã€‚ãƒ¢ãƒ‡ãƒ«ã¯è‚ºç‚ã§ã¯ãªãéƒ¨é–€ã‚¹ã‚¿ãƒ³ãƒ—ã‚’å­¦ç¿’ã—ã¾ã—ãŸã€‚", type: "crisis" },
            { year: "2020", text: "COVID CXR models proliferate. Claims of 95%+ accuracy. Deployed in some hospitals without rigorous validation.", type: "normal" },
            { year: "2021", text: "DeGrave et al. show COVID models used SHORTCUTS: patient positioning (COVID patients were sicker, positioned differently), image artifacts, and laterality markers. Not actual COVID lung findings.", type: "crisis" },
            { year: "Root Cause", text: "ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚° ãƒ‡ãƒ¼ã‚¿ã«å½ã®ç›¸é–¢ãŒã‚ã‚Šã¾ã—ãŸã€‚äº¤çµ¡å› å­ã¯å®Ÿéš›ã®ç—…ç†ã‚ˆã‚Šã‚‚å­¦ã³ã‚„ã™ã‹ã£ãŸã€‚é«˜ã„å†…éƒ¨ã€Œãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã€ã¯å¹»æƒ³ã§ã—ãŸã€‚", type: "revelation" },
            { year: "Lesson", text: "ML ãƒ¢ãƒ‡ãƒ«ã¯ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’è¦‹ã¤ã‘ã¾ã™ãŒã€å¿…ãšã—ã‚‚æ­£ã—ã„ãƒ‘ã‚¿ãƒ¼ãƒ³ã§ã‚ã‚‹ã¨ã¯é™ã‚Šã¾ã›ã‚“ã€‚ã•ã¾ã–ã¾ãªè¨­å®šã«ã‚ãŸã‚‹å¤–éƒ¨æ¤œè¨¼ãŒä¸å¯æ¬ ã§ã™ã€‚ãƒã‚¤ã‚¢ã‚¹è©•ä¾¡ã®ãªã„ã€ŒAI ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã€ã¯ç„¡æ„å‘³ã§ã™ã€‚", type: "revelation" }
          ],
          realData: {
            endpoint: "Pneumonia/COVID detection",
            claimed: "C-statistic >0.90",
            external: "C-statistic ~0.60 (different hospitals)",
            mechanism: "Learned hospital markers, patient positioning â€” not disease"
          },
          hook: "THE HOOK: AI models 'outperformed radiologists' â€” by learning what hospital the image came from, not what disease the patient had. This is why PROBAST and systematic bias assessment exist. High numbers mean nothing if the model learned the wrong things."
        }
      },
      {
        type: 'content',
        content: {
          title: "PROBAST: Prediction Model Risk of Bias Assessment Tool",
          sections: [
            {
              heading: "What Is PROBAST?",
              items: [
                "äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«ç ”ç©¶ã«ãŠã‘ã‚‹ãƒã‚¤ã‚¢ã‚¹ã‚’è©•ä¾¡ã™ã‚‹ãŸã‚ã®ã‚³ã‚¯ãƒ©ãƒ³æ‰¿èªãƒ„ãƒ¼ãƒ«",
                "Assesses RISK OF BIAS and APPLICABILITY concerns",
                "20 signaling questions across 4 domains",
                "Used in systematic reviews of prognostic models"
              ]
            },
            {
              heading: "Four Domains:",
              items: [
                "1. PARTICIPANTS: Appropriate enrollment, representative population",
                "2. PREDICTORS: Defined clearly, measured consistently, available at prediction time",
                "3. OUTCOME: Defined clearly, measured accurately, appropriate time horizon",
                "4. ANALYSIS: Adequate sample size, appropriate handling of missing data, proper validation"
              ]
            },
            {
              heading: "Overall Judgment:",
              text: "HIGH risk of bias if ANY domain is high risk. Like ROBINS-I, PROBAST is intentionally strict. One fatal flaw = study is unreliable."
            }
          ]
        }
      },
      {
        type: 'decision-tree',
        content: {
          id: 'probast-assessment',
          title: "PROBAST in Practice",
          situation: "You're reviewing a COVID mortality model. The study: (1) Used hospitalized patients from one NYC hospital in April 2020; (2) Predictors included 45 variables, selected by significance testing; (3) Outcome was in-hospital death, well-defined; (4) 500 patients, 150 deaths, internal validation by bootstrap only.",
          nodes: {
            start: {
              question: "Assess the PARTICIPANTS domain:",
              branches: [
                { text: "Low risk â€” all hospitalized COVID patients included", nextNode: "participants_low" },
                { text: "High risk â€” one hospital, peak pandemic, selection concerns", nextNode: "participants_high" }
              ]
            },
            participants_high: {
              situation: "Good judgment. Single NYC hospital during peak means: (1) severe cases overrepresented, (2) overwhelmed system, (3) unique local practices. Now assess ANALYSIS domain:",
              question: "ã“ã®ç ”ç©¶ã§ã¯ã€150 ã®ã‚¤ãƒ™ãƒ³ãƒˆã§ 45 ã®å¤‰æ•°ã‚’ãƒ†ã‚¹ãƒˆã—ã¾ã—ãŸã€‚ EPV ã¨ã¯ä½•ã§ã™ã‹?",
              branches: [
                { text: "150/45 = 3.3 â€” critically low, high risk of overfitting", nextNode: "epv_correct" },
                { text: "ãƒ–ãƒ¼ãƒˆã‚¹ãƒˆãƒ©ãƒƒãƒ—æ¤œè¨¼ã«ã‚ˆã‚Šã“ã‚ŒãŒä¿®æ­£ã•ã‚Œã¾ã™ - ä¸­ãƒªã‚¹ã‚¯", nextNode: "bootstrap_wrong" }
              ]
            },
            participants_low: {
              type: 'outcome',
              outcome: 'partial',
              title: "ä¸€èˆ¬åŒ–å¯èƒ½æ€§ã®æ‡¸å¿µã‚’è€ƒæ…®ã—ã¦ãã ã•ã„",
              text: "While all hospitalized patients were included, a single NYC hospital during peak pandemic has unique features: extreme case severity, overwhelmed resources, specific treatment protocols. External populations will differ substantially.",
              lesson: "PROBAST ã¯ã€BIAS (å†…éƒ¨å¦¥å½“æ€§) ã¨ APPLICABILITY (å¤–éƒ¨å¦¥å½“æ€§) ã®ä¸¡æ–¹ã‚’è©•ä¾¡ã—ã¾ã™ã€‚ãŸã¨ãˆãƒã‚¤ã‚¢ã‚¹ãŒã‹ã‹ã£ã¦ã„ãªãã¦ã‚‚ã€ãƒ¢ãƒ‡ãƒ«ã¯ä»–ã®å ´æ‰€ã«ã¯é©ç”¨ã•ã‚Œãªã„å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚"
            },
            epv_correct: {
              situation: "Exactly! EPV of 3.3 is critically low. Now: the authors report C-statistic of 0.88 after bootstrap validation.",
              question: "Does the high C-statistic indicate a good model?",
              branches: [
                { text: "ã¯ã„ â€” ãƒ–ãƒ¼ãƒˆã‚¹ãƒˆãƒ©ãƒƒãƒ—ã¯æ¥½è¦³çš„ã«ä¿®æ­£ã•ã‚Œã€C ã¯ä¾ç„¶ã¨ã—ã¦é«˜ã„", nextNode: "cstat_high_wrong" },
                { text: "No â€” with EPV 3.3, even bootstrap can't fix overfitting; this C is likely inflated", nextNode: "cstat_skeptic_correct" }
              ]
            },
            bootstrap_wrong: {
              type: 'outcome',
              outcome: 'danger',
              title: "Bootstrap cannot fix inadequate sample size!",
              text: "ãƒ–ãƒ¼ãƒˆã‚¹ãƒˆãƒ©ãƒƒãƒ—ã¯ã€é–‹ç™ºãƒ‡ãƒ¼ã‚¿ã®ã‚ªãƒ¼ãƒãƒ¼ãƒ•ã‚£ãƒƒãƒ†ã‚£ãƒ³ã‚°ã‹ã‚‰ OPTIMISM ã‚’æ¨å®šã—ã¾ã™ã€‚ãŸã ã—ã€EPV ãŒ 3.3 ã®å ´åˆã€ãƒ¢ãƒ‡ãƒ«ã¯ä¿¡å·ã§ã¯ãªããƒã‚¤ã‚ºã«é©åˆã—ã¾ã™ã€‚ãƒ–ãƒ¼ãƒˆã‚¹ãƒˆãƒ©ãƒƒãƒ—ã¯ã‚ã‚‹ç¨‹åº¦ã®æ¥½è¦³çš„ãªè¦‹æ–¹ã‚’ç¤ºã—ã¾ã™ãŒã€ãƒ¢ãƒ‡ãƒ«ãŒæ ¹æœ¬çš„ã«ç„¡åŠ¹ã§ã‚ã‚‹ã“ã¨ã‚’æ˜ã‚‰ã‹ã«ã™ã‚‹ã“ã¨ã¯ã§ãã¾ã›ã‚“ã€‚",
              lesson: "ãƒ–ãƒ¼ãƒˆã‚¹ãƒˆãƒ©ãƒƒãƒ—ã¯æ—¢çŸ¥ã®éå­¦ç¿’ã‚’ä¿®æ­£ã—ã¾ã™ã€‚ã‚µãƒ³ãƒ—ãƒ«ã‚µã‚¤ã‚ºãŒæ ¹æœ¬çš„ã«ä¸ååˆ†ãªãƒ¢ãƒ‡ãƒ«ã‚’æ•‘æ¸ˆã™ã‚‹ã“ã¨ã¯ã§ãã¾ã›ã‚“ã€‚"
            },
            cstat_high_wrong: {
              type: 'outcome',
              outcome: 'danger',
              title: "This C-statistic is almost certainly unreliable!",
              text: "With EPV 3.3 and 45 variables selected by significance testing, the model has absorbed massive amounts of noise. Bootstrap helps but cannot fully correct this. The true external C is likely 0.65-0.75 at best. High internal C with low EPV = red flag.",
              lesson: "When EPV is very low, internal metrics (even bootstrap-corrected) are unreliable. Only external validation reveals true performance."
            },
            cstat_skeptic_correct: {
              type: 'outcome',
              outcome: 'success',
              title: "Excellent critical appraisal!",
              text: "You correctly identified: (1) Participant concerns from single-site pandemic peak; (2) Analysis concerns from EPV 3.3; (3) Skepticism of high C despite statistical correction. This study has HIGH risk of bias in multiple domains. PROBAST overall: HIGH RISK.",
              lesson: "PROBAST requires domain-by-domain assessment. Multiple high-risk domains = study should not inform clinical practice without external validation."
            }
          }
        }
      },
      {
        type: 'quiz',
        content: {
          question: "A PROBAST assessment shows: Participants LOW, Predictors LOW, Outcome LOW, Analysis HIGH (inadequate sample size). The overall risk of bias is:",
          options: [
            { id: 'a', text: "Low â€” 3 of 4 domains are low risk", correct: false },
            { id: 'b', text: "Medium â€” mostly low with one concern", correct: false },
            { id: 'c', text: "High â€” one high-risk domain makes overall high", correct: true },
            { id: 'd', text: "Unclear â€” need to average the domains", correct: false }
          ],
          explanation: "ROBINS-I ã¨åŒæ§˜ã«ã€PROBAST ã¯ã€Œæœ€å¼±ãƒªãƒ³ã‚¯ã€åŸç†ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚ã„ãšã‚Œã‹ã®ãƒ‰ãƒ¡ã‚¤ãƒ³ãŒé«˜ãƒªã‚¹ã‚¯ã§ã‚ã‚Œã°ã€ç ”ç©¶å…¨ä½“ãŒé«˜ãƒªã‚¹ã‚¯ã«ãªã‚Šã¾ã™ã€‚å¹³å‡ã—ãŸã‚ŠæŠ•ç¥¨ã—ãŸã‚Šã™ã‚‹ã“ã¨ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚1 ã¤ã®é‡å¤§ãªæ¬ é™¥ã«ã‚ˆã‚Šã€ç ”ç©¶ã¯ç„¡åŠ¹ã«ãªã‚Šã¾ã™ã€‚ 1 ã¤ã®å¤§ããªå•é¡ŒãŒã‚ã‚‹ãƒ¢ãƒ‡ãƒ«ã¯ä¿¡é ¼æ€§ãŒä½ã„ãŸã‚ã€ã“ã‚Œã¯æ„å›³çš„ã«ä¿å®ˆçš„ã§ã™ã€‚"
        }
      },
      {
        type: 'principle',
        content: {
          text: "âš ï¸ THE WARNING: The chest X-ray AI debacle shows that impressive performance numbers can be completely artifactual. Models learn whatever predicts the outcome â€” including confounders, shortcuts, and spurious correlations. PROBAST systematically checks whether a model learned the RIGHT things for the RIGHT reasons."
        }
      }
    ]
  },
  {
    id: 9,
    title: "æ©Ÿæ¢°å­¦ç¿’",
    subtitle: "ML vs Regression",
    principle: 3,
    estimatedTime: "25 min",
    slides: [
      {
        type: 'principle-display',
        content: {
          principle: "äºˆæ¸¬å¤‰æ•°ãŒå¤šã„ã»ã©è‰¯ã„ã¨ã„ã†ã‚ã‘ã§ã¯ã‚ã‚Šã¾ã›ã‚“"
        }
      },
      {
        type: 'story-deep',
        content: {
          label: "THE MODEST TRUTH: ML vs LOGISTIC REGRESSION â€” WHEN COMPLEXITY DIDN'T PAY",
          source: "Christodoulou et al. 2019 | J Clin Epidemiol | Systematic review",
          timeline: [
            { year: "2010s", text: "æ©Ÿæ¢°å­¦ç¿’ã®èª‡å¤§å®£ä¼ã¯åŒ»å­¦ã«ã‚‚åŠã‚“ã§ã„ã¾ã™ã€‚ãƒ‡ã‚£ãƒ¼ãƒ— ãƒ©ãƒ¼ãƒ‹ãƒ³ã‚°ã€ãƒ©ãƒ³ãƒ€ãƒ  ãƒ•ã‚©ãƒ¬ã‚¹ãƒˆã€ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ« ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ãŒäºˆæ¸¬ã«é©å‘½ã‚’ã‚‚ãŸã‚‰ã™ã¨ä¸»å¼µã—ã¦ã„ã¾ã™ã€‚ ã€Œå¾“æ¥ã®çµ±è¨ˆã¯æ™‚ä»£é…ã‚Œã§ã™ã€‚ã€", type: "normal" },
            { year: "2019", text: "Christodoulou et al. systematic review: 71 studies directly comparing ML to logistic regression for clinical prediction. Same data, same outcomes.", type: "normal" },
            { year: "The Results", text: "ML outperformed logistic regression in... 24% of studies. Logistic regression outperformed ML in 10%. No significant difference in 66%. Median C-statistic difference: 0.00.", type: "revelation" },
            { year: "Why?", text: "ä¸­ç¨‹åº¦ã®æ¬¡å…ƒã‚’æŒã¤è¡¨å½¢å¼ã®è‡¨åºŠãƒ‡ãƒ¼ã‚¿ã®å ´åˆã€ãƒ­ã‚¸ã‚¹ãƒ†ã‚£ãƒƒã‚¯å›å¸°ã¯ã»ã¨ã‚“ã©ã®ã‚·ã‚°ãƒŠãƒ«ã‚’æ•æ‰ã—ã¾ã™ã€‚ ML ã®åˆ©ç‚¹ã¯ã€å…¸å‹çš„ãªè‡¨åºŠäºˆæ¸¬å­ã§ã¯ãªãã€ç”»åƒã€ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã€éå¸¸ã«é«˜æ¬¡å…ƒã®å ´åˆã«ç¾ã‚Œã¾ã™ã€‚", type: "revelation" },
            { year: "The Cost", text: "ML ãƒ¢ãƒ‡ãƒ«ã¯è§£é‡ˆã—ã«ããã€å®Ÿè£…ãŒé›£ã—ãã€å°ã•ãªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã¯éå‰°é©åˆãŒèµ·ã“ã‚Šã‚„ã™ãã€ã‚ˆã‚Šå¤šãã®è¨ˆç®—ãƒªã‚½ãƒ¼ã‚¹ã‚’å¿…è¦ã¨ã—ã¾ã™ã€‚åˆ©ç‚¹ã®ãªã„è¤‡é›‘ã•ã€‚", type: "crisis" },
            { year: "Lesson", text: "èª‡å¤§å®£ä¼ã§ã¯ãªãã€å•é¡Œã«åŸºã¥ã„ã¦æ–¹æ³•ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚ã»ã¨ã‚“ã©ã®è‡¨åºŠäºˆæ¸¬ã‚¿ã‚¹ã‚¯ã§ã¯ã€ãƒ­ã‚¸ã‚¹ãƒ†ã‚£ãƒƒã‚¯å›å¸°ã¯ ML ã¨ç«¶åˆã—ã€ã‚ˆã‚Šå®Ÿç”¨çš„ã§ã™ã€‚", type: "revelation" }
          ],
          realData: {
            endpoint: "Various clinical outcomes",
            comparison: "71 ML vs logistic regression comparisons",
            result: "Median AUC difference: 0.00",
            winner: "ç ”ç©¶ã® 66% ã«æœ‰æ„å·®ãªã—"
          },
          hook: "THE HOOK: The systematic comparison showed ML and logistic regression perform EQUALLY for most clinical prediction. ML wins in specific domains (imaging, sequences) but not for standard clinical data. Don't use complexity when simplicity works."
        }
      },
      {
        type: 'story-deep',
        content: {
          label: "REAL-WORLD CASE: THE COVID SEVERITY SCORES RACE â€” WHEN SPEED DEFEATED RIGOR",
          source: "Wynants et al. BMJ 2020 (ç”ŸããŸç³»çµ±çš„ãƒ¬ãƒ“ãƒ¥ãƒ¼) | ISARIC 4C ã‚¹ã‚¿ãƒ‡ã‚£ | COVID-19 äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«",
          timeline: [
            { year: "Early 2020", text: "COVID-19 pandemic begins. Clinicians desperately need tools to predict which patients will deteriorate. Researchers worldwide rush to develop prognostic models.", type: "normal" },
            { year: "March-June 2020", text: "ã‚ãšã‹ 4 ã‹æœˆã§ 100 ã‚’è¶…ãˆã‚‹ COVID äºˆå¾Œãƒ¢ãƒ‡ãƒ«ãŒå…¬é–‹ã•ã‚Œã¾ã—ãŸã€‚æ©Ÿæ¢°å­¦ç¿’ã€ãƒ­ã‚¸ã‚¹ãƒ†ã‚£ãƒƒã‚¯å›å¸°ã€ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ« ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ãªã©ã€ã‚ã‚‰ã‚†ã‚‹æ‰‹æ³•ãŒå°å…¥ã•ã‚Œã¦ã„ã¾ã™ã€‚ãƒ—ãƒ¬ãƒ—ãƒªãƒ³ãƒˆã¯ã‚µãƒ¼ãƒãƒ¼ã«ãƒ•ãƒ©ãƒƒãƒ‰ã—ã¾ã™ã€‚", type: "normal" },
            { year: "The Review", text: "Wynants et al. systematic review: Of 107 models evaluated, nearly ALL were at high risk of bias. Small samples, no external validation, overfitting to local populations, outcome data that hadn't matured.", type: "crisis" },
            { year: "Common Flaws", text: "ä»£è¡¨çš„ã§ã¯ãªã„ã‚µãƒ³ãƒ—ãƒ« (åˆæœŸã®ãƒ‘ãƒ³ãƒ‡ãƒŸãƒƒã‚¯ã®ã‚±ãƒ¼ã‚¹)ã€‚æ€¥æ€§ç–¾æ‚£æ™‚ã®è»¢å¸°ã®ç¢ºèªã€‚æ¬ æãƒ‡ãƒ¼ã‚¿ã®ä¸é©åˆ‡ãªå–ã‚Šæ‰±ã„ã€‚æ™‚é–“çš„ã¾ãŸã¯åœ°ç†çš„ãªæ¤œè¨¼ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚ä¿¡å·ã§ã¯ãªããƒã‚¤ã‚ºã«èª¿æ•´ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã€‚", type: "crisis" },
            { year: "The Exceptions", text: "A few models (4C Mortality Score, ISARIC) were developed properly: large datasets (tens of thousands), multiple sites, external validation across countries. These took LONGER but actually worked.", type: "revelation" },
            { year: "Lesson", text: "Urgent need doesn't justify methodological shortcuts. Most rushed COVID models were useless â€” or worse, misleading. The rigorous models that took time to develop properly were the ones that actually helped. <span class='lesson-gold'>THE LESSON: In a crisis, there's enormous pressure to 'do something.' But a bad model isn't better than no model. Speed without rigor produces predictions that can't be trusted when trust matters most.</span>", type: "revelation" }
          ],
          realData: {
            endpoint: "COVID-19 mortality or deterioration",
            models: ">100 published in 4 months",
            quality: "Nearly all at high risk of bias",
            validated: "Only handful properly externally validated"
          },
          hook: "THE HOOK: The COVID pandemic was a natural experiment in rapid model development. The result? Quantity did not equal quality. Over 100 models, nearly all useless. A handful of properly developed models (4C, ISARIC) required large multinational cohorts and careful validation. There are no shortcuts to good prognostic modeling, even in an emergency."
        }
      },
      {
        type: 'content',
        content: {
          title: "When Does ML Actually Help?",
          sections: [
            {
              heading: "ML Advantages:",
              items: [
                "é«˜æ¬¡å…ƒãƒ‡ãƒ¼ã‚¿ (ã‚²ãƒãƒŸã‚¯ã‚¹ã€ãƒ—ãƒ­ãƒ†ã‚ªãƒŸã‚¯ã‚¹)",
                "Image data (radiology, pathology, dermatology)",
                "Sequential/temporal data (ECGs, time series)",
                "Complex non-linear interactions (rare in clinical prediction)",
                "Very large datasets (>100,000 samples)"
              ]
            },
            {
              heading: "Logistic Regression Advantages:",
              items: [
                "Interpretable coefficients",
                "Handles small samples better (with penalization)",
                "å®Ÿè£…ã¨å±•é–‹ãŒå®¹æ˜“",
                "Explicit uncertainty quantification",
                "ã‚ˆãç†è§£ã•ã‚ŒãŸãƒ—ãƒ­ãƒ‘ãƒ†ã‚£ã¨è¨ºæ–­"
              ]
            },
            {
              heading: "The Decision Framework:",
              text: "If your data is tabular with <50 predictors and <10,000 samples, start with penalized logistic regression. Try ML if you have specific reasons (non-linearity, interactions, high dimensions). Compare fairly (same data, same validation)."
            }
          ]
        }
      },
      {
        type: 'decision-tree',
        content: {
          id: 'ml-vs-regression',
          title: "Should You Use Machine Learning?",
          situation: "You're developing a 30-day mortality model for heart failure patients. You have: 2,000 patients, 200 deaths, 25 candidate predictors (demographics, labs, vitals), structured EHR data. A colleague insists you use deep learning because it's 'state of the art.'",
          nodes: {
            start: {
              question: "25 äºˆæ¸¬å™¨ã® EPV ã¯ä½•ã§ã™ã‹ãƒ¢ãƒ‡ãƒ«?",
              branches: [
                { text: "200/25 = 8 â€” marginal for any method", nextNode: "epv_marginal" },
                { text: "ãƒ‡ã‚£ãƒ¼ãƒ— ãƒ©ãƒ¼ãƒ‹ãƒ³ã‚°ã«ã¯å¤§é‡ã®ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã™", nextNode: "plenty_wrong" }
              ]
            },
            epv_marginal: {
              situation: "Correct â€” EPV of 8 is marginal. Deep learning typically needs MORE data than logistic regression to avoid overfitting.",
              question: "ãƒ‡ãƒ¼ã‚¿ãŒé™ã‚‰ã‚Œã¦ã„ã‚‹å ´åˆã€ã©ã®ã‚ˆã†ãªã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’ã¨ã‚Šã¾ã™ã‹?",
              branches: [
                { text: "Use deep learning but with regularization", nextNode: "dl_regularize_partial" },
                { text: "Use penalized logistic regression (LASSO/ridge)", nextNode: "penalized_correct" }
              ]
            },
            plenty_wrong: {
              type: 'outcome',
              outcome: 'danger',
              title: "ãƒ‡ã‚£ãƒ¼ãƒ— ãƒ©ãƒ¼ãƒ‹ãƒ³ã‚°ã«ã¯ã€ãã‚Œä»¥ä¸‹ã§ã¯ãªãã€ã‚ˆã‚Šå¤šãã®ãƒ‡ãƒ¼ã‚¿ãŒå¿…è¦ã§ã™!",
              text: "ãƒ‡ã‚£ãƒ¼ãƒ— ãƒ©ãƒ¼ãƒ‹ãƒ³ã‚°ã«ã¯æ•°ç™¾ä¸‡ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ¼ãŒã‚ã‚Šã¾ã™ã€‚ 2,000 äººã®æ‚£è€…ã¨ 200 ã®ã‚¤ãƒ™ãƒ³ãƒˆãŒã‚ã‚‹å ´åˆã€ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ« ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã¯å¤§è¦æ¨¡ãªã‚ªãƒ¼ãƒãƒ¼ãƒ•ã‚£ãƒƒãƒˆã«ãªã‚Šã¾ã™ã€‚ã“ã‚Œã¯ã¾ã•ã«ã€ãƒ­ã‚¸ã‚¹ãƒ†ã‚£ãƒƒã‚¯å›å¸°ãŒ ML ã‚ˆã‚Šã‚‚å„ªã‚ŒãŸãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ç™ºæ®ã™ã‚‹è¨­å®šã§ã™ã€‚ã‚µãƒ³ãƒ—ãƒ« ã‚µã‚¤ã‚ºã®åˆ¶ç´„ãŒã‚ã‚‹ãŸã‚ã€ã‚ˆã‚Šã‚·ãƒ³ãƒ—ãƒ«ãªæ–¹æ³•ã‚’å„ªå…ˆã—ã¾ã™ã€‚",
              lesson: "ML/DL ã¯ãƒ“ãƒƒã‚° ãƒ‡ãƒ¼ã‚¿ã§å¨åŠ›ã‚’ç™ºæ®ã—ã¾ã™ã€‚ãƒ‡ãƒ¼ã‚¿ãŒé™ã‚‰ã‚Œã¦ã„ã‚‹å ´åˆã€ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãŒå°‘ãªã„å˜ç´”ãªãƒ¢ãƒ‡ãƒ«ã®æ–¹ãŒä¸€èˆ¬åŒ–ãŒå®¹æ˜“ã§ã™ã€‚"
            },
            dl_regularize_partial: {
              type: 'outcome',
              outcome: 'partial',
              title: "Regularization helps but doesn't fully solve the problem",
              text: "ãƒ‰ãƒ­ãƒƒãƒ—ã‚¢ã‚¦ãƒˆã€é‡ã¿æ¸›è¡°ã€ãŠã‚ˆã³æ—©æœŸåœæ­¢ã‚’é©ç”¨ã§ãã¾ã™ã€‚ã—ã‹ã—ã€200 ã®ã‚¤ãƒ™ãƒ³ãƒˆã‚’ä¼´ã†ãƒ‡ã‚£ãƒ¼ãƒ—ãƒ©ãƒ¼ãƒ‹ãƒ³ã‚°ã¯è‹¦æˆ¦ã—ã¦ã„ã¾ã™ã€‚ååˆ†ã«æ­£è¦åŒ–ã•ã‚ŒãŸãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ« ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã§ã‚‚ã€ã‚µãƒ³ãƒ—ãƒ«ãŒå°ã•ã„ã¨è‹¦åŠ´ã—ã¾ã™ã€‚ LASSO ã‚’ä½¿ç”¨ã—ãŸãƒ­ã‚¸ã‚¹ãƒ†ã‚£ãƒƒã‚¯å›å¸°ã¯ã€ã‚ˆã‚Šå°‘ãªã„åŠ´åŠ›ã§åŒç­‰ä»¥ä¸Šã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ç™ºæ®ã™ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚",
              lesson: "Regularization is essential but doesn't overcome fundamental sample size limitations for complex models."
            },
            penalized_correct: {
              situation: "Good choice! Now: Your logistic regression model achieves C = 0.78. A vendor offers a proprietary ML model claiming C = 0.82 on similar populations.",
              question: "ãƒ™ãƒ³ãƒ€ãƒ¼ã® ML ãƒ¢ãƒ‡ãƒ«ã«åˆ‡ã‚Šæ›¿ãˆã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã‹?",
              branches: [
                { text: "Yes â€” 0.82 > 0.78, and ML is more sophisticated", nextNode: "switch_wrong" },
                { text: "No â€” demand external validation on YOUR population first", nextNode: "validation_first_correct" }
              ]
            },
            switch_wrong: {
              type: 'outcome',
              outcome: 'danger',
              title: "Remember Epic Sepsis!",
              text: "Vendor-reported metrics are often inflated. A 0.04 difference in C-statistic is within noise. Without validation on YOUR population, you don't know if the ML model works in your context. Plus: Can you interpret it? Debug it? Trust it?",
              lesson: "ãƒ™ãƒ³ãƒ€ãƒ¼ã®ä¸»å¼µã«åŸºã¥ããƒ¢ãƒ‡ãƒ«ã‚’æ±ºã—ã¦æ¡ç”¨ã—ãªã„ã§ãã ã•ã„ã€‚è¨­å®šã®ä»£è¡¨çš„ãªãƒ‡ãƒ¼ã‚¿ã«å¯¾ã—ã¦ç‹¬ç«‹ã—ãŸæ¤œè¨¼ã‚’è¦æ±‚ã—ã¾ã™ã€‚"
            },
            validation_first_correct: {
              type: 'outcome',
              outcome: 'success',
              title: "Evidence-based skepticism!",
              text: "æ¡ç”¨å‰ã«æ­£ã—ãæ¤œè¨¼ã‚’è¦æ±‚ã—ã¾ã—ãŸã€‚ 0.04 C çµ±è¨ˆã®å·® (0.78 å¯¾ 0.82) ã¯ãƒã‚¤ã‚ºã§ã‚ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚ãŸã¨ãˆæœ¬ç‰©ã ã£ãŸã¨ã—ã¦ã‚‚ã€è‡¨åºŠä¸Šã®æœ‰ç”¨æ€§ãŒå‘ä¸Šã™ã‚‹ã¨ã¯é™ã‚Šã¾ã›ã‚“ã€‚è§£é‡ˆå¯èƒ½ãªãƒ­ã‚¸ã‚¹ãƒ†ã‚£ãƒƒã‚¯ ãƒ¢ãƒ‡ãƒ«ã¯ã€ã‚ˆã‚Šå®‰å…¨ã§å®Ÿè£…ãŒç°¡å˜ã«ãªã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚",
              lesson: "Prefer simpler models unless complexity provides clear, validated, clinically meaningful benefit."
            }
          }
        }
      },
      {
        type: 'quiz',
        content: {
          question: "A radiology department wants to implement an AI model for detecting pneumonia on chest X-rays. The model was trained and validated at Stanford with C = 0.92. Before deploying at your community hospital, you should:",
          options: [
            { id: 'a', text: "Deploy immediately â€” Stanford is a top institution", correct: false },
            { id: 'b', text: "Validate on a sample of your hospital's images first", correct: true },
            { id: 'c', text: "FDA ã®æ‰¿èªã‚’å¾…ã¡ã¾ã™", correct: false },
            { id: 'd', text: "Use it only for patients similar to Stanford's population", correct: false }
          ],
          explanation: "æ”¾å°„ç·šç§‘ AI ãƒ¢ãƒ‡ãƒ«ã¯ã€å–å¾—ãƒ—ãƒ­ãƒˆã‚³ãƒ«ã€æ©Ÿå™¨ã€æ‚£è€…é›†å›£ã€ç”»è³ªã«æ•æ„Ÿã§ã‚ã‚‹ã“ã¨ã§çŸ¥ã‚‰ã‚Œã¦ã„ã¾ã™ã€‚ã‚¹ã‚¿ãƒ³ãƒ•ã‚©ãƒ¼ãƒ‰ã§ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã¯ã€ã‚¹ã‚¿ãƒ³ãƒ•ã‚©ãƒ¼ãƒ‰å›ºæœ‰ã®æ©Ÿèƒ½ã‚’å­¦ç¿’ã—ã¦ã„ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚å°å…¥å‰ã«ãƒ­ãƒ¼ã‚«ãƒ«æ¤œè¨¼ãŒä¸å¯æ¬ ã§ã™ã€‚èƒ¸éƒ¨ X ç·š AI ã®å¤±æ•—ãŒã“ã‚Œã‚’è¨¼æ˜ã—ã¾ã—ãŸã€‚"
        }
      },
      {
        type: 'principle',
        content: {
          text: "ğŸ¯ PROGRESS CHECK: You've learned that ML isn't magic. For tabular clinical data, logistic regression often matches ML performance with better interpretability. ML advantages emerge with images, sequences, or very large datasets. Choose methods based on your data and problem, not hype. Always validate before deployment."
        }
      }
    ]
  },
  {
    id: 10,
    title: "The Implementation",
    subtitle: "ãƒ¢ãƒ‡ãƒ«ã‹ã‚‰å®Ÿè·µã¸",
    principle: 5,
    estimatedTime: "20 min",
    slides: [
      {
        type: 'principle-display',
        content: {
          principle: "Clinical utility trumps statistics"
        }
      },
      {
        type: 'story-deep',
        content: {
          label: "THE IMPLEMENTATION GAP: CURB-65 â€” WHEN A GOOD MODEL GATHERED DUST",
          source: "Implementation science literature | Pneumonia severity scores | Clinical workflow",
          timeline: [
            { year: "2003", text: "CURB-65 published for pneumonia severity assessment. Beautifully simple: 5 items, integer points, validated. C-statistic ~0.75 for mortality.", type: "normal" },
            { year: "Development", text: "Confusion, Urea >7, Respiratory rate â‰¥30, BP low, Age â‰¥65. Score 0-1 = outpatient. Score 2 = consider admission. Score 3-5 = ICU.", type: "normal" },
            { year: "The Problem", text: "Widespread publication didn't mean widespread use. Studies showed CURB-65 used in <50% of pneumonia admissions. Clinicians continued using gestalt.", type: "crisis" },
            { year: "Barriers", text: "ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã«çµ±åˆã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ EHR ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã¯è¡¨ç¤ºã•ã‚Œã¾ã›ã‚“ã€‚æ¤œç´¢åŸºæº–ãŒå¿…è¦ã§ã™ã€‚ ã€Œèª°ãŒç—…æ°—ã‹ã‚ã‹ã‚‹ã€ã¨ãã¯ã€ãã®å¿…è¦ã¯ãªã„ã¨æ„Ÿã˜ã¾ã™ã€‚è‡¨åºŠæ…£æ€§ã€‚", type: "crisis" },
            { year: "ã†ã¾ãã„ã£ãŸè§£æ±ºç­–", text: "EHR auto-calculation, mandatory documentation, clinical decision support alerts. When CURB-65 was EMBEDDED in workflow, usage increased dramatically.", type: "revelation" },
            { year: "Lesson", text: "A valid model that isn't USED is worthless. Implementation requires: EHR integration, workflow fit, clinician buy-in, and often, mandatory documentation.", type: "revelation" }
          ],
          realData: {
            endpoint: "30-day mortality in pneumonia",
            model: "CURB-65",
            discrimination: "C-statistic ~0.75",
            usage: "<50% before implementation interventions"
          },
          hook: "THE HOOK: CURB-65 was published in 2003. Twenty years later, it's still underused in many hospitals. A prediction model is only as good as its implementation. The final mile â€” from validation to bedside â€” is often the hardest."
        }
      },
      {
        type: 'content',
        content: {
          title: "Implementation Barriers",
          sections: [
            {
              heading: "Clinician Factors:",
              items: [
                "Awareness: Don't know the score exists",
                "Agreement: Don't believe it adds value over clinical judgment",
                "Self-efficacy: Don't know how to use it",
                "Outcome expectancy: Don't expect it to improve patient outcomes",
                "Inertia: Existing practice works 'well enough'"
              ]
            },
            {
              heading: "System Factors:",
              items: [
                "No EHR integration â€” requires separate calculation",
                "Workflow disruption â€” extra steps, extra time",
                "No feedback â€” clinicians don't see if score helped",
                "No accountability â€” no tracking of score use",
                "Alert fatigue â€” if auto-calculated, may be ignored"
              ]
            },
            {
              heading: "Model Factors:",
              items: [
                "Complexity â€” can't remember the criteria",
                "ãƒ‡ãƒ¼ã‚¿è¦ä»¶ - æ—¥å¸¸çš„ã«åé›†ã•ã‚Œã¦ã„ãªã„äºˆæ¸¬å› å­",
                "Unclear thresholds â€” what action for what score?",
                "Lack of local validation â€” doesn't feel applicable"
              ]
            }
          ]
        }
      },
      {
        type: 'method',
        content: {
          label: "æ–¹æ³•: æˆåŠŸã—ãŸå®Ÿè£…",
          title: "How to Get Models Into Practice",
          sections: [
            {
              heading: "1. Choose the Right Model:",
              text: "â€¢ Simple enough to use (or auto-calculate)\nâ€¢ Validated in similar population\nâ€¢ Clear action thresholds\nâ€¢ Addresses a real clinical need"
            },
            {
              heading: "2. Integrate Into Workflow:",
              text: "â€¢ EHR ã«çµ„ã¿è¾¼ã‚€ (å¯èƒ½ãªå ´åˆã¯è‡ªå‹•è¨ˆç®—) â€¢ ãƒˆãƒªã‚¬ãƒ¼é©åˆ‡ãªè‡¨åºŠçš„ç¬é–“ â€¢ æ„æ€æ±ºå®šãŒè¡Œã‚ã‚Œã‚‹å ´æ‰€ã«çµæœã‚’è¡¨ç¤ºã™ã‚‹ â€¢ è¿½åŠ ã®ãƒ‡ãƒ¼ã‚¿å…¥åŠ›ã‚’æœ€å°é™ã«æŠ‘ãˆã‚‹"
            },
            {
              heading: "3. Provide Decision Support:",
              text: "â€¢ ã‚¹ã‚³ã‚¢ã‚’æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã«å¤‰æ›ã™ã‚‹ â€¢ æ¨å¥¨äº‹é …ã®èª¬æ˜ï¼ˆã“ã®ã‚¹ã‚³ã‚¢ãŒã“ã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’æ¨å¥¨ã™ã‚‹ç†ç”±ï¼‰ â€¢ æ–‡æ›¸ã«ã‚ˆã‚‹ä¸Šæ›¸ãã‚’è¨±å¯ã™ã‚‹ â€¢ æ•°å€¤ã‚’ä¸ãˆã‚‹ã ã‘ã§ãªãã€ã‚¬ã‚¤ãƒ€ãƒ³ã‚¹ã‚’æä¾›ã™ã‚‹"
            },
            {
              heading: "4. Monitor and Feedback:",
              text: "â€¢ Track score usage rates\nâ€¢ Monitor patient outcomes\nâ€¢ Provide feedback to clinicians\nâ€¢ Iterate and improve"
            }
          ]
        }
      },
      {
        type: 'story-deep',
        content: {
          label: "REAL-WORLD CASE: THE EPIC DETERIORATION INDEX â€” TECHNICALLY VALID, CLINICALLY FRUSTRATED",
          source: "Epic Systems implementation studies | Alert fatigue literature | Clinical workflow research",
          timeline: [
            { year: "Development", text: "Epic's Deterioration Index is developed to predict patient decline 6-12 hours before clinical recognition. The algorithm analyzes vital signs, lab trends, nursing assessments. Technically sophisticated.", type: "normal" },
            { year: "Deployment", text: "ç—…é™¢ã¯æ‚ªåŒ–æŒ‡æ•°ã®å°å…¥ã‚’æ€¥ã„ã§ã„ã¾ã™ã€‚ç´„æŸã¯ã€æ‚£è€…ã®æ¸›å°‘ã‚’æ—©æœŸã«è­¦å‘Šã™ã‚‹ã“ã¨ã§ã™ã€‚çœ‹è­·å¸«ã¨åŒ»å¸«ã¯æ‚£è€…ãŒè¡çªã™ã‚‹å‰ã«è­¦å‘Šã‚’å—ã‘ã¾ã™ã€‚å‘½ã¯æ•‘ã‚ã‚Œã¾ã™ã€‚", type: "normal" },
            { year: "Reality Check", text: "ç ”ç©¶ã«ã‚ˆã‚Šå•é¡ŒãŒæ˜ã‚‰ã‹ã«ãªã‚Šã¾ã—ãŸã€‚ã™ã§ã«é©åˆ‡ãªã‚±ã‚¢ã‚’å—ã‘ã¦ã„ã‚‹æ‚£è€…ã«å¯¾ã—ã¦å¤šãã®ã‚¢ãƒ©ãƒ¼ãƒˆãŒç™ºã›ã‚‰ã‚Œã¾ã™ã€‚çœ‹è­·å¸«ã¯æ‚£è€…ãŒç—…æ°—ã§ã‚ã‚‹ã“ã¨ã‚’çŸ¥ã£ã¦ã„ã¾ã™ã€‚ã‚¢ãƒ©ãƒ¼ãƒˆã¯ä¿¡å·ã§ã¯ãªããƒã‚¤ã‚ºã‚’è¿½åŠ ã—ã¾ã™ã€‚", type: "crisis" },
            { year: "Alert Fatigue", text: "Clinicians receive dozens of alerts daily. Most are for patients already being managed. The 'cry wolf' effect sets in: alerts are ignored, dismissed without review, treated as background noise.", type: "crisis" },
            { year: "The Gap", text: "The model WORKS â€” it identifies deteriorating patients. But identification isn't the bottleneck. The question is: what can clinicians DO differently? If the patient is already on telemetry, already receiving fluids, already being watched â€” the alert provides no new action.", type: "revelation" },
            { year: "Lesson", text: "A prognostic model deployed without actionability is just noise. The Deterioration Index failed not because it couldn't predict â€” but because prediction without clear, novel intervention is useless at the bedside. <span class='lesson-gold'>THE LESSON: Implementation requires more than accurate prediction. It requires: actionable thresholds, novel information, clear interventions, and workflow integration. Prediction without actionability is just sophisticated interruption.</span>", type: "revelation" }
          ],
          realData: {
            endpoint: "Patient deterioration",
            model: "Epic Deterioration Index",
            problem: "Alert fatigue from non-actionable predictions",
            barrier: "Predictions often confirmed what clinicians already knew"
          },
          hook: "THE HOOK: The Epic Deterioration Index is a case study in implementation failure. The model wasn't wrong â€” it successfully identified deteriorating patients. But the alerts often told clinicians what they already knew, for patients already receiving appropriate care. Prediction needs a purpose: if knowing the score doesn't change what you do, the score is just noise."
        }
      },
      {
        type: 'decision-tree',
        content: {
          id: 'implementation-strategy',
          title: "Planning Implementation",
          situation: "Your hospital wants to implement a sepsis prediction model. The model requires: lactate level, vital signs, and WBC count. It outputs a probability of sepsis. You need to design the implementation.",
          nodes: {
            start: {
              question: "è‡¨åºŠãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã®ã©ã“ã§ãƒ¢ãƒ‡ãƒ«ã‚’ãƒˆãƒªã‚¬ãƒ¼ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã‹?",
              branches: [
                { text: "When a patient is admitted to any unit", nextNode: "admission_trigger" },
                { text: "When vital signs suggest possible deterioration (SIRS-like)", nextNode: "vital_trigger_correct" },
                { text: "Every 4 hours automatically for all inpatients", nextNode: "regular_trigger_partial" }
              ]
            },
            admission_trigger: {
              type: 'outcome',
              outcome: 'partial',
              title: "è‡¨åºŠã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’è€ƒæ…®ã—ã¦ãã ã•ã„ã€‚",
              text: "Admission is one trigger point, but sepsis can develop DURING hospitalization. A patient admitted for elective surgery who develops sepsis on day 3 wouldn't be captured. Consider continuous or recurrent triggering.",
              lesson: "ãƒˆãƒªã‚¬ãƒ¼ãƒã‚¤ãƒ³ãƒˆã‚’æ‚£è€…ã®å…¥é™¢æ™‚ã ã‘ã§ãªãã€æ•—è¡€ç—‡ç™ºç—‡æ™‚ã¨ä¸€è‡´ã•ã›ã¾ã™ã€‚"
            },
            vital_trigger_correct: {
              situation: "è‰¯ã„ - è‡¨åºŠç—‡çŠ¶ã®æ‚ªåŒ–ã«å¿œã˜ã¦ãƒˆãƒªã‚¬ãƒ¼ã—ã€æ–°è¦ç™ºç—‡ç—‡ä¾‹ã‚’æ•æ‰ã—ã¾ã™ã€‚ã“ã“ã§ã€ãƒ¢ãƒ‡ãƒ«ãŒèµ·å‹•ã—ã€æ•—è¡€ç—‡ã®ç¢ºç‡ãŒ 45% ã§ã‚ã‚‹ã¨äºˆæ¸¬ã—ã¾ã™ã€‚ã‚¢ãƒ©ãƒ¼ãƒˆã¯ä½•ã‚’è¡¨ç¤ºã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã‹?",
              question: "Alert design:",
              branches: [
                { text: "'Sepsis probability 45%' â€” let clinician decide", nextNode: "probability_only_partial" },
                { text: "'Moderate sepsis risk â€” consider: lactate, blood cultures, antibiotics' with order set link", nextNode: "actionable_correct" }
              ]
            },
            regular_trigger_partial: {
              type: 'outcome',
              outcome: 'partial',
              title: "Beware alert fatigue!",
              text: "ã™ã¹ã¦ã®å…¥é™¢æ‚£è€…ã«å¯¾ã—ã¦ 4 æ™‚é–“ã”ã¨ã«è¨ˆç®—ã™ã‚‹ã¨ã€è†¨å¤§ãªæ•°ã®ã‚¢ãƒ©ãƒ¼ãƒˆãŒç”Ÿæˆã•ã‚Œã€ãã®ã»ã¨ã‚“ã©ãŒä½ãƒªã‚¹ã‚¯ã®æ‚£è€…ã«å¯¾ã—ã¦ç™ºç”Ÿã—ã¾ã™ã€‚è‡¨åºŠåŒ»ã¯ãã‚Œã‚‰ã‚’ç„¡è¦–ã™ã‚‹ã“ã¨ã‚’å­¦ã³ã¾ã™ï¼ˆç–²åŠ´ã‚’è­¦å‘Šã—ã¾ã™ï¼‰ã€‚å¯¾è±¡ã‚’çµã£ãŸãƒˆãƒªã‚¬ãƒ¼ã¯ã‚ˆã‚ŠåŠ¹æœçš„ã§ã™ã€‚",
              lesson: "Implementation must balance sensitivity against clinician burden. Alert fatigue is a real implementation failure mode."
            },
            probability_only_partial: {
              type: 'outcome',
              outcome: 'partial',
              title: "Probabilities alone don't drive action",
              text: "Clinicians don't know what to DO with '45%.' Is that high? What action is warranted? Best practice: translate probability to risk category and link to specific recommended actions (orders, consults).",
              lesson: "è‡¨åºŠæ„æ€æ±ºå®šã‚µãƒãƒ¼ãƒˆã¯å®Ÿè¡Œå¯èƒ½ã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚æ•°å€¤ã¯æ„æ€æ±ºå®šã®ã‚µãƒãƒ¼ãƒˆã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚ãƒªãƒ³ã‚¯ã•ã‚ŒãŸã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’å«ã‚€æ¨å¥¨äº‹é …ã¯ã€"
            },
            actionable_correct: {
              type: 'outcome',
              outcome: 'success',
              title: "ã“ã‚Œã«ã‚ˆã‚Šé©åˆ‡ãªã‚¢ã‚¯ã‚·ãƒ§ãƒ³ãŒæ¨é€²ã•ã‚Œã¾ã™!",
              text: "Risk category + specific recommendations + order set link = actionable decision support. The clinician sees the warning, understands the risk level, knows what to do, and can act immediately. This is how models change behavior.",
              lesson: "Implementation success requires: right trigger, clear recommendation, actionable orders. Make the right thing the easy thing."
            }
          }
        }
      },
      {
        type: 'quiz',
        content: {
          question: "A hospital implements a readmission prediction model. Alerts fire frequently, but readmission rates don't improve. The most likely explanation is:",
          options: [
            { id: 'a', text: "The model has poor discrimination", correct: false },
            { id: 'b', text: "Alerts aren't linked to effective interventions", correct: true },
            { id: 'c', text: "ãƒ¢ãƒ‡ãƒ«ã®èª¿æ•´ãŒä¸ååˆ†ã§ã™", correct: false },
            { id: 'd', text: "Clinicians don't trust the model", correct: false }
          ],
          explanation: "åŠ¹æœçš„ãªä»‹å…¥ãŒãªã‘ã‚Œã°äºˆæ¸¬ã¯çµæœã‚’æ”¹å–„ã—ã¾ã›ã‚“ã€‚ã‚¢ãƒ©ãƒ¼ãƒˆã«ã€Œå†å…¥é™¢ãƒªã‚¹ã‚¯ãŒé«˜ã„ã€ã¨è¡¨ç¤ºã•ã‚Œã¦ã„ã‚‹ã«ã‚‚ã‹ã‹ã‚ã‚‰ãšã€ãã®ãƒªã‚¹ã‚¯ã‚’è»½æ¸›ã™ã‚‹ãŸã‚ã®æ˜ç¢ºã§åŠ¹æœçš„ãªã‚¢ã‚¯ã‚·ãƒ§ãƒ³ãŒãªã„å ´åˆã€ãã®ã‚¢ãƒ©ãƒ¼ãƒˆã¯ãƒã‚¤ã‚ºã§ã™ã€‚å®Ÿè£…ã§ã¯ã€äºˆæ¸¬ã‚’å®Ÿéš›ã«æ©Ÿèƒ½ã™ã‚‹ä»‹å…¥ã«çµã³ä»˜ã‘ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚"
        }
      },
      {
        type: 'principle',
        content: {
          text: "âš ï¸ THE WARNING: Most validated models never reach clinical practice. Those that do often fail to improve outcomes â€” not because the model is wrong, but because implementation is poor. The final step â€” embedding prediction into action â€” is where many projects fail."
        }
      }
    ]
  },
  {
    id: 11,
    title: "The Capstone",
    subtitle: "Full Model Evaluation",
    principle: null,
    estimatedTime: "30 min",
    slides: [
      {
        type: 'title',
        content: {
          title: "The Capstone",
          subtitle: "Evaluating a Prognostic Model",
          text: "Apply everything you've learned to critically evaluate a real prognostic model study."
        }
      },
      {
        type: 'content',
        content: {
          title: "Capstone Exercise: The COVID Mortality Model",
          sections: [
            {
              heading: "The Study:",
              text: "è«–æ–‡ã§ã¯ã€æ–°å‹ã‚³ãƒ­ãƒŠã‚¦ã‚¤ãƒ«ã‚¹æ„ŸæŸ“ç—‡ã«ã‚ˆã‚‹æ­»äº¡ç‡ã‚’äºˆæ¸¬ã™ã‚‹ãŸã‚ã®æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã‚’ç´¹ä»‹ã—ã¦ã„ã¾ã™ã€‚ä¸»å¼µ: ã€Œå½“ç¤¾ã® XGBoost ãƒ¢ãƒ‡ãƒ«ã¯ã€C çµ±è¨ˆå€¤ 0.91 ã‚’é”æˆã—ã€æ–°å‹ã‚³ãƒ­ãƒŠã‚¦ã‚¤ãƒ«ã‚¹ã®ãƒˆãƒªã‚¢ãƒ¼ã‚¸ã«é©å‘½ã‚’ã‚‚ãŸã‚‰ã—ã¾ã™ã€‚ã€"
            },
            {
              heading: "Study Details:",
              items: [
                "Data: 3,000 hospitalized COVID patients from one NYC hospital, March-May 2020",
                "Outcome: In-hospital mortality (600 deaths, 20% mortality rate)",
                "Predictors: 150 variables extracted from EHR, 25 selected by importance ranking",
                "Validation: 5-fold cross-validation on same dataset",
                "Calibration: 'Good' (no plot shown)",
                "No external validation"
              ]
            },
            {
              heading: "Your Task:",
              text: "ã“ã®ã‚³ãƒ¼ã‚¹ã®åŸå‰‡ã‚’ä½¿ç”¨ã—ã¦ã€ã“ã®ç ”ç©¶ã‚’ä½“ç³»çš„ã«è©•ä¾¡ã—ã¾ã™ã€‚"
            }
          ]
        }
      },
      {
        type: 'decision-tree',
        content: {
          id: 'capstone-evaluation',
          title: "Capstone: Full Evaluation",
          situation: "ã“ã® æ–°å‹ã‚³ãƒ­ãƒŠã‚¦ã‚¤ãƒ«ã‚¹æ­»äº¡ç‡ãƒ¢ãƒ‡ãƒ«ã®è©•ä¾¡ã®å„é ˜åŸŸã‚’æ¤œè¨ã—ã¾ã™ã€‚",
          nodes: {
            start: {
              question: "ã‚¹ãƒ†ãƒƒãƒ— 1 - ã‚µãƒ³ãƒ—ãƒ« ã‚µã‚¤ã‚º: 600 ã®ã‚¤ãƒ™ãƒ³ãƒˆã¨ 25 ã®äºˆæ¸¬å­ãŒã‚ã‚Šã¾ã™ã€‚ EPV ã¨ã¯ä½•ã§ã™ã‹?ãã‚Œã¯é©åˆ‡ã§ã™ã‹?",
              branches: [
                { text: "EPV = 600/25 = 24 â€” adequate", nextNode: "epv_surface" },
                { text: "EPV = 600/150 = 4 â€” they tested 150 variables", nextNode: "epv_correct" }
              ]
            },
            epv_surface: {
              type: 'outcome',
              outcome: 'partial',
              title: "Look deeper!",
              text: "They TESTED 150 variables before selecting 25. The effective degrees of freedom used is closer to 150. EPV = 600/150 = 4, which is critically low. Data-driven selection doesn't reduce overfitting â€” it increases it.",
              lesson: "EPV ã¯ã€ä¿æŒã•ã‚Œã¦ã„ã‚‹å¤‰æ•°ã ã‘ã§ãªãã€ãƒ†ã‚¹ãƒˆã•ã‚ŒãŸã™ã¹ã¦ã®å¤‰æ•°ã‚’ã‚«ã‚¦ãƒ³ãƒˆã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚é¸æŠã¯ã‚ãªãŸã‚’æ•‘ã„ã¾ã›ã‚“ã€‚"
            },
            epv_correct: {
              situation: "Correct! Effective EPV is ~4, critically low. Now assess VALIDATION:",
              question: "åŒã˜ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã«å¯¾ã—ã¦ 5 åˆ†å‰²ç›¸äº’æ¤œè¨¼ã‚’ä½¿ç”¨ã—ã¾ã—ãŸã€‚ã“ã‚Œã¯é©åˆ‡ã§ã™ã‹?",
              branches: [
                { text: "Yes â€” cross-validation is rigorous internal validation", nextNode: "cv_inadequate" },
                { text: "No â€” no external validation means unknown generalizability", nextNode: "cv_correct" }
              ]
            },
            cv_inadequate: {
              type: 'outcome',
              outcome: 'danger',
              title: "Cross-validation is internal only!",
              text: "5 å€ CV ãƒ†ã‚¹ãƒˆã¯ã‚ªãƒ¼ãƒãƒ¼ãƒ•ã‚£ãƒƒãƒ†ã‚£ãƒ³ã‚°ã§ã™ãŒã€ä¸€èˆ¬åŒ–å¯èƒ½æ€§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚ãƒ‡ãƒ¼ã‚¿ã¯ä¾ç„¶ã¨ã—ã¦ãƒ‘ãƒ³ãƒ‡ãƒŸãƒƒã‚¯ã®ãƒ”ãƒ¼ã‚¯æ™‚ã«ãƒ‹ãƒ¥ãƒ¼ãƒ¨ãƒ¼ã‚¯å¸‚ã® 1 ã¤ã®ç—…é™¢ã‹ã‚‰å¾—ã‚‰ã‚ŒãŸã‚‚ã®ã§ã™ã€‚ 2020 å¹´ 4 æœˆã®ãƒ‹ãƒ¥ãƒ¼ãƒ¨ãƒ¼ã‚¯å¸‚ã§ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã¯ã€2020 å¹´ 7 æœˆã®ãƒ†ã‚­ã‚µã‚¹å·ã§ã¯æ©Ÿèƒ½ã—ãªã„å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚å¤–éƒ¨æ¤œè¨¼ãŒå¿…è¦ã§ã™ã€‚",
              lesson: "Internal validation (CV, bootstrap) estimates optimism. External validation tests generalizability. Both are needed."
            },
            cv_correct: {
              situation: "Good! Now assess CALIBRATION:",
              question: "The paper says calibration is 'good' but shows no calibration plot. Your response:",
              branches: [
                { text: "Accept it â€” they're experts who evaluated calibration", nextNode: "accept_wrong" },
                { text: "Reject â€” without a calibration plot, claim is unverifiable", nextNode: "reject_correct" }
              ]
            },
            accept_wrong: {
              type: 'outcome',
              outcome: 'danger',
              title: "Trust but verify!",
              text: "'Good calibration' without a plot is meaningless. What threshold? What method? The COVID-19 model reviews found most papers didn't properly assess calibration. No plot = no evidence.",
              lesson: "TRIPOD ã«ã¯ã‚­ãƒ£ãƒªãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ ãƒ—ãƒ­ãƒƒãƒˆãŒå¿…è¦ã§ã™ã€‚è¨¼æ‹ ã®ãªã„ä¸»å¼µã¯è¨¼æ‹ ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚"
            },
            reject_correct: {
              situation: "Correct â€” demand the calibration plot. Now OVERALL ASSESSMENT:",
              question: "Given everything, what is your PROBAST risk of bias judgment?",
              branches: [
                { text: "Moderate â€” some concerns but promising", nextNode: "moderate_wrong" },
                { text: "High â€” multiple critical flaws", nextNode: "high_correct" }
              ]
            },
            moderate_wrong: {
              type: 'outcome',
              outcome: 'danger',
              title: "Too generous!",
              text: "This study has: (1) High risk participants (single site, peak pandemic); (2) High risk analysis (EPV ~4, data-driven selection, no external validation, no calibration plot). Multiple domains at high risk = overall HIGH RISK.",
              lesson: "PROBAST ã¯æ„å›³çš„ã«å³æ ¼ã§ã™ã€‚ã“ã®ãƒ¢ãƒ‡ãƒ«ã¯è‡¨åºŠç¾å ´ã«æƒ…å ±ã‚’æä¾›ã™ã¹ãã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚"
            },
            high_correct: {
              type: 'outcome',
              outcome: 'success',
              title: "Correct critical appraisal!",
              text: "You identified: critically low EPV, data-driven selection, internal-only validation, unverified calibration claim, single-site limitations. This is a HIGH risk of bias study. The C = 0.91 is likely massively optimistic. External performance is probably C = 0.65-0.75 at best.",
              lesson: "ã“ã®ç ”ç©¶ã¯ã€ä½¿ç”¨ã§ããªã‹ã£ãŸ COVID ãƒ¢ãƒ‡ãƒ«ã® 99% ã‚’è¡¨ã—ã¦ã„ã¾ã™ã€‚é©åˆ‡ãªæ‰¹åˆ¤çš„è©•ä¾¡ãŒã‚ã‚Œã°ã€ãã®ã‚ˆã†ãªãƒ¢ãƒ‡ãƒ«ã®å±•é–‹ã¯é˜»æ­¢ã•ã‚ŒãŸã§ã—ã‚‡ã†ã€‚"
            }
          }
        }
      },
      {
        type: 'content',
        content: {
          title: "ğŸ“ ã‚³ãƒ¼ã‚¹å®Œäº†: å­¦ã‚“ã ã“ã¨",
          sections: [
            {
              heading: "You Can Now:",
              items: [
                "âœ“ Distinguish prognostic factors from therapeutic targets",
                "âœ“ Evaluate EPV and recognize overfitting risk",
                "âœ“ Interpret C-statistics and calibration plots",
                "âœ“ Distinguish internal from external validation",
                "âœ“ Assess model bias using PROBAST",
                "âœ“ Evaluate clinical prediction rules and their pathways",
                "âœ“ Apply TRIPOD reporting standards",
                "âœ“ Interpret decision curves and net benefit",
                "âœ“ Compare ML to logistic regression appropriately",
                "âœ“ Identify implementation barriers",
                "âœ“ Critically appraise prognostic model studies"
              ]
            },
            {
              heading: "The Seven Principles:",
              items: [
                "1ã€‚äºˆæ¸¬ã¯å› æœé–¢ä¿‚ã§ã¯ã‚ã‚Šã¾ã›ã‚“",
                "2. A model is only as good as its validation",
                "3ã€‚è­˜åˆ¥ãŒååˆ†ã§ã¯ã‚ã‚Šã¾ã›ã‚“",
                "4.äºˆæ¸¬å¤‰æ•°ãŒå¤šã„ã»ã©è‰¯ã„ã‚ã‘ã§ã¯ã‚ã‚Šã¾ã›ã‚“",
                "5ã€‚æ¯é›†å›£ã¯äºˆæ¸¬ã‚’å®šç¾©ã—ã¾ã™",
                "6. Clinical utility trumps statistics",
                "7. Transparency enables trust"
              ]
            }
          ]
        }
      },
      {
        type: 'quiz',
        content: {
          question: "A colleague presents a new readmission model with C = 0.82, excellent calibration, and positive net benefit across thresholds 10-30%. No external validation yet. The model should:",
          options: [
            { id: 'a', text: "Be deployed immediately â€” performance is excellent", correct: false },
            { id: 'b', text: "é–‹ç™ºç ”ç©¶ã¨ã—ã¦å…¬é–‹ã•ã‚Œã¾ã™ãŒã€å±•é–‹å‰ã«å¤–éƒ¨æ¤œè¨¼ãŒå¿…è¦ã§ã™", correct: true },
            { id: 'c', text: "Be rejected â€” no external validation means it's invalid", correct: false },
            { id: 'd', text: "Be used only for research purposes", correct: false }
          ],
          explanation: "Development + internal validation = publishable, but NOT deployable. External validation is required before clinical use. This is the appropriate staging: develop â†’ validate internally â†’ publish â†’ validate externally â†’ deploy. Skipping external validation leads to Epic Sepsis failures."
        }
      },
      {
        type: 'principle',
        content: {
          text: "ğŸ“ FINAL MASTERY: You've completed the Prognostic Reviews course. You can now evaluate prediction models rigorously, distinguishing genuine clinical value from statistical theater. Use these skills to protect patients from poorly validated algorithms and to champion models that truly improve care. Remember: every model is wrong, but some are useful. Your job is to tell the difference."
        }
      }
    ]
  }
];

// Render Functions
function renderModuleNav() {
  const nav = document.getElementById('module-nav');
  nav.innerHTML = modules.map((m, i) => `
    <button class="module-item ${i === currentModule ? 'active' : ''} ${gameState.modulesCompleted.includes(i) ? 'completed' : ''}"
            onclick="goToModule(${i})"
            aria-current="${i === currentModule ? 'true' : 'false'}">
      <div class="module-number">${gameState.modulesCompleted.includes(i) ? 'âœ“' : i}</div>
      <div class="module-info">
        <div class="module-title">${m.title}</div>
        <div class="module-subtitle">${m.subtitle}${m.estimatedTime ? ` Â· <span class="time-estimate">${m.estimatedTime}</span>` : ''}</div>
      </div>
    </button>
  `).join('');
}

function renderSlide() {
  const container = document.getElementById('slide-container');
  const module = modules[currentModule];
  const slide = module.slides[currentSlide];

  let html = '';

  switch(slide.type) {
    case 'title':
      html = `
        <div class="slide-title">
          <h1>${slide.content.title}</h1>
          <div class="subtitle">${slide.content.subtitle}</div>
          <p class="description">${slide.content.text}</p>
        </div>
      `;
      break;

    case 'principle-display':
      html = `
        <div class="principle-box">
          <div class="number">${module.principle !== null ? module.principle + 1 : ''}</div>
          <div class="text">"${slide.content.principle}"</div>
        </div>
      `;
      break;

    case 'principle':
      html = `
        <div class="principle-box" style="background: linear-gradient(135deg, rgba(107,70,193,0.15), rgba(30,39,97,0.1)); padding: 2rem;">
          <div class="text" style="font-size: 1.2rem; line-height: 1.6; white-space: pre-line;">${slide.content.text}</div>
        </div>
      `;
      break;

    case 'story-deep':
      html = renderStoryDeep(slide.content);
      break;

    case 'content':
      html = renderContent(slide.content);
      break;

    case 'method':
      html = renderMethod(slide.content);
      break;

    case 'decision-tree':
      html = renderDecisionTree(slide.content);
      break;

    case 'quiz':
      html = renderQuiz(slide.content);
      break;
  }

  container.innerHTML = html;
  updateNavButtons();
  updateProgress();

  // Announce slide change for screen readers
  const announcer = document.getElementById('slide-announce');
  if (announcer) {
    const module = modules[currentModule];
    announcer.textContent = `Slide ${currentSlide + 1} of ${module.slides.length}, Module: ${module.title}`;
  }
}

function renderStoryDeep(content) {
  let html = `<div class="story-deep">`;
  html += `<div class="story-label">${content.label}</div>`;
  html += `<div class="story-source">${content.source}</div>`;

  if (content.timeline) {
    html += `<div class="timeline">`;
    content.timeline.forEach(event => {
      html += `
        <div class="timeline-event ${event.type || ''}">
          <div class="timeline-year">${event.year}</div>
          <div class="timeline-text">${event.text}</div>
        </div>
      `;
    });
    html += `</div>`;
  }

  if (content.realData) {
    html += `<div class="real-data-box">`;
    html += `<h4>ğŸ“Š Real Data</h4>`;
    html += `<div class="data-grid">`;
    Object.entries(content.realData).forEach(([key, value]) => {
      html += `
        <div class="data-item">
          <div class="data-label">${key}</div>
          <div class="data-value">${value}</div>
        </div>
      `;
    });
    html += `</div></div>`;
  }

  if (content.hook) {
    html += `<div class="hook-text">${content.hook}</div>`;
  }

  html += `</div>`;
  return html;
}

function renderContent(content) {
  let html = `<div class="content-box">`;
  html += `<h2>${content.title}</h2>`;

  content.sections.forEach(section => {
    html += `<div class="content-section">`;
    html += `<h3>${section.heading}</h3>`;
    if (section.items) {
      html += `<ul>`;
      section.items.forEach(item => {
        html += `<li>${item}</li>`;
      });
      html += `</ul>`;
    }
    if (section.text) {
      html += `<p>${section.text}</p>`;
    }
    html += `</div>`;
  });

  html += `</div>`;
  return html;
}

function renderMethod(content) {
  let html = `<div class="method-box">`;
  html += `<div class="method-label">${content.label}</div>`;
  html += `<h2>${content.title}</h2>`;

  content.sections.forEach(section => {
    html += `<div class="method-section">`;
    html += `<h3>${section.heading}</h3>`;
    html += `<p>${section.text}</p>`;
    html += `</div>`;
  });

  html += `</div>`;
  return html;
}

function renderDecisionTree(content) {
  const treeId = content.id;
  if (!gameState.decisionTrees[treeId]) {
    gameState.decisionTrees[treeId] = { currentNode: 'start', history: [] };
  }

  const currentNodeId = gameState.decisionTrees[treeId].currentNode;
  const currentNode = content.nodes[currentNodeId];

  let html = `<div class="decision-tree">`;
  html += `<h2>ğŸŒ³ ${content.title}</h2>`;

  if (currentNodeId === 'start') {
    html += `<div class="decision-situation">${content.situation}</div>`;
  }

  if (currentNode.type === 'outcome') {
    html += `
      <div class="decision-outcome ${currentNode.outcome}">
        <div class="outcome-title">${currentNode.title}</div>
        <div class="outcome-text">${currentNode.text}</div>
        <div class="outcome-lesson">${currentNode.lesson}</div>
      </div>
    `;
    html += `<div class="tree-controls">
      <button class="tree-btn" onclick="resetDecisionTree('${treeId}')">Try Again</button>
    </div>`;
  } else {
    if (currentNode.situation) {
      html += `<div class="decision-situation">${currentNode.situation}</div>`;
    }
    html += `<div class="decision-question">${currentNode.question}</div>`;
    html += `<div class="decision-branches">`;
    currentNode.branches.forEach((branch, i) => {
      html += `
        <button class="decision-branch" onclick="makeDecision('${treeId}', '${branch.nextNode}', '${branch.text.replace(/\\/g, '\\\\').replace(/'/g, "\\'")}')">
          ${branch.text}
        </button>
      `;
    });
    html += `</div>`;
  }

  html += `</div>`;
  return html;
}

function makeDecision(treeId, nextNode, choiceText) {
  if (!gameState.decisionTrees[treeId]) {
    gameState.decisionTrees[treeId] = { currentNode: 'start', history: [] };
  }
  gameState.decisionTrees[treeId].history.push(choiceText);
  gameState.decisionTrees[treeId].currentNode = nextNode;
  addPoints(10);
  saveProgress();
  renderSlide();
}

function resetDecisionTree(treeId) {
  gameState.decisionTrees[treeId] = { currentNode: 'start', history: [] };
  saveProgress();
  renderSlide();
}

function renderQuiz(content) {
  const quizId = `quiz_${currentModule}_${currentSlide}`;

  return `
    <div class="quiz-container">
      <div class="quiz-question">${content.question}</div>
      <div class="quiz-options" role="radiogroup" aria-label="Quiz options">
        ${content.options.map((opt, i) => `
          <button class="quiz-option" role="radio" aria-checked="false"
                  data-correct="${opt.correct}"
                  onclick="selectQuizOption(this, '${quizId}', ${opt.correct})">
            ${opt.text}
          </button>
        `).join('')}
      </div>
      <div class="quiz-feedback" id="feedback-${quizId}" role="alert" aria-live="polite">
        <p>${content.explanation}</p>
      </div>
    </div>
  `;
}

const _answeredQuizzes = new Set();

function selectQuizOption(element, quizId, isCorrect) {
  // Prevent re-answering after first answer
  if (_answeredQuizzes.has(quizId)) return;

  const container = element.closest('.quiz-container');
  const options = container.querySelectorAll('.quiz-option');
  const feedback = document.getElementById(`feedback-${quizId}`);

  options.forEach(opt => {
    opt.classList.remove('selected', 'correct', 'incorrect');
  });

  element.classList.add('selected');
  options.forEach(opt => opt.setAttribute('aria-checked', 'false'));
  element.setAttribute('aria-checked', 'true');

  if (isCorrect) {
    element.classList.add('correct');
    feedback.classList.add('show', 'correct');
    feedback.classList.remove('incorrect');
    addPoints(30);
  } else {
    element.classList.add('incorrect');
    feedback.classList.add('show', 'incorrect');
    feedback.classList.remove('correct');
    options.forEach(opt => {
      if (opt.dataset.correct === 'true') {
        opt.classList.add('correct');
      }
    });
  }

  // Lock quiz after answering
  _answeredQuizzes.add(quizId);
  options.forEach(opt => {
    opt.style.pointerEvents = 'none';
    opt.setAttribute('aria-disabled', 'true');
  });

  saveProgress();
}

// Navigation
function nextSlide() {
  const module = modules[currentModule];
  if (currentSlide < module.slides.length - 1) {
    currentSlide++;
  } else if (currentModule < modules.length - 1) {
    if (!gameState.modulesCompleted.includes(currentModule)) {
      gameState.modulesCompleted.push(currentModule);
      addPoints(100);
      checkBadges();
    }
    currentModule++;
    currentSlide = 0;
  }
  saveProgress();
  renderSlide();
  renderModuleNav();
  window.scrollTo(0, 0);
}

function prevSlide() {
  if (currentSlide > 0) {
    currentSlide--;
  } else if (currentModule > 0) {
    currentModule--;
    currentSlide = modules[currentModule].slides.length - 1;
  }
  saveProgress();
  renderSlide();
  renderModuleNav();
  window.scrollTo(0, 0);
}

function goToModule(moduleIndex) {
  currentModule = moduleIndex;
  currentSlide = 0;
  saveProgress();
  renderSlide();
  renderModuleNav();
  closeSidebar();
  window.scrollTo(0, 0);
}

function updateNavButtons() {
  const prevBtn = document.getElementById('prev-btn');
  const nextBtn = document.getElementById('next-btn');

  prevBtn.disabled = currentModule === 0 && currentSlide === 0;

  const isLastSlide = currentModule === modules.length - 1 &&
                      currentSlide === modules[currentModule].slides.length - 1;
  nextBtn.textContent = isLastSlide ? 'Complete Course' : 'Next â†’';
}

function updateProgress() {
  let totalSlides = 0;
  let completedSlides = 0;

  modules.forEach((m, i) => {
    totalSlides += m.slides.length;
    if (i < currentModule) {
      completedSlides += m.slides.length;
    } else if (i === currentModule) {
      completedSlides += currentSlide;
    }
  });

  const percent = Math.round((completedSlides / totalSlides) * 100);
  document.getElementById('progress-fill').style.width = `${percent}%`;
  document.getElementById('progress-text').textContent = `${percent}% Complete`;
}

// Points and Badges
function addPoints(points) {
  gameState.points += points;
  document.getElementById('points-display').textContent = gameState.points;
}

function checkBadges() {
  const newBadges = [];

  // Story Collector: Read most case studies
  if (gameState.modulesCompleted.length >= 10 && !gameState.earnedBadges.includes('story-collector')) {
    newBadges.push('story-collector');
  }

  // Tree Navigator: Complete 15+ decision trees
  const treesCompleted = Object.keys(gameState.decisionTrees).filter(k =>
    gameState.decisionTrees[k].history && gameState.decisionTrees[k].history.length > 0
  ).length;
  if (treesCompleted >= 15 && !gameState.earnedBadges.includes('tree-navigator')) {
    newBadges.push('tree-navigator');
  }

  // Prognosis Master: Complete entire course
  if (gameState.modulesCompleted.length === 12 && !gameState.earnedBadges.includes('prognosis-master')) {
    newBadges.push('prognosis-master');
  }

  // Model Builder: Complete Module 2 (The Models)
  if (gameState.modulesCompleted.includes(2) && !gameState.earnedBadges.includes('model-builder')) {
    newBadges.push('model-builder');
  }

  // Validation Expert: Complete Module 4 (The Validation)
  if (gameState.modulesCompleted.includes(4) && !gameState.earnedBadges.includes('validation-expert')) {
    newBadges.push('validation-expert');
  }

  // Calibration Master: Complete Module 3 (The Performance)
  if (gameState.modulesCompleted.includes(3) && !gameState.earnedBadges.includes('calibration-master')) {
    newBadges.push('calibration-master');
  }

  // TRIPOD Scholar: Complete Module 6 (The Reporting)
  if (gameState.modulesCompleted.includes(6) && !gameState.earnedBadges.includes('tripod-scholar')) {
    newBadges.push('tripod-scholar');
  }

  // Decision Analyst: Complete Module 7 (The Utility)
  if (gameState.modulesCompleted.includes(7) && !gameState.earnedBadges.includes('decision-analyst')) {
    newBadges.push('decision-analyst');
  }

  // Penalization Pro: Complete penalization decision tree
  if (gameState.decisionTrees['penalization-choice'] &&
      gameState.decisionTrees['penalization-choice'].history &&
      gameState.decisionTrees['penalization-choice'].history.length > 0 &&
      !gameState.earnedBadges.includes('penalization-pro')) {
    newBadges.push('penalization-pro');
  }

  // Patient Communicator: Complete calibration-plot-reading tree (communication content)
  if (gameState.decisionTrees['calibration-plot-reading'] &&
      gameState.decisionTrees['calibration-plot-reading'].history &&
      gameState.decisionTrees['calibration-plot-reading'].history.length > 0 &&
      !gameState.earnedBadges.includes('communicator')) {
    newBadges.push('communicator');
  }

  // AI Skeptic: Complete Module 9 (ML vs Regression)
  if (gameState.modulesCompleted.includes(9) && !gameState.earnedBadges.includes('skeptic')) {
    newBadges.push('skeptic');
  }

  // Implementation Expert: Complete Module 10 (The Implementation)
  if (gameState.modulesCompleted.includes(10) && !gameState.earnedBadges.includes('implementer')) {
    newBadges.push('implementer');
  }

  newBadges.forEach(badge => {
    gameState.earnedBadges.push(badge);
    showBadgeNotification(badge);
  });

  if (newBadges.length > 0) saveProgress();
}

function showBadgeNotification(badgeId) {
  const badge = BADGES[badgeId];
  if (!badge) return;

  const notification = document.createElement('div');
  notification.className = 'badge-notification';
  notification.innerHTML = `
    <div class="badge-icon" style="background: ${badge.color}">${badge.icon}</div>
    <div class="badge-info">
      <div class="badge-earned">Badge Earned!</div>
      <div class="badge-name">${badge.name}</div>
    </div>
  `;
  document.body.appendChild(notification);

  setTimeout(() => notification.classList.add('show'), 100);
  setTimeout(() => {
    notification.classList.remove('show');
    setTimeout(() => notification.remove(), 500);
  }, 3000);
}

// Persistence
function saveProgress() {
  try {
    localStorage.setItem(STORAGE_KEY, JSON.stringify({
      currentModule,
      currentSlide,
      gameState
    }));
  } catch (e) {
    console.log('Could not save progress:', e);
  }
}

function loadProgress() {
  try {
    const saved = localStorage.getItem(STORAGE_KEY);
    if (saved) {
      const data = JSON.parse(saved);
      if (data.gameState) {
        gameState = { ...gameState, ...data.gameState };
      }
      if (typeof data.currentModule === 'number' && data.currentModule >= 0 && data.currentModule < modules.length) {
        currentModule = data.currentModule;
      }
      if (typeof data.currentSlide === 'number' && data.currentSlide >= 0) {
        currentSlide = Math.min(data.currentSlide, modules[currentModule].slides.length - 1);
      }
    }
  } catch (e) {
    console.log('Could not load progress:', e);
  }
}

// Mobile Menu
function toggleSidebar() {
  const sidebar = document.querySelector('.sidebar');
  const overlay = document.querySelector('.sidebar-overlay');
  sidebar.classList.toggle('open');
  overlay.classList.toggle('show');
}

function closeSidebar() {
  const sidebar = document.querySelector('.sidebar');
  const overlay = document.querySelector('.sidebar-overlay');
  sidebar.classList.remove('open');
  overlay.classList.remove('show');
}

// Modal utilities: close by ID, Escape key handler
function closeModalOverlay(id) {
  const el = document.getElementById(id);
  if (el) el.remove();
}

function _attachModalEscapeHandler(overlayId) {
  function handler(e) {
    if (e.key === 'Escape') {
      closeModalOverlay(overlayId);
      document.removeEventListener('keydown', handler);
    }
  }
  document.addEventListener('keydown', handler);
}

// Badges Modal
function openBadges() {
  const earnedCount = gameState.earnedBadges.length;
  const totalCount = Object.keys(BADGES).length;

  const html = `
    <div id="badges-modal-overlay" role="dialog" aria-modal="true" aria-label="Badges" style="position: fixed; inset: 0; background: rgba(0,0,0,0.5); z-index: 2000; display: flex; align-items: center; justify-content: center; padding: 1rem;">
      <div style="background: white; border-radius: 12px; max-width: 700px; max-height: 80vh; overflow-y: auto; padding: 2rem;">
        <div style="display: flex; justify-content: space-between; align-items: center; margin-bottom: 1rem;">
          <h2 style="font-family: 'Cormorant Garamond', serif; color: var(--navy);">ğŸ† Badges (${earnedCount}/${totalCount})</h2>
          <button id="badges-modal-close" onclick="closeModalOverlay('badges-modal-overlay')" style="background: none; border: none; font-size: 1.5rem; cursor: pointer;" aria-label="Close badges">&times;</button>
        </div>
        <div class="badge-grid">
          ${Object.entries(BADGES).map(([id, badge]) => {
            const earned = gameState.earnedBadges.includes(id);
            return `
              <div class="badge-card ${earned ? 'earned' : 'locked'}">
                <div class="badge-icon" style="background: ${badge.color}">${badge.icon}</div>
                <div style="font-weight: 600; color: var(--navy); margin-top: 0.5rem;">${badge.name}</div>
                <div style="font-size: 0.75rem; color: var(--light-text);">${earned ? 'âœ“ Earned!' : badge.requirement}</div>
              </div>
            `;
          }).join('')}
        </div>
      </div>
    </div>
  `;

  document.body.insertAdjacentHTML('beforeend', html);
  const closeBtn = document.getElementById('badges-modal-close');
  if (closeBtn) closeBtn.focus();
  _attachModalEscapeHandler('badges-modal-overlay');
}

// Glossary
function openGlossary() {
  const terms = [
    { term: "Prognostic Factor", def: "A variable associated with future clinical outcomes in patients with a condition." },
    { term: "C-Statistic (AUC)", def: "Measure of discrimination; probability that a random case is ranked higher than a random non-case." },
    { term: "Calibration", def: "Agreement between predicted probabilities and observed event rates." },
    { term: "Calibration Plot", def: "Graph showing predicted vs observed probabilities across risk groups." },
    { term: "Calibration-in-the-Large", def: "Overall agreement between total predicted and observed events; expressed as P/O ratio." },
    { term: "Overfitting", def: "When a model learns noise in training data rather than true signal; causes poor generalization." },
    { term: "EPV", def: "Events Per Variable; ratio of outcome events to predictors. Should be â‰¥10, preferably â‰¥20." },
    { term: "Internal Validation", def: "Testing model on same data source (bootstrap, cross-validation)." },
    { term: "External Validation", def: "Testing model on completely independent data (different time, place, or population)." },
    { term: "Temporal Validation", def: "External validation using data from a different time period at the same site." },
    { term: "Geographic Validation", def: "External validation using data from a different location or institution." },
    { term: "TRIPOD", def: "Transparent Reporting of prediction models; 22-item reporting guideline." },
    { term: "PROBAST", def: "Prediction model Risk Of Bias Assessment Tool; evaluates bias in prediction studies." },
    { term: "Decision Curve", def: "Graph showing net benefit across treatment thresholds; assesses clinical utility." },
    { term: "Net Benefit", def: "True positives minus weighted false positives; measures clinical value of predictions." },
    { term: "Shrinkage", def: "Reducing model coefficients to correct for optimism from overfitting." },
    { term: "Calibration Slope", def: "Regression of outcomes on predictions; slope=1 is ideal, <1 indicates overfitting." },
    { term: "Clinical Prediction Rule", def: "Scoring system using clinical data to estimate probability or guide decisions." },
    { term: "Treatment Threshold", def: "Probability above which treatment is indicated; reflects benefit-harm tradeoff." },
    { term: "LASSO", def: "Least Absolute Shrinkage and Selection Operator; penalization method that shrinks coefficients and sets some to zero." },
    { term: "Ridge Regression", def: "Penalization method that shrinks all coefficients toward zero but never exactly to zero." },
    { term: "Elastic Net", def: "Penalization combining LASSO (L1) and Ridge (L2); balances selection and grouped shrinkage." },
    { term: "Recalibration", def: "Updating model intercept and/or slope to improve calibration in a new population." },
    { term: "Competing Risks", def: "When patients can experience multiple mutually exclusive events (e.g., death prevents later fracture)." },
    { term: "Subdistribution Hazard", def: "Hazard function that accounts for competing risks (Fine-Gray method)." },
    { term: "Cumulative Incidence", def: "Probability of event accounting for competing risks; preferred over 1-KM when competing events occur." },
    { term: "Prediction Interval", def: "Range of predicted probabilities expected in future similar patients; wider than confidence interval." },
    { term: "Brier Score", def: "Overall measure combining discrimination and calibration; average squared difference between predicted and observed." }
  ];

  const html = `
    <div id="glossary-modal-overlay" role="dialog" aria-modal="true" aria-label="Glossary" style="position: fixed; inset: 0; background: rgba(0,0,0,0.5); z-index: 2000; display: flex; align-items: center; justify-content: center; padding: 1rem;">
      <div style="background: white; border-radius: 12px; max-width: 600px; max-height: 80vh; overflow-y: auto; padding: 2rem;">
        <div style="display: flex; justify-content: space-between; align-items: center; margin-bottom: 1rem;">
          <h2 style="font-family: 'Cormorant Garamond', serif; color: var(--navy);">Glossary</h2>
          <button id="glossary-modal-close" onclick="closeModalOverlay('glossary-modal-overlay')" style="background: none; border: none; font-size: 1.5rem; cursor: pointer;" aria-label="Close glossary">&times;</button>
        </div>
        ${terms.map(t => `
          <div style="margin-bottom: 1rem; padding-bottom: 1rem; border-bottom: 1px solid rgba(0,0,0,0.1);">
            <strong style="color: var(--purple);">${t.term}</strong>
            <p style="margin-top: 0.25rem; color: var(--navy);">${t.def}</p>
          </div>
        `).join('')}
      </div>
    </div>
  `;

  document.body.insertAdjacentHTML('beforeend', html);
  const closeBtn = document.getElementById('glossary-modal-close');
  if (closeBtn) closeBtn.focus();
  _attachModalEscapeHandler('glossary-modal-overlay');
}

// Initialize
document.addEventListener('DOMContentLoaded', () => {
  loadProgress();
  renderModuleNav();
  renderSlide();
  document.getElementById('points-display').textContent = gameState.points;

  document.querySelector('.hamburger').addEventListener('click', toggleSidebar);
  document.querySelector('.sidebar-overlay').addEventListener('click', closeSidebar);

  document.addEventListener('keydown', (e) => {
    if (e.key === 'ArrowRight' && !e.target.matches('input, textarea, button, select, [role="button"]')) {
      nextSlide();
    } else if (e.key === 'ArrowLeft' && !e.target.matches('input, textarea, button, select, [role="button"]')) {
      prevSlide();
    }
  });
});
</script>
</body>
</html>
